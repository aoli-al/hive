// $ANTLR 3.5.2 org/apache/hadoop/hive/ql/parse/HiveParser.g 2023-02-08 15:38:03

package org.apache.hadoop.hive.ql.parse;

import java.util.Arrays;
import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.List;
import org.apache.commons.lang3.tuple.ImmutablePair;
import org.apache.commons.lang3.tuple.Pair;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hive.conf.HiveConf;


import org.antlr.runtime.*;
import java.util.Stack;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;

import org.antlr.runtime.tree.*;


/**
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/
@SuppressWarnings("all")
public class HiveParser extends Parser {
	public static String[] tokenNames;
    public static void tokenNamesInit() {
        tokenNames = new String[]{
                "<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR",
                "ByteLengthLiteral", "COLON", "COMMA", "CONCATENATE", "CharSetLiteral",
                "CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "Digit", "EQUAL", "EQUAL_NS",
                "Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier",
                "IntegralLiteral", "KW_ABORT", "KW_ACTIVATE", "KW_ACTIVE", "KW_ADD", "KW_ADMIN",
                "KW_AFTER", "KW_ALL", "KW_ALLOC_FRACTION", "KW_ALTER", "KW_ANALYZE", "KW_AND",
                "KW_ANY", "KW_APPLICATION", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC",
                "KW_AST", "KW_AT", "KW_AUTHORIZATION", "KW_AUTOCOMMIT", "KW_BEFORE", "KW_BETWEEN",
                "KW_BIGINT", "KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS",
                "KW_BY", "KW_CACHE", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CBO", "KW_CHANGE",
                "KW_CHAR", "KW_CHECK", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS",
                "KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMMIT",
                "KW_COMPACT", "KW_COMPACTIONS", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONF",
                "KW_CONSTRAINT", "KW_CONTINUE", "KW_COST", "KW_CREATE", "KW_CRON", "KW_CROSS",
                "KW_CUBE", "KW_CURRENT", "KW_CURRENT_DATE", "KW_CURRENT_TIMESTAMP", "KW_CURSOR",
                "KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATACONNECTOR", "KW_DATACONNECTORS",
                "KW_DATE", "KW_DATETIME", "KW_DAY", "KW_DBPROPERTIES", "KW_DCPROPERTIES",
                "KW_DDL", "KW_DEBUG", "KW_DECIMAL", "KW_DEFAULT", "KW_DEFERRED", "KW_DEFINED",
                "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", "KW_DESCRIBE",
                "KW_DETAIL", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", "KW_DISTINCT",
                "KW_DISTRIBUTE", "KW_DISTRIBUTED", "KW_DO", "KW_DOUBLE", "KW_DOW", "KW_DROP",
                "KW_DUMP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", "KW_END", "KW_ENFORCED",
                "KW_ESCAPED", "KW_EVERY", "KW_EXCEPT", "KW_EXCHANGE", "KW_EXCLUSIVE",
                "KW_EXECUTE", "KW_EXECUTED", "KW_EXISTS", "KW_EXPIRE_SNAPSHOTS", "KW_EXPLAIN",
                "KW_EXPORT", "KW_EXPRESSION", "KW_EXTENDED", "KW_EXTERNAL", "KW_EXTRACT",
                "KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILE", "KW_FILEFORMAT", "KW_FIRST",
                "KW_FLOAT", "KW_FLOOR", "KW_FOLLOWING", "KW_FOR", "KW_FORCE", "KW_FOREIGN",
                "KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", "KW_FUNCTION", "KW_FUNCTIONS",
                "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_HAVING", "KW_HOUR", "KW_ID",
                "KW_IDXPROPERTIES", "KW_IF", "KW_IGNORE", "KW_IMPORT", "KW_IN", "KW_INDEX",
                "KW_INDEXES", "KW_INNER", "KW_INPATH", "KW_INPUTDRIVER", "KW_INPUTFORMAT",
                "KW_INSERT", "KW_INT", "KW_INTERSECT", "KW_INTERVAL", "KW_INTO", "KW_IS",
                "KW_ISOLATION", "KW_ITEMS", "KW_JAR", "KW_JOIN", "KW_JOINCOST", "KW_KEY",
                "KW_KEYS", "KW_KEY_TYPE", "KW_KILL", "KW_LAST", "KW_LATERAL", "KW_LEADING",
                "KW_LEFT", "KW_LESS", "KW_LEVEL", "KW_LIKE", "KW_LIMIT", "KW_LINES", "KW_LOAD",
                "KW_LOCAL", "KW_LOCATION", "KW_LOCK", "KW_LOCKS", "KW_LOGICAL", "KW_LONG",
                "KW_MACRO", "KW_MANAGED", "KW_MANAGEDLOCATION", "KW_MANAGEMENT", "KW_MAP",
                "KW_MAPJOIN", "KW_MAPPING", "KW_MATCHED", "KW_MATERIALIZED", "KW_MERGE",
                "KW_METADATA", "KW_MINUS", "KW_MINUTE", "KW_MONTH", "KW_MORE", "KW_MOVE",
                "KW_MSCK", "KW_NONE", "KW_NORELY", "KW_NOSCAN", "KW_NOT", "KW_NOVALIDATE",
                "KW_NULL", "KW_NULLS", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONLY", "KW_OPERATOR",
                "KW_OPTION", "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER",
                "KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_OWNER", "KW_PARTITION",
                "KW_PARTITIONED", "KW_PARTITIONS", "KW_PATH", "KW_PERCENT", "KW_PKFK_JOIN",
                "KW_PLAN", "KW_PLANS", "KW_PLUS", "KW_POOL", "KW_PRECEDING", "KW_PRECISION",
                "KW_PREPARE", "KW_PRESERVE", "KW_PRIMARY", "KW_PRINCIPALS", "KW_PROCEDURE",
                "KW_PURGE", "KW_QUALIFY", "KW_QUARTER", "KW_QUERY", "KW_QUERY_PARALLELISM",
                "KW_RANGE", "KW_READ", "KW_READS", "KW_REAL", "KW_REBUILD", "KW_RECORDREADER",
                "KW_RECORDWRITER", "KW_REDUCE", "KW_REFERENCES", "KW_REGEXP", "KW_RELOAD",
                "KW_RELY", "KW_REMOTE", "KW_RENAME", "KW_REOPTIMIZATION", "KW_REPAIR",
                "KW_REPL", "KW_REPLACE", "KW_REPLICATION", "KW_RESOURCE", "KW_RESPECT",
                "KW_RESTRICT", "KW_REVOKE", "KW_REWRITE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE",
                "KW_ROLES", "KW_ROLLBACK", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEDULED",
                "KW_SCHEDULING_POLICY", "KW_SCHEMA", "KW_SCHEMAS", "KW_SECOND", "KW_SELECT",
                "KW_SEMI", "KW_SERDE", "KW_SERDEPROPERTIES", "KW_SERVER", "KW_SET", "KW_SETS",
                "KW_SHARED", "KW_SHOW", "KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT",
                "KW_SNAPSHOT", "KW_SOME", "KW_SORT", "KW_SORTED", "KW_SPEC", "KW_SSL",
                "KW_START", "KW_STATISTICS", "KW_STATUS", "KW_STORED", "KW_STREAMTABLE",
                "KW_STRING", "KW_STRUCT", "KW_SUMMARY", "KW_SYNC", "KW_SYSTEM_TIME", "KW_SYSTEM_VERSION",
                "KW_TABLE", "KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", "KW_TEMPORARY",
                "KW_TERMINATED", "KW_THEN", "KW_TIME", "KW_TIMESTAMP", "KW_TIMESTAMPLOCALTZ",
                "KW_TINYINT", "KW_TO", "KW_TOUCH", "KW_TRAILING", "KW_TRANSACTION", "KW_TRANSACTIONAL",
                "KW_TRANSACTIONS", "KW_TRANSFORM", "KW_TRIGGER", "KW_TRIM", "KW_TRUE",
                "KW_TRUNCATE", "KW_TYPE", "KW_UNARCHIVE", "KW_UNBOUNDED", "KW_UNDO", "KW_UNION",
                "KW_UNIONTYPE", "KW_UNIQUE", "KW_UNIQUEJOIN", "KW_UNKNOWN", "KW_UNLOCK",
                "KW_UNMANAGED", "KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_URI", "KW_URL",
                "KW_USE", "KW_USER", "KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALIDATE",
                "KW_VALUES", "KW_VALUE_TYPE", "KW_VARCHAR", "KW_VECTORIZATION", "KW_VIEW",
                "KW_VIEWS", "KW_WAIT", "KW_WEEK", "KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW",
                "KW_WITH", "KW_WITHIN", "KW_WORK", "KW_WORKLOAD", "KW_WRITE", "KW_YEAR",
                "KW_ZONE", "LCURLY", "LESSTHAN", "LESSTHANOREQUALTO", "LINE_COMMENT",
                "LPAREN", "LSQUARE", "Letter", "MINUS", "MOD", "NOTEQUAL", "Number", "NumberLiteral",
                "PLUS", "QUERY_HINT", "QUESTION", "QuotedIdentifier", "RCURLY", "RPAREN",
                "RSQUARE", "RegexComponent", "SEMICOLON", "STAR", "StringLiteral", "TILDE",
                "Tokens", "WS", "KW_ANTI", "KW_BATCH", "KW_DAYOFWEEK", "KW_HOLD_DDLTIME",
                "KW_NO_DROP", "KW_OFFLINE", "KW_PROTECTION", "KW_READONLY", "KW_TIMESTAMPTZ",
                "TOK_ABORT_TRANSACTIONS", "TOK_ACTIVATE", "TOK_ADD_TRIGGER", "TOK_ADMIN_OPTION_FOR",
                "TOK_ALIAS", "TOK_ALIASLIST", "TOK_ALLCOLREF", "TOK_ALLOC_FRACTION", "TOK_ALTERDATABASE_LOCATION",
                "TOK_ALTERDATABASE_MANAGEDLOCATION", "TOK_ALTERDATABASE_OWNER", "TOK_ALTERDATABASE_PROPERTIES",
                "TOK_ALTERDATACONNECTOR_OWNER", "TOK_ALTERDATACONNECTOR_PROPERTIES", "TOK_ALTERDATACONNECTOR_URL",
                "TOK_ALTERPARTITION_BUCKETS", "TOK_ALTERPARTITION_FILEFORMAT", "TOK_ALTERPARTITION_LOCATION",
                "TOK_ALTERPARTITION_MERGEFILES", "TOK_ALTERPARTITION_SERIALIZER",
                "TOK_ALTERPARTITION_SETSERDEPROPERTIES",
                "TOK_ALTERPARTITION_UNSETSERDEPROPERTIES", "TOK_ALTERPARTITION_UPDATECOLSTATS",
                "TOK_ALTERPARTITION_UPDATESTATS", "TOK_ALTERTABLE", "TOK_ALTERTABLE_ADDCOLS",
                "TOK_ALTERTABLE_ADDCONSTRAINT", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ARCHIVE",
                "TOK_ALTERTABLE_BUCKETS", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT",
                "TOK_ALTERTABLE_COMPACT", "TOK_ALTERTABLE_DROPCONSTRAINT", "TOK_ALTERTABLE_DROPPARTS",
                "TOK_ALTERTABLE_DROPPROPERTIES", "TOK_ALTERTABLE_EXCHANGEPARTITION", "TOK_ALTERTABLE_EXECUTE",
                "TOK_ALTERTABLE_FILEFORMAT", "TOK_ALTERTABLE_LOCATION", "TOK_ALTERTABLE_MERGEFILES",
                "TOK_ALTERTABLE_OWNER", "TOK_ALTERTABLE_PARTCOLTYPE", "TOK_ALTERTABLE_PROPERTIES",
                "TOK_ALTERTABLE_RENAME", "TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART",
                "TOK_ALTERTABLE_REPLACECOLS", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SETPARTSPEC",
                "TOK_ALTERTABLE_SETSERDEPROPERTIES", "TOK_ALTERTABLE_SKEWED", "TOK_ALTERTABLE_SKEWED_LOCATION",
                "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", "TOK_ALTERTABLE_UNSETSERDEPROPERTIES",
                "TOK_ALTERTABLE_UPDATECOLSTATS", "TOK_ALTERTABLE_UPDATECOLUMNS", "TOK_ALTERTABLE_UPDATESTATS",
                "TOK_ALTERVIEW", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_AS", "TOK_ALTERVIEW_DROPPARTS",
                "TOK_ALTERVIEW_DROPPROPERTIES", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME",
                "TOK_ALTER_MAPPING", "TOK_ALTER_MATERIALIZED_VIEW", "TOK_ALTER_MATERIALIZED_VIEW_REBUILD",
                "TOK_ALTER_MATERIALIZED_VIEW_REWRITE", "TOK_ALTER_POOL", "TOK_ALTER_POOL_ADD_TRIGGER",
                "TOK_ALTER_POOL_DROP_TRIGGER", "TOK_ALTER_RP_DISABLE", "TOK_ALTER_RP_ENABLE",
                "TOK_ALTER_RP_RENAME", "TOK_ALTER_RP_REPLACE", "TOK_ALTER_RP_SET", "TOK_ALTER_RP_UNSET",
                "TOK_ALTER_RP_VALIDATE", "TOK_ALTER_SCHEDULED_QUERY", "TOK_ALTER_TRIGGER",
                "TOK_ANALYZE", "TOK_ARCHIVE", "TOK_AS_OF_TIME", "TOK_AS_OF_VERSION", "TOK_BIGINT",
                "TOK_BINARY", "TOK_BLOCKING", "TOK_BOOLEAN", "TOK_BUCKET", "TOK_CACHE_METADATA",
                "TOK_CASCADE", "TOK_CHAR", "TOK_CHARSETLITERAL", "TOK_CHECK_CONSTRAINT",
                "TOK_CLUSTERBY", "TOK_COLTYPELIST", "TOK_COL_NAME", "TOK_COMMIT", "TOK_COMPACTION_STATUS",
                "TOK_COMPACTION_TYPE", "TOK_COMPACT_ID", "TOK_COMPACT_POOL", "TOK_CONSTRAINT_NAME",
                "TOK_CREATEDATABASE", "TOK_CREATEDATACONNECTOR", "TOK_CREATEFUNCTION",
                "TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", "TOK_CREATEVIEW",
                "TOK_CREATE_MAPPING", "TOK_CREATE_MATERIALIZED_VIEW", "TOK_CREATE_POOL",
                "TOK_CREATE_RP", "TOK_CREATE_SCHEDULED_QUERY", "TOK_CREATE_TRIGGER", "TOK_CRON",
                "TOK_CROSSJOIN", "TOK_CTE", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT",
                "TOK_DATABASELOCATION", "TOK_DATABASEPROPERTIES", "TOK_DATABASE_MANAGEDLOCATION",
                "TOK_DATACONNECTOR", "TOK_DATACONNECTORCOMMENT", "TOK_DATACONNECTOROWNER",
                "TOK_DATACONNECTORPROPERTIES", "TOK_DATACONNECTORTYPE", "TOK_DATACONNECTORURL",
                "TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", "TOK_DAY", "TOK_DBNAME",
                "TOK_DBPROPLIST", "TOK_DB_TYPE", "TOK_DDL", "TOK_DECIMAL", "TOK_DEFAULT_POOL",
                "TOK_DEFAULT_VALUE", "TOK_DELETE", "TOK_DELETE_FROM", "TOK_DESCDATABASE",
                "TOK_DESCDATACONNECTOR", "TOK_DESCFUNCTION", "TOK_DESCTABLE", "TOK_DESTINATION",
                "TOK_DETAIL", "TOK_DIR", "TOK_DISABLE", "TOK_DISTRIBUTEBY", "TOK_DOUBLE",
                "TOK_DROPDATABASE", "TOK_DROPDATACONNECTOR", "TOK_DROPFUNCTION", "TOK_DROPMACRO",
                "TOK_DROPROLE", "TOK_DROPTABLE", "TOK_DROPVIEW", "TOK_DROP_MAPPING", "TOK_DROP_MATERIALIZED_VIEW",
                "TOK_DROP_POOL", "TOK_DROP_RP", "TOK_DROP_SCHEDULED_QUERY", "TOK_DROP_TRIGGER",
                "TOK_ENABLE", "TOK_EVERY", "TOK_EXCEPTALL", "TOK_EXCEPTDISTINCT", "TOK_EXECUTE",
                "TOK_EXECUTED_AS", "TOK_EXECUTE_PARAM_LIST", "TOK_EXPLAIN", "TOK_EXPLAIN_SQ_REWRITE",
                "TOK_EXPLIST", "TOK_EXPORT", "TOK_EXPRESSION", "TOK_FALSE", "TOK_FILE",
                "TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", "TOK_FORCE", "TOK_FOREIGN_KEY",
                "TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", "TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR",
                "TOK_GRANT", "TOK_GRANT_OPTION_FOR", "TOK_GRANT_ROLE", "TOK_GRANT_WITH_ADMIN_OPTION",
                "TOK_GRANT_WITH_OPTION", "TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS",
                "TOK_GROUPING_SETS_EXPRESSION", "TOK_HAVING", "TOK_HOUR", "TOK_IDENTITY",
                "TOK_IFEXISTS", "TOK_IFNOTEXISTS", "TOK_IGNORE_NULLS", "TOK_IMPORT", "TOK_INPUTFORMAT",
                "TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", "TOK_INTERSECTALL", "TOK_INTERSECTDISTINCT",
                "TOK_INTERVAL_DAY_LITERAL", "TOK_INTERVAL_DAY_TIME", "TOK_INTERVAL_DAY_TIME_LITERAL",
                "TOK_INTERVAL_HOUR_LITERAL", "TOK_INTERVAL_MINUTE_LITERAL", "TOK_INTERVAL_MONTH_LITERAL",
                "TOK_INTERVAL_SECOND_LITERAL", "TOK_INTERVAL_YEAR_LITERAL", "TOK_INTERVAL_YEAR_MONTH",
                "TOK_INTERVAL_YEAR_MONTH_LITERAL", "TOK_ISOLATION_LEVEL", "TOK_ISOLATION_SNAPSHOT",
                "TOK_JAR", "TOK_JOIN", "TOK_KILL_QUERY", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER",
                "TOK_LEFTANTISEMIJOIN", "TOK_LEFTOUTERJOIN", "TOK_LEFTSEMIJOIN", "TOK_LENGTH",
                "TOK_LIKEFILE", "TOK_LIKERP", "TOK_LIKETABLE", "TOK_LIMIT", "TOK_LIST",
                "TOK_LOAD", "TOK_LOCKDB", "TOK_LOCKTABLE", "TOK_MAP", "TOK_MATCHED", "TOK_MERGE",
                "TOK_METADATA", "TOK_MONTH", "TOK_MSCK", "TOK_NORELY", "TOK_NOT_CLUSTERED",
                "TOK_NOT_MATCHED", "TOK_NOT_NULL", "TOK_NOT_SORTED", "TOK_NOVALIDATE",
                "TOK_NO_DROP", "TOK_NULL", "TOK_NULLS_FIRST", "TOK_NULLS_LAST", "TOK_OFFLINE",
                "TOK_OFFSET", "TOK_ONLY", "TOK_OPERATOR", "TOK_OP_ADD", "TOK_OP_AND",
                "TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", "TOK_OP_DIV",
                "TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", "TOK_OP_LT",
                "TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", "TOK_OP_SUB",
                "TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARAMETER", "TOK_PARAMETER_IDX",
                "TOK_PARTITIONINGSPEC", "TOK_PARTITIONLOCATION", "TOK_PARTSPEC", "TOK_PARTVAL",
                "TOK_PATH", "TOK_PERCENT", "TOK_PREPARE", "TOK_PRIMARY_KEY", "TOK_PRINCIPAL_NAME",
                "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", "TOK_PRIV_ALL", "TOK_PRIV_ALTER_DATA",
                "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", "TOK_PRIV_DELETE", "TOK_PRIV_DROP",
                "TOK_PRIV_INSERT", "TOK_PRIV_LOCK", "TOK_PRIV_OBJECT", "TOK_PRIV_OBJECT_COL",
                "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", "TOK_PTBLFUNCTION", "TOK_QUALIFY",
                "TOK_QUERY", "TOK_QUERY_PARALLELISM", "TOK_READONLY", "TOK_REAL", "TOK_RECORDREADER",
                "TOK_RECORDWRITER", "TOK_RELOADFUNCTIONS", "TOK_RELY", "TOK_REMOTE", "TOK_RENAME",
                "TOK_REPLACE", "TOK_REPLICATION", "TOK_REPL_CONFIG", "TOK_REPL_CONFIG_LIST",
                "TOK_REPL_DUMP", "TOK_REPL_LOAD", "TOK_REPL_STATUS", "TOK_REPL_TABLES",
                "TOK_REPL_TABLES_LIST", "TOK_RESOURCE_ALL", "TOK_RESOURCE_LIST", "TOK_RESOURCE_URI",
                "TOK_RESPECT_NULLS", "TOK_RESTRICT", "TOK_REVOKE", "TOK_REVOKE_ROLE",
                "TOK_REWRITE_DISABLED", "TOK_REWRITE_ENABLED", "TOK_RIGHTOUTERJOIN", "TOK_ROLE",
                "TOK_ROLLBACK", "TOK_ROLLUP_GROUPBY", "TOK_ROWCOUNT", "TOK_SCHEDULE",
                "TOK_SCHEDULING_POLICY", "TOK_SELECT", "TOK_SELECTDI", "TOK_SELEXPR",
                "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", "TOK_SERVER_TYPE", "TOK_SETCOLREF",
                "TOK_SET_AUTOCOMMIT", "TOK_SET_COLUMNS_CLAUSE", "TOK_SET_ROLE", "TOK_SHOWCOLUMNS",
                "TOK_SHOWCONF", "TOK_SHOWDATABASES", "TOK_SHOWDATACONNECTORS", "TOK_SHOWDBLOCKS",
                "TOK_SHOWFUNCTIONS", "TOK_SHOWLOCKS", "TOK_SHOWMATERIALIZEDVIEWS", "TOK_SHOWPARTITIONS",
                "TOK_SHOWTABLES", "TOK_SHOWVIEWS", "TOK_SHOW_COMPACTIONS", "TOK_SHOW_CREATEDATABASE",
                "TOK_SHOW_CREATETABLE", "TOK_SHOW_CURRENT_ROLE", "TOK_SHOW_GRANT", "TOK_SHOW_ROLES",
                "TOK_SHOW_ROLE_GRANT", "TOK_SHOW_ROLE_PRINCIPALS", "TOK_SHOW_RP", "TOK_SHOW_TABLESTATUS",
                "TOK_SHOW_TBLPROPERTIES", "TOK_SHOW_TRANSACTIONS", "TOK_SKEWED_LOCATIONS",
                "TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", "TOK_SMALLINT",
                "TOK_SORTBY", "TOK_START_TRANSACTION", "TOK_STORAGEHANDLER", "TOK_STOREDASDIRS",
                "TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", "TOK_SUBQUERY",
                "TOK_SUBQUERY_EXPR", "TOK_SUBQUERY_OP", "TOK_SUBQUERY_OP_NOTEXISTS", "TOK_SUBQUERY_OP_NOTIN",
                "TOK_SUMMARY", "TOK_SWITCHDATABASE", "TOK_TAB", "TOK_TABALIAS", "TOK_TABCOL",
                "TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", "TOK_TABCOLVALUES",
                "TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", "TOK_TABLEFILEFORMAT",
                "TOK_TABLELOCATION", "TOK_TABLEPARTCOLNAMES", "TOK_TABLEPARTCOLS", "TOK_TABLEPARTCOLSBYSPEC",
                "TOK_TABLEPROPERTIES", "TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT",
                "TOK_TABLEROWFORMATCOLLITEMS", "TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES",
                "TOK_TABLEROWFORMATMAPKEYS", "TOK_TABLEROWFORMATNULL", "TOK_TABLESERIALIZER",
                "TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", "TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION",
                "TOK_TABLE_TYPE", "TOK_TABNAME", "TOK_TABREF", "TOK_TABSORTCOLNAMEASC",
                "TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", "TOK_TABTYPE", "TOK_TEMPORARY",
                "TOK_TIMESTAMP", "TOK_TIMESTAMPLITERAL", "TOK_TIMESTAMPLOCALTZ", "TOK_TIMESTAMPLOCALTZLITERAL",
                "TOK_TINYINT", "TOK_TMP_FILE", "TOK_TO", "TOK_TRANSFORM", "TOK_TRIGGER_EXPRESSION",
                "TOK_TRUE", "TOK_TRUNCATE", "TOK_TRUNCATETABLE", "TOK_TXN_ACCESS_MODE",
                "TOK_TXN_READ_ONLY", "TOK_TXN_READ_WRITE", "TOK_UNIONALL", "TOK_UNIONDISTINCT",
                "TOK_UNIONTYPE", "TOK_UNIQUE", "TOK_UNIQUEJOIN", "TOK_UNKNOWN", "TOK_UNLOCKDB",
                "TOK_UNLOCKTABLE", "TOK_UNMANAGED", "TOK_UPDATE", "TOK_UPDATE_TABLE",
                "TOK_URI_TYPE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", "TOK_USERSCRIPTCOLSCHEMA",
                "TOK_VALIDATE", "TOK_VARCHAR", "TOK_VIEWCLUSTERCOLS", "TOK_VIEWDISTRIBUTECOLS",
                "TOK_VIEWPARTCOLS", "TOK_VIEWSORTCOLS", "TOK_WHERE", "TOK_WINDOWDEF",
                "TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES", "TOK_WITHIN_GROUP",
                "TOK_YEAR"
        };
    }
	public static final int EOF=-1;
	public static final int AMPERSAND=4;
	public static final int BITWISEOR=5;
	public static final int BITWISEXOR=6;
	public static final int ByteLengthLiteral=7;
	public static final int COLON=8;
	public static final int COMMA=9;
	public static final int CONCATENATE=10;
	public static final int CharSetLiteral=11;
	public static final int CharSetName=12;
	public static final int DIV=13;
	public static final int DIVIDE=14;
	public static final int DOLLAR=15;
	public static final int DOT=16;
	public static final int Digit=17;
	public static final int EQUAL=18;
	public static final int EQUAL_NS=19;
	public static final int Exponent=20;
	public static final int GREATERTHAN=21;
	public static final int GREATERTHANOREQUALTO=22;
	public static final int HexDigit=23;
	public static final int Identifier=24;
	public static final int IntegralLiteral=25;
	public static final int KW_ABORT=26;
	public static final int KW_ACTIVATE=27;
	public static final int KW_ACTIVE=28;
	public static final int KW_ADD=29;
	public static final int KW_ADMIN=30;
	public static final int KW_AFTER=31;
	public static final int KW_ALL=32;
	public static final int KW_ALLOC_FRACTION=33;
	public static final int KW_ALTER=34;
	public static final int KW_ANALYZE=35;
	public static final int KW_AND=36;
	public static final int KW_ANY=37;
	public static final int KW_APPLICATION=38;
	public static final int KW_ARCHIVE=39;
	public static final int KW_ARRAY=40;
	public static final int KW_AS=41;
	public static final int KW_ASC=42;
	public static final int KW_AST=43;
	public static final int KW_AT=44;
	public static final int KW_AUTHORIZATION=45;
	public static final int KW_AUTOCOMMIT=46;
	public static final int KW_BEFORE=47;
	public static final int KW_BETWEEN=48;
	public static final int KW_BIGINT=49;
	public static final int KW_BINARY=50;
	public static final int KW_BOOLEAN=51;
	public static final int KW_BOTH=52;
	public static final int KW_BUCKET=53;
	public static final int KW_BUCKETS=54;
	public static final int KW_BY=55;
	public static final int KW_CACHE=56;
	public static final int KW_CASCADE=57;
	public static final int KW_CASE=58;
	public static final int KW_CAST=59;
	public static final int KW_CBO=60;
	public static final int KW_CHANGE=61;
	public static final int KW_CHAR=62;
	public static final int KW_CHECK=63;
	public static final int KW_CLUSTER=64;
	public static final int KW_CLUSTERED=65;
	public static final int KW_CLUSTERSTATUS=66;
	public static final int KW_COLLECTION=67;
	public static final int KW_COLUMN=68;
	public static final int KW_COLUMNS=69;
	public static final int KW_COMMENT=70;
	public static final int KW_COMMIT=71;
	public static final int KW_COMPACT=72;
	public static final int KW_COMPACTIONS=73;
	public static final int KW_COMPUTE=74;
	public static final int KW_CONCATENATE=75;
	public static final int KW_CONF=76;
	public static final int KW_CONSTRAINT=77;
	public static final int KW_CONTINUE=78;
	public static final int KW_COST=79;
	public static final int KW_CREATE=80;
	public static final int KW_CRON=81;
	public static final int KW_CROSS=82;
	public static final int KW_CUBE=83;
	public static final int KW_CURRENT=84;
	public static final int KW_CURRENT_DATE=85;
	public static final int KW_CURRENT_TIMESTAMP=86;
	public static final int KW_CURSOR=87;
	public static final int KW_DATA=88;
	public static final int KW_DATABASE=89;
	public static final int KW_DATABASES=90;
	public static final int KW_DATACONNECTOR=91;
	public static final int KW_DATACONNECTORS=92;
	public static final int KW_DATE=93;
	public static final int KW_DATETIME=94;
	public static final int KW_DAY=95;
	public static final int KW_DBPROPERTIES=96;
	public static final int KW_DCPROPERTIES=97;
	public static final int KW_DDL=98;
	public static final int KW_DEBUG=99;
	public static final int KW_DECIMAL=100;
	public static final int KW_DEFAULT=101;
	public static final int KW_DEFERRED=102;
	public static final int KW_DEFINED=103;
	public static final int KW_DELETE=104;
	public static final int KW_DELIMITED=105;
	public static final int KW_DEPENDENCY=106;
	public static final int KW_DESC=107;
	public static final int KW_DESCRIBE=108;
	public static final int KW_DETAIL=109;
	public static final int KW_DIRECTORIES=110;
	public static final int KW_DIRECTORY=111;
	public static final int KW_DISABLE=112;
	public static final int KW_DISTINCT=113;
	public static final int KW_DISTRIBUTE=114;
	public static final int KW_DISTRIBUTED=115;
	public static final int KW_DO=116;
	public static final int KW_DOUBLE=117;
	public static final int KW_DOW=118;
	public static final int KW_DROP=119;
	public static final int KW_DUMP=120;
	public static final int KW_ELEM_TYPE=121;
	public static final int KW_ELSE=122;
	public static final int KW_ENABLE=123;
	public static final int KW_END=124;
	public static final int KW_ENFORCED=125;
	public static final int KW_ESCAPED=126;
	public static final int KW_EVERY=127;
	public static final int KW_EXCEPT=128;
	public static final int KW_EXCHANGE=129;
	public static final int KW_EXCLUSIVE=130;
	public static final int KW_EXECUTE=131;
	public static final int KW_EXECUTED=132;
	public static final int KW_EXISTS=133;
	public static final int KW_EXPIRE_SNAPSHOTS=134;
	public static final int KW_EXPLAIN=135;
	public static final int KW_EXPORT=136;
	public static final int KW_EXPRESSION=137;
	public static final int KW_EXTENDED=138;
	public static final int KW_EXTERNAL=139;
	public static final int KW_EXTRACT=140;
	public static final int KW_FALSE=141;
	public static final int KW_FETCH=142;
	public static final int KW_FIELDS=143;
	public static final int KW_FILE=144;
	public static final int KW_FILEFORMAT=145;
	public static final int KW_FIRST=146;
	public static final int KW_FLOAT=147;
	public static final int KW_FLOOR=148;
	public static final int KW_FOLLOWING=149;
	public static final int KW_FOR=150;
	public static final int KW_FORCE=151;
	public static final int KW_FOREIGN=152;
	public static final int KW_FORMAT=153;
	public static final int KW_FORMATTED=154;
	public static final int KW_FROM=155;
	public static final int KW_FULL=156;
	public static final int KW_FUNCTION=157;
	public static final int KW_FUNCTIONS=158;
	public static final int KW_GRANT=159;
	public static final int KW_GROUP=160;
	public static final int KW_GROUPING=161;
	public static final int KW_HAVING=162;
	public static final int KW_HOUR=163;
	public static final int KW_ID=164;
	public static final int KW_IDXPROPERTIES=165;
	public static final int KW_IF=166;
	public static final int KW_IGNORE=167;
	public static final int KW_IMPORT=168;
	public static final int KW_IN=169;
	public static final int KW_INDEX=170;
	public static final int KW_INDEXES=171;
	public static final int KW_INNER=172;
	public static final int KW_INPATH=173;
	public static final int KW_INPUTDRIVER=174;
	public static final int KW_INPUTFORMAT=175;
	public static final int KW_INSERT=176;
	public static final int KW_INT=177;
	public static final int KW_INTERSECT=178;
	public static final int KW_INTERVAL=179;
	public static final int KW_INTO=180;
	public static final int KW_IS=181;
	public static final int KW_ISOLATION=182;
	public static final int KW_ITEMS=183;
	public static final int KW_JAR=184;
	public static final int KW_JOIN=185;
	public static final int KW_JOINCOST=186;
	public static final int KW_KEY=187;
	public static final int KW_KEYS=188;
	public static final int KW_KEY_TYPE=189;
	public static final int KW_KILL=190;
	public static final int KW_LAST=191;
	public static final int KW_LATERAL=192;
	public static final int KW_LEADING=193;
	public static final int KW_LEFT=194;
	public static final int KW_LESS=195;
	public static final int KW_LEVEL=196;
	public static final int KW_LIKE=197;
	public static final int KW_LIMIT=198;
	public static final int KW_LINES=199;
	public static final int KW_LOAD=200;
	public static final int KW_LOCAL=201;
	public static final int KW_LOCATION=202;
	public static final int KW_LOCK=203;
	public static final int KW_LOCKS=204;
	public static final int KW_LOGICAL=205;
	public static final int KW_LONG=206;
	public static final int KW_MACRO=207;
	public static final int KW_MANAGED=208;
	public static final int KW_MANAGEDLOCATION=209;
	public static final int KW_MANAGEMENT=210;
	public static final int KW_MAP=211;
	public static final int KW_MAPJOIN=212;
	public static final int KW_MAPPING=213;
	public static final int KW_MATCHED=214;
	public static final int KW_MATERIALIZED=215;
	public static final int KW_MERGE=216;
	public static final int KW_METADATA=217;
	public static final int KW_MINUS=218;
	public static final int KW_MINUTE=219;
	public static final int KW_MONTH=220;
	public static final int KW_MORE=221;
	public static final int KW_MOVE=222;
	public static final int KW_MSCK=223;
	public static final int KW_NONE=224;
	public static final int KW_NORELY=225;
	public static final int KW_NOSCAN=226;
	public static final int KW_NOT=227;
	public static final int KW_NOVALIDATE=228;
	public static final int KW_NULL=229;
	public static final int KW_NULLS=230;
	public static final int KW_OF=231;
	public static final int KW_OFFSET=232;
	public static final int KW_ON=233;
	public static final int KW_ONLY=234;
	public static final int KW_OPERATOR=235;
	public static final int KW_OPTION=236;
	public static final int KW_OR=237;
	public static final int KW_ORDER=238;
	public static final int KW_OUT=239;
	public static final int KW_OUTER=240;
	public static final int KW_OUTPUTDRIVER=241;
	public static final int KW_OUTPUTFORMAT=242;
	public static final int KW_OVER=243;
	public static final int KW_OVERWRITE=244;
	public static final int KW_OWNER=245;
	public static final int KW_PARTITION=246;
	public static final int KW_PARTITIONED=247;
	public static final int KW_PARTITIONS=248;
	public static final int KW_PATH=249;
	public static final int KW_PERCENT=250;
	public static final int KW_PKFK_JOIN=251;
	public static final int KW_PLAN=252;
	public static final int KW_PLANS=253;
	public static final int KW_PLUS=254;
	public static final int KW_POOL=255;
	public static final int KW_PRECEDING=256;
	public static final int KW_PRECISION=257;
	public static final int KW_PREPARE=258;
	public static final int KW_PRESERVE=259;
	public static final int KW_PRIMARY=260;
	public static final int KW_PRINCIPALS=261;
	public static final int KW_PROCEDURE=262;
	public static final int KW_PURGE=263;
	public static final int KW_QUALIFY=264;
	public static final int KW_QUARTER=265;
	public static final int KW_QUERY=266;
	public static final int KW_QUERY_PARALLELISM=267;
	public static final int KW_RANGE=268;
	public static final int KW_READ=269;
	public static final int KW_READS=270;
	public static final int KW_REAL=271;
	public static final int KW_REBUILD=272;
	public static final int KW_RECORDREADER=273;
	public static final int KW_RECORDWRITER=274;
	public static final int KW_REDUCE=275;
	public static final int KW_REFERENCES=276;
	public static final int KW_REGEXP=277;
	public static final int KW_RELOAD=278;
	public static final int KW_RELY=279;
	public static final int KW_REMOTE=280;
	public static final int KW_RENAME=281;
	public static final int KW_REOPTIMIZATION=282;
	public static final int KW_REPAIR=283;
	public static final int KW_REPL=284;
	public static final int KW_REPLACE=285;
	public static final int KW_REPLICATION=286;
	public static final int KW_RESOURCE=287;
	public static final int KW_RESPECT=288;
	public static final int KW_RESTRICT=289;
	public static final int KW_REVOKE=290;
	public static final int KW_REWRITE=291;
	public static final int KW_RIGHT=292;
	public static final int KW_RLIKE=293;
	public static final int KW_ROLE=294;
	public static final int KW_ROLES=295;
	public static final int KW_ROLLBACK=296;
	public static final int KW_ROLLUP=297;
	public static final int KW_ROW=298;
	public static final int KW_ROWS=299;
	public static final int KW_SCHEDULED=300;
	public static final int KW_SCHEDULING_POLICY=301;
	public static final int KW_SCHEMA=302;
	public static final int KW_SCHEMAS=303;
	public static final int KW_SECOND=304;
	public static final int KW_SELECT=305;
	public static final int KW_SEMI=306;
	public static final int KW_SERDE=307;
	public static final int KW_SERDEPROPERTIES=308;
	public static final int KW_SERVER=309;
	public static final int KW_SET=310;
	public static final int KW_SETS=311;
	public static final int KW_SHARED=312;
	public static final int KW_SHOW=313;
	public static final int KW_SHOW_DATABASE=314;
	public static final int KW_SKEWED=315;
	public static final int KW_SMALLINT=316;
	public static final int KW_SNAPSHOT=317;
	public static final int KW_SOME=318;
	public static final int KW_SORT=319;
	public static final int KW_SORTED=320;
	public static final int KW_SPEC=321;
	public static final int KW_SSL=322;
	public static final int KW_START=323;
	public static final int KW_STATISTICS=324;
	public static final int KW_STATUS=325;
	public static final int KW_STORED=326;
	public static final int KW_STREAMTABLE=327;
	public static final int KW_STRING=328;
	public static final int KW_STRUCT=329;
	public static final int KW_SUMMARY=330;
	public static final int KW_SYNC=331;
	public static final int KW_SYSTEM_TIME=332;
	public static final int KW_SYSTEM_VERSION=333;
	public static final int KW_TABLE=334;
	public static final int KW_TABLES=335;
	public static final int KW_TABLESAMPLE=336;
	public static final int KW_TBLPROPERTIES=337;
	public static final int KW_TEMPORARY=338;
	public static final int KW_TERMINATED=339;
	public static final int KW_THEN=340;
	public static final int KW_TIME=341;
	public static final int KW_TIMESTAMP=342;
	public static final int KW_TIMESTAMPLOCALTZ=343;
	public static final int KW_TINYINT=344;
	public static final int KW_TO=345;
	public static final int KW_TOUCH=346;
	public static final int KW_TRAILING=347;
	public static final int KW_TRANSACTION=348;
	public static final int KW_TRANSACTIONAL=349;
	public static final int KW_TRANSACTIONS=350;
	public static final int KW_TRANSFORM=351;
	public static final int KW_TRIGGER=352;
	public static final int KW_TRIM=353;
	public static final int KW_TRUE=354;
	public static final int KW_TRUNCATE=355;
	public static final int KW_TYPE=356;
	public static final int KW_UNARCHIVE=357;
	public static final int KW_UNBOUNDED=358;
	public static final int KW_UNDO=359;
	public static final int KW_UNION=360;
	public static final int KW_UNIONTYPE=361;
	public static final int KW_UNIQUE=362;
	public static final int KW_UNIQUEJOIN=363;
	public static final int KW_UNKNOWN=364;
	public static final int KW_UNLOCK=365;
	public static final int KW_UNMANAGED=366;
	public static final int KW_UNSET=367;
	public static final int KW_UNSIGNED=368;
	public static final int KW_UPDATE=369;
	public static final int KW_URI=370;
	public static final int KW_URL=371;
	public static final int KW_USE=372;
	public static final int KW_USER=373;
	public static final int KW_USING=374;
	public static final int KW_UTC=375;
	public static final int KW_UTCTIMESTAMP=376;
	public static final int KW_VALIDATE=377;
	public static final int KW_VALUES=378;
	public static final int KW_VALUE_TYPE=379;
	public static final int KW_VARCHAR=380;
	public static final int KW_VECTORIZATION=381;
	public static final int KW_VIEW=382;
	public static final int KW_VIEWS=383;
	public static final int KW_WAIT=384;
	public static final int KW_WEEK=385;
	public static final int KW_WHEN=386;
	public static final int KW_WHERE=387;
	public static final int KW_WHILE=388;
	public static final int KW_WINDOW=389;
	public static final int KW_WITH=390;
	public static final int KW_WITHIN=391;
	public static final int KW_WORK=392;
	public static final int KW_WORKLOAD=393;
	public static final int KW_WRITE=394;
	public static final int KW_YEAR=395;
	public static final int KW_ZONE=396;
	public static final int LCURLY=397;
	public static final int LESSTHAN=398;
	public static final int LESSTHANOREQUALTO=399;
	public static final int LINE_COMMENT=400;
	public static final int LPAREN=401;
	public static final int LSQUARE=402;
	public static final int Letter=403;
	public static final int MINUS=404;
	public static final int MOD=405;
	public static final int NOTEQUAL=406;
	public static final int Number=407;
	public static final int NumberLiteral=408;
	public static final int PLUS=409;
	public static final int QUERY_HINT=410;
	public static final int QUESTION=411;
	public static final int QuotedIdentifier=412;
	public static final int RCURLY=413;
	public static final int RPAREN=414;
	public static final int RSQUARE=415;
	public static final int RegexComponent=416;
	public static final int SEMICOLON=417;
	public static final int STAR=418;
	public static final int StringLiteral=419;
	public static final int TILDE=420;
	public static final int Tokens=421;
	public static final int WS=422;
	public static final int KW_ANTI=451;
	public static final int KW_BATCH=461;
	public static final int KW_DAYOFWEEK=506;
	public static final int KW_HOLD_DDLTIME=563;
	public static final int KW_NO_DROP=620;
	public static final int KW_OFFLINE=624;
	public static final int KW_PROTECTION=651;
	public static final int KW_READONLY=659;
	public static final int KW_TIMESTAMPTZ=728;
	public static final int TOK_ABORT_TRANSACTIONS=796;
	public static final int TOK_ACTIVATE=797;
	public static final int TOK_ADD_TRIGGER=798;
	public static final int TOK_ADMIN_OPTION_FOR=799;
	public static final int TOK_ALIAS=800;
	public static final int TOK_ALIASLIST=801;
	public static final int TOK_ALLCOLREF=802;
	public static final int TOK_ALLOC_FRACTION=803;
	public static final int TOK_ALTERDATABASE_LOCATION=804;
	public static final int TOK_ALTERDATABASE_MANAGEDLOCATION=805;
	public static final int TOK_ALTERDATABASE_OWNER=806;
	public static final int TOK_ALTERDATABASE_PROPERTIES=807;
	public static final int TOK_ALTERDATACONNECTOR_OWNER=808;
	public static final int TOK_ALTERDATACONNECTOR_PROPERTIES=809;
	public static final int TOK_ALTERDATACONNECTOR_URL=810;
	public static final int TOK_ALTERPARTITION_BUCKETS=811;
	public static final int TOK_ALTERPARTITION_FILEFORMAT=812;
	public static final int TOK_ALTERPARTITION_LOCATION=813;
	public static final int TOK_ALTERPARTITION_MERGEFILES=814;
	public static final int TOK_ALTERPARTITION_SERIALIZER=815;
	public static final int TOK_ALTERPARTITION_SETSERDEPROPERTIES=816;
	public static final int TOK_ALTERPARTITION_UNSETSERDEPROPERTIES=817;
	public static final int TOK_ALTERPARTITION_UPDATECOLSTATS=818;
	public static final int TOK_ALTERPARTITION_UPDATESTATS=819;
	public static final int TOK_ALTERTABLE=820;
	public static final int TOK_ALTERTABLE_ADDCOLS=821;
	public static final int TOK_ALTERTABLE_ADDCONSTRAINT=822;
	public static final int TOK_ALTERTABLE_ADDPARTS=823;
	public static final int TOK_ALTERTABLE_ARCHIVE=824;
	public static final int TOK_ALTERTABLE_BUCKETS=825;
	public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION=826;
	public static final int TOK_ALTERTABLE_CLUSTER_SORT=827;
	public static final int TOK_ALTERTABLE_COMPACT=828;
	public static final int TOK_ALTERTABLE_DROPCONSTRAINT=829;
	public static final int TOK_ALTERTABLE_DROPPARTS=830;
	public static final int TOK_ALTERTABLE_DROPPROPERTIES=831;
	public static final int TOK_ALTERTABLE_EXCHANGEPARTITION=832;
	public static final int TOK_ALTERTABLE_EXECUTE=833;
	public static final int TOK_ALTERTABLE_FILEFORMAT=834;
	public static final int TOK_ALTERTABLE_LOCATION=835;
	public static final int TOK_ALTERTABLE_MERGEFILES=836;
	public static final int TOK_ALTERTABLE_OWNER=837;
	public static final int TOK_ALTERTABLE_PARTCOLTYPE=838;
	public static final int TOK_ALTERTABLE_PROPERTIES=839;
	public static final int TOK_ALTERTABLE_RENAME=840;
	public static final int TOK_ALTERTABLE_RENAMECOL=841;
	public static final int TOK_ALTERTABLE_RENAMEPART=842;
	public static final int TOK_ALTERTABLE_REPLACECOLS=843;
	public static final int TOK_ALTERTABLE_SERIALIZER=844;
	public static final int TOK_ALTERTABLE_SETPARTSPEC=845;
	public static final int TOK_ALTERTABLE_SETSERDEPROPERTIES=846;
	public static final int TOK_ALTERTABLE_SKEWED=847;
	public static final int TOK_ALTERTABLE_SKEWED_LOCATION=848;
	public static final int TOK_ALTERTABLE_TOUCH=849;
	public static final int TOK_ALTERTABLE_UNARCHIVE=850;
	public static final int TOK_ALTERTABLE_UNSETSERDEPROPERTIES=851;
	public static final int TOK_ALTERTABLE_UPDATECOLSTATS=852;
	public static final int TOK_ALTERTABLE_UPDATECOLUMNS=853;
	public static final int TOK_ALTERTABLE_UPDATESTATS=854;
	public static final int TOK_ALTERVIEW=855;
	public static final int TOK_ALTERVIEW_ADDPARTS=856;
	public static final int TOK_ALTERVIEW_AS=857;
	public static final int TOK_ALTERVIEW_DROPPARTS=858;
	public static final int TOK_ALTERVIEW_DROPPROPERTIES=859;
	public static final int TOK_ALTERVIEW_PROPERTIES=860;
	public static final int TOK_ALTERVIEW_RENAME=861;
	public static final int TOK_ALTER_MAPPING=862;
	public static final int TOK_ALTER_MATERIALIZED_VIEW=863;
	public static final int TOK_ALTER_MATERIALIZED_VIEW_REBUILD=864;
	public static final int TOK_ALTER_MATERIALIZED_VIEW_REWRITE=865;
	public static final int TOK_ALTER_POOL=866;
	public static final int TOK_ALTER_POOL_ADD_TRIGGER=867;
	public static final int TOK_ALTER_POOL_DROP_TRIGGER=868;
	public static final int TOK_ALTER_RP_DISABLE=869;
	public static final int TOK_ALTER_RP_ENABLE=870;
	public static final int TOK_ALTER_RP_RENAME=871;
	public static final int TOK_ALTER_RP_REPLACE=872;
	public static final int TOK_ALTER_RP_SET=873;
	public static final int TOK_ALTER_RP_UNSET=874;
	public static final int TOK_ALTER_RP_VALIDATE=875;
	public static final int TOK_ALTER_SCHEDULED_QUERY=876;
	public static final int TOK_ALTER_TRIGGER=877;
	public static final int TOK_ANALYZE=878;
	public static final int TOK_ARCHIVE=879;
	public static final int TOK_AS_OF_TIME=880;
	public static final int TOK_AS_OF_VERSION=881;
	public static final int TOK_BIGINT=882;
	public static final int TOK_BINARY=883;
	public static final int TOK_BLOCKING=884;
	public static final int TOK_BOOLEAN=885;
	public static final int TOK_BUCKET=886;
	public static final int TOK_CACHE_METADATA=887;
	public static final int TOK_CASCADE=888;
	public static final int TOK_CHAR=889;
	public static final int TOK_CHARSETLITERAL=890;
	public static final int TOK_CHECK_CONSTRAINT=891;
	public static final int TOK_CLUSTERBY=892;
	public static final int TOK_COLTYPELIST=893;
	public static final int TOK_COL_NAME=894;
	public static final int TOK_COMMIT=895;
	public static final int TOK_COMPACTION_STATUS=896;
	public static final int TOK_COMPACTION_TYPE=897;
	public static final int TOK_COMPACT_ID=898;
	public static final int TOK_COMPACT_POOL=899;
	public static final int TOK_CONSTRAINT_NAME=900;
	public static final int TOK_CREATEDATABASE=901;
	public static final int TOK_CREATEDATACONNECTOR=902;
	public static final int TOK_CREATEFUNCTION=903;
	public static final int TOK_CREATEMACRO=904;
	public static final int TOK_CREATEROLE=905;
	public static final int TOK_CREATETABLE=906;
	public static final int TOK_CREATEVIEW=907;
	public static final int TOK_CREATE_MAPPING=908;
	public static final int TOK_CREATE_MATERIALIZED_VIEW=909;
	public static final int TOK_CREATE_POOL=910;
	public static final int TOK_CREATE_RP=911;
	public static final int TOK_CREATE_SCHEDULED_QUERY=912;
	public static final int TOK_CREATE_TRIGGER=913;
	public static final int TOK_CRON=914;
	public static final int TOK_CROSSJOIN=915;
	public static final int TOK_CTE=916;
	public static final int TOK_CUBE_GROUPBY=917;
	public static final int TOK_DATABASECOMMENT=918;
	public static final int TOK_DATABASELOCATION=919;
	public static final int TOK_DATABASEPROPERTIES=920;
	public static final int TOK_DATABASE_MANAGEDLOCATION=921;
	public static final int TOK_DATACONNECTOR=922;
	public static final int TOK_DATACONNECTORCOMMENT=923;
	public static final int TOK_DATACONNECTOROWNER=924;
	public static final int TOK_DATACONNECTORPROPERTIES=925;
	public static final int TOK_DATACONNECTORTYPE=926;
	public static final int TOK_DATACONNECTORURL=927;
	public static final int TOK_DATE=928;
	public static final int TOK_DATELITERAL=929;
	public static final int TOK_DATETIME=930;
	public static final int TOK_DAY=931;
	public static final int TOK_DBNAME=932;
	public static final int TOK_DBPROPLIST=933;
	public static final int TOK_DB_TYPE=934;
	public static final int TOK_DDL=935;
	public static final int TOK_DECIMAL=936;
	public static final int TOK_DEFAULT_POOL=937;
	public static final int TOK_DEFAULT_VALUE=938;
	public static final int TOK_DELETE=939;
	public static final int TOK_DELETE_FROM=940;
	public static final int TOK_DESCDATABASE=941;
	public static final int TOK_DESCDATACONNECTOR=942;
	public static final int TOK_DESCFUNCTION=943;
	public static final int TOK_DESCTABLE=944;
	public static final int TOK_DESTINATION=945;
	public static final int TOK_DETAIL=946;
	public static final int TOK_DIR=947;
	public static final int TOK_DISABLE=948;
	public static final int TOK_DISTRIBUTEBY=949;
	public static final int TOK_DOUBLE=950;
	public static final int TOK_DROPDATABASE=951;
	public static final int TOK_DROPDATACONNECTOR=952;
	public static final int TOK_DROPFUNCTION=953;
	public static final int TOK_DROPMACRO=954;
	public static final int TOK_DROPROLE=955;
	public static final int TOK_DROPTABLE=956;
	public static final int TOK_DROPVIEW=957;
	public static final int TOK_DROP_MAPPING=958;
	public static final int TOK_DROP_MATERIALIZED_VIEW=959;
	public static final int TOK_DROP_POOL=960;
	public static final int TOK_DROP_RP=961;
	public static final int TOK_DROP_SCHEDULED_QUERY=962;
	public static final int TOK_DROP_TRIGGER=963;
	public static final int TOK_ENABLE=964;
	public static final int TOK_EVERY=965;
	public static final int TOK_EXCEPTALL=966;
	public static final int TOK_EXCEPTDISTINCT=967;
	public static final int TOK_EXECUTE=968;
	public static final int TOK_EXECUTED_AS=969;
	public static final int TOK_EXECUTE_PARAM_LIST=970;
	public static final int TOK_EXPLAIN=971;
	public static final int TOK_EXPLAIN_SQ_REWRITE=972;
	public static final int TOK_EXPLIST=973;
	public static final int TOK_EXPORT=974;
	public static final int TOK_EXPRESSION=975;
	public static final int TOK_FALSE=976;
	public static final int TOK_FILE=977;
	public static final int TOK_FILEFORMAT_GENERIC=978;
	public static final int TOK_FLOAT=979;
	public static final int TOK_FORCE=980;
	public static final int TOK_FOREIGN_KEY=981;
	public static final int TOK_FROM=982;
	public static final int TOK_FULLOUTERJOIN=983;
	public static final int TOK_FUNCTION=984;
	public static final int TOK_FUNCTIONDI=985;
	public static final int TOK_FUNCTIONSTAR=986;
	public static final int TOK_GRANT=987;
	public static final int TOK_GRANT_OPTION_FOR=988;
	public static final int TOK_GRANT_ROLE=989;
	public static final int TOK_GRANT_WITH_ADMIN_OPTION=990;
	public static final int TOK_GRANT_WITH_OPTION=991;
	public static final int TOK_GROUP=992;
	public static final int TOK_GROUPBY=993;
	public static final int TOK_GROUPING_SETS=994;
	public static final int TOK_GROUPING_SETS_EXPRESSION=995;
	public static final int TOK_HAVING=996;
	public static final int TOK_HOUR=997;
	public static final int TOK_IDENTITY=998;
	public static final int TOK_IFEXISTS=999;
	public static final int TOK_IFNOTEXISTS=1000;
	public static final int TOK_IGNORE_NULLS=1001;
	public static final int TOK_IMPORT=1002;
	public static final int TOK_INPUTFORMAT=1003;
	public static final int TOK_INSERT=1004;
	public static final int TOK_INSERT_INTO=1005;
	public static final int TOK_INT=1006;
	public static final int TOK_INTERSECTALL=1007;
	public static final int TOK_INTERSECTDISTINCT=1008;
	public static final int TOK_INTERVAL_DAY_LITERAL=1009;
	public static final int TOK_INTERVAL_DAY_TIME=1010;
	public static final int TOK_INTERVAL_DAY_TIME_LITERAL=1011;
	public static final int TOK_INTERVAL_HOUR_LITERAL=1012;
	public static final int TOK_INTERVAL_MINUTE_LITERAL=1013;
	public static final int TOK_INTERVAL_MONTH_LITERAL=1014;
	public static final int TOK_INTERVAL_SECOND_LITERAL=1015;
	public static final int TOK_INTERVAL_YEAR_LITERAL=1016;
	public static final int TOK_INTERVAL_YEAR_MONTH=1017;
	public static final int TOK_INTERVAL_YEAR_MONTH_LITERAL=1018;
	public static final int TOK_ISOLATION_LEVEL=1019;
	public static final int TOK_ISOLATION_SNAPSHOT=1020;
	public static final int TOK_JAR=1021;
	public static final int TOK_JOIN=1022;
	public static final int TOK_KILL_QUERY=1023;
	public static final int TOK_LATERAL_VIEW=1024;
	public static final int TOK_LATERAL_VIEW_OUTER=1025;
	public static final int TOK_LEFTANTISEMIJOIN=1026;
	public static final int TOK_LEFTOUTERJOIN=1027;
	public static final int TOK_LEFTSEMIJOIN=1028;
	public static final int TOK_LENGTH=1029;
	public static final int TOK_LIKEFILE=1030;
	public static final int TOK_LIKERP=1031;
	public static final int TOK_LIKETABLE=1032;
	public static final int TOK_LIMIT=1033;
	public static final int TOK_LIST=1034;
	public static final int TOK_LOAD=1035;
	public static final int TOK_LOCKDB=1036;
	public static final int TOK_LOCKTABLE=1037;
	public static final int TOK_MAP=1038;
	public static final int TOK_MATCHED=1039;
	public static final int TOK_MERGE=1040;
	public static final int TOK_METADATA=1041;
	public static final int TOK_MONTH=1042;
	public static final int TOK_MSCK=1043;
	public static final int TOK_NORELY=1044;
	public static final int TOK_NOT_CLUSTERED=1045;
	public static final int TOK_NOT_MATCHED=1046;
	public static final int TOK_NOT_NULL=1047;
	public static final int TOK_NOT_SORTED=1048;
	public static final int TOK_NOVALIDATE=1049;
	public static final int TOK_NO_DROP=1050;
	public static final int TOK_NULL=1051;
	public static final int TOK_NULLS_FIRST=1052;
	public static final int TOK_NULLS_LAST=1053;
	public static final int TOK_OFFLINE=1054;
	public static final int TOK_OFFSET=1055;
	public static final int TOK_ONLY=1056;
	public static final int TOK_OPERATOR=1057;
	public static final int TOK_OP_ADD=1058;
	public static final int TOK_OP_AND=1059;
	public static final int TOK_OP_BITAND=1060;
	public static final int TOK_OP_BITNOT=1061;
	public static final int TOK_OP_BITOR=1062;
	public static final int TOK_OP_BITXOR=1063;
	public static final int TOK_OP_DIV=1064;
	public static final int TOK_OP_EQ=1065;
	public static final int TOK_OP_GE=1066;
	public static final int TOK_OP_GT=1067;
	public static final int TOK_OP_LE=1068;
	public static final int TOK_OP_LIKE=1069;
	public static final int TOK_OP_LT=1070;
	public static final int TOK_OP_MOD=1071;
	public static final int TOK_OP_MUL=1072;
	public static final int TOK_OP_NE=1073;
	public static final int TOK_OP_NOT=1074;
	public static final int TOK_OP_OR=1075;
	public static final int TOK_OP_SUB=1076;
	public static final int TOK_ORDERBY=1077;
	public static final int TOK_ORREPLACE=1078;
	public static final int TOK_PARAMETER=1079;
	public static final int TOK_PARAMETER_IDX=1080;
	public static final int TOK_PARTITIONINGSPEC=1081;
	public static final int TOK_PARTITIONLOCATION=1082;
	public static final int TOK_PARTSPEC=1083;
	public static final int TOK_PARTVAL=1084;
	public static final int TOK_PATH=1085;
	public static final int TOK_PERCENT=1086;
	public static final int TOK_PREPARE=1087;
	public static final int TOK_PRIMARY_KEY=1088;
	public static final int TOK_PRINCIPAL_NAME=1089;
	public static final int TOK_PRIVILEGE=1090;
	public static final int TOK_PRIVILEGE_LIST=1091;
	public static final int TOK_PRIV_ALL=1092;
	public static final int TOK_PRIV_ALTER_DATA=1093;
	public static final int TOK_PRIV_ALTER_METADATA=1094;
	public static final int TOK_PRIV_CREATE=1095;
	public static final int TOK_PRIV_DELETE=1096;
	public static final int TOK_PRIV_DROP=1097;
	public static final int TOK_PRIV_INSERT=1098;
	public static final int TOK_PRIV_LOCK=1099;
	public static final int TOK_PRIV_OBJECT=1100;
	public static final int TOK_PRIV_OBJECT_COL=1101;
	public static final int TOK_PRIV_SELECT=1102;
	public static final int TOK_PRIV_SHOW_DATABASE=1103;
	public static final int TOK_PTBLFUNCTION=1104;
	public static final int TOK_QUALIFY=1105;
	public static final int TOK_QUERY=1106;
	public static final int TOK_QUERY_PARALLELISM=1107;
	public static final int TOK_READONLY=1108;
	public static final int TOK_REAL=1109;
	public static final int TOK_RECORDREADER=1110;
	public static final int TOK_RECORDWRITER=1111;
	public static final int TOK_RELOADFUNCTIONS=1112;
	public static final int TOK_RELY=1113;
	public static final int TOK_REMOTE=1114;
	public static final int TOK_RENAME=1115;
	public static final int TOK_REPLACE=1116;
	public static final int TOK_REPLICATION=1117;
	public static final int TOK_REPL_CONFIG=1118;
	public static final int TOK_REPL_CONFIG_LIST=1119;
	public static final int TOK_REPL_DUMP=1120;
	public static final int TOK_REPL_LOAD=1121;
	public static final int TOK_REPL_STATUS=1122;
	public static final int TOK_REPL_TABLES=1123;
	public static final int TOK_REPL_TABLES_LIST=1124;
	public static final int TOK_RESOURCE_ALL=1125;
	public static final int TOK_RESOURCE_LIST=1126;
	public static final int TOK_RESOURCE_URI=1127;
	public static final int TOK_RESPECT_NULLS=1128;
	public static final int TOK_RESTRICT=1129;
	public static final int TOK_REVOKE=1130;
	public static final int TOK_REVOKE_ROLE=1131;
	public static final int TOK_REWRITE_DISABLED=1132;
	public static final int TOK_REWRITE_ENABLED=1133;
	public static final int TOK_RIGHTOUTERJOIN=1134;
	public static final int TOK_ROLE=1135;
	public static final int TOK_ROLLBACK=1136;
	public static final int TOK_ROLLUP_GROUPBY=1137;
	public static final int TOK_ROWCOUNT=1138;
	public static final int TOK_SCHEDULE=1139;
	public static final int TOK_SCHEDULING_POLICY=1140;
	public static final int TOK_SELECT=1141;
	public static final int TOK_SELECTDI=1142;
	public static final int TOK_SELEXPR=1143;
	public static final int TOK_SERDE=1144;
	public static final int TOK_SERDENAME=1145;
	public static final int TOK_SERDEPROPS=1146;
	public static final int TOK_SERVER_TYPE=1147;
	public static final int TOK_SETCOLREF=1148;
	public static final int TOK_SET_AUTOCOMMIT=1149;
	public static final int TOK_SET_COLUMNS_CLAUSE=1150;
	public static final int TOK_SET_ROLE=1151;
	public static final int TOK_SHOWCOLUMNS=1152;
	public static final int TOK_SHOWCONF=1153;
	public static final int TOK_SHOWDATABASES=1154;
	public static final int TOK_SHOWDATACONNECTORS=1155;
	public static final int TOK_SHOWDBLOCKS=1156;
	public static final int TOK_SHOWFUNCTIONS=1157;
	public static final int TOK_SHOWLOCKS=1158;
	public static final int TOK_SHOWMATERIALIZEDVIEWS=1159;
	public static final int TOK_SHOWPARTITIONS=1160;
	public static final int TOK_SHOWTABLES=1161;
	public static final int TOK_SHOWVIEWS=1162;
	public static final int TOK_SHOW_COMPACTIONS=1163;
	public static final int TOK_SHOW_CREATEDATABASE=1164;
	public static final int TOK_SHOW_CREATETABLE=1165;
	public static final int TOK_SHOW_CURRENT_ROLE=1166;
	public static final int TOK_SHOW_GRANT=1167;
	public static final int TOK_SHOW_ROLES=1168;
	public static final int TOK_SHOW_ROLE_GRANT=1169;
	public static final int TOK_SHOW_ROLE_PRINCIPALS=1170;
	public static final int TOK_SHOW_RP=1171;
	public static final int TOK_SHOW_TABLESTATUS=1172;
	public static final int TOK_SHOW_TBLPROPERTIES=1173;
	public static final int TOK_SHOW_TRANSACTIONS=1174;
	public static final int TOK_SKEWED_LOCATIONS=1175;
	public static final int TOK_SKEWED_LOCATION_LIST=1176;
	public static final int TOK_SKEWED_LOCATION_MAP=1177;
	public static final int TOK_SMALLINT=1178;
	public static final int TOK_SORTBY=1179;
	public static final int TOK_START_TRANSACTION=1180;
	public static final int TOK_STORAGEHANDLER=1181;
	public static final int TOK_STOREDASDIRS=1182;
	public static final int TOK_STRING=1183;
	public static final int TOK_STRINGLITERALSEQUENCE=1184;
	public static final int TOK_STRUCT=1185;
	public static final int TOK_SUBQUERY=1186;
	public static final int TOK_SUBQUERY_EXPR=1187;
	public static final int TOK_SUBQUERY_OP=1188;
	public static final int TOK_SUBQUERY_OP_NOTEXISTS=1189;
	public static final int TOK_SUBQUERY_OP_NOTIN=1190;
	public static final int TOK_SUMMARY=1191;
	public static final int TOK_SWITCHDATABASE=1192;
	public static final int TOK_TAB=1193;
	public static final int TOK_TABALIAS=1194;
	public static final int TOK_TABCOL=1195;
	public static final int TOK_TABCOLLIST=1196;
	public static final int TOK_TABCOLNAME=1197;
	public static final int TOK_TABCOLVALUE=1198;
	public static final int TOK_TABCOLVALUES=1199;
	public static final int TOK_TABCOLVALUE_PAIR=1200;
	public static final int TOK_TABLEBUCKETSAMPLE=1201;
	public static final int TOK_TABLECOMMENT=1202;
	public static final int TOK_TABLEFILEFORMAT=1203;
	public static final int TOK_TABLELOCATION=1204;
	public static final int TOK_TABLEPARTCOLNAMES=1205;
	public static final int TOK_TABLEPARTCOLS=1206;
	public static final int TOK_TABLEPARTCOLSBYSPEC=1207;
	public static final int TOK_TABLEPROPERTIES=1208;
	public static final int TOK_TABLEPROPERTY=1209;
	public static final int TOK_TABLEPROPLIST=1210;
	public static final int TOK_TABLEROWFORMAT=1211;
	public static final int TOK_TABLEROWFORMATCOLLITEMS=1212;
	public static final int TOK_TABLEROWFORMATFIELD=1213;
	public static final int TOK_TABLEROWFORMATLINES=1214;
	public static final int TOK_TABLEROWFORMATMAPKEYS=1215;
	public static final int TOK_TABLEROWFORMATNULL=1216;
	public static final int TOK_TABLESERIALIZER=1217;
	public static final int TOK_TABLESKEWED=1218;
	public static final int TOK_TABLESPLITSAMPLE=1219;
	public static final int TOK_TABLE_OR_COL=1220;
	public static final int TOK_TABLE_PARTITION=1221;
	public static final int TOK_TABLE_TYPE=1222;
	public static final int TOK_TABNAME=1223;
	public static final int TOK_TABREF=1224;
	public static final int TOK_TABSORTCOLNAMEASC=1225;
	public static final int TOK_TABSORTCOLNAMEDESC=1226;
	public static final int TOK_TABSRC=1227;
	public static final int TOK_TABTYPE=1228;
	public static final int TOK_TEMPORARY=1229;
	public static final int TOK_TIMESTAMP=1230;
	public static final int TOK_TIMESTAMPLITERAL=1231;
	public static final int TOK_TIMESTAMPLOCALTZ=1232;
	public static final int TOK_TIMESTAMPLOCALTZLITERAL=1233;
	public static final int TOK_TINYINT=1234;
	public static final int TOK_TMP_FILE=1235;
	public static final int TOK_TO=1236;
	public static final int TOK_TRANSFORM=1237;
	public static final int TOK_TRIGGER_EXPRESSION=1238;
	public static final int TOK_TRUE=1239;
	public static final int TOK_TRUNCATE=1240;
	public static final int TOK_TRUNCATETABLE=1241;
	public static final int TOK_TXN_ACCESS_MODE=1242;
	public static final int TOK_TXN_READ_ONLY=1243;
	public static final int TOK_TXN_READ_WRITE=1244;
	public static final int TOK_UNIONALL=1245;
	public static final int TOK_UNIONDISTINCT=1246;
	public static final int TOK_UNIONTYPE=1247;
	public static final int TOK_UNIQUE=1248;
	public static final int TOK_UNIQUEJOIN=1249;
	public static final int TOK_UNKNOWN=1250;
	public static final int TOK_UNLOCKDB=1251;
	public static final int TOK_UNLOCKTABLE=1252;
	public static final int TOK_UNMANAGED=1253;
	public static final int TOK_UPDATE=1254;
	public static final int TOK_UPDATE_TABLE=1255;
	public static final int TOK_URI_TYPE=1256;
	public static final int TOK_USER=1257;
	public static final int TOK_USERSCRIPTCOLNAMES=1258;
	public static final int TOK_USERSCRIPTCOLSCHEMA=1259;
	public static final int TOK_VALIDATE=1260;
	public static final int TOK_VARCHAR=1261;
	public static final int TOK_VIEWCLUSTERCOLS=1262;
	public static final int TOK_VIEWDISTRIBUTECOLS=1263;
	public static final int TOK_VIEWPARTCOLS=1264;
	public static final int TOK_VIEWSORTCOLS=1265;
	public static final int TOK_WHERE=1266;
	public static final int TOK_WINDOWDEF=1267;
	public static final int TOK_WINDOWRANGE=1268;
	public static final int TOK_WINDOWSPEC=1269;
	public static final int TOK_WINDOWVALUES=1270;
	public static final int TOK_WITHIN_GROUP=1271;
	public static final int TOK_YEAR=1272;

	// delegates
	public HiveParser_AlterClauseParser gAlterClauseParser;
	public HiveParser_SelectClauseParser gSelectClauseParser;
	public HiveParser_FromClauseParser gFromClauseParser;
	public HiveParser_IdentifiersParser gIdentifiersParser;
	public HiveParser_ResourcePlanParser gResourcePlanParser;
	public HiveParser_CreateDDLParser gCreateDDLParser;
	public HiveParser_PrepareStatementParser gPrepareStatementParser;
	public Parser[] getDelegates() {
		return new Parser[] {gAlterClauseParser, gSelectClauseParser, gFromClauseParser, gIdentifiersParser, gResourcePlanParser, gCreateDDLParser, gPrepareStatementParser};
	}

	// delegators


	public HiveParser(TokenStream input) {
		this(input, new RecognizerSharedState());
	}
	public HiveParser(TokenStream input, RecognizerSharedState state) {
		super(input, state);
		gAlterClauseParser = new HiveParser_AlterClauseParser(input, state, this);
		gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
		gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
		gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
		gResourcePlanParser = new HiveParser_ResourcePlanParser(input, state, this);
		gCreateDDLParser = new HiveParser_CreateDDLParser(input, state, this);
		gPrepareStatementParser = new HiveParser_PrepareStatementParser(input, state, this);
	}

	protected TreeAdaptor adaptor = new CommonTreeAdaptor();

	public void setTreeAdaptor(TreeAdaptor adaptor) {
		this.adaptor = adaptor;
		gAlterClauseParser.setTreeAdaptor(this.adaptor);gSelectClauseParser.setTreeAdaptor(this.adaptor);gFromClauseParser.setTreeAdaptor(this.adaptor);gIdentifiersParser.setTreeAdaptor(this.adaptor);gResourcePlanParser.setTreeAdaptor(this.adaptor);gCreateDDLParser.setTreeAdaptor(this.adaptor);gPrepareStatementParser.setTreeAdaptor(this.adaptor);
	}
	public TreeAdaptor getTreeAdaptor() {
		return adaptor;
	}
	@Override public String[] getTokenNames() { return HiveParser.tokenNames; }
	@Override public String getGrammarFileName() { return "org/apache/hadoop/hive/ql/parse/HiveParser.g"; }


	  ArrayList<ParseError> errors = new ArrayList<ParseError>();
	  Stack msgs = new Stack<String>();

	  private static HashMap<String, String> xlateMap;

	  public static void xlateMapInit() {
	    //this is used to support auto completion in CLI
	    xlateMap = new HashMap<String, String>();

	    // Keywords
	    xlateMap.put("KW_TRUE", "TRUE");
	    xlateMap.put("KW_FALSE", "FALSE");
	    xlateMap.put("KW_UNKNOWN", "UNKNOWN");
	    xlateMap.put("KW_ALL", "ALL");
	    xlateMap.put("KW_NONE", "NONE");
	    xlateMap.put("KW_AND", "AND");
	    xlateMap.put("KW_OR", "OR");
	    xlateMap.put("KW_NOT", "NOT");
	    xlateMap.put("KW_LIKE", "LIKE");

	    xlateMap.put("KW_ASC", "ASC");
	    xlateMap.put("KW_DESC", "DESC");
	    xlateMap.put("KW_NULLS", "NULLS");
	    xlateMap.put("KW_LAST", "LAST");
	    xlateMap.put("KW_ORDER", "ORDER");
	    xlateMap.put("KW_BY", "BY");
	    xlateMap.put("KW_GROUP", "GROUP");
	    xlateMap.put("KW_WHERE", "WHERE");
	    xlateMap.put("KW_FROM", "FROM");
	    xlateMap.put("KW_AS", "AS");
	    xlateMap.put("KW_SELECT", "SELECT");
	    xlateMap.put("KW_DISTINCT", "DISTINCT");
	    xlateMap.put("KW_INSERT", "INSERT");
	    xlateMap.put("KW_OVERWRITE", "OVERWRITE");
	    xlateMap.put("KW_OUTER", "OUTER");
	    xlateMap.put("KW_JOIN", "JOIN");
	    xlateMap.put("KW_LEFT", "LEFT");
	    xlateMap.put("KW_RIGHT", "RIGHT");
	    xlateMap.put("KW_FULL", "FULL");
	    xlateMap.put("KW_ON", "ON");
	    xlateMap.put("KW_PARTITION", "PARTITION");
	    xlateMap.put("KW_PARTITIONS", "PARTITIONS");
	    xlateMap.put("KW_TABLE", "TABLE");
	    xlateMap.put("KW_TABLES", "TABLES");
	    xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
	    xlateMap.put("KW_SHOW", "SHOW");
	    xlateMap.put("KW_MSCK", "MSCK");
	    xlateMap.put("KW_DIRECTORY", "DIRECTORY");
	    xlateMap.put("KW_LOCAL", "LOCAL");
	    xlateMap.put("KW_TRANSFORM", "TRANSFORM");
	    xlateMap.put("KW_USING", "USING");
	    xlateMap.put("KW_CLUSTER", "CLUSTER");
	    xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
	    xlateMap.put("KW_SORT", "SORT");
	    xlateMap.put("KW_SYNC", "SYNC");
	    xlateMap.put("KW_UNION", "UNION");
	    xlateMap.put("KW_INTERSECT", "INTERSECT");
	    xlateMap.put("KW_EXCEPT", "EXCEPT");
	    xlateMap.put("KW_LOAD", "LOAD");
	    xlateMap.put("KW_DATA", "DATA");
	    xlateMap.put("KW_INPATH", "INPATH");
	    xlateMap.put("KW_IS", "IS");
	    xlateMap.put("KW_NULL", "NULL");
	    xlateMap.put("KW_CREATE", "CREATE");
	    xlateMap.put("KW_EXTERNAL", "EXTERNAL");
	    xlateMap.put("KW_ALTER", "ALTER");
	    xlateMap.put("KW_DESCRIBE", "DESCRIBE");
	    xlateMap.put("KW_DROP", "DROP");
	    xlateMap.put("KW_RENAME", "RENAME");
	    xlateMap.put("KW_TO", "TO");
	    xlateMap.put("KW_COMMENT", "COMMENT");
	    xlateMap.put("KW_BOOLEAN", "BOOLEAN");
	    xlateMap.put("KW_TINYINT", "TINYINT");
	    xlateMap.put("KW_SMALLINT", "SMALLINT");
	    xlateMap.put("KW_INT", "INT");
	    xlateMap.put("KW_BIGINT", "BIGINT");
	    xlateMap.put("KW_FLOAT", "FLOAT");
	    xlateMap.put("KW_REAL", "REAL");
	    xlateMap.put("KW_DOUBLE", "DOUBLE");
	    xlateMap.put("KW_PRECISION", "PRECISION");
	    xlateMap.put("KW_DATE", "DATE");
	    xlateMap.put("KW_DATETIME", "DATETIME");
	    xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
	    xlateMap.put("KW_TIMESTAMPLOCALTZ", "TIMESTAMPLOCALTZ");
	    xlateMap.put("KW_TIME", "TIME");
	    xlateMap.put("KW_ZONE", "ZONE");
	    xlateMap.put("KW_STRING", "STRING");
	    xlateMap.put("KW_BINARY", "BINARY");
	    xlateMap.put("KW_ARRAY", "ARRAY");
	    xlateMap.put("KW_MAP", "MAP");
	    xlateMap.put("KW_REDUCE", "REDUCE");
	    xlateMap.put("KW_PARTITIONED", "PARTITIONED");
	    xlateMap.put("KW_CLUSTERED", "CLUSTERED");
	    xlateMap.put("KW_SORTED", "SORTED");
	    xlateMap.put("KW_INTO", "INTO");
	    xlateMap.put("KW_BUCKETS", "BUCKETS");
	    xlateMap.put("KW_ROW", "ROW");
	    xlateMap.put("KW_FORMAT", "FORMAT");
	    xlateMap.put("KW_DELIMITED", "DELIMITED");
	    xlateMap.put("KW_FIELDS", "FIELDS");
	    xlateMap.put("KW_TERMINATED", "TERMINATED");
	    xlateMap.put("KW_COLLECTION", "COLLECTION");
	    xlateMap.put("KW_ITEMS", "ITEMS");
	    xlateMap.put("KW_KEYS", "KEYS");
	    xlateMap.put("KW_KEY_TYPE", "$KEY$");
	    xlateMap.put("KW_LINES", "LINES");
	    xlateMap.put("KW_STORED", "STORED");
	    xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
	    xlateMap.put("KW_TEXTFILE", "TEXTFILE");
	    xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
	    xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
	    xlateMap.put("KW_LOCATION", "LOCATION");
	    xlateMap.put("KW_MANAGEDLOCATION", "MANAGEDLOCATION");
	    xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
	    xlateMap.put("KW_BUCKET", "BUCKET");
	    xlateMap.put("KW_OUT", "OUT");
	    xlateMap.put("KW_OF", "OF");
	    xlateMap.put("KW_CAST", "CAST");
	    xlateMap.put("KW_ADD", "ADD");
	    xlateMap.put("KW_REPLACE", "REPLACE");
	    xlateMap.put("KW_COLUMNS", "COLUMNS");
	    xlateMap.put("KW_RLIKE", "RLIKE");
	    xlateMap.put("KW_REGEXP", "REGEXP");
	    xlateMap.put("KW_TEMPORARY", "TEMPORARY");
	    xlateMap.put("KW_FUNCTION", "FUNCTION");
	    xlateMap.put("KW_FUNCTIONS", "FUNCTIONS");
	    xlateMap.put("KW_EXPLAIN", "EXPLAIN");
	    xlateMap.put("KW_DDL", "DDL");
	    xlateMap.put("KW_EXTENDED", "EXTENDED");
	    xlateMap.put("KW_DEBUG", "DEBUG");
	    xlateMap.put("KW_SERDE", "SERDE");
	    xlateMap.put("KW_WITH", "WITH");
	    xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
	    xlateMap.put("KW_LIMIT", "LIMIT");
	    xlateMap.put("KW_OFFSET", "OFFSET");
	    xlateMap.put("KW_SET", "SET");
	    xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
	    xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
	    xlateMap.put("KW_ELEM_TYPE", "$ELEM$");
	    xlateMap.put("KW_DEFINED", "DEFINED");
	    xlateMap.put("KW_SUBQUERY", "SUBQUERY");
	    xlateMap.put("KW_REWRITE", "REWRITE");
	    xlateMap.put("KW_UPDATE", "UPDATE");
	    xlateMap.put("KW_VALUES", "VALUES");
	    xlateMap.put("KW_PURGE", "PURGE");
	    xlateMap.put("KW_UNIQUE", "UNIQUE");
	    xlateMap.put("KW_PRIMARY", "PRIMARY");
	    xlateMap.put("KW_FOREIGN", "FOREIGN");
	    xlateMap.put("KW_KEY", "KEY");
	    xlateMap.put("KW_REFERENCES", "REFERENCES");
	    xlateMap.put("KW_CONSTRAINT", "CONSTRAINT");
	    xlateMap.put("KW_ENABLE", "ENABLE");
	    xlateMap.put("KW_DISABLE", "DISABLE");
	    xlateMap.put("KW_VALIDATE", "VALIDATE");
	    xlateMap.put("KW_NOVALIDATE", "NOVALIDATE");
	    xlateMap.put("KW_RELY", "RELY");
	    xlateMap.put("KW_NORELY", "NORELY");
	    xlateMap.put("KW_ABORT", "ABORT");
	    xlateMap.put("KW_TRANSACTIONS", "TRANSACTIONS");
	    xlateMap.put("KW_COMPACTIONS", "COMPACTIONS");
	    xlateMap.put("KW_COMPACT", "COMPACT");
	    xlateMap.put("KW_WAIT", "WAIT");
	    xlateMap.put("KW_KILL", "KILL");
	    xlateMap.put("KW_QUERY", "QUERY");
	    xlateMap.put("KW_RESOURCE", "RESOURCE");
	    xlateMap.put("KW_PLAN", "PLAN");
	    xlateMap.put("KW_QUERY_PARALLELISM", "QUERY_PARALLELISM");
	    xlateMap.put("KW_PLANS", "PLANS");
	    xlateMap.put("KW_ACTIVATE", "ACTIVATE");
	    xlateMap.put("KW_DEFAULT", "DEFAULT");
	    xlateMap.put("KW_CHECK", "CHECK");
	    xlateMap.put("KW_POOL", "POOL");
	    xlateMap.put("KW_ID", "ID");
	    xlateMap.put("KW_MOVE", "MOVE");
	    xlateMap.put("KW_DO", "DO");
	    xlateMap.put("KW_ALLOC_FRACTION", "ALLOC_FRACTION");
	    xlateMap.put("KW_SCHEDULING_POLICY", "SCHEDULING_POLICY");
	    xlateMap.put("KW_PATH", "PATH");
	    xlateMap.put("KW_AST", "AST");
	    xlateMap.put("KW_TRANSACTIONAL", "TRANSACTIONAL");
	    xlateMap.put("KW_MANAGED", "MANAGED");
	    xlateMap.put("KW_LEADING", "LEADING");
	    xlateMap.put("KW_TRAILING", "TRAILING");
	    xlateMap.put("KW_BOTH", "BOTH");

	    xlateMap.put("KW_TYPE", "TYPE");
	    xlateMap.put("KW_DATACONNECTOR", "CONNECTOR");
	    xlateMap.put("KW_DATACONNECTORS", "CONNECTORS");
	    xlateMap.put("KW_REMOTE", "REMOTE");
	    xlateMap.put("KW_SPEC", "SPEC");
	    xlateMap.put("KW_YEAR", "YEAR");
	    xlateMap.put("KW_MONTH", "MONTH");
	    xlateMap.put("KW_DAY", "DAY");
	    xlateMap.put("KW_HOUR", "HOUR");
	    xlateMap.put("KW_BUCKET", "BUCKET");
	    xlateMap.put("KW_TRUNCATE", "TRUNCATE");

	    // Operators
	    xlateMap.put("DOT", ".");
	    xlateMap.put("COLON", ":");
	    xlateMap.put("COMMA", ",");
	    xlateMap.put("SEMICOLON", ");");

	    xlateMap.put("LPAREN", "(");
	    xlateMap.put("RPAREN", ")");
	    xlateMap.put("LSQUARE", "[");
	    xlateMap.put("RSQUARE", "]");

	    xlateMap.put("EQUAL", "=");
	    xlateMap.put("NOTEQUAL", "<>");
	    xlateMap.put("EQUAL_NS", "<=>");
	    xlateMap.put("LESSTHANOREQUALTO", "<=");
	    xlateMap.put("LESSTHAN", "<");
	    xlateMap.put("GREATERTHANOREQUALTO", ">=");
	    xlateMap.put("GREATERTHAN", ">");

	    xlateMap.put("DIVIDE", "/");
	    xlateMap.put("PLUS", "+");
	    xlateMap.put("MINUS", "-");
	    xlateMap.put("STAR", "*");
	    xlateMap.put("MOD", "%");

	    xlateMap.put("AMPERSAND", "&");
	    xlateMap.put("TILDE", "~");
	    xlateMap.put("BITWISEOR", "|");
	    xlateMap.put("BITWISEXOR", "^");
	    xlateMap.put("CharSetLiteral", "\\'");
	  }


	  static {
	    xlateMapInit();
        tokenNamesInit();
	  }

	  public static Collection<String> getKeywords() {
	    return xlateMap.values();
	  }

	  private static String xlate(String name) {

	    String ret = xlateMap.get(name);
	    if (ret == null) {
	      ret = name;
	    }

	    return ret;
	  }

	  @Override
	  public Object recoverFromMismatchedSet(IntStream input,
	      RecognitionException re, BitSet follow) throws RecognitionException {
	    throw re;
	  }

	  @Override
	  public void displayRecognitionError(String[] tokenNames,
	      RecognitionException e) {
	    errors.add(new ParseError(this, e, tokenNames));
	  }

	  @Override
	  public String getErrorHeader(RecognitionException e) {
	    String header = null;
	    if (e.charPositionInLine < 0 && input.LT(-1) != null) {
	      Token t = input.LT(-1);
	      header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
	    } else {
	      header = super.getErrorHeader(e);
	    }

	    return header;
	  }

	  @Override
	  public String getErrorMessage(RecognitionException e, String[] tokenNames) {
	    String msg = null;

	    // Translate the token names to something that the user can understand
	    String[] xlateNames = new String[tokenNames.length];
	    for (int i = 0; i < tokenNames.length; ++i) {
	      xlateNames[i] = HiveParser.xlate(tokenNames[i]);
	    }

	    if (e instanceof NoViableAltException) {
	      @SuppressWarnings("unused")
	      NoViableAltException nvae = (NoViableAltException) e;
	      // for development, can add
	      // "decision=<<"+nvae.grammarDecisionDescription+">>"
	      // and "(decision="+nvae.decisionNumber+") and
	      // "state "+nvae.stateNumber
	      msg = "cannot recognize input near"
	              + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "")
	              + (input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "")
	              + (input.LT(3) != null ? " " + getTokenErrorDisplay(input.LT(3)) : "");
	    } else if (e instanceof MismatchedTokenException) {
	      MismatchedTokenException mte = (MismatchedTokenException) e;
	      msg = super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "":" near '" + input.LT(-1).getText()) + "'";
	    } else if (e instanceof FailedPredicateException) {
	      FailedPredicateException fpe = (FailedPredicateException) e;
	      msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
	    } else {
	      msg = super.getErrorMessage(e, xlateNames);
	    }

	    if (msgs.size() > 0) {
	      msg = msg + " in " + msgs.peek();
	    }
	    return msg;
	  }

	  public void pushMsg(String msg, RecognizerSharedState state) {
	    // ANTLR generated code does not wrap the @init code wit this backtracking check,
	    //  even if the matching @after has it. If we have parser rules with that are doing
	    // some lookahead with syntactic predicates this can cause the push() and pop() calls
	    // to become unbalanced, so make sure both push/pop check the backtracking state.
	    if (state.backtracking == 0) {
	      msgs.push(msg);
	    }
	  }

	  public void popMsg(RecognizerSharedState state) {
	    if (state.backtracking == 0) {
	      Object o = msgs.pop();
	    }
	  }

	  // counter to generate unique union aliases
	  private int aliasCounter;
	  private String generateUnionAlias() {
	    return "__u" + (++aliasCounter);
	  }
	  private char [] excludedCharForColumnName = {'.', ':'};
	  private boolean containExcludedCharForCreateTableColumnName(String input) {
	    for(char c : excludedCharForColumnName) {
	      if(input.indexOf(c)>-1) {
	        return true;
	      }
	    }
	    return false;
	  }
	  private CommonTree throwSetOpException() throws RecognitionException {
	    throw new FailedPredicateException(input, "orderByClause clusterByClause distributeByClause sortByClause limitClause can only be applied to the whole union.", "");
	  }
	  private CommonTree throwColumnNameException() throws RecognitionException {
	    throw new FailedPredicateException(input, Arrays.toString(excludedCharForColumnName) + " can not be used in column name in create table statement.", "");
	  }
	  private Configuration hiveConf;
	  public void setHiveConf(Configuration hiveConf) {
	    this.hiveConf = hiveConf;
	  }
	  protected boolean nullsLast() {
	    if(hiveConf == null){
	      return HiveConf.ConfVars.HIVE_DEFAULT_NULLS_LAST.defaultBoolVal;
	    }
	    return HiveConf.getBoolVar(hiveConf, HiveConf.ConfVars.HIVE_DEFAULT_NULLS_LAST);
	  }


	public static class statement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "statement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:894:1: statement : ( explainStatement EOF | execStatement EOF );
	public final HiveParser.statement_return statement() throws RecognitionException {
		HiveParser.statement_return retval = new HiveParser.statement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token EOF2=null;
		Token EOF4=null;
		ParserRuleReturnScope explainStatement1 =null;
		ParserRuleReturnScope execStatement3 =null;

		ASTNode EOF2_tree=null;
		ASTNode EOF4_tree=null;

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:895:2: ( explainStatement EOF | execStatement EOF )
			int alt1=2;
			int LA1_0 = input.LA(1);
			if ( (LA1_0==KW_EXPLAIN) ) {
				alt1=1;
			}
			else if ( (LA1_0==KW_ABORT||(LA1_0 >= KW_ALTER && LA1_0 <= KW_ANALYZE)||LA1_0==KW_COMMIT||LA1_0==KW_CREATE||LA1_0==KW_DELETE||(LA1_0 >= KW_DESC && LA1_0 <= KW_DESCRIBE)||LA1_0==KW_DISABLE||LA1_0==KW_DROP||LA1_0==KW_ENABLE||LA1_0==KW_EXECUTE||LA1_0==KW_EXPORT||LA1_0==KW_FROM||LA1_0==KW_GRANT||LA1_0==KW_IMPORT||LA1_0==KW_INSERT||LA1_0==KW_KILL||LA1_0==KW_LOAD||LA1_0==KW_LOCK||LA1_0==KW_MAP||LA1_0==KW_MERGE||LA1_0==KW_MSCK||LA1_0==KW_PREPARE||LA1_0==KW_REDUCE||LA1_0==KW_RELOAD||(LA1_0 >= KW_REPL && LA1_0 <= KW_REPLACE)||LA1_0==KW_REVOKE||LA1_0==KW_ROLLBACK||LA1_0==KW_SELECT||LA1_0==KW_SET||LA1_0==KW_SHOW||LA1_0==KW_START||LA1_0==KW_TRUNCATE||LA1_0==KW_UNLOCK||LA1_0==KW_UPDATE||LA1_0==KW_USE||LA1_0==KW_VALUES||LA1_0==KW_WITH||LA1_0==LPAREN) ) {
				alt1=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 1, 0, input);
				throw nvae;
			}

			switch (alt1) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:895:4: explainStatement EOF
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_explainStatement_in_statement1527);
					explainStatement1=explainStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, explainStatement1.getTree());

					EOF2=(Token)match(input,EOF,FOLLOW_EOF_in_statement1529); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EOF2_tree = (ASTNode)adaptor.create(EOF2);
					adaptor.addChild(root_0, EOF2_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:896:4: execStatement EOF
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_execStatement_in_statement1534);
					execStatement3=execStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, execStatement3.getTree());

					EOF4=(Token)match(input,EOF,FOLLOW_EOF_in_statement1536); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EOF4_tree = (ASTNode)adaptor.create(EOF4);
					adaptor.addChild(root_0, EOF4_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "statement"


	public static class explainStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "explainStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:899:1: explainStatement : KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) ;
	public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
		HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXPLAIN5=null;
		Token KW_REWRITE8=null;
		ParserRuleReturnScope explainOption6 =null;
		ParserRuleReturnScope execStatement7 =null;
		ParserRuleReturnScope queryStatementExpression9 =null;

		ASTNode KW_EXPLAIN5_tree=null;
		ASTNode KW_REWRITE8_tree=null;
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
		RewriteRuleTokenStream stream_KW_EXPLAIN=new RewriteRuleTokenStream(adaptor,"token KW_EXPLAIN");
		RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");
		RewriteRuleSubtreeStream stream_explainOption=new RewriteRuleSubtreeStream(adaptor,"rule explainOption");
		RewriteRuleSubtreeStream stream_execStatement=new RewriteRuleSubtreeStream(adaptor,"rule execStatement");

		 pushMsg("explain statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:2: ( KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:4: KW_EXPLAIN ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
			{
			KW_EXPLAIN5=(Token)match(input,KW_EXPLAIN,FOLLOW_KW_EXPLAIN_in_explainStatement1557); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXPLAIN.add(KW_EXPLAIN5);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:902:15: ( ( explainOption )* execStatement -> ^( TOK_EXPLAIN execStatement ( explainOption )* ) | KW_REWRITE queryStatementExpression -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression ) )
			int alt3=2;
			int LA3_0 = input.LA(1);
			if ( (LA3_0==KW_ABORT||(LA3_0 >= KW_ALTER && LA3_0 <= KW_ANALYZE)||LA3_0==KW_AST||LA3_0==KW_AUTHORIZATION||LA3_0==KW_CBO||LA3_0==KW_COMMIT||LA3_0==KW_CREATE||(LA3_0 >= KW_DDL && LA3_0 <= KW_DEBUG)||LA3_0==KW_DELETE||(LA3_0 >= KW_DEPENDENCY && LA3_0 <= KW_DESCRIBE)||LA3_0==KW_DISABLE||LA3_0==KW_DROP||LA3_0==KW_ENABLE||LA3_0==KW_EXECUTE||LA3_0==KW_EXPORT||LA3_0==KW_EXTENDED||(LA3_0 >= KW_FORMATTED && LA3_0 <= KW_FROM)||LA3_0==KW_GRANT||LA3_0==KW_IMPORT||LA3_0==KW_INSERT||LA3_0==KW_KILL||LA3_0==KW_LOAD||(LA3_0 >= KW_LOCK && LA3_0 <= KW_LOGICAL)||LA3_0==KW_MAP||LA3_0==KW_MERGE||LA3_0==KW_MSCK||LA3_0==KW_PREPARE||LA3_0==KW_REDUCE||LA3_0==KW_RELOAD||LA3_0==KW_REOPTIMIZATION||(LA3_0 >= KW_REPL && LA3_0 <= KW_REPLACE)||LA3_0==KW_REVOKE||LA3_0==KW_ROLLBACK||LA3_0==KW_SELECT||LA3_0==KW_SET||LA3_0==KW_SHOW||LA3_0==KW_START||LA3_0==KW_TRUNCATE||LA3_0==KW_UNLOCK||LA3_0==KW_UPDATE||LA3_0==KW_USE||LA3_0==KW_VALUES||LA3_0==KW_VECTORIZATION||LA3_0==KW_WITH||LA3_0==LPAREN) ) {
				alt3=1;
			}
			else if ( (LA3_0==KW_REWRITE) ) {
				alt3=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 3, 0, input);
				throw nvae;
			}

			switch (alt3) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:6: ( explainOption )* execStatement
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:6: ( explainOption )*
					loop2:
					while (true) {
						int alt2=2;
						alt2 = dfa2.predict(input);
						switch (alt2) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:6: explainOption
							{
							pushFollow(FOLLOW_explainOption_in_explainStatement1566);
							explainOption6=explainOption();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_explainOption.add(explainOption6.getTree());
							}
							break;

						default :
							break loop2;
						}
					}

					pushFollow(FOLLOW_execStatement_in_explainStatement1569);
					execStatement7=execStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_execStatement.add(execStatement7.getTree());
					// AST REWRITE
					// elements: execStatement, explainOption
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 903:35: -> ^( TOK_EXPLAIN execStatement ( explainOption )* )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:38: ^( TOK_EXPLAIN execStatement ( explainOption )* )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN"), root_1);
						adaptor.addChild(root_1, stream_execStatement.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:903:66: ( explainOption )*
						while ( stream_explainOption.hasNext() ) {
							adaptor.addChild(root_1, stream_explainOption.nextTree());
						}
						stream_explainOption.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:905:9: KW_REWRITE queryStatementExpression
					{
					KW_REWRITE8=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_explainStatement1600); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE8);

					pushFollow(FOLLOW_queryStatementExpression_in_explainStatement1602);
					queryStatementExpression9=queryStatementExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression9.getTree());
					// AST REWRITE
					// elements: queryStatementExpression
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 905:45: -> ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:905:48: ^( TOK_EXPLAIN_SQ_REWRITE queryStatementExpression )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPLAIN_SQ_REWRITE, "TOK_EXPLAIN_SQ_REWRITE"), root_1);
						adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "explainStatement"


	public static class explainOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "explainOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:909:1: explainOption : ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_CBO ( KW_COST | KW_JOINCOST )? | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE | KW_REOPTIMIZATION | KW_LOCKS | KW_AST | ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? ) | KW_DEBUG | KW_DDL );
	public final HiveParser.explainOption_return explainOption() throws RecognitionException {
		HiveParser.explainOption_return retval = new HiveParser.explainOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXTENDED10=null;
		Token KW_FORMATTED11=null;
		Token KW_DEPENDENCY12=null;
		Token KW_CBO13=null;
		Token set14=null;
		Token KW_LOGICAL15=null;
		Token KW_AUTHORIZATION16=null;
		Token KW_ANALYZE17=null;
		Token KW_REOPTIMIZATION18=null;
		Token KW_LOCKS19=null;
		Token KW_AST20=null;
		Token KW_VECTORIZATION21=null;
		Token KW_DEBUG24=null;
		Token KW_DDL25=null;
		ParserRuleReturnScope vectorizationOnly22 =null;
		ParserRuleReturnScope vectorizatonDetail23 =null;

		ASTNode KW_EXTENDED10_tree=null;
		ASTNode KW_FORMATTED11_tree=null;
		ASTNode KW_DEPENDENCY12_tree=null;
		ASTNode KW_CBO13_tree=null;
		ASTNode set14_tree=null;
		ASTNode KW_LOGICAL15_tree=null;
		ASTNode KW_AUTHORIZATION16_tree=null;
		ASTNode KW_ANALYZE17_tree=null;
		ASTNode KW_REOPTIMIZATION18_tree=null;
		ASTNode KW_LOCKS19_tree=null;
		ASTNode KW_AST20_tree=null;
		ASTNode KW_VECTORIZATION21_tree=null;
		ASTNode KW_DEBUG24_tree=null;
		ASTNode KW_DDL25_tree=null;

		 msgs.push("explain option"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:5: ( KW_EXTENDED | KW_FORMATTED | KW_DEPENDENCY | KW_CBO ( KW_COST | KW_JOINCOST )? | KW_LOGICAL | KW_AUTHORIZATION | KW_ANALYZE | KW_REOPTIMIZATION | KW_LOCKS | KW_AST | ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? ) | KW_DEBUG | KW_DDL )
			int alt7=13;
			switch ( input.LA(1) ) {
			case KW_EXTENDED:
				{
				alt7=1;
				}
				break;
			case KW_FORMATTED:
				{
				alt7=2;
				}
				break;
			case KW_DEPENDENCY:
				{
				alt7=3;
				}
				break;
			case KW_CBO:
				{
				alt7=4;
				}
				break;
			case KW_LOGICAL:
				{
				alt7=5;
				}
				break;
			case KW_AUTHORIZATION:
				{
				alt7=6;
				}
				break;
			case KW_ANALYZE:
				{
				alt7=7;
				}
				break;
			case KW_REOPTIMIZATION:
				{
				alt7=8;
				}
				break;
			case KW_LOCKS:
				{
				alt7=9;
				}
				break;
			case KW_AST:
				{
				alt7=10;
				}
				break;
			case KW_VECTORIZATION:
				{
				alt7=11;
				}
				break;
			case KW_DEBUG:
				{
				alt7=12;
				}
				break;
			case KW_DDL:
				{
				alt7=13;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 7, 0, input);
				throw nvae;
			}
			switch (alt7) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:912:7: KW_EXTENDED
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_EXTENDED10=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_explainOption1642); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_EXTENDED10_tree = (ASTNode)adaptor.create(KW_EXTENDED10);
					adaptor.addChild(root_0, KW_EXTENDED10_tree);
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:913:7: KW_FORMATTED
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_FORMATTED11=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_explainOption1650); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_FORMATTED11_tree = (ASTNode)adaptor.create(KW_FORMATTED11);
					adaptor.addChild(root_0, KW_FORMATTED11_tree);
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:914:7: KW_DEPENDENCY
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DEPENDENCY12=(Token)match(input,KW_DEPENDENCY,FOLLOW_KW_DEPENDENCY_in_explainOption1658); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DEPENDENCY12_tree = (ASTNode)adaptor.create(KW_DEPENDENCY12);
					adaptor.addChild(root_0, KW_DEPENDENCY12_tree);
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:7: KW_CBO ( KW_COST | KW_JOINCOST )?
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_CBO13=(Token)match(input,KW_CBO,FOLLOW_KW_CBO_in_explainOption1666); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_CBO13_tree = (ASTNode)adaptor.create(KW_CBO13);
					adaptor.addChild(root_0, KW_CBO13_tree);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:915:14: ( KW_COST | KW_JOINCOST )?
					int alt4=2;
					int LA4_0 = input.LA(1);
					if ( (LA4_0==KW_COST||LA4_0==KW_JOINCOST) ) {
						alt4=1;
					}
					switch (alt4) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:
							{
							set14=input.LT(1);
							if ( input.LA(1)==KW_COST||input.LA(1)==KW_JOINCOST ) {
								input.consume();
								if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set14));
								state.errorRecovery=false;
								state.failed=false;
							}
							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								MismatchedSetException mse = new MismatchedSetException(null,input);
								throw mse;
							}
							}
							break;

					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:916:7: KW_LOGICAL
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LOGICAL15=(Token)match(input,KW_LOGICAL,FOLLOW_KW_LOGICAL_in_explainOption1683); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LOGICAL15_tree = (ASTNode)adaptor.create(KW_LOGICAL15);
					adaptor.addChild(root_0, KW_LOGICAL15_tree);
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:917:7: KW_AUTHORIZATION
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_AUTHORIZATION16=(Token)match(input,KW_AUTHORIZATION,FOLLOW_KW_AUTHORIZATION_in_explainOption1691); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_AUTHORIZATION16_tree = (ASTNode)adaptor.create(KW_AUTHORIZATION16);
					adaptor.addChild(root_0, KW_AUTHORIZATION16_tree);
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:918:7: KW_ANALYZE
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_ANALYZE17=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_explainOption1699); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_ANALYZE17_tree = (ASTNode)adaptor.create(KW_ANALYZE17);
					adaptor.addChild(root_0, KW_ANALYZE17_tree);
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:919:7: KW_REOPTIMIZATION
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_REOPTIMIZATION18=(Token)match(input,KW_REOPTIMIZATION,FOLLOW_KW_REOPTIMIZATION_in_explainOption1707); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_REOPTIMIZATION18_tree = (ASTNode)adaptor.create(KW_REOPTIMIZATION18);
					adaptor.addChild(root_0, KW_REOPTIMIZATION18_tree);
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:920:7: KW_LOCKS
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LOCKS19=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_explainOption1715); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LOCKS19_tree = (ASTNode)adaptor.create(KW_LOCKS19);
					adaptor.addChild(root_0, KW_LOCKS19_tree);
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:921:7: KW_AST
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_AST20=(Token)match(input,KW_AST,FOLLOW_KW_AST_in_explainOption1723); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_AST20_tree = (ASTNode)adaptor.create(KW_AST20);
					adaptor.addChild(root_0, KW_AST20_tree);
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:7: ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:7: ( KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )? )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:8: KW_VECTORIZATION ( vectorizationOnly )? ( vectorizatonDetail )?
					{
					KW_VECTORIZATION21=(Token)match(input,KW_VECTORIZATION,FOLLOW_KW_VECTORIZATION_in_explainOption1732); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_VECTORIZATION21_tree = (ASTNode)adaptor.create(KW_VECTORIZATION21);
					adaptor.addChild(root_0, KW_VECTORIZATION21_tree);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:25: ( vectorizationOnly )?
					int alt5=2;
					int LA5_0 = input.LA(1);
					if ( (LA5_0==KW_ONLY) ) {
						alt5=1;
					}
					switch (alt5) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:25: vectorizationOnly
							{
							pushFollow(FOLLOW_vectorizationOnly_in_explainOption1734);
							vectorizationOnly22=vectorizationOnly();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, vectorizationOnly22.getTree());

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:44: ( vectorizatonDetail )?
					int alt6=2;
					int LA6_0 = input.LA(1);
					if ( (LA6_0==KW_DETAIL||LA6_0==KW_EXPRESSION||LA6_0==KW_OPERATOR||LA6_0==KW_SUMMARY) ) {
						alt6=1;
					}
					switch (alt6) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:922:44: vectorizatonDetail
							{
							pushFollow(FOLLOW_vectorizatonDetail_in_explainOption1737);
							vectorizatonDetail23=vectorizatonDetail();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, vectorizatonDetail23.getTree());

							}
							break;

					}

					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:923:7: KW_DEBUG
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DEBUG24=(Token)match(input,KW_DEBUG,FOLLOW_KW_DEBUG_in_explainOption1747); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DEBUG24_tree = (ASTNode)adaptor.create(KW_DEBUG24);
					adaptor.addChild(root_0, KW_DEBUG24_tree);
					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:924:7: KW_DDL
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_DDL25=(Token)match(input,KW_DDL,FOLLOW_KW_DDL_in_explainOption1755); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_DDL25_tree = (ASTNode)adaptor.create(KW_DDL25);
					adaptor.addChild(root_0, KW_DDL25_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "explainOption"


	public static class vectorizationOnly_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "vectorizationOnly"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:927:1: vectorizationOnly : KW_ONLY -> ^( TOK_ONLY ) ;
	public final HiveParser.vectorizationOnly_return vectorizationOnly() throws RecognitionException {
		HiveParser.vectorizationOnly_return retval = new HiveParser.vectorizationOnly_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ONLY26=null;

		ASTNode KW_ONLY26_tree=null;
		RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");

		 pushMsg("vectorization's only clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:930:5: ( KW_ONLY -> ^( TOK_ONLY ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:930:7: KW_ONLY
			{
			KW_ONLY26=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_vectorizationOnly1782); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY26);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 931:5: -> ^( TOK_ONLY )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:931:8: ^( TOK_ONLY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ONLY, "TOK_ONLY"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "vectorizationOnly"


	public static class vectorizatonDetail_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "vectorizatonDetail"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:934:1: vectorizatonDetail : ( KW_SUMMARY -> ^( TOK_SUMMARY ) | KW_OPERATOR -> ^( TOK_OPERATOR ) | KW_EXPRESSION -> ^( TOK_EXPRESSION ) | KW_DETAIL -> ^( TOK_DETAIL ) );
	public final HiveParser.vectorizatonDetail_return vectorizatonDetail() throws RecognitionException {
		HiveParser.vectorizatonDetail_return retval = new HiveParser.vectorizatonDetail_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SUMMARY27=null;
		Token KW_OPERATOR28=null;
		Token KW_EXPRESSION29=null;
		Token KW_DETAIL30=null;

		ASTNode KW_SUMMARY27_tree=null;
		ASTNode KW_OPERATOR28_tree=null;
		ASTNode KW_EXPRESSION29_tree=null;
		ASTNode KW_DETAIL30_tree=null;
		RewriteRuleTokenStream stream_KW_SUMMARY=new RewriteRuleTokenStream(adaptor,"token KW_SUMMARY");
		RewriteRuleTokenStream stream_KW_DETAIL=new RewriteRuleTokenStream(adaptor,"token KW_DETAIL");
		RewriteRuleTokenStream stream_KW_OPERATOR=new RewriteRuleTokenStream(adaptor,"token KW_OPERATOR");
		RewriteRuleTokenStream stream_KW_EXPRESSION=new RewriteRuleTokenStream(adaptor,"token KW_EXPRESSION");

		 pushMsg("vectorization's detail level clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:937:5: ( KW_SUMMARY -> ^( TOK_SUMMARY ) | KW_OPERATOR -> ^( TOK_OPERATOR ) | KW_EXPRESSION -> ^( TOK_EXPRESSION ) | KW_DETAIL -> ^( TOK_DETAIL ) )
			int alt8=4;
			switch ( input.LA(1) ) {
			case KW_SUMMARY:
				{
				alt8=1;
				}
				break;
			case KW_OPERATOR:
				{
				alt8=2;
				}
				break;
			case KW_EXPRESSION:
				{
				alt8=3;
				}
				break;
			case KW_DETAIL:
				{
				alt8=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 8, 0, input);
				throw nvae;
			}
			switch (alt8) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:937:7: KW_SUMMARY
					{
					KW_SUMMARY27=(Token)match(input,KW_SUMMARY,FOLLOW_KW_SUMMARY_in_vectorizatonDetail1819); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SUMMARY.add(KW_SUMMARY27);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 938:5: -> ^( TOK_SUMMARY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:938:8: ^( TOK_SUMMARY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUMMARY, "TOK_SUMMARY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:939:7: KW_OPERATOR
					{
					KW_OPERATOR28=(Token)match(input,KW_OPERATOR,FOLLOW_KW_OPERATOR_in_vectorizatonDetail1837); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OPERATOR.add(KW_OPERATOR28);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 940:5: -> ^( TOK_OPERATOR )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:940:8: ^( TOK_OPERATOR )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_OPERATOR, "TOK_OPERATOR"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:941:7: KW_EXPRESSION
					{
					KW_EXPRESSION29=(Token)match(input,KW_EXPRESSION,FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1855); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXPRESSION.add(KW_EXPRESSION29);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 942:5: -> ^( TOK_EXPRESSION )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:942:8: ^( TOK_EXPRESSION )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPRESSION, "TOK_EXPRESSION"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:943:7: KW_DETAIL
					{
					KW_DETAIL30=(Token)match(input,KW_DETAIL,FOLLOW_KW_DETAIL_in_vectorizatonDetail1873); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DETAIL.add(KW_DETAIL30);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 944:5: -> ^( TOK_DETAIL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:944:8: ^( TOK_DETAIL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DETAIL, "TOK_DETAIL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "vectorizatonDetail"


	public static class execStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "execStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:947:1: execStatement : ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement | prepareStatement | executeStatement );
	public final HiveParser.execStatement_return execStatement() throws RecognitionException {
		HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope queryStatementExpression31 =null;
		ParserRuleReturnScope loadStatement32 =null;
		ParserRuleReturnScope exportStatement33 =null;
		ParserRuleReturnScope importStatement34 =null;
		ParserRuleReturnScope replDumpStatement35 =null;
		ParserRuleReturnScope replLoadStatement36 =null;
		ParserRuleReturnScope replStatusStatement37 =null;
		ParserRuleReturnScope ddlStatement38 =null;
		ParserRuleReturnScope deleteStatement39 =null;
		ParserRuleReturnScope updateStatement40 =null;
		ParserRuleReturnScope sqlTransactionStatement41 =null;
		ParserRuleReturnScope mergeStatement42 =null;
		ParserRuleReturnScope prepareStatement43 =null;
		ParserRuleReturnScope executeStatement44 =null;


		 pushMsg("statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:950:5: ( queryStatementExpression | loadStatement | exportStatement | importStatement | replDumpStatement | replLoadStatement | replStatusStatement | ddlStatement | deleteStatement | updateStatement | sqlTransactionStatement | mergeStatement | prepareStatement | executeStatement )
			int alt9=14;
			switch ( input.LA(1) ) {
			case KW_FROM:
			case KW_INSERT:
			case KW_MAP:
			case KW_REDUCE:
			case KW_SELECT:
			case KW_VALUES:
			case KW_WITH:
			case LPAREN:
				{
				alt9=1;
				}
				break;
			case KW_LOAD:
				{
				alt9=2;
				}
				break;
			case KW_EXPORT:
				{
				alt9=3;
				}
				break;
			case KW_IMPORT:
				{
				alt9=4;
				}
				break;
			case KW_REPL:
				{
				switch ( input.LA(2) ) {
				case KW_DUMP:
					{
					alt9=5;
					}
					break;
				case KW_LOAD:
					{
					alt9=6;
					}
					break;
				case KW_STATUS:
					{
					alt9=7;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 9, 12, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
				}
				break;
			case KW_ABORT:
			case KW_ALTER:
			case KW_ANALYZE:
			case KW_CREATE:
			case KW_DESC:
			case KW_DESCRIBE:
			case KW_DISABLE:
			case KW_DROP:
			case KW_ENABLE:
			case KW_GRANT:
			case KW_KILL:
			case KW_LOCK:
			case KW_MSCK:
			case KW_RELOAD:
			case KW_REPLACE:
			case KW_REVOKE:
			case KW_SHOW:
			case KW_TRUNCATE:
			case KW_UNLOCK:
			case KW_USE:
				{
				alt9=8;
				}
				break;
			case KW_SET:
				{
				int LA9_28 = input.LA(2);
				if ( (LA9_28==KW_ROLE) ) {
					alt9=8;
				}
				else if ( (LA9_28==KW_AUTOCOMMIT) ) {
					alt9=11;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 9, 28, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_DELETE:
				{
				alt9=9;
				}
				break;
			case KW_UPDATE:
				{
				alt9=10;
				}
				break;
			case KW_COMMIT:
			case KW_ROLLBACK:
			case KW_START:
				{
				alt9=11;
				}
				break;
			case KW_MERGE:
				{
				alt9=12;
				}
				break;
			case KW_PREPARE:
				{
				alt9=13;
				}
				break;
			case KW_EXECUTE:
				{
				alt9=14;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 9, 0, input);
				throw nvae;
			}
			switch (alt9) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:950:7: queryStatementExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_queryStatementExpression_in_execStatement1910);
					queryStatementExpression31=queryStatementExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, queryStatementExpression31.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:951:7: loadStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_loadStatement_in_execStatement1918);
					loadStatement32=loadStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, loadStatement32.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:952:7: exportStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_exportStatement_in_execStatement1926);
					exportStatement33=exportStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, exportStatement33.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:953:7: importStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_importStatement_in_execStatement1934);
					importStatement34=importStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, importStatement34.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:954:7: replDumpStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replDumpStatement_in_execStatement1942);
					replDumpStatement35=replDumpStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replDumpStatement35.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:955:7: replLoadStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replLoadStatement_in_execStatement1950);
					replLoadStatement36=replLoadStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replLoadStatement36.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:956:7: replStatusStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_replStatusStatement_in_execStatement1958);
					replStatusStatement37=replStatusStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, replStatusStatement37.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:957:7: ddlStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_ddlStatement_in_execStatement1966);
					ddlStatement38=ddlStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, ddlStatement38.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:958:7: deleteStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_deleteStatement_in_execStatement1974);
					deleteStatement39=deleteStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, deleteStatement39.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:959:7: updateStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_updateStatement_in_execStatement1982);
					updateStatement40=updateStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, updateStatement40.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:960:7: sqlTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_sqlTransactionStatement_in_execStatement1990);
					sqlTransactionStatement41=sqlTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, sqlTransactionStatement41.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:961:7: mergeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_mergeStatement_in_execStatement1998);
					mergeStatement42=mergeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, mergeStatement42.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:962:7: prepareStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_prepareStatement_in_execStatement2006);
					prepareStatement43=prepareStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, prepareStatement43.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:963:7: executeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_executeStatement_in_execStatement2014);
					executeStatement44=executeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, executeStatement44.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "execStatement"


	public static class loadStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "loadStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:966:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )? -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? ) ;
	public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
		HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token islocal=null;
		Token path=null;
		Token isoverwrite=null;
		Token KW_LOAD45=null;
		Token KW_DATA46=null;
		Token KW_INPATH47=null;
		Token KW_INTO48=null;
		Token KW_TABLE49=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope inputFileFormat50 =null;

		ASTNode islocal_tree=null;
		ASTNode path_tree=null;
		ASTNode isoverwrite_tree=null;
		ASTNode KW_LOAD45_tree=null;
		ASTNode KW_DATA46_tree=null;
		ASTNode KW_INPATH47_tree=null;
		ASTNode KW_INTO48_tree=null;
		ASTNode KW_TABLE49_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_INPATH=new RewriteRuleTokenStream(adaptor,"token KW_INPATH");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
		RewriteRuleTokenStream stream_KW_DATA=new RewriteRuleTokenStream(adaptor,"token KW_DATA");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleSubtreeStream stream_inputFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule inputFileFormat");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("load statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )? -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) ( inputFileFormat )?
			{
			KW_LOAD45=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_loadStatement2041); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD45);

			KW_DATA46=(Token)match(input,KW_DATA,FOLLOW_KW_DATA_in_loadStatement2043); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DATA.add(KW_DATA46);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:23: (islocal= KW_LOCAL )?
			int alt10=2;
			int LA10_0 = input.LA(1);
			if ( (LA10_0==KW_LOCAL) ) {
				alt10=1;
			}
			switch (alt10) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:24: islocal= KW_LOCAL
					{
					islocal=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_loadStatement2048); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCAL.add(islocal);

					}
					break;

			}

			KW_INPATH47=(Token)match(input,KW_INPATH,FOLLOW_KW_INPATH_in_loadStatement2052); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INPATH.add(KW_INPATH47);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:53: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:54: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_loadStatement2057); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:74: (isoverwrite= KW_OVERWRITE )?
			int alt11=2;
			int LA11_0 = input.LA(1);
			if ( (LA11_0==KW_OVERWRITE) ) {
				alt11=1;
			}
			switch (alt11) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:75: isoverwrite= KW_OVERWRITE
					{
					isoverwrite=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_loadStatement2063); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(isoverwrite);

					}
					break;

			}

			KW_INTO48=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_loadStatement2067); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO48);

			KW_TABLE49=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_loadStatement2069); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE49);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:119: (tab= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:120: tab= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_loadStatement2074);
			tab=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:142: ( inputFileFormat )?
			int alt12=2;
			int LA12_0 = input.LA(1);
			if ( (LA12_0==KW_INPUTFORMAT) ) {
				alt12=1;
			}
			switch (alt12) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:969:142: inputFileFormat
					{
					pushFollow(FOLLOW_inputFileFormat_in_loadStatement2077);
					inputFileFormat50=inputFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_inputFileFormat.add(inputFileFormat50.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: path, tab, inputFileFormat, islocal, isoverwrite
			// token labels: islocal, path, isoverwrite
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_islocal=new RewriteRuleTokenStream(adaptor,"token islocal",islocal);
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleTokenStream stream_isoverwrite=new RewriteRuleTokenStream(adaptor,"token isoverwrite",isoverwrite);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 970:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:970:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ( inputFileFormat )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOAD, "TOK_LOAD"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				adaptor.addChild(root_1, stream_tab.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:970:31: ( $islocal)?
				if ( stream_islocal.hasNext() ) {
					adaptor.addChild(root_1, stream_islocal.nextNode());
				}
				stream_islocal.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:970:41: ( $isoverwrite)?
				if ( stream_isoverwrite.hasNext() ) {
					adaptor.addChild(root_1, stream_isoverwrite.nextNode());
				}
				stream_isoverwrite.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:970:54: ( inputFileFormat )?
				if ( stream_inputFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_inputFileFormat.nextTree());
				}
				stream_inputFileFormat.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "loadStatement"


	public static class replicationClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replicationClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:973:1: replicationClause : KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) ;
	public final HiveParser.replicationClause_return replicationClause() throws RecognitionException {
		HiveParser.replicationClause_return retval = new HiveParser.replicationClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token isMetadataOnly=null;
		Token replId=null;
		Token KW_FOR51=null;
		Token KW_REPLICATION52=null;
		Token LPAREN53=null;
		Token RPAREN54=null;

		ASTNode isMetadataOnly_tree=null;
		ASTNode replId_tree=null;
		ASTNode KW_FOR51_tree=null;
		ASTNode KW_REPLICATION52_tree=null;
		ASTNode LPAREN53_tree=null;
		ASTNode RPAREN54_tree=null;
		RewriteRuleTokenStream stream_KW_REPLICATION=new RewriteRuleTokenStream(adaptor,"token KW_REPLICATION");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");

		 pushMsg("replication clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:5: ( KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:7: KW_FOR (isMetadataOnly= KW_METADATA )? KW_REPLICATION LPAREN (replId= StringLiteral ) RPAREN
			{
			KW_FOR51=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_replicationClause2132); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR51);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:14: (isMetadataOnly= KW_METADATA )?
			int alt13=2;
			int LA13_0 = input.LA(1);
			if ( (LA13_0==KW_METADATA) ) {
				alt13=1;
			}
			switch (alt13) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:15: isMetadataOnly= KW_METADATA
					{
					isMetadataOnly=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_replicationClause2137); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_METADATA.add(isMetadataOnly);

					}
					break;

			}

			KW_REPLICATION52=(Token)match(input,KW_REPLICATION,FOLLOW_KW_REPLICATION_in_replicationClause2141); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPLICATION.add(KW_REPLICATION52);

			LPAREN53=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replicationClause2143); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN53);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:66: (replId= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:976:67: replId= StringLiteral
			{
			replId=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replicationClause2148); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(replId);

			}

			RPAREN54=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replicationClause2151); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN54);

			// AST REWRITE
			// elements: isMetadataOnly, replId
			// token labels: replId, isMetadataOnly
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_replId=new RewriteRuleTokenStream(adaptor,"token replId",replId);
			RewriteRuleTokenStream stream_isMetadataOnly=new RewriteRuleTokenStream(adaptor,"token isMetadataOnly",isMetadataOnly);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 977:5: -> ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:977:8: ^( TOK_REPLICATION $replId ( $isMetadataOnly)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPLICATION, "TOK_REPLICATION"), root_1);
				adaptor.addChild(root_1, stream_replId.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:977:35: ( $isMetadataOnly)?
				if ( stream_isMetadataOnly.hasNext() ) {
					adaptor.addChild(root_1, stream_isMetadataOnly.nextNode());
				}
				stream_isMetadataOnly.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replicationClause"


	public static class exportStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "exportStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:980:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) ;
	public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
		HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_EXPORT55=null;
		Token KW_TABLE56=null;
		Token KW_TO57=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope replicationClause58 =null;

		ASTNode path_tree=null;
		ASTNode KW_EXPORT55_tree=null;
		ASTNode KW_TABLE56_tree=null;
		ASTNode KW_TO57_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_EXPORT=new RewriteRuleTokenStream(adaptor,"token KW_EXPORT");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");

		 pushMsg("export statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )? -> ^( TOK_EXPORT $tab $path ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:983:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) ( replicationClause )?
			{
			KW_EXPORT55=(Token)match(input,KW_EXPORT,FOLLOW_KW_EXPORT_in_exportStatement2195); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXPORT.add(KW_EXPORT55);

			KW_TABLE56=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_exportStatement2203); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE56);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:984:16: (tab= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:984:17: tab= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_exportStatement2208);
			tab=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
			}

			KW_TO57=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_exportStatement2217); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO57);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:985:13: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:985:14: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_exportStatement2222); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:986:7: ( replicationClause )?
			int alt14=2;
			int LA14_0 = input.LA(1);
			if ( (LA14_0==KW_FOR) ) {
				alt14=1;
			}
			switch (alt14) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:986:7: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_exportStatement2231);
					replicationClause58=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause58.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: path, replicationClause, tab
			// token labels: path
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 987:5: -> ^( TOK_EXPORT $tab $path ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:987:8: ^( TOK_EXPORT $tab $path ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXPORT, "TOK_EXPORT"), root_1);
				adaptor.addChild(root_1, stream_tab.nextTree());
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:987:32: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "exportStatement"


	public static class importStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "importStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:990:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) ;
	public final HiveParser.importStatement_return importStatement() throws RecognitionException {
		HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token ext=null;
		Token path=null;
		Token KW_IMPORT59=null;
		Token KW_TABLE60=null;
		Token KW_FROM61=null;
		ParserRuleReturnScope tab =null;
		ParserRuleReturnScope tableLocation62 =null;

		ASTNode ext_tree=null;
		ASTNode path_tree=null;
		ASTNode KW_IMPORT59_tree=null;
		ASTNode KW_TABLE60_tree=null;
		ASTNode KW_FROM61_tree=null;
		RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_IMPORT=new RewriteRuleTokenStream(adaptor,"token KW_IMPORT");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("import statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:993:8: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:993:10: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )?
			{
			KW_IMPORT59=(Token)match(input,KW_IMPORT,FOLLOW_KW_IMPORT_in_importStatement2281); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IMPORT.add(KW_IMPORT59);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:10: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
			int alt16=2;
			int LA16_0 = input.LA(1);
			if ( (LA16_0==KW_EXTERNAL||LA16_0==KW_TABLE) ) {
				alt16=1;
			}
			switch (alt16) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:11: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:11: (ext= KW_EXTERNAL )?
					int alt15=2;
					int LA15_0 = input.LA(1);
					if ( (LA15_0==KW_EXTERNAL) ) {
						alt15=1;
					}
					switch (alt15) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:12: ext= KW_EXTERNAL
							{
							ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_importStatement2296); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTERNAL.add(ext);

							}
							break;

					}

					KW_TABLE60=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_importStatement2300); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE60);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:39: (tab= tableOrPartition )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:994:40: tab= tableOrPartition
					{
					pushFollow(FOLLOW_tableOrPartition_in_importStatement2305);
					tab=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tab.getTree());
					}

					}
					break;

			}

			KW_FROM61=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_importStatement2319); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM61);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:995:18: (path= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:995:19: path= StringLiteral
			{
			path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_importStatement2324); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(path);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:996:10: ( tableLocation )?
			int alt17=2;
			int LA17_0 = input.LA(1);
			if ( (LA17_0==KW_LOCATION) ) {
				alt17=1;
			}
			switch (alt17) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:996:10: tableLocation
					{
					pushFollow(FOLLOW_tableLocation_in_importStatement2336);
					tableLocation62=tableLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation62.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: ext, tab, path, tableLocation
			// token labels: ext, path
			// rule labels: tab, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
			RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
			RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 997:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:997:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IMPORT, "TOK_IMPORT"), root_1);
				adaptor.addChild(root_1, stream_path.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:997:28: ( $tab)?
				if ( stream_tab.hasNext() ) {
					adaptor.addChild(root_1, stream_tab.nextTree());
				}
				stream_tab.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:997:34: ( $ext)?
				if ( stream_ext.hasNext() ) {
					adaptor.addChild(root_1, stream_ext.nextNode());
				}
				stream_ext.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:997:39: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "importStatement"


	public static class replDumpStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replDumpStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1000:1: replDumpStatement : KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( $replConf)? ) ;
	public final HiveParser.replDumpStatement_return replDumpStatement() throws RecognitionException {
		HiveParser.replDumpStatement_return retval = new HiveParser.replDumpStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REPL63=null;
		Token KW_DUMP64=null;
		Token KW_REPLACE65=null;
		Token KW_WITH66=null;
		ParserRuleReturnScope dbPolicy =null;
		ParserRuleReturnScope oldDbPolicy =null;
		ParserRuleReturnScope replConf =null;

		ASTNode KW_REPL63_tree=null;
		ASTNode KW_DUMP64_tree=null;
		ASTNode KW_REPLACE65_tree=null;
		ASTNode KW_WITH66_tree=null;
		RewriteRuleTokenStream stream_KW_DUMP=new RewriteRuleTokenStream(adaptor,"token KW_DUMP");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleSubtreeStream stream_replDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replDbPolicy");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("Replication dump statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:7: ( KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:9: KW_REPL KW_DUMP (dbPolicy= replDbPolicy ) ( KW_REPLACE oldDbPolicy= replDbPolicy )? ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL63=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replDumpStatement2390); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL63);

			KW_DUMP64=(Token)match(input,KW_DUMP,FOLLOW_KW_DUMP_in_replDumpStatement2392); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DUMP.add(KW_DUMP64);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:9: (dbPolicy= replDbPolicy )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:10: dbPolicy= replDbPolicy
			{
			pushFollow(FOLLOW_replDbPolicy_in_replDumpStatement2405);
			dbPolicy=replDbPolicy();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replDbPolicy.add(dbPolicy.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:9: ( KW_REPLACE oldDbPolicy= replDbPolicy )?
			int alt18=2;
			int LA18_0 = input.LA(1);
			if ( (LA18_0==KW_REPLACE) ) {
				alt18=1;
			}
			switch (alt18) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1005:10: KW_REPLACE oldDbPolicy= replDbPolicy
					{
					KW_REPLACE65=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_replDumpStatement2417); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE65);

					pushFollow(FOLLOW_replDbPolicy_in_replDumpStatement2421);
					oldDbPolicy=replDbPolicy();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replDbPolicy.add(oldDbPolicy.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1006:9: ( KW_WITH replConf= replConfigs )?
			int alt19=2;
			int LA19_0 = input.LA(1);
			if ( (LA19_0==KW_WITH) ) {
				alt19=1;
			}
			switch (alt19) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1006:10: KW_WITH replConf= replConfigs
					{
					KW_WITH66=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replDumpStatement2434); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH66);

					pushFollow(FOLLOW_replConfigs_in_replDumpStatement2438);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: dbPolicy, oldDbPolicy, replConf
			// token labels: 
			// rule labels: oldDbPolicy, dbPolicy, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_oldDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule oldDbPolicy",oldDbPolicy!=null?oldDbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_dbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule dbPolicy",dbPolicy!=null?dbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1007:5: -> ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:8: ^( TOK_REPL_DUMP $dbPolicy ( ^( TOK_REPLACE $oldDbPolicy) )? ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_DUMP, "TOK_REPL_DUMP"), root_1);
				adaptor.addChild(root_1, stream_dbPolicy.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:34: ( ^( TOK_REPLACE $oldDbPolicy) )?
				if ( stream_oldDbPolicy.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:34: ^( TOK_REPLACE $oldDbPolicy)
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPLACE, "TOK_REPLACE"), root_2);
					adaptor.addChild(root_2, stream_oldDbPolicy.nextTree());
					adaptor.addChild(root_1, root_2);
					}

				}
				stream_oldDbPolicy.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:64: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replDumpStatement"


	public static class replDbPolicy_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replDbPolicy"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1010:1: replDbPolicy : (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )? -> $dbName ( $tablePolicy)? ;
	public final HiveParser.replDbPolicy_return replDbPolicy() throws RecognitionException {
		HiveParser.replDbPolicy_return retval = new HiveParser.replDbPolicy_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT67=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope tablePolicy =null;

		ASTNode DOT67_tree=null;
		RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replTableLevelPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replTableLevelPolicy");

		 pushMsg("Repl dump DB replication policy", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:5: ( (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )? -> $dbName ( $tablePolicy)? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:7: (dbName= identifier ) ( DOT tablePolicy= replTableLevelPolicy )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:7: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:8: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_replDbPolicy2501);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:27: ( DOT tablePolicy= replTableLevelPolicy )?
			int alt20=2;
			int LA20_0 = input.LA(1);
			if ( (LA20_0==DOT) ) {
				alt20=1;
			}
			switch (alt20) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:28: DOT tablePolicy= replTableLevelPolicy
					{
					DOT67=(Token)match(input,DOT,FOLLOW_DOT_in_replDbPolicy2505); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_DOT.add(DOT67);

					pushFollow(FOLLOW_replTableLevelPolicy_in_replDbPolicy2509);
					tablePolicy=replTableLevelPolicy();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replTableLevelPolicy.add(tablePolicy.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: dbName, tablePolicy
			// token labels: 
			// rule labels: dbName, tablePolicy, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_tablePolicy=new RewriteRuleSubtreeStream(adaptor,"rule tablePolicy",tablePolicy!=null?tablePolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1014:67: -> $dbName ( $tablePolicy)?
			{
				adaptor.addChild(root_0, stream_dbName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1014:79: ( $tablePolicy)?
				if ( stream_tablePolicy.hasNext() ) {
					adaptor.addChild(root_0, stream_tablePolicy.nextTree());
				}
				stream_tablePolicy.reset();

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replDbPolicy"


	public static class replLoadStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replLoadStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1017:1: replLoadStatement : KW_REPL KW_LOAD (sourceDbPolicy= replDbPolicy ) ( KW_INTO dbName= identifier )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_LOAD $sourceDbPolicy ( ^( TOK_DBNAME $dbName) )? ( $replConf)? ) ;
	public final HiveParser.replLoadStatement_return replLoadStatement() throws RecognitionException {
		HiveParser.replLoadStatement_return retval = new HiveParser.replLoadStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REPL68=null;
		Token KW_LOAD69=null;
		Token KW_INTO70=null;
		Token KW_WITH71=null;
		ParserRuleReturnScope sourceDbPolicy =null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope replConf =null;

		ASTNode KW_REPL68_tree=null;
		ASTNode KW_LOAD69_tree=null;
		ASTNode KW_INTO70_tree=null;
		ASTNode KW_WITH71_tree=null;
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule replDbPolicy");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("Replication load statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:7: ( KW_REPL KW_LOAD (sourceDbPolicy= replDbPolicy ) ( KW_INTO dbName= identifier )? ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_LOAD $sourceDbPolicy ( ^( TOK_DBNAME $dbName) )? ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:9: KW_REPL KW_LOAD (sourceDbPolicy= replDbPolicy ) ( KW_INTO dbName= identifier )? ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL68=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replLoadStatement2549); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL68);

			KW_LOAD69=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_replLoadStatement2551); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOAD.add(KW_LOAD69);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:7: (sourceDbPolicy= replDbPolicy )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:8: sourceDbPolicy= replDbPolicy
			{
			pushFollow(FOLLOW_replDbPolicy_in_replLoadStatement2562);
			sourceDbPolicy=replDbPolicy();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replDbPolicy.add(sourceDbPolicy.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1022:7: ( KW_INTO dbName= identifier )?
			int alt21=2;
			int LA21_0 = input.LA(1);
			if ( (LA21_0==KW_INTO) ) {
				alt21=1;
			}
			switch (alt21) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1022:8: KW_INTO dbName= identifier
					{
					KW_INTO70=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_replLoadStatement2572); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO70);

					pushFollow(FOLLOW_identifier_in_replLoadStatement2576);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:7: ( KW_WITH replConf= replConfigs )?
			int alt22=2;
			int LA22_0 = input.LA(1);
			if ( (LA22_0==KW_WITH) ) {
				alt22=1;
			}
			switch (alt22) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1023:8: KW_WITH replConf= replConfigs
					{
					KW_WITH71=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replLoadStatement2587); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH71);

					pushFollow(FOLLOW_replConfigs_in_replLoadStatement2591);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: replConf, dbName, sourceDbPolicy
			// token labels: 
			// rule labels: dbName, sourceDbPolicy, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_sourceDbPolicy=new RewriteRuleSubtreeStream(adaptor,"rule sourceDbPolicy",sourceDbPolicy!=null?sourceDbPolicy.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1024:7: -> ^( TOK_REPL_LOAD $sourceDbPolicy ( ^( TOK_DBNAME $dbName) )? ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:10: ^( TOK_REPL_LOAD $sourceDbPolicy ( ^( TOK_DBNAME $dbName) )? ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_LOAD, "TOK_REPL_LOAD"), root_1);
				adaptor.addChild(root_1, stream_sourceDbPolicy.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:42: ( ^( TOK_DBNAME $dbName) )?
				if ( stream_dbName.hasNext() ) {
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:42: ^( TOK_DBNAME $dbName)
					{
					ASTNode root_2 = (ASTNode)adaptor.nil();
					root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DBNAME, "TOK_DBNAME"), root_2);
					adaptor.addChild(root_2, stream_dbName.nextTree());
					adaptor.addChild(root_1, root_2);
					}

				}
				stream_dbName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1024:66: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replLoadStatement"


	public static class replConfigs_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replConfigs"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1027:1: replConfigs : LPAREN replConfigsList RPAREN -> ^( TOK_REPL_CONFIG replConfigsList ) ;
	public final HiveParser.replConfigs_return replConfigs() throws RecognitionException {
		HiveParser.replConfigs_return retval = new HiveParser.replConfigs_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN72=null;
		Token RPAREN74=null;
		ParserRuleReturnScope replConfigsList73 =null;

		ASTNode LPAREN72_tree=null;
		ASTNode RPAREN74_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_replConfigsList=new RewriteRuleSubtreeStream(adaptor,"rule replConfigsList");

		 pushMsg("Repl configurations", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1030:5: ( LPAREN replConfigsList RPAREN -> ^( TOK_REPL_CONFIG replConfigsList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1031:7: LPAREN replConfigsList RPAREN
			{
			LPAREN72=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_replConfigs2655); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN72);

			pushFollow(FOLLOW_replConfigsList_in_replConfigs2657);
			replConfigsList73=replConfigsList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_replConfigsList.add(replConfigsList73.getTree());
			RPAREN74=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_replConfigs2659); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN74);

			// AST REWRITE
			// elements: replConfigsList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1031:37: -> ^( TOK_REPL_CONFIG replConfigsList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1031:40: ^( TOK_REPL_CONFIG replConfigsList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_CONFIG, "TOK_REPL_CONFIG"), root_1);
				adaptor.addChild(root_1, stream_replConfigsList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replConfigs"


	public static class replConfigsList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replConfigsList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1034:1: replConfigsList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ ) ;
	public final HiveParser.replConfigsList_return replConfigsList() throws RecognitionException {
		HiveParser.replConfigsList_return retval = new HiveParser.replConfigsList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA76=null;
		ParserRuleReturnScope keyValueProperty75 =null;
		ParserRuleReturnScope keyValueProperty77 =null;

		ASTNode COMMA76_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");

		 pushMsg("Repl configurations list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:7: keyValueProperty ( COMMA keyValueProperty )*
			{
			pushFollow(FOLLOW_keyValueProperty_in_replConfigsList2700);
			keyValueProperty75=keyValueProperty();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty75.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:24: ( COMMA keyValueProperty )*
			loop23:
			while (true) {
				int alt23=2;
				int LA23_0 = input.LA(1);
				if ( (LA23_0==COMMA) ) {
					alt23=1;
				}

				switch (alt23) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:25: COMMA keyValueProperty
					{
					COMMA76=(Token)match(input,COMMA,FOLLOW_COMMA_in_replConfigsList2703); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA76);

					pushFollow(FOLLOW_keyValueProperty_in_replConfigsList2705);
					keyValueProperty77=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty77.getTree());
					}
					break;

				default :
					break loop23;
				}
			}

			// AST REWRITE
			// elements: keyValueProperty
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1038:50: -> ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:53: ^( TOK_REPL_CONFIG_LIST ( keyValueProperty )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_CONFIG_LIST, "TOK_REPL_CONFIG_LIST"), root_1);
				if ( !(stream_keyValueProperty.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_keyValueProperty.hasNext() ) {
					adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
				}
				stream_keyValueProperty.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replConfigsList"


	public static class replTableLevelPolicy_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replTableLevelPolicy"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1041:1: replTableLevelPolicy : ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? ) -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? ) ;
	public final HiveParser.replTableLevelPolicy_return replTableLevelPolicy() throws RecognitionException {
		HiveParser.replTableLevelPolicy_return retval = new HiveParser.replTableLevelPolicy_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token replTablesIncludeList=null;
		Token replTablesExcludeList=null;
		Token DOT78=null;

		ASTNode replTablesIncludeList_tree=null;
		ASTNode replTablesExcludeList_tree=null;
		ASTNode DOT78_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_DOT=new RewriteRuleTokenStream(adaptor,"token DOT");

		 pushMsg("Replication table level policy definition", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1044:5: ( ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? ) -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:7: ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:7: ( (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:8: (replTablesIncludeList= StringLiteral ) ( DOT replTablesExcludeList= StringLiteral )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:8: (replTablesIncludeList= StringLiteral )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:9: replTablesIncludeList= StringLiteral
			{
			replTablesIncludeList=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replTableLevelPolicy2753); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(replTablesIncludeList);

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:46: ( DOT replTablesExcludeList= StringLiteral )?
			int alt24=2;
			int LA24_0 = input.LA(1);
			if ( (LA24_0==DOT) ) {
				alt24=1;
			}
			switch (alt24) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:47: DOT replTablesExcludeList= StringLiteral
					{
					DOT78=(Token)match(input,DOT,FOLLOW_DOT_in_replTableLevelPolicy2757); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_DOT.add(DOT78);

					replTablesExcludeList=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_replTableLevelPolicy2761); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(replTablesExcludeList);

					}
					break;

			}

			}

			// AST REWRITE
			// elements: replTablesExcludeList, replTablesIncludeList
			// token labels: replTablesExcludeList, replTablesIncludeList
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_replTablesExcludeList=new RewriteRuleTokenStream(adaptor,"token replTablesExcludeList",replTablesExcludeList);
			RewriteRuleTokenStream stream_replTablesIncludeList=new RewriteRuleTokenStream(adaptor,"token replTablesIncludeList",replTablesIncludeList);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1046:7: -> ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:10: ^( TOK_REPL_TABLES $replTablesIncludeList ( $replTablesExcludeList)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_TABLES, "TOK_REPL_TABLES"), root_1);
				adaptor.addChild(root_1, stream_replTablesIncludeList.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:52: ( $replTablesExcludeList)?
				if ( stream_replTablesExcludeList.hasNext() ) {
					adaptor.addChild(root_1, stream_replTablesExcludeList.nextNode());
				}
				stream_replTablesExcludeList.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replTableLevelPolicy"


	public static class replStatusStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "replStatusStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1049:1: replStatusStatement : KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_STATUS $dbName ( $replConf)? ) ;
	public final HiveParser.replStatusStatement_return replStatusStatement() throws RecognitionException {
		HiveParser.replStatusStatement_return retval = new HiveParser.replStatusStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REPL79=null;
		Token KW_STATUS80=null;
		Token KW_WITH81=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope replConf =null;

		ASTNode KW_REPL79_tree=null;
		ASTNode KW_STATUS80_tree=null;
		ASTNode KW_WITH81_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_STATUS=new RewriteRuleTokenStream(adaptor,"token KW_STATUS");
		RewriteRuleTokenStream stream_KW_REPL=new RewriteRuleTokenStream(adaptor,"token KW_REPL");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_replConfigs=new RewriteRuleSubtreeStream(adaptor,"rule replConfigs");

		 pushMsg("replication status statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1052:7: ( KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )? -> ^( TOK_REPL_STATUS $dbName ( $replConf)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1052:9: KW_REPL KW_STATUS (dbName= identifier ) ( KW_WITH replConf= replConfigs )?
			{
			KW_REPL79=(Token)match(input,KW_REPL,FOLLOW_KW_REPL_in_replStatusStatement2812); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPL.add(KW_REPL79);

			KW_STATUS80=(Token)match(input,KW_STATUS,FOLLOW_KW_STATUS_in_replStatusStatement2814); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATUS.add(KW_STATUS80);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1053:9: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1053:10: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_replStatusStatement2827);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1054:9: ( KW_WITH replConf= replConfigs )?
			int alt25=2;
			int LA25_0 = input.LA(1);
			if ( (LA25_0==KW_WITH) ) {
				alt25=1;
			}
			switch (alt25) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1054:10: KW_WITH replConf= replConfigs
					{
					KW_WITH81=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_replStatusStatement2839); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH81);

					pushFollow(FOLLOW_replConfigs_in_replStatusStatement2843);
					replConf=replConfigs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replConfigs.add(replConf.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: replConf, dbName
			// token labels: 
			// rule labels: dbName, retval, replConf
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_replConf=new RewriteRuleSubtreeStream(adaptor,"rule replConf",replConf!=null?replConf.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1055:7: -> ^( TOK_REPL_STATUS $dbName ( $replConf)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1055:10: ^( TOK_REPL_STATUS $dbName ( $replConf)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REPL_STATUS, "TOK_REPL_STATUS"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1055:37: ( $replConf)?
				if ( stream_replConf.hasNext() ) {
					adaptor.addChild(root_1, stream_replConf.nextTree());
				}
				stream_replConf.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "replStatusStatement"


	public static class ddlStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ddlStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | createScheduledQueryStatement | alterScheduledQueryStatement | dropScheduledQueryStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements | createDataConnectorStatement | dropDataConnectorStatement );
	public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
		HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope createDatabaseStatement82 =null;
		ParserRuleReturnScope switchDatabaseStatement83 =null;
		ParserRuleReturnScope dropDatabaseStatement84 =null;
		ParserRuleReturnScope createTableStatement85 =null;
		ParserRuleReturnScope dropTableStatement86 =null;
		ParserRuleReturnScope truncateTableStatement87 =null;
		ParserRuleReturnScope alterStatement88 =null;
		ParserRuleReturnScope descStatement89 =null;
		ParserRuleReturnScope showStatement90 =null;
		ParserRuleReturnScope metastoreCheck91 =null;
		ParserRuleReturnScope createViewStatement92 =null;
		ParserRuleReturnScope createMaterializedViewStatement93 =null;
		ParserRuleReturnScope createScheduledQueryStatement94 =null;
		ParserRuleReturnScope alterScheduledQueryStatement95 =null;
		ParserRuleReturnScope dropScheduledQueryStatement96 =null;
		ParserRuleReturnScope dropViewStatement97 =null;
		ParserRuleReturnScope dropMaterializedViewStatement98 =null;
		ParserRuleReturnScope createFunctionStatement99 =null;
		ParserRuleReturnScope createMacroStatement100 =null;
		ParserRuleReturnScope dropFunctionStatement101 =null;
		ParserRuleReturnScope reloadFunctionsStatement102 =null;
		ParserRuleReturnScope dropMacroStatement103 =null;
		ParserRuleReturnScope analyzeStatement104 =null;
		ParserRuleReturnScope lockStatement105 =null;
		ParserRuleReturnScope unlockStatement106 =null;
		ParserRuleReturnScope lockDatabase107 =null;
		ParserRuleReturnScope unlockDatabase108 =null;
		ParserRuleReturnScope createRoleStatement109 =null;
		ParserRuleReturnScope dropRoleStatement110 =null;
		ParserRuleReturnScope grantPrivileges111 =null;
		ParserRuleReturnScope revokePrivileges112 =null;
		ParserRuleReturnScope showGrants113 =null;
		ParserRuleReturnScope showRoleGrants114 =null;
		ParserRuleReturnScope showRolePrincipals115 =null;
		ParserRuleReturnScope showRoles116 =null;
		ParserRuleReturnScope grantRole117 =null;
		ParserRuleReturnScope revokeRole118 =null;
		ParserRuleReturnScope setRole119 =null;
		ParserRuleReturnScope showCurrentRole120 =null;
		ParserRuleReturnScope abortTransactionStatement121 =null;
		ParserRuleReturnScope killQueryStatement122 =null;
		ParserRuleReturnScope resourcePlanDdlStatements123 =null;
		ParserRuleReturnScope createDataConnectorStatement124 =null;
		ParserRuleReturnScope dropDataConnectorStatement125 =null;


		 pushMsg("ddl statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | createScheduledQueryStatement | alterScheduledQueryStatement | dropScheduledQueryStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements | createDataConnectorStatement | dropDataConnectorStatement )
			int alt26=44;
			alt26 = dfa26.predict(input);
			switch (alt26) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1061:7: createDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement2893);
					createDatabaseStatement82=createDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createDatabaseStatement82.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1062:7: switchDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement2901);
					switchDatabaseStatement83=switchDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, switchDatabaseStatement83.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1063:7: dropDatabaseStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement2909);
					dropDatabaseStatement84=dropDatabaseStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropDatabaseStatement84.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1064:7: createTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createTableStatement_in_ddlStatement2917);
					createTableStatement85=createTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createTableStatement85.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:7: dropTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropTableStatement_in_ddlStatement2925);
					dropTableStatement86=dropTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropTableStatement86.getTree());

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:7: truncateTableStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement2933);
					truncateTableStatement87=truncateTableStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, truncateTableStatement87.getTree());

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1067:7: alterStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterStatement_in_ddlStatement2941);
					alterStatement88=alterStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterStatement88.getTree());

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1068:7: descStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_descStatement_in_ddlStatement2949);
					descStatement89=descStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, descStatement89.getTree());

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1069:7: showStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showStatement_in_ddlStatement2957);
					showStatement90=showStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showStatement90.getTree());

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1070:7: metastoreCheck
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_metastoreCheck_in_ddlStatement2965);
					metastoreCheck91=metastoreCheck();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, metastoreCheck91.getTree());

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1071:7: createViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createViewStatement_in_ddlStatement2973);
					createViewStatement92=createViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createViewStatement92.getTree());

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1072:7: createMaterializedViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createMaterializedViewStatement_in_ddlStatement2981);
					createMaterializedViewStatement93=createMaterializedViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createMaterializedViewStatement93.getTree());

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:7: createScheduledQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createScheduledQueryStatement_in_ddlStatement2989);
					createScheduledQueryStatement94=createScheduledQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createScheduledQueryStatement94.getTree());

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1074:7: alterScheduledQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_alterScheduledQueryStatement_in_ddlStatement2997);
					alterScheduledQueryStatement95=alterScheduledQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterScheduledQueryStatement95.getTree());

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1075:7: dropScheduledQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropScheduledQueryStatement_in_ddlStatement3005);
					dropScheduledQueryStatement96=dropScheduledQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropScheduledQueryStatement96.getTree());

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1076:7: dropViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropViewStatement_in_ddlStatement3013);
					dropViewStatement97=dropViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropViewStatement97.getTree());

					}
					break;
				case 17 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1077:7: dropMaterializedViewStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropMaterializedViewStatement_in_ddlStatement3021);
					dropMaterializedViewStatement98=dropMaterializedViewStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMaterializedViewStatement98.getTree());

					}
					break;
				case 18 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1078:7: createFunctionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement3029);
					createFunctionStatement99=createFunctionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createFunctionStatement99.getTree());

					}
					break;
				case 19 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1079:7: createMacroStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createMacroStatement_in_ddlStatement3037);
					createMacroStatement100=createMacroStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createMacroStatement100.getTree());

					}
					break;
				case 20 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:7: dropFunctionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement3045);
					dropFunctionStatement101=dropFunctionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropFunctionStatement101.getTree());

					}
					break;
				case 21 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:7: reloadFunctionsStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_reloadFunctionsStatement_in_ddlStatement3053);
					reloadFunctionsStatement102=reloadFunctionsStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, reloadFunctionsStatement102.getTree());

					}
					break;
				case 22 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1082:7: dropMacroStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement3061);
					dropMacroStatement103=dropMacroStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropMacroStatement103.getTree());

					}
					break;
				case 23 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1083:7: analyzeStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_analyzeStatement_in_ddlStatement3069);
					analyzeStatement104=analyzeStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, analyzeStatement104.getTree());

					}
					break;
				case 24 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:7: lockStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_lockStatement_in_ddlStatement3077);
					lockStatement105=lockStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, lockStatement105.getTree());

					}
					break;
				case 25 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1085:7: unlockStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unlockStatement_in_ddlStatement3085);
					unlockStatement106=unlockStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockStatement106.getTree());

					}
					break;
				case 26 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1086:7: lockDatabase
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_lockDatabase_in_ddlStatement3093);
					lockDatabase107=lockDatabase();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, lockDatabase107.getTree());

					}
					break;
				case 27 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1087:7: unlockDatabase
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unlockDatabase_in_ddlStatement3101);
					unlockDatabase108=unlockDatabase();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unlockDatabase108.getTree());

					}
					break;
				case 28 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:7: createRoleStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createRoleStatement_in_ddlStatement3109);
					createRoleStatement109=createRoleStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createRoleStatement109.getTree());

					}
					break;
				case 29 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1089:7: dropRoleStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement3117);
					dropRoleStatement110=dropRoleStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropRoleStatement110.getTree());

					}
					break;
				case 30 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1090:7: ( grantPrivileges )=> grantPrivileges
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_grantPrivileges_in_ddlStatement3131);
					grantPrivileges111=grantPrivileges();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, grantPrivileges111.getTree());

					}
					break;
				case 31 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:7: ( revokePrivileges )=> revokePrivileges
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_revokePrivileges_in_ddlStatement3145);
					revokePrivileges112=revokePrivileges();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, revokePrivileges112.getTree());

					}
					break;
				case 32 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1092:7: showGrants
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showGrants_in_ddlStatement3153);
					showGrants113=showGrants();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showGrants113.getTree());

					}
					break;
				case 33 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1093:7: showRoleGrants
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRoleGrants_in_ddlStatement3161);
					showRoleGrants114=showRoleGrants();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoleGrants114.getTree());

					}
					break;
				case 34 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:7: showRolePrincipals
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRolePrincipals_in_ddlStatement3169);
					showRolePrincipals115=showRolePrincipals();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRolePrincipals115.getTree());

					}
					break;
				case 35 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:7: showRoles
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showRoles_in_ddlStatement3177);
					showRoles116=showRoles();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showRoles116.getTree());

					}
					break;
				case 36 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1096:7: grantRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_grantRole_in_ddlStatement3185);
					grantRole117=grantRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, grantRole117.getTree());

					}
					break;
				case 37 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1097:7: revokeRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_revokeRole_in_ddlStatement3193);
					revokeRole118=revokeRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, revokeRole118.getTree());

					}
					break;
				case 38 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:7: setRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_setRole_in_ddlStatement3201);
					setRole119=setRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, setRole119.getTree());

					}
					break;
				case 39 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1099:7: showCurrentRole
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_showCurrentRole_in_ddlStatement3209);
					showCurrentRole120=showCurrentRole();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showCurrentRole120.getTree());

					}
					break;
				case 40 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1100:7: abortTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_abortTransactionStatement_in_ddlStatement3217);
					abortTransactionStatement121=abortTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, abortTransactionStatement121.getTree());

					}
					break;
				case 41 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1101:7: killQueryStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_killQueryStatement_in_ddlStatement3225);
					killQueryStatement122=killQueryStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, killQueryStatement122.getTree());

					}
					break;
				case 42 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1102:7: resourcePlanDdlStatements
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_resourcePlanDdlStatements_in_ddlStatement3233);
					resourcePlanDdlStatements123=resourcePlanDdlStatements();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, resourcePlanDdlStatements123.getTree());

					}
					break;
				case 43 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1103:7: createDataConnectorStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_createDataConnectorStatement_in_ddlStatement3241);
					createDataConnectorStatement124=createDataConnectorStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createDataConnectorStatement124.getTree());

					}
					break;
				case 44 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1104:7: dropDataConnectorStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_dropDataConnectorStatement_in_ddlStatement3249);
					dropDataConnectorStatement125=dropDataConnectorStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, dropDataConnectorStatement125.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ddlStatement"


	public static class ifExists_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ifExists"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1107:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
	public final HiveParser.ifExists_return ifExists() throws RecognitionException {
		HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_IF126=null;
		Token KW_EXISTS127=null;

		ASTNode KW_IF126_tree=null;
		ASTNode KW_EXISTS127_tree=null;
		RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
		RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

		 pushMsg("if exists clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1110:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1110:7: KW_IF KW_EXISTS
			{
			KW_IF126=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifExists3276); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF126);

			KW_EXISTS127=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifExists3278); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS127);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1111:5: -> ^( TOK_IFEXISTS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1111:8: ^( TOK_IFEXISTS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ifExists"


	public static class restrictOrCascade_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "restrictOrCascade"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1114:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
	public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
		HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RESTRICT128=null;
		Token KW_CASCADE129=null;

		ASTNode KW_RESTRICT128_tree=null;
		ASTNode KW_CASCADE129_tree=null;
		RewriteRuleTokenStream stream_KW_CASCADE=new RewriteRuleTokenStream(adaptor,"token KW_CASCADE");
		RewriteRuleTokenStream stream_KW_RESTRICT=new RewriteRuleTokenStream(adaptor,"token KW_RESTRICT");

		 pushMsg("restrict or cascade clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1117:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
			int alt27=2;
			int LA27_0 = input.LA(1);
			if ( (LA27_0==KW_RESTRICT) ) {
				alt27=1;
			}
			else if ( (LA27_0==KW_CASCADE) ) {
				alt27=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 27, 0, input);
				throw nvae;
			}

			switch (alt27) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1117:7: KW_RESTRICT
					{
					KW_RESTRICT128=(Token)match(input,KW_RESTRICT,FOLLOW_KW_RESTRICT_in_restrictOrCascade3315); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RESTRICT.add(KW_RESTRICT128);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1118:5: -> ^( TOK_RESTRICT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1118:8: ^( TOK_RESTRICT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESTRICT, "TOK_RESTRICT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:7: KW_CASCADE
					{
					KW_CASCADE129=(Token)match(input,KW_CASCADE,FOLLOW_KW_CASCADE_in_restrictOrCascade3333); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CASCADE.add(KW_CASCADE129);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1120:5: -> ^( TOK_CASCADE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1120:8: ^( TOK_CASCADE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CASCADE, "TOK_CASCADE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "restrictOrCascade"


	public static class ifNotExists_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "ifNotExists"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
	public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
		HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_IF130=null;
		Token KW_NOT131=null;
		Token KW_EXISTS132=null;

		ASTNode KW_IF130_tree=null;
		ASTNode KW_NOT131_tree=null;
		ASTNode KW_EXISTS132_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");
		RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");

		 pushMsg("if not exists clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1126:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1126:7: KW_IF KW_NOT KW_EXISTS
			{
			KW_IF130=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifNotExists3370); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_IF.add(KW_IF130);

			KW_NOT131=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_ifNotExists3372); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT131);

			KW_EXISTS132=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifNotExists3374); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXISTS.add(KW_EXISTS132);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1127:5: -> ^( TOK_IFNOTEXISTS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1127:8: ^( TOK_IFNOTEXISTS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "ifNotExists"


	public static class force_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "force"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:1: force : KW_FORCE -> ^( TOK_FORCE ) ;
	public final HiveParser.force_return force() throws RecognitionException {
		HiveParser.force_return retval = new HiveParser.force_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_FORCE133=null;

		ASTNode KW_FORCE133_tree=null;
		RewriteRuleTokenStream stream_KW_FORCE=new RewriteRuleTokenStream(adaptor,"token KW_FORCE");

		 msgs.push("force clause"); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1133:5: ( KW_FORCE -> ^( TOK_FORCE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1133:7: KW_FORCE
			{
			KW_FORCE133=(Token)match(input,KW_FORCE,FOLLOW_KW_FORCE_in_force3411); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORCE.add(KW_FORCE133);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1134:5: -> ^( TOK_FORCE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1134:8: ^( TOK_FORCE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FORCE, "TOK_FORCE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { msgs.pop(); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "force"


	public static class rewriteEnabled_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rewriteEnabled"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:1: rewriteEnabled : KW_ENABLE KW_REWRITE -> ^( TOK_REWRITE_ENABLED ) ;
	public final HiveParser.rewriteEnabled_return rewriteEnabled() throws RecognitionException {
		HiveParser.rewriteEnabled_return retval = new HiveParser.rewriteEnabled_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENABLE134=null;
		Token KW_REWRITE135=null;

		ASTNode KW_ENABLE134_tree=null;
		ASTNode KW_REWRITE135_tree=null;
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");
		RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

		 pushMsg("rewrite enabled clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1140:5: ( KW_ENABLE KW_REWRITE -> ^( TOK_REWRITE_ENABLED ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1140:7: KW_ENABLE KW_REWRITE
			{
			KW_ENABLE134=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_rewriteEnabled3448); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE134);

			KW_REWRITE135=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_rewriteEnabled3450); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE135);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1141:5: -> ^( TOK_REWRITE_ENABLED )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1141:8: ^( TOK_REWRITE_ENABLED )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REWRITE_ENABLED, "TOK_REWRITE_ENABLED"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rewriteEnabled"


	public static class rewriteDisabled_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rewriteDisabled"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1144:1: rewriteDisabled : KW_DISABLE KW_REWRITE -> ^( TOK_REWRITE_DISABLED ) ;
	public final HiveParser.rewriteDisabled_return rewriteDisabled() throws RecognitionException {
		HiveParser.rewriteDisabled_return retval = new HiveParser.rewriteDisabled_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DISABLE136=null;
		Token KW_REWRITE137=null;

		ASTNode KW_DISABLE136_tree=null;
		ASTNode KW_REWRITE137_tree=null;
		RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
		RewriteRuleTokenStream stream_KW_REWRITE=new RewriteRuleTokenStream(adaptor,"token KW_REWRITE");

		 pushMsg("rewrite disabled clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:5: ( KW_DISABLE KW_REWRITE -> ^( TOK_REWRITE_DISABLED ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:7: KW_DISABLE KW_REWRITE
			{
			KW_DISABLE136=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_rewriteDisabled3487); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE136);

			KW_REWRITE137=(Token)match(input,KW_REWRITE,FOLLOW_KW_REWRITE_in_rewriteDisabled3489); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REWRITE.add(KW_REWRITE137);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1148:5: -> ^( TOK_REWRITE_DISABLED )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1148:8: ^( TOK_REWRITE_DISABLED )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REWRITE_DISABLED, "TOK_REWRITE_DISABLED"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rewriteDisabled"


	public static class storedAsDirs_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "storedAsDirs"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
	public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
		HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_STORED138=null;
		Token KW_AS139=null;
		Token KW_DIRECTORIES140=null;

		ASTNode KW_STORED138_tree=null;
		ASTNode KW_AS139_tree=null;
		ASTNode KW_DIRECTORIES140_tree=null;
		RewriteRuleTokenStream stream_KW_DIRECTORIES=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORIES");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");

		 pushMsg("stored as directories", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:7: KW_STORED KW_AS KW_DIRECTORIES
			{
			KW_STORED138=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_storedAsDirs3526); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED138);

			KW_AS139=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_storedAsDirs3528); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS139);

			KW_DIRECTORIES140=(Token)match(input,KW_DIRECTORIES,FOLLOW_KW_DIRECTORIES_in_storedAsDirs3530); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DIRECTORIES.add(KW_DIRECTORIES140);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1155:5: -> ^( TOK_STOREDASDIRS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1155:8: ^( TOK_STOREDASDIRS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "storedAsDirs"


	public static class orReplace_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orReplace"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
	public final HiveParser.orReplace_return orReplace() throws RecognitionException {
		HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_OR141=null;
		Token KW_REPLACE142=null;

		ASTNode KW_OR141_tree=null;
		ASTNode KW_REPLACE142_tree=null;
		RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
		RewriteRuleTokenStream stream_KW_OR=new RewriteRuleTokenStream(adaptor,"token KW_OR");

		 pushMsg("or replace clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1161:7: KW_OR KW_REPLACE
			{
			KW_OR141=(Token)match(input,KW_OR,FOLLOW_KW_OR_in_orReplace3567); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OR.add(KW_OR141);

			KW_REPLACE142=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_orReplace3569); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REPLACE.add(KW_REPLACE142);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1162:5: -> ^( TOK_ORREPLACE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:8: ^( TOK_ORREPLACE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orReplace"


	public static class createDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:1: createDatabaseStatement : ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( dbManagedLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? ) | KW_CREATE KW_REMOTE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? dbConnectorName ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( databaseComment )? ( $dbprops)? dbConnectorName ) );
	public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
		HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE143=null;
		Token KW_DATABASE144=null;
		Token KW_SCHEMA145=null;
		Token KW_WITH150=null;
		Token KW_DBPROPERTIES151=null;
		Token KW_CREATE152=null;
		Token KW_REMOTE153=null;
		Token KW_DATABASE154=null;
		Token KW_SCHEMA155=null;
		Token KW_WITH159=null;
		Token KW_DBPROPERTIES160=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope dbprops =null;
		ParserRuleReturnScope ifNotExists146 =null;
		ParserRuleReturnScope databaseComment147 =null;
		ParserRuleReturnScope dbLocation148 =null;
		ParserRuleReturnScope dbManagedLocation149 =null;
		ParserRuleReturnScope ifNotExists156 =null;
		ParserRuleReturnScope databaseComment157 =null;
		ParserRuleReturnScope dbConnectorName158 =null;

		ASTNode KW_CREATE143_tree=null;
		ASTNode KW_DATABASE144_tree=null;
		ASTNode KW_SCHEMA145_tree=null;
		ASTNode KW_WITH150_tree=null;
		ASTNode KW_DBPROPERTIES151_tree=null;
		ASTNode KW_CREATE152_tree=null;
		ASTNode KW_REMOTE153_tree=null;
		ASTNode KW_DATABASE154_tree=null;
		ASTNode KW_SCHEMA155_tree=null;
		ASTNode KW_WITH159_tree=null;
		ASTNode KW_DBPROPERTIES160_tree=null;
		RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_REMOTE=new RewriteRuleTokenStream(adaptor,"token KW_REMOTE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
		RewriteRuleSubtreeStream stream_databaseComment=new RewriteRuleSubtreeStream(adaptor,"rule databaseComment");
		RewriteRuleSubtreeStream stream_dbConnectorName=new RewriteRuleSubtreeStream(adaptor,"rule dbConnectorName");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_dbLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbLocation");
		RewriteRuleSubtreeStream stream_dbManagedLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbManagedLocation");

		 pushMsg("create database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( dbManagedLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? ) | KW_CREATE KW_REMOTE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? dbConnectorName ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( databaseComment )? ( $dbprops)? dbConnectorName ) )
			int alt38=2;
			int LA38_0 = input.LA(1);
			if ( (LA38_0==KW_CREATE) ) {
				int LA38_1 = input.LA(2);
				if ( (LA38_1==KW_REMOTE) ) {
					alt38=2;
				}
				else if ( (LA38_1==KW_DATABASE||LA38_1==KW_SCHEMA) ) {
					alt38=1;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 38, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 38, 0, input);
				throw nvae;
			}

			switch (alt38) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( dbManagedLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
					{
					KW_CREATE143=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createDatabaseStatement3606); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE143);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:17: ( KW_DATABASE | KW_SCHEMA )
					int alt28=2;
					int LA28_0 = input.LA(1);
					if ( (LA28_0==KW_DATABASE) ) {
						alt28=1;
					}
					else if ( (LA28_0==KW_SCHEMA) ) {
						alt28=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 28, 0, input);
						throw nvae;
					}

					switch (alt28) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:18: KW_DATABASE
							{
							KW_DATABASE144=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_createDatabaseStatement3609); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE144);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1168:30: KW_SCHEMA
							{
							KW_SCHEMA145=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_createDatabaseStatement3611); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA145);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:9: ( ifNotExists )?
					int alt29=2;
					int LA29_0 = input.LA(1);
					if ( (LA29_0==KW_IF) ) {
						alt29=1;
					}
					switch (alt29) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:9: ifNotExists
							{
							pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement3622);
							ifNotExists146=ifNotExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists146.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_createDatabaseStatement3635);
					name=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:9: ( databaseComment )?
					int alt30=2;
					int LA30_0 = input.LA(1);
					if ( (LA30_0==KW_COMMENT) ) {
						alt30=1;
					}
					switch (alt30) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1171:9: databaseComment
							{
							pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement3645);
							databaseComment147=databaseComment();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_databaseComment.add(databaseComment147.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:9: ( dbLocation )?
					int alt31=2;
					int LA31_0 = input.LA(1);
					if ( (LA31_0==KW_LOCATION) ) {
						alt31=1;
					}
					switch (alt31) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:9: dbLocation
							{
							pushFollow(FOLLOW_dbLocation_in_createDatabaseStatement3656);
							dbLocation148=dbLocation();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_dbLocation.add(dbLocation148.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:9: ( dbManagedLocation )?
					int alt32=2;
					int LA32_0 = input.LA(1);
					if ( (LA32_0==KW_MANAGEDLOCATION) ) {
						alt32=1;
					}
					switch (alt32) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:9: dbManagedLocation
							{
							pushFollow(FOLLOW_dbManagedLocation_in_createDatabaseStatement3667);
							dbManagedLocation149=dbManagedLocation();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_dbManagedLocation.add(dbManagedLocation149.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1174:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
					int alt33=2;
					int LA33_0 = input.LA(1);
					if ( (LA33_0==KW_WITH) ) {
						alt33=1;
					}
					switch (alt33) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1174:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
							{
							KW_WITH150=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_createDatabaseStatement3679); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH150);

							KW_DBPROPERTIES151=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3681); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES151);

							pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement3685);
							dbprops=dbProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_dbProperties.add(dbprops.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: name, dbprops, dbLocation, ifNotExists, dbManagedLocation, databaseComment
					// token labels: 
					// rule labels: name, dbprops, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
					RewriteRuleSubtreeStream stream_dbprops=new RewriteRuleSubtreeStream(adaptor,"rule dbprops",dbprops!=null?dbprops.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1175:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( dbManagedLocation )? ( databaseComment )? ( $dbprops)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE"), root_1);
						adaptor.addChild(root_1, stream_name.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:35: ( ifNotExists )?
						if ( stream_ifNotExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifNotExists.nextTree());
						}
						stream_ifNotExists.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:48: ( dbLocation )?
						if ( stream_dbLocation.hasNext() ) {
							adaptor.addChild(root_1, stream_dbLocation.nextTree());
						}
						stream_dbLocation.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:60: ( dbManagedLocation )?
						if ( stream_dbManagedLocation.hasNext() ) {
							adaptor.addChild(root_1, stream_dbManagedLocation.nextTree());
						}
						stream_dbManagedLocation.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:79: ( databaseComment )?
						if ( stream_databaseComment.hasNext() ) {
							adaptor.addChild(root_1, stream_databaseComment.nextTree());
						}
						stream_databaseComment.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:97: ( $dbprops)?
						if ( stream_dbprops.hasNext() ) {
							adaptor.addChild(root_1, stream_dbprops.nextTree());
						}
						stream_dbprops.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:7: KW_CREATE KW_REMOTE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? dbConnectorName ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
					{
					KW_CREATE152=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createDatabaseStatement3725); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE152);

					KW_REMOTE153=(Token)match(input,KW_REMOTE,FOLLOW_KW_REMOTE_in_createDatabaseStatement3727); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REMOTE.add(KW_REMOTE153);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:27: ( KW_DATABASE | KW_SCHEMA )
					int alt34=2;
					int LA34_0 = input.LA(1);
					if ( (LA34_0==KW_DATABASE) ) {
						alt34=1;
					}
					else if ( (LA34_0==KW_SCHEMA) ) {
						alt34=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 34, 0, input);
						throw nvae;
					}

					switch (alt34) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:28: KW_DATABASE
							{
							KW_DATABASE154=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_createDatabaseStatement3730); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE154);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:40: KW_SCHEMA
							{
							KW_SCHEMA155=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_createDatabaseStatement3732); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA155);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:9: ( ifNotExists )?
					int alt35=2;
					int LA35_0 = input.LA(1);
					if ( (LA35_0==KW_IF) ) {
						alt35=1;
					}
					switch (alt35) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:9: ifNotExists
							{
							pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement3743);
							ifNotExists156=ifNotExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists156.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_createDatabaseStatement3756);
					name=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:9: ( databaseComment )?
					int alt36=2;
					int LA36_0 = input.LA(1);
					if ( (LA36_0==KW_COMMENT) ) {
						alt36=1;
					}
					switch (alt36) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1180:9: databaseComment
							{
							pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement3766);
							databaseComment157=databaseComment();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_databaseComment.add(databaseComment157.getTree());
							}
							break;

					}

					pushFollow(FOLLOW_dbConnectorName_in_createDatabaseStatement3777);
					dbConnectorName158=dbConnectorName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_dbConnectorName.add(dbConnectorName158.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1182:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
					int alt37=2;
					int LA37_0 = input.LA(1);
					if ( (LA37_0==KW_WITH) ) {
						alt37=1;
					}
					switch (alt37) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1182:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
							{
							KW_WITH159=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_createDatabaseStatement3788); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH159);

							KW_DBPROPERTIES160=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3790); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES160);

							pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement3794);
							dbprops=dbProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_dbProperties.add(dbprops.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: name, databaseComment, dbprops, dbConnectorName, ifNotExists
					// token labels: 
					// rule labels: name, dbprops, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
					RewriteRuleSubtreeStream stream_dbprops=new RewriteRuleSubtreeStream(adaptor,"rule dbprops",dbprops!=null?dbprops.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1183:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( databaseComment )? ( $dbprops)? dbConnectorName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( databaseComment )? ( $dbprops)? dbConnectorName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE"), root_1);
						adaptor.addChild(root_1, stream_name.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:35: ( ifNotExists )?
						if ( stream_ifNotExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifNotExists.nextTree());
						}
						stream_ifNotExists.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:48: ( databaseComment )?
						if ( stream_databaseComment.hasNext() ) {
							adaptor.addChild(root_1, stream_databaseComment.nextTree());
						}
						stream_databaseComment.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1183:66: ( $dbprops)?
						if ( stream_dbprops.hasNext() ) {
							adaptor.addChild(root_1, stream_dbprops.nextTree());
						}
						stream_dbprops.reset();

						adaptor.addChild(root_1, stream_dbConnectorName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createDatabaseStatement"


	public static class dbLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1186:1: dbLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) ;
	public final HiveParser.dbLocation_return dbLocation() throws RecognitionException {
		HiveParser.dbLocation_return retval = new HiveParser.dbLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION161=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION161_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("database location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1189:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION161=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_dbLocation3854); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION161);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbLocation3858); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1190:38: -> ^( TOK_DATABASELOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1190:41: ^( TOK_DATABASELOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASELOCATION, "TOK_DATABASELOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbLocation"


	public static class dbManagedLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbManagedLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1193:1: dbManagedLocation : KW_MANAGEDLOCATION locn= StringLiteral -> ^( TOK_DATABASE_MANAGEDLOCATION $locn) ;
	public final HiveParser.dbManagedLocation_return dbManagedLocation() throws RecognitionException {
		HiveParser.dbManagedLocation_return retval = new HiveParser.dbManagedLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_MANAGEDLOCATION162=null;

		ASTNode locn_tree=null;
		ASTNode KW_MANAGEDLOCATION162_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_MANAGEDLOCATION=new RewriteRuleTokenStream(adaptor,"token KW_MANAGEDLOCATION");

		 pushMsg("database managed location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1196:5: ( KW_MANAGEDLOCATION locn= StringLiteral -> ^( TOK_DATABASE_MANAGEDLOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:7: KW_MANAGEDLOCATION locn= StringLiteral
			{
			KW_MANAGEDLOCATION162=(Token)match(input,KW_MANAGEDLOCATION,FOLLOW_KW_MANAGEDLOCATION_in_dbManagedLocation3900); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MANAGEDLOCATION.add(KW_MANAGEDLOCATION162);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbManagedLocation3904); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1197:45: -> ^( TOK_DATABASE_MANAGEDLOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1197:48: ^( TOK_DATABASE_MANAGEDLOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASE_MANAGEDLOCATION, "TOK_DATABASE_MANAGEDLOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbManagedLocation"


	public static class dbProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1200:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
	public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
		HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN163=null;
		Token RPAREN165=null;
		ParserRuleReturnScope dbPropertiesList164 =null;

		ASTNode LPAREN163_tree=null;
		ASTNode RPAREN165_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_dbPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule dbPropertiesList");

		 pushMsg("dbproperties", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1203:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:7: LPAREN dbPropertiesList RPAREN
			{
			LPAREN163=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_dbProperties3946); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN163);

			pushFollow(FOLLOW_dbPropertiesList_in_dbProperties3948);
			dbPropertiesList164=dbPropertiesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_dbPropertiesList.add(dbPropertiesList164.getTree());
			RPAREN165=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_dbProperties3950); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN165);

			// AST REWRITE
			// elements: dbPropertiesList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1204:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbProperties"


	public static class dbPropertiesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbPropertiesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
	public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
		HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA167=null;
		ParserRuleReturnScope keyValueProperty166 =null;
		ParserRuleReturnScope keyValueProperty168 =null;

		ASTNode COMMA167_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");

		 pushMsg("database properties list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:7: keyValueProperty ( COMMA keyValueProperty )*
			{
			pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList3991);
			keyValueProperty166=keyValueProperty();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty166.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:24: ( COMMA keyValueProperty )*
			loop39:
			while (true) {
				int alt39=2;
				int LA39_0 = input.LA(1);
				if ( (LA39_0==COMMA) ) {
					alt39=1;
				}

				switch (alt39) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:25: COMMA keyValueProperty
					{
					COMMA167=(Token)match(input,COMMA,FOLLOW_COMMA_in_dbPropertiesList3994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA167);

					pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList3996);
					keyValueProperty168=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty168.getTree());
					}
					break;

				default :
					break loop39;
				}
			}

			// AST REWRITE
			// elements: keyValueProperty
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1211:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST"), root_1);
				if ( !(stream_keyValueProperty.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_keyValueProperty.hasNext() ) {
					adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
				}
				stream_keyValueProperty.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbPropertiesList"


	public static class dbConnectorName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dbConnectorName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1214:1: dbConnectorName : KW_USING dcName= identifier -> ^( TOK_DATACONNECTOR $dcName) ;
	public final HiveParser.dbConnectorName_return dbConnectorName() throws RecognitionException {
		HiveParser.dbConnectorName_return retval = new HiveParser.dbConnectorName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USING169=null;
		ParserRuleReturnScope dcName =null;

		ASTNode KW_USING169_tree=null;
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("remote database using connector", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1217:5: ( KW_USING dcName= identifier -> ^( TOK_DATACONNECTOR $dcName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:7: KW_USING dcName= identifier
			{
			KW_USING169=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_dbConnectorName4040); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING169);

			pushFollow(FOLLOW_identifier_in_dbConnectorName4044);
			dcName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dcName.getTree());
			// AST REWRITE
			// elements: dcName
			// token labels: 
			// rule labels: dcName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dcName=new RewriteRuleSubtreeStream(adaptor,"rule dcName",dcName!=null?dcName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1218:34: -> ^( TOK_DATACONNECTOR $dcName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:37: ^( TOK_DATACONNECTOR $dcName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATACONNECTOR, "TOK_DATACONNECTOR"), root_1);
				adaptor.addChild(root_1, stream_dcName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dbConnectorName"


	public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "switchDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1221:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
	public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
		HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USE170=null;
		ParserRuleReturnScope identifier171 =null;

		ASTNode KW_USE170_tree=null;
		RewriteRuleTokenStream stream_KW_USE=new RewriteRuleTokenStream(adaptor,"token KW_USE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("switch database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:7: KW_USE identifier
			{
			KW_USE170=(Token)match(input,KW_USE,FOLLOW_KW_USE_in_switchDatabaseStatement4080); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USE.add(KW_USE170);

			pushFollow(FOLLOW_identifier_in_switchDatabaseStatement4082);
			identifier171=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier171.getTree());
			// AST REWRITE
			// elements: identifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1225:5: -> ^( TOK_SWITCHDATABASE identifier )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:8: ^( TOK_SWITCHDATABASE identifier )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE"), root_1);
				adaptor.addChild(root_1, stream_identifier.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "switchDatabaseStatement"


	public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropDatabaseStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
	public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
		HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP172=null;
		Token KW_DATABASE173=null;
		Token KW_SCHEMA174=null;
		ParserRuleReturnScope ifExists175 =null;
		ParserRuleReturnScope identifier176 =null;
		ParserRuleReturnScope restrictOrCascade177 =null;

		ASTNode KW_DROP172_tree=null;
		ASTNode KW_DATABASE173_tree=null;
		ASTNode KW_SCHEMA174_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");

		 pushMsg("drop database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
			{
			KW_DROP172=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropDatabaseStatement4121); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP172);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:15: ( KW_DATABASE | KW_SCHEMA )
			int alt40=2;
			int LA40_0 = input.LA(1);
			if ( (LA40_0==KW_DATABASE) ) {
				alt40=1;
			}
			else if ( (LA40_0==KW_SCHEMA) ) {
				alt40=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 40, 0, input);
				throw nvae;
			}

			switch (alt40) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:16: KW_DATABASE
					{
					KW_DATABASE173=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_dropDatabaseStatement4124); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE173);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:28: KW_SCHEMA
					{
					KW_SCHEMA174=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_dropDatabaseStatement4126); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA174);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:39: ( ifExists )?
			int alt41=2;
			int LA41_0 = input.LA(1);
			if ( (LA41_0==KW_IF) ) {
				alt41=1;
			}
			switch (alt41) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:39: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement4129);
					ifExists175=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists175.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_dropDatabaseStatement4132);
			identifier176=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier176.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:60: ( restrictOrCascade )?
			int alt42=2;
			int LA42_0 = input.LA(1);
			if ( (LA42_0==KW_CASCADE||LA42_0==KW_RESTRICT) ) {
				alt42=1;
			}
			switch (alt42) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:60: restrictOrCascade
					{
					pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement4134);
					restrictOrCascade177=restrictOrCascade();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_restrictOrCascade.add(restrictOrCascade177.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: identifier, ifExists, restrictOrCascade
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1232:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE"), root_1);
				adaptor.addChild(root_1, stream_identifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:38: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:48: ( restrictOrCascade )?
				if ( stream_restrictOrCascade.hasNext() ) {
					adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());
				}
				stream_restrictOrCascade.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropDatabaseStatement"


	public static class databaseComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "databaseComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
	public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
		HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT178=null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT178_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

		 pushMsg("database's comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1238:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1238:7: KW_COMMENT comment= StringLiteral
			{
			KW_COMMENT178=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_databaseComment4180); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT178);

			comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_databaseComment4184); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

			// AST REWRITE
			// elements: comment
			// token labels: comment
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1239:5: -> ^( TOK_DATABASECOMMENT $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1239:8: ^( TOK_DATABASECOMMENT $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT"), root_1);
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "databaseComment"


	public static class truncateTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "truncateTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:1: truncateTableStatement : KW_TRUNCATE ( KW_TABLE )? tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? ) ;
	public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
		HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TRUNCATE179=null;
		Token KW_TABLE180=null;
		Token KW_COLUMNS182=null;
		Token LPAREN183=null;
		Token RPAREN185=null;
		ParserRuleReturnScope tablePartitionPrefix181 =null;
		ParserRuleReturnScope columnNameList184 =null;
		ParserRuleReturnScope force186 =null;

		ASTNode KW_TRUNCATE179_tree=null;
		ASTNode KW_TABLE180_tree=null;
		ASTNode KW_COLUMNS182_tree=null;
		ASTNode LPAREN183_tree=null;
		ASTNode RPAREN185_tree=null;
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_TRUNCATE=new RewriteRuleTokenStream(adaptor,"token KW_TRUNCATE");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_force=new RewriteRuleSubtreeStream(adaptor,"rule force");
		RewriteRuleSubtreeStream stream_tablePartitionPrefix=new RewriteRuleSubtreeStream(adaptor,"rule tablePartitionPrefix");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("truncate table statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:5: ( KW_TRUNCATE ( KW_TABLE )? tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:7: KW_TRUNCATE ( KW_TABLE )? tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? ( force )?
			{
			KW_TRUNCATE179=(Token)match(input,KW_TRUNCATE,FOLLOW_KW_TRUNCATE_in_truncateTableStatement4224); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRUNCATE.add(KW_TRUNCATE179);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:19: ( KW_TABLE )?
			int alt43=2;
			int LA43_0 = input.LA(1);
			if ( (LA43_0==KW_TABLE) ) {
				alt43=1;
			}
			switch (alt43) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:19: KW_TABLE
					{
					KW_TABLE180=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_truncateTableStatement4226); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE180);

					}
					break;

			}

			pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement4229);
			tablePartitionPrefix181=tablePartitionPrefix();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tablePartitionPrefix.add(tablePartitionPrefix181.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:50: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
			int alt44=2;
			int LA44_0 = input.LA(1);
			if ( (LA44_0==KW_COLUMNS) ) {
				alt44=1;
			}
			switch (alt44) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:51: KW_COLUMNS LPAREN columnNameList RPAREN
					{
					KW_COLUMNS182=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_truncateTableStatement4232); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS182);

					LPAREN183=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_truncateTableStatement4234); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN183);

					pushFollow(FOLLOW_columnNameList_in_truncateTableStatement4236);
					columnNameList184=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList184.getTree());
					RPAREN185=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_truncateTableStatement4238); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN185);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:93: ( force )?
			int alt45=2;
			int LA45_0 = input.LA(1);
			if ( (LA45_0==KW_FORCE) ) {
				alt45=1;
			}
			switch (alt45) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:93: force
					{
					pushFollow(FOLLOW_force_in_truncateTableStatement4242);
					force186=force();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_force.add(force186.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tablePartitionPrefix, columnNameList, force
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1246:5: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:8: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ( force )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE"), root_1);
				adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:49: ( columnNameList )?
				if ( stream_columnNameList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameList.nextTree());
				}
				stream_columnNameList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1246:65: ( force )?
				if ( stream_force.hasNext() ) {
					adaptor.addChild(root_1, stream_force.nextTree());
				}
				stream_force.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "truncateTableStatement"


	public static class dropTableStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropTableStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1248:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) ;
	public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
		HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP187=null;
		Token KW_TABLE188=null;
		Token KW_PURGE191=null;
		ParserRuleReturnScope ifExists189 =null;
		ParserRuleReturnScope tableName190 =null;
		ParserRuleReturnScope replicationClause192 =null;

		ASTNode KW_DROP187_tree=null;
		ASTNode KW_TABLE188_tree=null;
		ASTNode KW_PURGE191_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_PURGE=new RewriteRuleTokenStream(adaptor,"token KW_PURGE");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_replicationClause=new RewriteRuleSubtreeStream(adaptor,"rule replicationClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("drop statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:5: ( KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )? -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:7: KW_DROP KW_TABLE ( ifExists )? tableName ( KW_PURGE )? ( replicationClause )?
			{
			KW_DROP187=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropTableStatement4283); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP187);

			KW_TABLE188=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_dropTableStatement4285); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE188);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:24: ( ifExists )?
			int alt46=2;
			int LA46_0 = input.LA(1);
			if ( (LA46_0==KW_IF) ) {
				alt46=1;
			}
			switch (alt46) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:24: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropTableStatement4287);
					ifExists189=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists189.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_dropTableStatement4290);
			tableName190=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName190.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:44: ( KW_PURGE )?
			int alt47=2;
			int LA47_0 = input.LA(1);
			if ( (LA47_0==KW_PURGE) ) {
				alt47=1;
			}
			switch (alt47) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:44: KW_PURGE
					{
					KW_PURGE191=(Token)match(input,KW_PURGE,FOLLOW_KW_PURGE_in_dropTableStatement4292); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PURGE.add(KW_PURGE191);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:54: ( replicationClause )?
			int alt48=2;
			int LA48_0 = input.LA(1);
			if ( (LA48_0==KW_FOR) ) {
				alt48=1;
			}
			switch (alt48) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:54: replicationClause
					{
					pushFollow(FOLLOW_replicationClause_in_dropTableStatement4295);
					replicationClause192=replicationClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_replicationClause.add(replicationClause192.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, KW_PURGE, replicationClause, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1252:5: -> ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1252:8: ^( TOK_DROPTABLE tableName ( ifExists )? ( KW_PURGE )? ( replicationClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1252:34: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1252:44: ( KW_PURGE )?
				if ( stream_KW_PURGE.hasNext() ) {
					adaptor.addChild(root_1, stream_KW_PURGE.nextNode());
				}
				stream_KW_PURGE.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1252:54: ( replicationClause )?
				if ( stream_replicationClause.hasNext() ) {
					adaptor.addChild(root_1, stream_replicationClause.nextTree());
				}
				stream_replicationClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropTableStatement"


	public static class inputFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "inputFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1255:1: inputFileFormat : KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral -> ^( TOK_INPUTFORMAT $inFmt $serdeCls) ;
	public final HiveParser.inputFileFormat_return inputFileFormat() throws RecognitionException {
		HiveParser.inputFileFormat_return retval = new HiveParser.inputFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token serdeCls=null;
		Token KW_INPUTFORMAT193=null;
		Token KW_SERDE194=null;

		ASTNode inFmt_tree=null;
		ASTNode serdeCls_tree=null;
		ASTNode KW_INPUTFORMAT193_tree=null;
		ASTNode KW_SERDE194_tree=null;
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");

		 pushMsg("Load Data input file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1258:5: ( KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral -> ^( TOK_INPUTFORMAT $inFmt $serdeCls) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1258:7: KW_INPUTFORMAT inFmt= StringLiteral KW_SERDE serdeCls= StringLiteral
			{
			KW_INPUTFORMAT193=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_inputFileFormat4344); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT193);

			inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_inputFileFormat4348); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

			KW_SERDE194=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_inputFileFormat4350); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE194);

			serdeCls=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_inputFileFormat4354); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(serdeCls);

			// AST REWRITE
			// elements: serdeCls, inFmt
			// token labels: inFmt, serdeCls
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
			RewriteRuleTokenStream stream_serdeCls=new RewriteRuleTokenStream(adaptor,"token serdeCls",serdeCls);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1259:7: -> ^( TOK_INPUTFORMAT $inFmt $serdeCls)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1259:10: ^( TOK_INPUTFORMAT $inFmt $serdeCls)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INPUTFORMAT, "TOK_INPUTFORMAT"), root_1);
				adaptor.addChild(root_1, stream_inFmt.nextNode());
				adaptor.addChild(root_1, stream_serdeCls.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "inputFileFormat"


	public static class tabTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tabTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1262:1: tabTypeExpr : identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? ;
	public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
		HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT196=null;
		Token DOT199=null;
		Token KW_ELEM_TYPE200=null;
		Token KW_KEY_TYPE201=null;
		Token KW_VALUE_TYPE202=null;
		ParserRuleReturnScope identifier195 =null;
		ParserRuleReturnScope identifier197 =null;
		ParserRuleReturnScope identifier198 =null;
		ParserRuleReturnScope identifier203 =null;

		ASTNode DOT196_tree=null;
		ASTNode DOT199_tree=null;
		ASTNode KW_ELEM_TYPE200_tree=null;
		ASTNode KW_KEY_TYPE201_tree=null;
		ASTNode KW_VALUE_TYPE202_tree=null;

		 pushMsg("specifying table types", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1265:4: ( identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1265:6: identifier ( DOT ^ identifier )? ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_tabTypeExpr4398);
			identifier195=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier195.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1265:17: ( DOT ^ identifier )?
			int alt49=2;
			int LA49_0 = input.LA(1);
			if ( (LA49_0==DOT) ) {
				alt49=1;
			}
			switch (alt49) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1265:18: DOT ^ identifier
					{
					DOT196=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr4401); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					DOT196_tree = (ASTNode)adaptor.create(DOT196);
					root_0 = (ASTNode)adaptor.becomeRoot(DOT196_tree, root_0);
					}

					pushFollow(FOLLOW_identifier_in_tabTypeExpr4404);
					identifier197=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier197.getTree());

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1266:4: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )?
			int alt52=2;
			switch ( input.LA(1) ) {
				case Identifier:
				case KW_ABORT:
				case KW_ACTIVATE:
				case KW_ACTIVE:
				case KW_ADD:
				case KW_ADMIN:
				case KW_AFTER:
				case KW_ALLOC_FRACTION:
				case KW_ANALYZE:
				case KW_ARCHIVE:
				case KW_ASC:
				case KW_AST:
				case KW_AT:
				case KW_AUTOCOMMIT:
				case KW_BEFORE:
				case KW_BUCKET:
				case KW_BUCKETS:
				case KW_CACHE:
				case KW_CASCADE:
				case KW_CBO:
				case KW_CHANGE:
				case KW_CHECK:
				case KW_CLUSTER:
				case KW_CLUSTERED:
				case KW_CLUSTERSTATUS:
				case KW_COLLECTION:
				case KW_COLUMNS:
				case KW_COMMENT:
				case KW_COMPACT:
				case KW_COMPACTIONS:
				case KW_COMPUTE:
				case KW_CONCATENATE:
				case KW_CONTINUE:
				case KW_COST:
				case KW_CRON:
				case KW_DATA:
				case KW_DATABASES:
				case KW_DATETIME:
				case KW_DAY:
				case KW_DBPROPERTIES:
				case KW_DCPROPERTIES:
				case KW_DEBUG:
				case KW_DEFAULT:
				case KW_DEFERRED:
				case KW_DEFINED:
				case KW_DELIMITED:
				case KW_DEPENDENCY:
				case KW_DESC:
				case KW_DETAIL:
				case KW_DIRECTORIES:
				case KW_DIRECTORY:
				case KW_DISABLE:
				case KW_DISTRIBUTE:
				case KW_DISTRIBUTED:
				case KW_DO:
				case KW_DOW:
				case KW_DUMP:
				case KW_ELEM_TYPE:
				case KW_ENABLE:
				case KW_ENFORCED:
				case KW_ESCAPED:
				case KW_EVERY:
				case KW_EXCLUSIVE:
				case KW_EXECUTE:
				case KW_EXECUTED:
				case KW_EXPIRE_SNAPSHOTS:
				case KW_EXPLAIN:
				case KW_EXPORT:
				case KW_EXPRESSION:
				case KW_FIELDS:
				case KW_FILE:
				case KW_FILEFORMAT:
				case KW_FIRST:
				case KW_FORMAT:
				case KW_FORMATTED:
				case KW_FUNCTIONS:
				case KW_HOUR:
				case KW_ID:
				case KW_IDXPROPERTIES:
				case KW_IGNORE:
				case KW_INDEX:
				case KW_INDEXES:
				case KW_INPATH:
				case KW_INPUTDRIVER:
				case KW_INPUTFORMAT:
				case KW_ISOLATION:
				case KW_ITEMS:
				case KW_JAR:
				case KW_JOINCOST:
				case KW_KEY:
				case KW_KEYS:
				case KW_KEY_TYPE:
				case KW_KILL:
				case KW_LAST:
				case KW_LEVEL:
				case KW_LINES:
				case KW_LOAD:
				case KW_LOCATION:
				case KW_LOCK:
				case KW_LOCKS:
				case KW_LOGICAL:
				case KW_LONG:
				case KW_MANAGED:
				case KW_MANAGEDLOCATION:
				case KW_MANAGEMENT:
				case KW_MAPJOIN:
				case KW_MAPPING:
				case KW_MATCHED:
				case KW_MATERIALIZED:
				case KW_METADATA:
				case KW_MINUTE:
				case KW_MONTH:
				case KW_MOVE:
				case KW_MSCK:
				case KW_NORELY:
				case KW_NOSCAN:
				case KW_NOVALIDATE:
				case KW_NULLS:
				case KW_OFFSET:
				case KW_OPERATOR:
				case KW_OPTION:
				case KW_OUTPUTDRIVER:
				case KW_OUTPUTFORMAT:
				case KW_OVERWRITE:
				case KW_OWNER:
				case KW_PARTITIONED:
				case KW_PARTITIONS:
				case KW_PATH:
				case KW_PLAN:
				case KW_PLANS:
				case KW_PLUS:
				case KW_PRINCIPALS:
				case KW_PURGE:
				case KW_QUARTER:
				case KW_QUERY:
				case KW_QUERY_PARALLELISM:
				case KW_READ:
				case KW_REBUILD:
				case KW_RECORDREADER:
				case KW_RECORDWRITER:
				case KW_RELOAD:
				case KW_RELY:
				case KW_REMOTE:
				case KW_RENAME:
				case KW_REOPTIMIZATION:
				case KW_REPAIR:
				case KW_REPL:
				case KW_REPLACE:
				case KW_REPLICATION:
				case KW_RESOURCE:
				case KW_RESPECT:
				case KW_RESTRICT:
				case KW_REWRITE:
				case KW_ROLE:
				case KW_ROLES:
				case KW_SCHEDULED:
				case KW_SCHEDULING_POLICY:
				case KW_SCHEMA:
				case KW_SCHEMAS:
				case KW_SECOND:
				case KW_SEMI:
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
				case KW_SERVER:
				case KW_SETS:
				case KW_SHARED:
				case KW_SHOW:
				case KW_SHOW_DATABASE:
				case KW_SKEWED:
				case KW_SNAPSHOT:
				case KW_SORT:
				case KW_SORTED:
				case KW_SPEC:
				case KW_SSL:
				case KW_STATISTICS:
				case KW_STORED:
				case KW_STREAMTABLE:
				case KW_STRING:
				case KW_STRUCT:
				case KW_SUMMARY:
				case KW_SYSTEM_TIME:
				case KW_SYSTEM_VERSION:
				case KW_TABLES:
				case KW_TBLPROPERTIES:
				case KW_TEMPORARY:
				case KW_TERMINATED:
				case KW_TINYINT:
				case KW_TOUCH:
				case KW_TRANSACTION:
				case KW_TRANSACTIONAL:
				case KW_TRANSACTIONS:
				case KW_TRIM:
				case KW_UNARCHIVE:
				case KW_UNDO:
				case KW_UNIONTYPE:
				case KW_UNKNOWN:
				case KW_UNLOCK:
				case KW_UNMANAGED:
				case KW_UNSET:
				case KW_UNSIGNED:
				case KW_URI:
				case KW_URL:
				case KW_USE:
				case KW_UTC:
				case KW_UTCTIMESTAMP:
				case KW_VALIDATE:
				case KW_VALUE_TYPE:
				case KW_VECTORIZATION:
				case KW_VIEW:
				case KW_VIEWS:
				case KW_WAIT:
				case KW_WEEK:
				case KW_WHILE:
				case KW_WITHIN:
				case KW_WORK:
				case KW_WORKLOAD:
				case KW_WRITE:
				case KW_YEAR:
				case KW_ZONE:
				case KW_BATCH:
				case KW_DAYOFWEEK:
				case KW_HOLD_DDLTIME:
				case KW_NO_DROP:
				case KW_OFFLINE:
				case KW_PROTECTION:
				case KW_READONLY:
				case KW_TIMESTAMPTZ:
					{
					alt52=1;
					}
					break;
				case KW_POOL:
					{
					int LA52_2 = input.LA(2);
					if ( (LA52_2==EOF||LA52_2==DOT||LA52_2==KW_EXTENDED||LA52_2==KW_LIMIT||LA52_2==KW_ORDER||LA52_2==KW_PARTITION||LA52_2==KW_POOL||LA52_2==KW_STATUS||LA52_2==KW_TYPE) ) {
						alt52=1;
					}
					}
					break;
				case KW_TYPE:
					{
					int LA52_6 = input.LA(2);
					if ( (LA52_6==EOF||LA52_6==DOT||LA52_6==KW_EXTENDED||LA52_6==KW_LIMIT||LA52_6==KW_ORDER||LA52_6==KW_PARTITION||LA52_6==KW_POOL||LA52_6==KW_STATUS||LA52_6==KW_TYPE) ) {
						alt52=1;
					}
					}
					break;
				case KW_STATUS:
					{
					int LA52_7 = input.LA(2);
					if ( (LA52_7==EOF||LA52_7==DOT||LA52_7==KW_EXTENDED||LA52_7==KW_LIMIT||LA52_7==KW_ORDER||LA52_7==KW_PARTITION||LA52_7==KW_POOL||LA52_7==KW_STATUS||LA52_7==KW_TYPE) ) {
						alt52=1;
					}
					}
					break;
				case KW_LIMIT:
					{
					int LA52_8 = input.LA(2);
					if ( (LA52_8==EOF||LA52_8==DOT||LA52_8==KW_EXTENDED||LA52_8==KW_LIMIT||LA52_8==KW_ORDER||LA52_8==KW_PARTITION||LA52_8==KW_POOL||LA52_8==KW_STATUS||LA52_8==KW_TYPE) ) {
						alt52=1;
					}
					}
					break;
			}
			switch (alt52) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1266:5: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
					{
					pushFollow(FOLLOW_identifier_in_tabTypeExpr4412);
					identifier198=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier198.getTree());

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1266:16: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
					loop51:
					while (true) {
						int alt51=2;
						int LA51_0 = input.LA(1);
						if ( (LA51_0==DOT) ) {
							alt51=1;
						}

						switch (alt51) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1266:17: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
							{
							DOT199=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr4415); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							DOT199_tree = (ASTNode)adaptor.create(DOT199);
							root_0 = (ASTNode)adaptor.becomeRoot(DOT199_tree, root_0);
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:4: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
							int alt50=4;
							switch ( input.LA(1) ) {
							case KW_ELEM_TYPE:
								{
								int LA50_1 = input.LA(2);
								if ( (synpred3_HiveParser()) ) {
									alt50=1;
								}
								else if ( (true) ) {
									alt50=4;
								}

								}
								break;
							case KW_KEY_TYPE:
								{
								int LA50_2 = input.LA(2);
								if ( (synpred4_HiveParser()) ) {
									alt50=2;
								}
								else if ( (true) ) {
									alt50=4;
								}

								}
								break;
							case KW_VALUE_TYPE:
								{
								int LA50_3 = input.LA(2);
								if ( (synpred5_HiveParser()) ) {
									alt50=3;
								}
								else if ( (true) ) {
									alt50=4;
								}

								}
								break;
							case Identifier:
							case KW_ABORT:
							case KW_ACTIVATE:
							case KW_ACTIVE:
							case KW_ADD:
							case KW_ADMIN:
							case KW_AFTER:
							case KW_ALLOC_FRACTION:
							case KW_ANALYZE:
							case KW_ARCHIVE:
							case KW_ASC:
							case KW_AST:
							case KW_AT:
							case KW_AUTOCOMMIT:
							case KW_BEFORE:
							case KW_BUCKET:
							case KW_BUCKETS:
							case KW_CACHE:
							case KW_CASCADE:
							case KW_CBO:
							case KW_CHANGE:
							case KW_CHECK:
							case KW_CLUSTER:
							case KW_CLUSTERED:
							case KW_CLUSTERSTATUS:
							case KW_COLLECTION:
							case KW_COLUMNS:
							case KW_COMMENT:
							case KW_COMPACT:
							case KW_COMPACTIONS:
							case KW_COMPUTE:
							case KW_CONCATENATE:
							case KW_CONTINUE:
							case KW_COST:
							case KW_CRON:
							case KW_DATA:
							case KW_DATABASES:
							case KW_DATETIME:
							case KW_DAY:
							case KW_DBPROPERTIES:
							case KW_DCPROPERTIES:
							case KW_DEBUG:
							case KW_DEFAULT:
							case KW_DEFERRED:
							case KW_DEFINED:
							case KW_DELIMITED:
							case KW_DEPENDENCY:
							case KW_DESC:
							case KW_DETAIL:
							case KW_DIRECTORIES:
							case KW_DIRECTORY:
							case KW_DISABLE:
							case KW_DISTRIBUTE:
							case KW_DISTRIBUTED:
							case KW_DO:
							case KW_DOW:
							case KW_DUMP:
							case KW_ENABLE:
							case KW_ENFORCED:
							case KW_ESCAPED:
							case KW_EVERY:
							case KW_EXCLUSIVE:
							case KW_EXECUTE:
							case KW_EXECUTED:
							case KW_EXPIRE_SNAPSHOTS:
							case KW_EXPLAIN:
							case KW_EXPORT:
							case KW_EXPRESSION:
							case KW_FIELDS:
							case KW_FILE:
							case KW_FILEFORMAT:
							case KW_FIRST:
							case KW_FORMAT:
							case KW_FORMATTED:
							case KW_FUNCTIONS:
							case KW_HOUR:
							case KW_ID:
							case KW_IDXPROPERTIES:
							case KW_IGNORE:
							case KW_INDEX:
							case KW_INDEXES:
							case KW_INPATH:
							case KW_INPUTDRIVER:
							case KW_INPUTFORMAT:
							case KW_ISOLATION:
							case KW_ITEMS:
							case KW_JAR:
							case KW_JOINCOST:
							case KW_KEY:
							case KW_KEYS:
							case KW_KILL:
							case KW_LAST:
							case KW_LEVEL:
							case KW_LIMIT:
							case KW_LINES:
							case KW_LOAD:
							case KW_LOCATION:
							case KW_LOCK:
							case KW_LOCKS:
							case KW_LOGICAL:
							case KW_LONG:
							case KW_MANAGED:
							case KW_MANAGEDLOCATION:
							case KW_MANAGEMENT:
							case KW_MAPJOIN:
							case KW_MAPPING:
							case KW_MATCHED:
							case KW_MATERIALIZED:
							case KW_METADATA:
							case KW_MINUTE:
							case KW_MONTH:
							case KW_MOVE:
							case KW_MSCK:
							case KW_NORELY:
							case KW_NOSCAN:
							case KW_NOVALIDATE:
							case KW_NULLS:
							case KW_OFFSET:
							case KW_OPERATOR:
							case KW_OPTION:
							case KW_OUTPUTDRIVER:
							case KW_OUTPUTFORMAT:
							case KW_OVERWRITE:
							case KW_OWNER:
							case KW_PARTITIONED:
							case KW_PARTITIONS:
							case KW_PATH:
							case KW_PLAN:
							case KW_PLANS:
							case KW_PLUS:
							case KW_POOL:
							case KW_PRINCIPALS:
							case KW_PURGE:
							case KW_QUARTER:
							case KW_QUERY:
							case KW_QUERY_PARALLELISM:
							case KW_READ:
							case KW_REBUILD:
							case KW_RECORDREADER:
							case KW_RECORDWRITER:
							case KW_RELOAD:
							case KW_RELY:
							case KW_REMOTE:
							case KW_RENAME:
							case KW_REOPTIMIZATION:
							case KW_REPAIR:
							case KW_REPL:
							case KW_REPLACE:
							case KW_REPLICATION:
							case KW_RESOURCE:
							case KW_RESPECT:
							case KW_RESTRICT:
							case KW_REWRITE:
							case KW_ROLE:
							case KW_ROLES:
							case KW_SCHEDULED:
							case KW_SCHEDULING_POLICY:
							case KW_SCHEMA:
							case KW_SCHEMAS:
							case KW_SECOND:
							case KW_SEMI:
							case KW_SERDE:
							case KW_SERDEPROPERTIES:
							case KW_SERVER:
							case KW_SETS:
							case KW_SHARED:
							case KW_SHOW:
							case KW_SHOW_DATABASE:
							case KW_SKEWED:
							case KW_SNAPSHOT:
							case KW_SORT:
							case KW_SORTED:
							case KW_SPEC:
							case KW_SSL:
							case KW_STATISTICS:
							case KW_STATUS:
							case KW_STORED:
							case KW_STREAMTABLE:
							case KW_STRING:
							case KW_STRUCT:
							case KW_SUMMARY:
							case KW_SYSTEM_TIME:
							case KW_SYSTEM_VERSION:
							case KW_TABLES:
							case KW_TBLPROPERTIES:
							case KW_TEMPORARY:
							case KW_TERMINATED:
							case KW_TINYINT:
							case KW_TOUCH:
							case KW_TRANSACTION:
							case KW_TRANSACTIONAL:
							case KW_TRANSACTIONS:
							case KW_TRIM:
							case KW_TYPE:
							case KW_UNARCHIVE:
							case KW_UNDO:
							case KW_UNIONTYPE:
							case KW_UNKNOWN:
							case KW_UNLOCK:
							case KW_UNMANAGED:
							case KW_UNSET:
							case KW_UNSIGNED:
							case KW_URI:
							case KW_URL:
							case KW_USE:
							case KW_UTC:
							case KW_UTCTIMESTAMP:
							case KW_VALIDATE:
							case KW_VECTORIZATION:
							case KW_VIEW:
							case KW_VIEWS:
							case KW_WAIT:
							case KW_WEEK:
							case KW_WHILE:
							case KW_WITHIN:
							case KW_WORK:
							case KW_WORKLOAD:
							case KW_WRITE:
							case KW_YEAR:
							case KW_ZONE:
							case KW_BATCH:
							case KW_DAYOFWEEK:
							case KW_HOLD_DDLTIME:
							case KW_NO_DROP:
							case KW_OFFLINE:
							case KW_PROTECTION:
							case KW_READONLY:
							case KW_TIMESTAMPTZ:
								{
								alt50=4;
								}
								break;
							default:
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 50, 0, input);
								throw nvae;
							}
							switch (alt50) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:4: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
									{
									KW_ELEM_TYPE200=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr4432); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_ELEM_TYPE200_tree = (ASTNode)adaptor.create(KW_ELEM_TYPE200);
									adaptor.addChild(root_0, KW_ELEM_TYPE200_tree);
									}

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:4: ( KW_KEY_TYPE )=> KW_KEY_TYPE
									{
									KW_KEY_TYPE201=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_tabTypeExpr4448); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_KEY_TYPE201_tree = (ASTNode)adaptor.create(KW_KEY_TYPE201);
									adaptor.addChild(root_0, KW_KEY_TYPE201_tree);
									}

									}
									break;
								case 3 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1272:4: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
									{
									KW_VALUE_TYPE202=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr4464); if (state.failed) return retval;
									if ( state.backtracking==0 ) {
									KW_VALUE_TYPE202_tree = (ASTNode)adaptor.create(KW_VALUE_TYPE202);
									adaptor.addChild(root_0, KW_VALUE_TYPE202_tree);
									}

									}
									break;
								case 4 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1273:6: identifier
									{
									pushFollow(FOLLOW_identifier_in_tabTypeExpr4471);
									identifier203=identifier();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier203.getTree());

									}
									break;

							}

							}
							break;

						default :
							break loop51;
						}
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tabTypeExpr"


	public static class partTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
	public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
		HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tabTypeExpr204 =null;
		ParserRuleReturnScope partitionSpec205 =null;

		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tabTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabTypeExpr");

		 pushMsg("specifying table partitions", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:8: tabTypeExpr ( partitionSpec )?
			{
			pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr4511);
			tabTypeExpr204=tabTypeExpr();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tabTypeExpr.add(tabTypeExpr204.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:20: ( partitionSpec )?
			int alt53=2;
			int LA53_0 = input.LA(1);
			if ( (LA53_0==KW_PARTITION) ) {
				alt53=1;
			}
			switch (alt53) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:20: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_partTypeExpr4513);
					partitionSpec205=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec205.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tabTypeExpr, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1281:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);
				adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:64: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partTypeExpr"


	public static class tabPartColTypeExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tabPartColTypeExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:1: tabPartColTypeExpr : tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) ;
	public final HiveParser.tabPartColTypeExpr_return tabPartColTypeExpr() throws RecognitionException {
		HiveParser.tabPartColTypeExpr_return retval = new HiveParser.tabPartColTypeExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableName206 =null;
		ParserRuleReturnScope partitionSpec207 =null;
		ParserRuleReturnScope extColumnName208 =null;

		RewriteRuleSubtreeStream stream_extColumnName=new RewriteRuleSubtreeStream(adaptor,"rule extColumnName");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("specifying table partitions columnName", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:5: ( tableName ( partitionSpec )? ( extColumnName )? -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:8: tableName ( partitionSpec )? ( extColumnName )?
			{
			pushFollow(FOLLOW_tableName_in_tabPartColTypeExpr4553);
			tableName206=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName206.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:18: ( partitionSpec )?
			int alt54=2;
			int LA54_0 = input.LA(1);
			if ( (LA54_0==KW_PARTITION) ) {
				alt54=1;
			}
			switch (alt54) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:18: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_tabPartColTypeExpr4555);
					partitionSpec207=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec207.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:33: ( extColumnName )?
			int alt55=2;
			int LA55_0 = input.LA(1);
			if ( (LA55_0==Identifier||(LA55_0 >= KW_ABORT && LA55_0 <= KW_AFTER)||LA55_0==KW_ALLOC_FRACTION||LA55_0==KW_ANALYZE||LA55_0==KW_ARCHIVE||(LA55_0 >= KW_ASC && LA55_0 <= KW_AT)||(LA55_0 >= KW_AUTOCOMMIT && LA55_0 <= KW_BEFORE)||(LA55_0 >= KW_BUCKET && LA55_0 <= KW_BUCKETS)||(LA55_0 >= KW_CACHE && LA55_0 <= KW_CASCADE)||(LA55_0 >= KW_CBO && LA55_0 <= KW_CHANGE)||(LA55_0 >= KW_CHECK && LA55_0 <= KW_COLLECTION)||(LA55_0 >= KW_COLUMNS && LA55_0 <= KW_COMMENT)||(LA55_0 >= KW_COMPACT && LA55_0 <= KW_CONCATENATE)||(LA55_0 >= KW_CONTINUE && LA55_0 <= KW_COST)||LA55_0==KW_CRON||LA55_0==KW_DATA||LA55_0==KW_DATABASES||(LA55_0 >= KW_DATETIME && LA55_0 <= KW_DCPROPERTIES)||LA55_0==KW_DEBUG||(LA55_0 >= KW_DEFAULT && LA55_0 <= KW_DEFINED)||(LA55_0 >= KW_DELIMITED && LA55_0 <= KW_DESC)||(LA55_0 >= KW_DETAIL && LA55_0 <= KW_DISABLE)||(LA55_0 >= KW_DISTRIBUTE && LA55_0 <= KW_DO)||LA55_0==KW_DOW||(LA55_0 >= KW_DUMP && LA55_0 <= KW_ELEM_TYPE)||LA55_0==KW_ENABLE||(LA55_0 >= KW_ENFORCED && LA55_0 <= KW_EVERY)||(LA55_0 >= KW_EXCLUSIVE && LA55_0 <= KW_EXECUTED)||(LA55_0 >= KW_EXPIRE_SNAPSHOTS && LA55_0 <= KW_EXPRESSION)||(LA55_0 >= KW_FIELDS && LA55_0 <= KW_FIRST)||(LA55_0 >= KW_FORMAT && LA55_0 <= KW_FORMATTED)||LA55_0==KW_FUNCTIONS||(LA55_0 >= KW_HOUR && LA55_0 <= KW_IDXPROPERTIES)||LA55_0==KW_IGNORE||(LA55_0 >= KW_INDEX && LA55_0 <= KW_INDEXES)||(LA55_0 >= KW_INPATH && LA55_0 <= KW_INPUTFORMAT)||(LA55_0 >= KW_ISOLATION && LA55_0 <= KW_JAR)||(LA55_0 >= KW_JOINCOST && LA55_0 <= KW_LAST)||LA55_0==KW_LEVEL||(LA55_0 >= KW_LIMIT && LA55_0 <= KW_LOAD)||(LA55_0 >= KW_LOCATION && LA55_0 <= KW_LONG)||(LA55_0 >= KW_MANAGED && LA55_0 <= KW_MANAGEMENT)||(LA55_0 >= KW_MAPJOIN && LA55_0 <= KW_MATERIALIZED)||LA55_0==KW_METADATA||(LA55_0 >= KW_MINUTE && LA55_0 <= KW_MONTH)||(LA55_0 >= KW_MOVE && LA55_0 <= KW_MSCK)||(LA55_0 >= KW_NORELY && LA55_0 <= KW_NOSCAN)||LA55_0==KW_NOVALIDATE||LA55_0==KW_NULLS||LA55_0==KW_OFFSET||(LA55_0 >= KW_OPERATOR && LA55_0 <= KW_OPTION)||(LA55_0 >= KW_OUTPUTDRIVER && LA55_0 <= KW_OUTPUTFORMAT)||(LA55_0 >= KW_OVERWRITE && LA55_0 <= KW_OWNER)||(LA55_0 >= KW_PARTITIONED && LA55_0 <= KW_PATH)||(LA55_0 >= KW_PLAN && LA55_0 <= KW_POOL)||LA55_0==KW_PRINCIPALS||LA55_0==KW_PURGE||(LA55_0 >= KW_QUARTER && LA55_0 <= KW_QUERY_PARALLELISM)||LA55_0==KW_READ||(LA55_0 >= KW_REBUILD && LA55_0 <= KW_RECORDWRITER)||(LA55_0 >= KW_RELOAD && LA55_0 <= KW_RESTRICT)||LA55_0==KW_REWRITE||(LA55_0 >= KW_ROLE && LA55_0 <= KW_ROLES)||(LA55_0 >= KW_SCHEDULED && LA55_0 <= KW_SECOND)||(LA55_0 >= KW_SEMI && LA55_0 <= KW_SERVER)||(LA55_0 >= KW_SETS && LA55_0 <= KW_SKEWED)||LA55_0==KW_SNAPSHOT||(LA55_0 >= KW_SORT && LA55_0 <= KW_SSL)||(LA55_0 >= KW_STATISTICS && LA55_0 <= KW_SUMMARY)||(LA55_0 >= KW_SYSTEM_TIME && LA55_0 <= KW_SYSTEM_VERSION)||LA55_0==KW_TABLES||(LA55_0 >= KW_TBLPROPERTIES && LA55_0 <= KW_TERMINATED)||LA55_0==KW_TINYINT||LA55_0==KW_TOUCH||(LA55_0 >= KW_TRANSACTION && LA55_0 <= KW_TRANSACTIONS)||LA55_0==KW_TRIM||(LA55_0 >= KW_TYPE && LA55_0 <= KW_UNARCHIVE)||LA55_0==KW_UNDO||LA55_0==KW_UNIONTYPE||(LA55_0 >= KW_UNKNOWN && LA55_0 <= KW_UNSIGNED)||(LA55_0 >= KW_URI && LA55_0 <= KW_USE)||(LA55_0 >= KW_UTC && LA55_0 <= KW_VALIDATE)||LA55_0==KW_VALUE_TYPE||(LA55_0 >= KW_VECTORIZATION && LA55_0 <= KW_WEEK)||LA55_0==KW_WHILE||(LA55_0 >= KW_WITHIN && LA55_0 <= KW_ZONE)||LA55_0==KW_BATCH||LA55_0==KW_DAYOFWEEK||LA55_0==KW_HOLD_DDLTIME||LA55_0==KW_NO_DROP||LA55_0==KW_OFFLINE||LA55_0==KW_PROTECTION||LA55_0==KW_READONLY||LA55_0==KW_TIMESTAMPTZ) ) {
				alt55=1;
			}
			switch (alt55) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:33: extColumnName
					{
					pushFollow(FOLLOW_extColumnName_in_tabPartColTypeExpr4558);
					extColumnName208=extColumnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_extColumnName.add(extColumnName208.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: partitionSpec, extColumnName, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1287:48: -> ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:51: ^( TOK_TABTYPE tableName ( partitionSpec )? ( extColumnName )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:75: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1287:90: ( extColumnName )?
				if ( stream_extColumnName.hasNext() ) {
					adaptor.addChild(root_1, stream_extColumnName.nextTree());
				}
				stream_extColumnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tabPartColTypeExpr"


	public static class descStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "descStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1290:1: descStatement : ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DATACONNECTOR )=> ( KW_DATACONNECTOR ) ( KW_EXTENDED )? (dcName= identifier ) -> ^( TOK_DESCDATACONNECTOR $dcName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) ;
	public final HiveParser.descStatement_return descStatement() throws RecognitionException {
		HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token descOptions=null;
		Token KW_DESCRIBE209=null;
		Token KW_DESC210=null;
		Token KW_DATABASE211=null;
		Token KW_SCHEMA212=null;
		Token KW_EXTENDED213=null;
		Token KW_DATACONNECTOR214=null;
		Token KW_EXTENDED215=null;
		Token KW_FUNCTION216=null;
		Token KW_EXTENDED217=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope dcName =null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope parttype =null;

		ASTNode descOptions_tree=null;
		ASTNode KW_DESCRIBE209_tree=null;
		ASTNode KW_DESC210_tree=null;
		ASTNode KW_DATABASE211_tree=null;
		ASTNode KW_SCHEMA212_tree=null;
		ASTNode KW_EXTENDED213_tree=null;
		ASTNode KW_DATACONNECTOR214_tree=null;
		ASTNode KW_EXTENDED215_tree=null;
		ASTNode KW_FUNCTION216_tree=null;
		ASTNode KW_EXTENDED217_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
		RewriteRuleTokenStream stream_KW_DATACONNECTOR=new RewriteRuleTokenStream(adaptor,"token KW_DATACONNECTOR");
		RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
		RewriteRuleTokenStream stream_KW_DESCRIBE=new RewriteRuleTokenStream(adaptor,"token KW_DESCRIBE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tabPartColTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabPartColTypeExpr");
		RewriteRuleSubtreeStream stream_descFuncNames=new RewriteRuleSubtreeStream(adaptor,"rule descFuncNames");

		 pushMsg("describe statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1293:5: ( ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DATACONNECTOR )=> ( KW_DATACONNECTOR ) ( KW_EXTENDED )? (dcName= identifier ) -> ^( TOK_DESCDATACONNECTOR $dcName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:5: ( KW_DESCRIBE | KW_DESC ) ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DATACONNECTOR )=> ( KW_DATACONNECTOR ) ( KW_EXTENDED )? (dcName= identifier ) -> ^( TOK_DESCDATACONNECTOR $dcName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:5: ( KW_DESCRIBE | KW_DESC )
			int alt56=2;
			int LA56_0 = input.LA(1);
			if ( (LA56_0==KW_DESCRIBE) ) {
				alt56=1;
			}
			else if ( (LA56_0==KW_DESC) ) {
				alt56=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 56, 0, input);
				throw nvae;
			}

			switch (alt56) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:6: KW_DESCRIBE
					{
					KW_DESCRIBE209=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement4605); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESCRIBE.add(KW_DESCRIBE209);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1294:18: KW_DESC
					{
					KW_DESC210=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement4607); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC210);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1295:5: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) | ( KW_DATACONNECTOR )=> ( KW_DATACONNECTOR ) ( KW_EXTENDED )? (dcName= identifier ) -> ^( TOK_DESCDATACONNECTOR $dcName ( KW_EXTENDED )? ) | ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr ) -> ^( TOK_DESCTABLE $parttype $descOptions) |parttype= tabPartColTypeExpr -> ^( TOK_DESCTABLE $parttype) )
			int alt62=5;
			int LA62_0 = input.LA(1);
			if ( (LA62_0==KW_DATABASE) && (synpred6_HiveParser())) {
				alt62=1;
			}
			else if ( (LA62_0==KW_SCHEMA) ) {
				int LA62_2 = input.LA(2);
				if ( (LA62_2==KW_EXTENDED) && (synpred6_HiveParser())) {
					alt62=1;
				}
				else if ( (LA62_2==Identifier) ) {
					int LA62_10 = input.LA(3);
					if ( (synpred6_HiveParser()) ) {
						alt62=1;
					}
					else if ( (true) ) {
						alt62=5;
					}

				}
				else if ( ((LA62_2 >= KW_ABORT && LA62_2 <= KW_AFTER)||LA62_2==KW_ALLOC_FRACTION||LA62_2==KW_ANALYZE||LA62_2==KW_ARCHIVE||(LA62_2 >= KW_ASC && LA62_2 <= KW_AT)||(LA62_2 >= KW_AUTOCOMMIT && LA62_2 <= KW_BEFORE)||(LA62_2 >= KW_BUCKET && LA62_2 <= KW_BUCKETS)||(LA62_2 >= KW_CACHE && LA62_2 <= KW_CASCADE)||(LA62_2 >= KW_CBO && LA62_2 <= KW_CHANGE)||(LA62_2 >= KW_CHECK && LA62_2 <= KW_COLLECTION)||(LA62_2 >= KW_COLUMNS && LA62_2 <= KW_COMMENT)||(LA62_2 >= KW_COMPACT && LA62_2 <= KW_CONCATENATE)||(LA62_2 >= KW_CONTINUE && LA62_2 <= KW_COST)||LA62_2==KW_CRON||LA62_2==KW_DATA||LA62_2==KW_DATABASES||(LA62_2 >= KW_DATETIME && LA62_2 <= KW_DCPROPERTIES)||LA62_2==KW_DEBUG||(LA62_2 >= KW_DEFAULT && LA62_2 <= KW_DEFINED)||(LA62_2 >= KW_DELIMITED && LA62_2 <= KW_DESC)||(LA62_2 >= KW_DETAIL && LA62_2 <= KW_DISABLE)||(LA62_2 >= KW_DISTRIBUTE && LA62_2 <= KW_DO)||LA62_2==KW_DOW||(LA62_2 >= KW_DUMP && LA62_2 <= KW_ELEM_TYPE)||LA62_2==KW_ENABLE||(LA62_2 >= KW_ENFORCED && LA62_2 <= KW_EVERY)||(LA62_2 >= KW_EXCLUSIVE && LA62_2 <= KW_EXECUTED)||(LA62_2 >= KW_EXPIRE_SNAPSHOTS && LA62_2 <= KW_EXPRESSION)||(LA62_2 >= KW_FIELDS && LA62_2 <= KW_FIRST)||(LA62_2 >= KW_FORMAT && LA62_2 <= KW_FORMATTED)||LA62_2==KW_FUNCTIONS||(LA62_2 >= KW_HOUR && LA62_2 <= KW_IDXPROPERTIES)||LA62_2==KW_IGNORE||(LA62_2 >= KW_INDEX && LA62_2 <= KW_INDEXES)||(LA62_2 >= KW_INPATH && LA62_2 <= KW_INPUTFORMAT)||(LA62_2 >= KW_ISOLATION && LA62_2 <= KW_JAR)||(LA62_2 >= KW_JOINCOST && LA62_2 <= KW_LAST)||LA62_2==KW_LEVEL||(LA62_2 >= KW_LIMIT && LA62_2 <= KW_LOAD)||(LA62_2 >= KW_LOCATION && LA62_2 <= KW_LONG)||(LA62_2 >= KW_MANAGED && LA62_2 <= KW_MANAGEMENT)||(LA62_2 >= KW_MAPJOIN && LA62_2 <= KW_MATERIALIZED)||LA62_2==KW_METADATA||(LA62_2 >= KW_MINUTE && LA62_2 <= KW_MONTH)||(LA62_2 >= KW_MOVE && LA62_2 <= KW_MSCK)||(LA62_2 >= KW_NORELY && LA62_2 <= KW_NOSCAN)||LA62_2==KW_NOVALIDATE||LA62_2==KW_NULLS||LA62_2==KW_OFFSET||(LA62_2 >= KW_OPERATOR && LA62_2 <= KW_OPTION)||(LA62_2 >= KW_OUTPUTDRIVER && LA62_2 <= KW_OUTPUTFORMAT)||(LA62_2 >= KW_OVERWRITE && LA62_2 <= KW_OWNER)||(LA62_2 >= KW_PARTITIONED && LA62_2 <= KW_PATH)||(LA62_2 >= KW_PLAN && LA62_2 <= KW_POOL)||LA62_2==KW_PRINCIPALS||LA62_2==KW_PURGE||(LA62_2 >= KW_QUARTER && LA62_2 <= KW_QUERY_PARALLELISM)||LA62_2==KW_READ||(LA62_2 >= KW_REBUILD && LA62_2 <= KW_RECORDWRITER)||(LA62_2 >= KW_RELOAD && LA62_2 <= KW_RESTRICT)||LA62_2==KW_REWRITE||(LA62_2 >= KW_ROLE && LA62_2 <= KW_ROLES)||(LA62_2 >= KW_SCHEDULED && LA62_2 <= KW_SECOND)||(LA62_2 >= KW_SEMI && LA62_2 <= KW_SERVER)||(LA62_2 >= KW_SETS && LA62_2 <= KW_SKEWED)||LA62_2==KW_SNAPSHOT||(LA62_2 >= KW_SORT && LA62_2 <= KW_SSL)||(LA62_2 >= KW_STATISTICS && LA62_2 <= KW_SUMMARY)||(LA62_2 >= KW_SYSTEM_TIME && LA62_2 <= KW_SYSTEM_VERSION)||LA62_2==KW_TABLES||(LA62_2 >= KW_TBLPROPERTIES && LA62_2 <= KW_TERMINATED)||LA62_2==KW_TINYINT||LA62_2==KW_TOUCH||(LA62_2 >= KW_TRANSACTION && LA62_2 <= KW_TRANSACTIONS)||LA62_2==KW_TRIM||(LA62_2 >= KW_TYPE && LA62_2 <= KW_UNARCHIVE)||LA62_2==KW_UNDO||LA62_2==KW_UNIONTYPE||(LA62_2 >= KW_UNKNOWN && LA62_2 <= KW_UNSIGNED)||(LA62_2 >= KW_URI && LA62_2 <= KW_USE)||(LA62_2 >= KW_UTC && LA62_2 <= KW_VALIDATE)||LA62_2==KW_VALUE_TYPE||(LA62_2 >= KW_VECTORIZATION && LA62_2 <= KW_WEEK)||LA62_2==KW_WHILE||(LA62_2 >= KW_WITHIN && LA62_2 <= KW_ZONE)||LA62_2==KW_BATCH||LA62_2==KW_DAYOFWEEK||LA62_2==KW_HOLD_DDLTIME||LA62_2==KW_NO_DROP||LA62_2==KW_OFFLINE||LA62_2==KW_PROTECTION||LA62_2==KW_READONLY||LA62_2==KW_TIMESTAMPTZ) ) {
					int LA62_11 = input.LA(3);
					if ( (synpred6_HiveParser()) ) {
						alt62=1;
					}
					else if ( (true) ) {
						alt62=5;
					}

				}
				else if ( (LA62_2==EOF||LA62_2==DOT||LA62_2==KW_PARTITION) ) {
					alt62=5;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 62, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA62_0==KW_DATACONNECTOR) && (synpred7_HiveParser())) {
				alt62=2;
			}
			else if ( (LA62_0==KW_FUNCTION) && (synpred8_HiveParser())) {
				alt62=3;
			}
			else if ( (LA62_0==KW_FORMATTED) ) {
				switch ( input.LA(2) ) {
				case Identifier:
					{
					int LA62_15 = input.LA(3);
					if ( (synpred9_HiveParser()) ) {
						alt62=4;
					}
					else if ( (true) ) {
						alt62=5;
					}

					}
					break;
				case KW_ABORT:
				case KW_ACTIVATE:
				case KW_ACTIVE:
				case KW_ADD:
				case KW_ADMIN:
				case KW_AFTER:
				case KW_ALLOC_FRACTION:
				case KW_ANALYZE:
				case KW_ARCHIVE:
				case KW_ASC:
				case KW_AST:
				case KW_AT:
				case KW_AUTOCOMMIT:
				case KW_BEFORE:
				case KW_BUCKET:
				case KW_BUCKETS:
				case KW_CACHE:
				case KW_CASCADE:
				case KW_CBO:
				case KW_CHANGE:
				case KW_CHECK:
				case KW_CLUSTER:
				case KW_CLUSTERED:
				case KW_CLUSTERSTATUS:
				case KW_COLLECTION:
				case KW_COLUMNS:
				case KW_COMMENT:
				case KW_COMPACT:
				case KW_COMPACTIONS:
				case KW_COMPUTE:
				case KW_CONCATENATE:
				case KW_CONTINUE:
				case KW_COST:
				case KW_CRON:
				case KW_DATA:
				case KW_DATABASES:
				case KW_DATETIME:
				case KW_DAY:
				case KW_DBPROPERTIES:
				case KW_DCPROPERTIES:
				case KW_DEBUG:
				case KW_DEFAULT:
				case KW_DEFERRED:
				case KW_DEFINED:
				case KW_DELIMITED:
				case KW_DEPENDENCY:
				case KW_DESC:
				case KW_DETAIL:
				case KW_DIRECTORIES:
				case KW_DIRECTORY:
				case KW_DISABLE:
				case KW_DISTRIBUTE:
				case KW_DISTRIBUTED:
				case KW_DO:
				case KW_DOW:
				case KW_DUMP:
				case KW_ELEM_TYPE:
				case KW_ENABLE:
				case KW_ENFORCED:
				case KW_ESCAPED:
				case KW_EVERY:
				case KW_EXCLUSIVE:
				case KW_EXECUTE:
				case KW_EXECUTED:
				case KW_EXPIRE_SNAPSHOTS:
				case KW_EXPLAIN:
				case KW_EXPORT:
				case KW_EXPRESSION:
				case KW_FIELDS:
				case KW_FILE:
				case KW_FILEFORMAT:
				case KW_FIRST:
				case KW_FORMAT:
				case KW_FORMATTED:
				case KW_FUNCTIONS:
				case KW_HOUR:
				case KW_ID:
				case KW_IDXPROPERTIES:
				case KW_IGNORE:
				case KW_INDEX:
				case KW_INDEXES:
				case KW_INPATH:
				case KW_INPUTDRIVER:
				case KW_INPUTFORMAT:
				case KW_ISOLATION:
				case KW_ITEMS:
				case KW_JAR:
				case KW_JOINCOST:
				case KW_KEY:
				case KW_KEYS:
				case KW_KEY_TYPE:
				case KW_KILL:
				case KW_LAST:
				case KW_LEVEL:
				case KW_LIMIT:
				case KW_LINES:
				case KW_LOAD:
				case KW_LOCATION:
				case KW_LOCK:
				case KW_LOCKS:
				case KW_LOGICAL:
				case KW_LONG:
				case KW_MANAGED:
				case KW_MANAGEDLOCATION:
				case KW_MANAGEMENT:
				case KW_MAPJOIN:
				case KW_MAPPING:
				case KW_MATCHED:
				case KW_MATERIALIZED:
				case KW_METADATA:
				case KW_MINUTE:
				case KW_MONTH:
				case KW_MOVE:
				case KW_MSCK:
				case KW_NORELY:
				case KW_NOSCAN:
				case KW_NOVALIDATE:
				case KW_NULLS:
				case KW_OFFSET:
				case KW_OPERATOR:
				case KW_OPTION:
				case KW_OUTPUTDRIVER:
				case KW_OUTPUTFORMAT:
				case KW_OVERWRITE:
				case KW_OWNER:
				case KW_PARTITIONED:
				case KW_PARTITIONS:
				case KW_PATH:
				case KW_PLAN:
				case KW_PLANS:
				case KW_PLUS:
				case KW_POOL:
				case KW_PRINCIPALS:
				case KW_PURGE:
				case KW_QUARTER:
				case KW_QUERY:
				case KW_QUERY_PARALLELISM:
				case KW_READ:
				case KW_REBUILD:
				case KW_RECORDREADER:
				case KW_RECORDWRITER:
				case KW_RELOAD:
				case KW_RELY:
				case KW_REMOTE:
				case KW_RENAME:
				case KW_REOPTIMIZATION:
				case KW_REPAIR:
				case KW_REPL:
				case KW_REPLACE:
				case KW_REPLICATION:
				case KW_RESOURCE:
				case KW_RESPECT:
				case KW_RESTRICT:
				case KW_REWRITE:
				case KW_ROLE:
				case KW_ROLES:
				case KW_SCHEDULED:
				case KW_SCHEDULING_POLICY:
				case KW_SCHEMA:
				case KW_SCHEMAS:
				case KW_SECOND:
				case KW_SEMI:
				case KW_SERDE:
				case KW_SERDEPROPERTIES:
				case KW_SERVER:
				case KW_SETS:
				case KW_SHARED:
				case KW_SHOW:
				case KW_SHOW_DATABASE:
				case KW_SKEWED:
				case KW_SNAPSHOT:
				case KW_SORT:
				case KW_SORTED:
				case KW_SPEC:
				case KW_SSL:
				case KW_STATISTICS:
				case KW_STATUS:
				case KW_STORED:
				case KW_STREAMTABLE:
				case KW_STRING:
				case KW_STRUCT:
				case KW_SUMMARY:
				case KW_SYSTEM_TIME:
				case KW_SYSTEM_VERSION:
				case KW_TABLES:
				case KW_TBLPROPERTIES:
				case KW_TEMPORARY:
				case KW_TERMINATED:
				case KW_TINYINT:
				case KW_TOUCH:
				case KW_TRANSACTION:
				case KW_TRANSACTIONAL:
				case KW_TRANSACTIONS:
				case KW_TRIM:
				case KW_TYPE:
				case KW_UNARCHIVE:
				case KW_UNDO:
				case KW_UNIONTYPE:
				case KW_UNKNOWN:
				case KW_UNLOCK:
				case KW_UNMANAGED:
				case KW_UNSET:
				case KW_UNSIGNED:
				case KW_URI:
				case KW_URL:
				case KW_USE:
				case KW_UTC:
				case KW_UTCTIMESTAMP:
				case KW_VALIDATE:
				case KW_VALUE_TYPE:
				case KW_VECTORIZATION:
				case KW_VIEW:
				case KW_VIEWS:
				case KW_WAIT:
				case KW_WEEK:
				case KW_WHILE:
				case KW_WITHIN:
				case KW_WORK:
				case KW_WORKLOAD:
				case KW_WRITE:
				case KW_YEAR:
				case KW_ZONE:
				case KW_BATCH:
				case KW_DAYOFWEEK:
				case KW_HOLD_DDLTIME:
				case KW_NO_DROP:
				case KW_OFFLINE:
				case KW_PROTECTION:
				case KW_READONLY:
				case KW_TIMESTAMPTZ:
					{
					int LA62_16 = input.LA(3);
					if ( (synpred9_HiveParser()) ) {
						alt62=4;
					}
					else if ( (true) ) {
						alt62=5;
					}

					}
					break;
				case EOF:
				case DOT:
				case KW_PARTITION:
					{
					alt62=5;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 62, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}
			else if ( (LA62_0==KW_EXTENDED) && (synpred9_HiveParser())) {
				alt62=4;
			}
			else if ( (LA62_0==Identifier||(LA62_0 >= KW_ABORT && LA62_0 <= KW_AFTER)||LA62_0==KW_ALLOC_FRACTION||LA62_0==KW_ANALYZE||LA62_0==KW_ARCHIVE||(LA62_0 >= KW_ASC && LA62_0 <= KW_AT)||(LA62_0 >= KW_AUTOCOMMIT && LA62_0 <= KW_BEFORE)||(LA62_0 >= KW_BUCKET && LA62_0 <= KW_BUCKETS)||(LA62_0 >= KW_CACHE && LA62_0 <= KW_CASCADE)||(LA62_0 >= KW_CBO && LA62_0 <= KW_CHANGE)||(LA62_0 >= KW_CHECK && LA62_0 <= KW_COLLECTION)||(LA62_0 >= KW_COLUMNS && LA62_0 <= KW_COMMENT)||(LA62_0 >= KW_COMPACT && LA62_0 <= KW_CONCATENATE)||(LA62_0 >= KW_CONTINUE && LA62_0 <= KW_COST)||LA62_0==KW_CRON||LA62_0==KW_DATA||LA62_0==KW_DATABASES||(LA62_0 >= KW_DATETIME && LA62_0 <= KW_DCPROPERTIES)||LA62_0==KW_DEBUG||(LA62_0 >= KW_DEFAULT && LA62_0 <= KW_DEFINED)||(LA62_0 >= KW_DELIMITED && LA62_0 <= KW_DESC)||(LA62_0 >= KW_DETAIL && LA62_0 <= KW_DISABLE)||(LA62_0 >= KW_DISTRIBUTE && LA62_0 <= KW_DO)||LA62_0==KW_DOW||(LA62_0 >= KW_DUMP && LA62_0 <= KW_ELEM_TYPE)||LA62_0==KW_ENABLE||(LA62_0 >= KW_ENFORCED && LA62_0 <= KW_EVERY)||(LA62_0 >= KW_EXCLUSIVE && LA62_0 <= KW_EXECUTED)||(LA62_0 >= KW_EXPIRE_SNAPSHOTS && LA62_0 <= KW_EXPRESSION)||(LA62_0 >= KW_FIELDS && LA62_0 <= KW_FIRST)||LA62_0==KW_FORMAT||LA62_0==KW_FUNCTIONS||(LA62_0 >= KW_HOUR && LA62_0 <= KW_IDXPROPERTIES)||LA62_0==KW_IGNORE||(LA62_0 >= KW_INDEX && LA62_0 <= KW_INDEXES)||(LA62_0 >= KW_INPATH && LA62_0 <= KW_INPUTFORMAT)||(LA62_0 >= KW_ISOLATION && LA62_0 <= KW_JAR)||(LA62_0 >= KW_JOINCOST && LA62_0 <= KW_LAST)||LA62_0==KW_LEVEL||(LA62_0 >= KW_LIMIT && LA62_0 <= KW_LOAD)||(LA62_0 >= KW_LOCATION && LA62_0 <= KW_LONG)||(LA62_0 >= KW_MANAGED && LA62_0 <= KW_MANAGEMENT)||(LA62_0 >= KW_MAPJOIN && LA62_0 <= KW_MATERIALIZED)||LA62_0==KW_METADATA||(LA62_0 >= KW_MINUTE && LA62_0 <= KW_MONTH)||(LA62_0 >= KW_MOVE && LA62_0 <= KW_MSCK)||(LA62_0 >= KW_NORELY && LA62_0 <= KW_NOSCAN)||LA62_0==KW_NOVALIDATE||LA62_0==KW_NULLS||LA62_0==KW_OFFSET||(LA62_0 >= KW_OPERATOR && LA62_0 <= KW_OPTION)||(LA62_0 >= KW_OUTPUTDRIVER && LA62_0 <= KW_OUTPUTFORMAT)||(LA62_0 >= KW_OVERWRITE && LA62_0 <= KW_OWNER)||(LA62_0 >= KW_PARTITIONED && LA62_0 <= KW_PATH)||(LA62_0 >= KW_PLAN && LA62_0 <= KW_POOL)||LA62_0==KW_PRINCIPALS||LA62_0==KW_PURGE||(LA62_0 >= KW_QUARTER && LA62_0 <= KW_QUERY_PARALLELISM)||LA62_0==KW_READ||(LA62_0 >= KW_REBUILD && LA62_0 <= KW_RECORDWRITER)||(LA62_0 >= KW_RELOAD && LA62_0 <= KW_RESTRICT)||LA62_0==KW_REWRITE||(LA62_0 >= KW_ROLE && LA62_0 <= KW_ROLES)||(LA62_0 >= KW_SCHEDULED && LA62_0 <= KW_SCHEDULING_POLICY)||(LA62_0 >= KW_SCHEMAS && LA62_0 <= KW_SECOND)||(LA62_0 >= KW_SEMI && LA62_0 <= KW_SERVER)||(LA62_0 >= KW_SETS && LA62_0 <= KW_SKEWED)||LA62_0==KW_SNAPSHOT||(LA62_0 >= KW_SORT && LA62_0 <= KW_SSL)||(LA62_0 >= KW_STATISTICS && LA62_0 <= KW_SUMMARY)||(LA62_0 >= KW_SYSTEM_TIME && LA62_0 <= KW_SYSTEM_VERSION)||LA62_0==KW_TABLES||(LA62_0 >= KW_TBLPROPERTIES && LA62_0 <= KW_TERMINATED)||LA62_0==KW_TINYINT||LA62_0==KW_TOUCH||(LA62_0 >= KW_TRANSACTION && LA62_0 <= KW_TRANSACTIONS)||LA62_0==KW_TRIM||(LA62_0 >= KW_TYPE && LA62_0 <= KW_UNARCHIVE)||LA62_0==KW_UNDO||LA62_0==KW_UNIONTYPE||(LA62_0 >= KW_UNKNOWN && LA62_0 <= KW_UNSIGNED)||(LA62_0 >= KW_URI && LA62_0 <= KW_USE)||(LA62_0 >= KW_UTC && LA62_0 <= KW_VALIDATE)||LA62_0==KW_VALUE_TYPE||(LA62_0 >= KW_VECTORIZATION && LA62_0 <= KW_WEEK)||LA62_0==KW_WHILE||(LA62_0 >= KW_WITHIN && LA62_0 <= KW_ZONE)||LA62_0==KW_BATCH||LA62_0==KW_DAYOFWEEK||LA62_0==KW_HOLD_DDLTIME||LA62_0==KW_NO_DROP||LA62_0==KW_OFFLINE||LA62_0==KW_PROTECTION||LA62_0==KW_READONLY||LA62_0==KW_TIMESTAMPTZ) ) {
				alt62=5;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 62, 0, input);
				throw nvae;
			}

			switch (alt62) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:5: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) ( KW_EXTENDED )? (dbName= identifier )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:32: ( KW_DATABASE | KW_SCHEMA )
					int alt57=2;
					int LA57_0 = input.LA(1);
					if ( (LA57_0==KW_DATABASE) ) {
						alt57=1;
					}
					else if ( (LA57_0==KW_SCHEMA) ) {
						alt57=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 57, 0, input);
						throw nvae;
					}

					switch (alt57) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:33: KW_DATABASE
							{
							KW_DATABASE211=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_descStatement4629); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE211);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:45: KW_SCHEMA
							{
							KW_SCHEMA212=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_descStatement4631); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA212);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:56: ( KW_EXTENDED )?
					int alt58=2;
					int LA58_0 = input.LA(1);
					if ( (LA58_0==KW_EXTENDED) ) {
						alt58=1;
					}
					switch (alt58) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:56: KW_EXTENDED
							{
							KW_EXTENDED213=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement4634); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED213);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:69: (dbName= identifier )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:70: dbName= identifier
					{
					pushFollow(FOLLOW_identifier_in_descStatement4640);
					dbName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
					}

					// AST REWRITE
					// elements: dbName, KW_EXTENDED
					// token labels: 
					// rule labels: dbName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1296:89: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:92: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE"), root_1);
						adaptor.addChild(root_1, stream_dbName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:119: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:5: ( KW_DATACONNECTOR )=> ( KW_DATACONNECTOR ) ( KW_EXTENDED )? (dcName= identifier )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:27: ( KW_DATACONNECTOR )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:28: KW_DATACONNECTOR
					{
					KW_DATACONNECTOR214=(Token)match(input,KW_DATACONNECTOR,FOLLOW_KW_DATACONNECTOR_in_descStatement4672); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATACONNECTOR.add(KW_DATACONNECTOR214);

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:46: ( KW_EXTENDED )?
					int alt59=2;
					int LA59_0 = input.LA(1);
					if ( (LA59_0==KW_EXTENDED) ) {
						alt59=1;
					}
					switch (alt59) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:46: KW_EXTENDED
							{
							KW_EXTENDED215=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement4675); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED215);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:59: (dcName= identifier )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:60: dcName= identifier
					{
					pushFollow(FOLLOW_identifier_in_descStatement4681);
					dcName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(dcName.getTree());
					}

					// AST REWRITE
					// elements: dcName, KW_EXTENDED
					// token labels: 
					// rule labels: dcName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_dcName=new RewriteRuleSubtreeStream(adaptor,"rule dcName",dcName!=null?dcName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1298:79: -> ^( TOK_DESCDATACONNECTOR $dcName ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:82: ^( TOK_DESCDATACONNECTOR $dcName ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCDATACONNECTOR, "TOK_DESCDATACONNECTOR"), root_1);
						adaptor.addChild(root_1, stream_dcName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:114: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:5: ( KW_FUNCTION )=> KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
					{
					KW_FUNCTION216=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_descStatement4712); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION216);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:34: ( KW_EXTENDED )?
					int alt60=2;
					int LA60_0 = input.LA(1);
					if ( (LA60_0==KW_EXTENDED) ) {
						alt60=1;
					}
					switch (alt60) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:34: KW_EXTENDED
							{
							KW_EXTENDED217=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement4714); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED217);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:47: (name= descFuncNames )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:48: name= descFuncNames
					{
					pushFollow(FOLLOW_descFuncNames_in_descStatement4720);
					name=descFuncNames();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_descFuncNames.add(name.getTree());
					}

					// AST REWRITE
					// elements: KW_EXTENDED, name
					// token labels: 
					// rule labels: name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1300:68: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:71: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION"), root_1);
						adaptor.addChild(root_1, stream_name.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:96: ( KW_EXTENDED )?
						if ( stream_KW_EXTENDED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_EXTENDED.nextNode());
						}
						stream_KW_EXTENDED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:5: ( KW_FORMATTED | KW_EXTENDED )=> ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:35: ( (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:36: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED ) parttype= tabPartColTypeExpr
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:36: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED )
					int alt61=2;
					int LA61_0 = input.LA(1);
					if ( (LA61_0==KW_FORMATTED) ) {
						alt61=1;
					}
					else if ( (LA61_0==KW_EXTENDED) ) {
						alt61=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 61, 0, input);
						throw nvae;
					}

					switch (alt61) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:37: descOptions= KW_FORMATTED
							{
							descOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_descStatement4757); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FORMATTED.add(descOptions);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:62: descOptions= KW_EXTENDED
							{
							descOptions=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement4761); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(descOptions);

							}
							break;

					}

					pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement4766);
					parttype=tabPartColTypeExpr();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());
					}

					// AST REWRITE
					// elements: descOptions, parttype
					// token labels: descOptions
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_descOptions=new RewriteRuleTokenStream(adaptor,"token descOptions",descOptions);
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1302:116: -> ^( TOK_DESCTABLE $parttype $descOptions)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:119: ^( TOK_DESCTABLE $parttype $descOptions)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_1, stream_descOptions.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1304:5: parttype= tabPartColTypeExpr
					{
					pushFollow(FOLLOW_tabPartColTypeExpr_in_descStatement4793);
					parttype=tabPartColTypeExpr();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tabPartColTypeExpr.add(parttype.getTree());
					// AST REWRITE
					// elements: parttype
					// token labels: 
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1304:33: -> ^( TOK_DESCTABLE $parttype)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1304:36: ^( TOK_DESCTABLE $parttype)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "descStatement"


	public static class analyzeStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "analyzeStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1308:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) ;
	public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
		HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token noscan=null;
		Token KW_ANALYZE218=null;
		Token KW_TABLE219=null;
		Token KW_COMPUTE220=null;
		Token KW_STATISTICS221=null;
		Token KW_FOR222=null;
		Token KW_COLUMNS223=null;
		Token KW_CACHE224=null;
		Token KW_METADATA225=null;
		ParserRuleReturnScope parttype =null;
		ParserRuleReturnScope statsColumnName =null;

		ASTNode noscan_tree=null;
		ASTNode KW_ANALYZE218_tree=null;
		ASTNode KW_TABLE219_tree=null;
		ASTNode KW_COMPUTE220_tree=null;
		ASTNode KW_STATISTICS221_tree=null;
		ASTNode KW_FOR222_tree=null;
		ASTNode KW_COLUMNS223_tree=null;
		ASTNode KW_CACHE224_tree=null;
		ASTNode KW_METADATA225_tree=null;
		RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
		RewriteRuleTokenStream stream_KW_ANALYZE=new RewriteRuleTokenStream(adaptor,"token KW_ANALYZE");
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_COMPUTE=new RewriteRuleTokenStream(adaptor,"token KW_COMPUTE");
		RewriteRuleTokenStream stream_KW_METADATA=new RewriteRuleTokenStream(adaptor,"token KW_METADATA");
		RewriteRuleTokenStream stream_KW_NOSCAN=new RewriteRuleTokenStream(adaptor,"token KW_NOSCAN");
		RewriteRuleTokenStream stream_KW_CACHE=new RewriteRuleTokenStream(adaptor,"token KW_CACHE");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("analyze statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1311:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1311:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
			{
			KW_ANALYZE218=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_analyzeStatement4835); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ANALYZE.add(KW_ANALYZE218);

			KW_TABLE219=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_analyzeStatement4837); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE219);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1311:27: (parttype= tableOrPartition )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1311:28: parttype= tableOrPartition
			{
			pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement4842);
			parttype=tableOrPartition();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableOrPartition.add(parttype.getTree());
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:7: ( ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? ) | ( KW_CACHE )=> KW_CACHE KW_METADATA -> ^( TOK_CACHE_METADATA $parttype) )
			int alt65=2;
			int LA65_0 = input.LA(1);
			if ( (LA65_0==KW_COMPUTE) && (synpred10_HiveParser())) {
				alt65=1;
			}
			else if ( (LA65_0==KW_CACHE) && (synpred11_HiveParser())) {
				alt65=2;
			}

			switch (alt65) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:7: ( KW_COMPUTE )=> KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
					{
					KW_COMPUTE220=(Token)match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_analyzeStatement4865); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMPUTE.add(KW_COMPUTE220);

					KW_STATISTICS221=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_analyzeStatement4867); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STATISTICS.add(KW_STATISTICS221);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:48: ( (noscan= KW_NOSCAN ) | ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? ) )?
					int alt64=3;
					int LA64_0 = input.LA(1);
					if ( (LA64_0==KW_NOSCAN) ) {
						alt64=1;
					}
					else if ( (LA64_0==KW_FOR) ) {
						alt64=2;
					}
					switch (alt64) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:49: (noscan= KW_NOSCAN )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:49: (noscan= KW_NOSCAN )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:50: noscan= KW_NOSCAN
							{
							noscan=(Token)match(input,KW_NOSCAN,FOLLOW_KW_NOSCAN_in_analyzeStatement4873); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_NOSCAN.add(noscan);

							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:57: ( KW_FOR KW_COLUMNS (statsColumnName= columnNameList )? )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:58: KW_FOR KW_COLUMNS (statsColumnName= columnNameList )?
							{
							KW_FOR222=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_analyzeStatement4933); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR222);

							KW_COLUMNS223=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_analyzeStatement4935); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS223);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:76: (statsColumnName= columnNameList )?
							int alt63=2;
							int LA63_0 = input.LA(1);
							if ( (LA63_0==Identifier||(LA63_0 >= KW_ABORT && LA63_0 <= KW_AFTER)||LA63_0==KW_ALLOC_FRACTION||LA63_0==KW_ANALYZE||LA63_0==KW_ARCHIVE||(LA63_0 >= KW_ASC && LA63_0 <= KW_AT)||(LA63_0 >= KW_AUTOCOMMIT && LA63_0 <= KW_BEFORE)||(LA63_0 >= KW_BUCKET && LA63_0 <= KW_BUCKETS)||(LA63_0 >= KW_CACHE && LA63_0 <= KW_CASCADE)||(LA63_0 >= KW_CBO && LA63_0 <= KW_CHANGE)||(LA63_0 >= KW_CHECK && LA63_0 <= KW_COLLECTION)||(LA63_0 >= KW_COLUMNS && LA63_0 <= KW_COMMENT)||(LA63_0 >= KW_COMPACT && LA63_0 <= KW_CONCATENATE)||(LA63_0 >= KW_CONTINUE && LA63_0 <= KW_COST)||LA63_0==KW_CRON||LA63_0==KW_DATA||LA63_0==KW_DATABASES||(LA63_0 >= KW_DATETIME && LA63_0 <= KW_DCPROPERTIES)||LA63_0==KW_DEBUG||(LA63_0 >= KW_DEFAULT && LA63_0 <= KW_DEFINED)||(LA63_0 >= KW_DELIMITED && LA63_0 <= KW_DESC)||(LA63_0 >= KW_DETAIL && LA63_0 <= KW_DISABLE)||(LA63_0 >= KW_DISTRIBUTE && LA63_0 <= KW_DO)||LA63_0==KW_DOW||(LA63_0 >= KW_DUMP && LA63_0 <= KW_ELEM_TYPE)||LA63_0==KW_ENABLE||(LA63_0 >= KW_ENFORCED && LA63_0 <= KW_EVERY)||(LA63_0 >= KW_EXCLUSIVE && LA63_0 <= KW_EXECUTED)||(LA63_0 >= KW_EXPIRE_SNAPSHOTS && LA63_0 <= KW_EXPRESSION)||(LA63_0 >= KW_FIELDS && LA63_0 <= KW_FIRST)||(LA63_0 >= KW_FORMAT && LA63_0 <= KW_FORMATTED)||LA63_0==KW_FUNCTIONS||(LA63_0 >= KW_HOUR && LA63_0 <= KW_IDXPROPERTIES)||LA63_0==KW_IGNORE||(LA63_0 >= KW_INDEX && LA63_0 <= KW_INDEXES)||(LA63_0 >= KW_INPATH && LA63_0 <= KW_INPUTFORMAT)||(LA63_0 >= KW_ISOLATION && LA63_0 <= KW_JAR)||(LA63_0 >= KW_JOINCOST && LA63_0 <= KW_LAST)||LA63_0==KW_LEVEL||(LA63_0 >= KW_LIMIT && LA63_0 <= KW_LOAD)||(LA63_0 >= KW_LOCATION && LA63_0 <= KW_LONG)||(LA63_0 >= KW_MANAGED && LA63_0 <= KW_MANAGEMENT)||(LA63_0 >= KW_MAPJOIN && LA63_0 <= KW_MATERIALIZED)||LA63_0==KW_METADATA||(LA63_0 >= KW_MINUTE && LA63_0 <= KW_MONTH)||(LA63_0 >= KW_MOVE && LA63_0 <= KW_MSCK)||(LA63_0 >= KW_NORELY && LA63_0 <= KW_NOSCAN)||LA63_0==KW_NOVALIDATE||LA63_0==KW_NULLS||LA63_0==KW_OFFSET||(LA63_0 >= KW_OPERATOR && LA63_0 <= KW_OPTION)||(LA63_0 >= KW_OUTPUTDRIVER && LA63_0 <= KW_OUTPUTFORMAT)||(LA63_0 >= KW_OVERWRITE && LA63_0 <= KW_OWNER)||(LA63_0 >= KW_PARTITIONED && LA63_0 <= KW_PATH)||(LA63_0 >= KW_PLAN && LA63_0 <= KW_POOL)||LA63_0==KW_PRINCIPALS||LA63_0==KW_PURGE||(LA63_0 >= KW_QUARTER && LA63_0 <= KW_QUERY_PARALLELISM)||LA63_0==KW_READ||(LA63_0 >= KW_REBUILD && LA63_0 <= KW_RECORDWRITER)||(LA63_0 >= KW_RELOAD && LA63_0 <= KW_RESTRICT)||LA63_0==KW_REWRITE||(LA63_0 >= KW_ROLE && LA63_0 <= KW_ROLES)||(LA63_0 >= KW_SCHEDULED && LA63_0 <= KW_SECOND)||(LA63_0 >= KW_SEMI && LA63_0 <= KW_SERVER)||(LA63_0 >= KW_SETS && LA63_0 <= KW_SKEWED)||LA63_0==KW_SNAPSHOT||(LA63_0 >= KW_SORT && LA63_0 <= KW_SSL)||(LA63_0 >= KW_STATISTICS && LA63_0 <= KW_SUMMARY)||(LA63_0 >= KW_SYSTEM_TIME && LA63_0 <= KW_SYSTEM_VERSION)||LA63_0==KW_TABLES||(LA63_0 >= KW_TBLPROPERTIES && LA63_0 <= KW_TERMINATED)||LA63_0==KW_TINYINT||LA63_0==KW_TOUCH||(LA63_0 >= KW_TRANSACTION && LA63_0 <= KW_TRANSACTIONS)||LA63_0==KW_TRIM||(LA63_0 >= KW_TYPE && LA63_0 <= KW_UNARCHIVE)||LA63_0==KW_UNDO||LA63_0==KW_UNIONTYPE||(LA63_0 >= KW_UNKNOWN && LA63_0 <= KW_UNSIGNED)||(LA63_0 >= KW_URI && LA63_0 <= KW_USE)||(LA63_0 >= KW_UTC && LA63_0 <= KW_VALIDATE)||LA63_0==KW_VALUE_TYPE||(LA63_0 >= KW_VECTORIZATION && LA63_0 <= KW_WEEK)||LA63_0==KW_WHILE||(LA63_0 >= KW_WITHIN && LA63_0 <= KW_ZONE)||LA63_0==KW_BATCH||LA63_0==KW_DAYOFWEEK||LA63_0==KW_HOLD_DDLTIME||LA63_0==KW_NO_DROP||LA63_0==KW_OFFLINE||LA63_0==KW_PROTECTION||LA63_0==KW_READONLY||LA63_0==KW_TIMESTAMPTZ) ) {
								alt63=1;
							}
							switch (alt63) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1314:77: statsColumnName= columnNameList
									{
									pushFollow(FOLLOW_columnNameList_in_analyzeStatement4940);
									statsColumnName=columnNameList();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_columnNameList.add(statsColumnName.getTree());
									}
									break;

							}

							}

							}
							break;

					}

					// AST REWRITE
					// elements: noscan, statsColumnName, KW_COLUMNS, parttype
					// token labels: noscan
					// rule labels: statsColumnName, parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_noscan=new RewriteRuleTokenStream(adaptor,"token noscan",noscan);
					RewriteRuleSubtreeStream stream_statsColumnName=new RewriteRuleSubtreeStream(adaptor,"rule statsColumnName",statsColumnName!=null?statsColumnName.getTree():null);
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1315:7: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:10: ^( TOK_ANALYZE $parttype ( $noscan)? ( KW_COLUMNS )? ( $statsColumnName)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ANALYZE, "TOK_ANALYZE"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:35: ( $noscan)?
						if ( stream_noscan.hasNext() ) {
							adaptor.addChild(root_1, stream_noscan.nextNode());
						}
						stream_noscan.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:43: ( KW_COLUMNS )?
						if ( stream_KW_COLUMNS.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_COLUMNS.nextNode());
						}
						stream_KW_COLUMNS.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1315:56: ( $statsColumnName)?
						if ( stream_statsColumnName.hasNext() ) {
							adaptor.addChild(root_1, stream_statsColumnName.nextTree());
						}
						stream_statsColumnName.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1317:7: ( KW_CACHE )=> KW_CACHE KW_METADATA
					{
					KW_CACHE224=(Token)match(input,KW_CACHE,FOLLOW_KW_CACHE_in_analyzeStatement4993); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CACHE.add(KW_CACHE224);

					KW_METADATA225=(Token)match(input,KW_METADATA,FOLLOW_KW_METADATA_in_analyzeStatement4995); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_METADATA.add(KW_METADATA225);

					// AST REWRITE
					// elements: parttype
					// token labels: 
					// rule labels: parttype, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1317:42: -> ^( TOK_CACHE_METADATA $parttype)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1317:45: ^( TOK_CACHE_METADATA $parttype)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CACHE_METADATA, "TOK_CACHE_METADATA"), root_1);
						adaptor.addChild(root_1, stream_parttype.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "analyzeStatement"


	public static class showStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1321:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? ) | KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW ( KW_SORTED )? KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ( KW_SORTED )? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW KW_COMPACTIONS ( ( KW_ID )=> compactionId -> ^( TOK_SHOW_COMPACTIONS compactionId ) | ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) | (parttype= partTypeExpr )? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) | KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) ) | KW_SHOW ( KW_DATACONNECTORS ) -> ^( TOK_SHOWDATACONNECTORS ) );
	public final HiveParser.showStatement_return showStatement() throws RecognitionException {
		HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token isExtended=null;
		Token prptyName=null;
		Token KW_SHOW226=null;
		Token KW_DATABASES227=null;
		Token KW_SCHEMAS228=null;
		Token KW_LIKE229=null;
		Token KW_SHOW231=null;
		Token KW_TABLES232=null;
		Token KW_FROM233=null;
		Token KW_IN234=null;
		Token KW_SHOW235=null;
		Token KW_VIEWS236=null;
		Token KW_FROM237=null;
		Token KW_IN238=null;
		Token KW_LIKE239=null;
		Token KW_SHOW242=null;
		Token KW_MATERIALIZED243=null;
		Token KW_VIEWS244=null;
		Token KW_FROM245=null;
		Token KW_IN246=null;
		Token KW_LIKE247=null;
		Token KW_SHOW250=null;
		Token KW_SORTED251=null;
		Token KW_COLUMNS252=null;
		Token KW_FROM253=null;
		Token KW_IN254=null;
		Token KW_FROM256=null;
		Token KW_IN257=null;
		Token KW_LIKE258=null;
		Token KW_SHOW261=null;
		Token KW_FUNCTIONS262=null;
		Token KW_LIKE263=null;
		Token KW_SHOW265=null;
		Token KW_PARTITIONS266=null;
		Token KW_SHOW271=null;
		Token KW_CREATE272=null;
		Token KW_DATABASE273=null;
		Token KW_SCHEMA274=null;
		Token KW_TABLE275=null;
		Token KW_SHOW276=null;
		Token KW_TABLE277=null;
		Token KW_EXTENDED278=null;
		Token KW_FROM279=null;
		Token KW_IN280=null;
		Token KW_LIKE281=null;
		Token KW_SHOW284=null;
		Token KW_TBLPROPERTIES285=null;
		Token LPAREN287=null;
		Token RPAREN288=null;
		Token KW_SHOW289=null;
		Token KW_LOCKS290=null;
		Token KW_DATABASE291=null;
		Token KW_SCHEMA292=null;
		Token KW_SHOW293=null;
		Token KW_COMPACTIONS294=null;
		Token KW_DATABASE296=null;
		Token KW_SCHEMA297=null;
		Token KW_SHOW308=null;
		Token KW_TRANSACTIONS309=null;
		Token KW_SHOW310=null;
		Token KW_CONF311=null;
		Token StringLiteral312=null;
		Token KW_SHOW313=null;
		Token KW_RESOURCE314=null;
		Token KW_PLAN315=null;
		Token KW_PLANS316=null;
		Token KW_SHOW317=null;
		Token KW_DATACONNECTORS318=null;
		ParserRuleReturnScope db_name =null;
		ParserRuleReturnScope filter =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope parttype =null;
		ParserRuleReturnScope rp_name =null;
		ParserRuleReturnScope showStmtIdentifier230 =null;
		ParserRuleReturnScope showStmtIdentifier240 =null;
		ParserRuleReturnScope showStmtIdentifier241 =null;
		ParserRuleReturnScope showStmtIdentifier248 =null;
		ParserRuleReturnScope showStmtIdentifier249 =null;
		ParserRuleReturnScope tableName255 =null;
		ParserRuleReturnScope showStmtIdentifier259 =null;
		ParserRuleReturnScope showStmtIdentifier260 =null;
		ParserRuleReturnScope showFunctionIdentifier264 =null;
		ParserRuleReturnScope partitionSpec267 =null;
		ParserRuleReturnScope whereClause268 =null;
		ParserRuleReturnScope orderByClause269 =null;
		ParserRuleReturnScope limitClause270 =null;
		ParserRuleReturnScope showStmtIdentifier282 =null;
		ParserRuleReturnScope partitionSpec283 =null;
		ParserRuleReturnScope tableName286 =null;
		ParserRuleReturnScope compactionId295 =null;
		ParserRuleReturnScope compactionPool298 =null;
		ParserRuleReturnScope compactionType299 =null;
		ParserRuleReturnScope compactionStatus300 =null;
		ParserRuleReturnScope orderByClause301 =null;
		ParserRuleReturnScope limitClause302 =null;
		ParserRuleReturnScope compactionPool303 =null;
		ParserRuleReturnScope compactionType304 =null;
		ParserRuleReturnScope compactionStatus305 =null;
		ParserRuleReturnScope orderByClause306 =null;
		ParserRuleReturnScope limitClause307 =null;

		ASTNode isExtended_tree=null;
		ASTNode prptyName_tree=null;
		ASTNode KW_SHOW226_tree=null;
		ASTNode KW_DATABASES227_tree=null;
		ASTNode KW_SCHEMAS228_tree=null;
		ASTNode KW_LIKE229_tree=null;
		ASTNode KW_SHOW231_tree=null;
		ASTNode KW_TABLES232_tree=null;
		ASTNode KW_FROM233_tree=null;
		ASTNode KW_IN234_tree=null;
		ASTNode KW_SHOW235_tree=null;
		ASTNode KW_VIEWS236_tree=null;
		ASTNode KW_FROM237_tree=null;
		ASTNode KW_IN238_tree=null;
		ASTNode KW_LIKE239_tree=null;
		ASTNode KW_SHOW242_tree=null;
		ASTNode KW_MATERIALIZED243_tree=null;
		ASTNode KW_VIEWS244_tree=null;
		ASTNode KW_FROM245_tree=null;
		ASTNode KW_IN246_tree=null;
		ASTNode KW_LIKE247_tree=null;
		ASTNode KW_SHOW250_tree=null;
		ASTNode KW_SORTED251_tree=null;
		ASTNode KW_COLUMNS252_tree=null;
		ASTNode KW_FROM253_tree=null;
		ASTNode KW_IN254_tree=null;
		ASTNode KW_FROM256_tree=null;
		ASTNode KW_IN257_tree=null;
		ASTNode KW_LIKE258_tree=null;
		ASTNode KW_SHOW261_tree=null;
		ASTNode KW_FUNCTIONS262_tree=null;
		ASTNode KW_LIKE263_tree=null;
		ASTNode KW_SHOW265_tree=null;
		ASTNode KW_PARTITIONS266_tree=null;
		ASTNode KW_SHOW271_tree=null;
		ASTNode KW_CREATE272_tree=null;
		ASTNode KW_DATABASE273_tree=null;
		ASTNode KW_SCHEMA274_tree=null;
		ASTNode KW_TABLE275_tree=null;
		ASTNode KW_SHOW276_tree=null;
		ASTNode KW_TABLE277_tree=null;
		ASTNode KW_EXTENDED278_tree=null;
		ASTNode KW_FROM279_tree=null;
		ASTNode KW_IN280_tree=null;
		ASTNode KW_LIKE281_tree=null;
		ASTNode KW_SHOW284_tree=null;
		ASTNode KW_TBLPROPERTIES285_tree=null;
		ASTNode LPAREN287_tree=null;
		ASTNode RPAREN288_tree=null;
		ASTNode KW_SHOW289_tree=null;
		ASTNode KW_LOCKS290_tree=null;
		ASTNode KW_DATABASE291_tree=null;
		ASTNode KW_SCHEMA292_tree=null;
		ASTNode KW_SHOW293_tree=null;
		ASTNode KW_COMPACTIONS294_tree=null;
		ASTNode KW_DATABASE296_tree=null;
		ASTNode KW_SCHEMA297_tree=null;
		ASTNode KW_SHOW308_tree=null;
		ASTNode KW_TRANSACTIONS309_tree=null;
		ASTNode KW_SHOW310_tree=null;
		ASTNode KW_CONF311_tree=null;
		ASTNode StringLiteral312_tree=null;
		ASTNode KW_SHOW313_tree=null;
		ASTNode KW_RESOURCE314_tree=null;
		ASTNode KW_PLAN315_tree=null;
		ASTNode KW_PLANS316_tree=null;
		ASTNode KW_SHOW317_tree=null;
		ASTNode KW_DATACONNECTORS318_tree=null;
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_VIEWS=new RewriteRuleTokenStream(adaptor,"token KW_VIEWS");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
		RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
		RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
		RewriteRuleTokenStream stream_KW_LOCKS=new RewriteRuleTokenStream(adaptor,"token KW_LOCKS");
		RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
		RewriteRuleTokenStream stream_KW_TABLES=new RewriteRuleTokenStream(adaptor,"token KW_TABLES");
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_CONF=new RewriteRuleTokenStream(adaptor,"token KW_CONF");
		RewriteRuleTokenStream stream_KW_PLAN=new RewriteRuleTokenStream(adaptor,"token KW_PLAN");
		RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
		RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
		RewriteRuleTokenStream stream_KW_DATACONNECTORS=new RewriteRuleTokenStream(adaptor,"token KW_DATACONNECTORS");
		RewriteRuleTokenStream stream_KW_SCHEMAS=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMAS");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_COMPACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_COMPACTIONS");
		RewriteRuleTokenStream stream_KW_PLANS=new RewriteRuleTokenStream(adaptor,"token KW_PLANS");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_RESOURCE=new RewriteRuleTokenStream(adaptor,"token KW_RESOURCE");
		RewriteRuleTokenStream stream_KW_DATABASES=new RewriteRuleTokenStream(adaptor,"token KW_DATABASES");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
		RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_compactionPool=new RewriteRuleSubtreeStream(adaptor,"rule compactionPool");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_showTablesFilterExpr=new RewriteRuleSubtreeStream(adaptor,"rule showTablesFilterExpr");
		RewriteRuleSubtreeStream stream_showFunctionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showFunctionIdentifier");
		RewriteRuleSubtreeStream stream_partTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule partTypeExpr");
		RewriteRuleSubtreeStream stream_compactionType=new RewriteRuleSubtreeStream(adaptor,"rule compactionType");
		RewriteRuleSubtreeStream stream_compactionId=new RewriteRuleSubtreeStream(adaptor,"rule compactionId");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
		RewriteRuleSubtreeStream stream_compactionStatus=new RewriteRuleSubtreeStream(adaptor,"rule compactionStatus");

		 pushMsg("show statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? ) | KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW ( KW_SORTED )? KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ( KW_SORTED )? ) | KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? ) | KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )? ) | KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) ) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? ) | KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) ) | KW_SHOW KW_COMPACTIONS ( ( KW_ID )=> compactionId -> ^( TOK_SHOW_COMPACTIONS compactionId ) | ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) | (parttype= partTypeExpr )? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) ) | KW_SHOW KW_TRANSACTIONS -> ^( TOK_SHOW_TRANSACTIONS ) | KW_SHOW KW_CONF StringLiteral -> ^( TOK_SHOWCONF StringLiteral ) | KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) ) | KW_SHOW ( KW_DATACONNECTORS ) -> ^( TOK_SHOWDATACONNECTORS ) )
			int alt113=16;
			int LA113_0 = input.LA(1);
			if ( (LA113_0==KW_SHOW) ) {
				switch ( input.LA(2) ) {
				case KW_VIEWS:
					{
					alt113=3;
					}
					break;
				case KW_MATERIALIZED:
					{
					alt113=4;
					}
					break;
				case KW_FUNCTIONS:
					{
					alt113=6;
					}
					break;
				case KW_PARTITIONS:
					{
					alt113=7;
					}
					break;
				case KW_CREATE:
					{
					alt113=8;
					}
					break;
				case KW_TABLE:
					{
					alt113=9;
					}
					break;
				case KW_TBLPROPERTIES:
					{
					alt113=10;
					}
					break;
				case KW_LOCKS:
					{
					alt113=11;
					}
					break;
				case KW_COMPACTIONS:
					{
					alt113=12;
					}
					break;
				case KW_TRANSACTIONS:
					{
					alt113=13;
					}
					break;
				case KW_CONF:
					{
					alt113=14;
					}
					break;
				case KW_RESOURCE:
					{
					alt113=15;
					}
					break;
				case KW_DATABASES:
				case KW_SCHEMAS:
					{
					alt113=1;
					}
					break;
				case KW_EXTENDED:
				case KW_TABLES:
					{
					alt113=2;
					}
					break;
				case KW_COLUMNS:
				case KW_SORTED:
					{
					alt113=5;
					}
					break;
				case KW_DATACONNECTORS:
					{
					alt113=16;
					}
					break;
				default:
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 113, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 113, 0, input);
				throw nvae;
			}

			switch (alt113) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
					{
					KW_SHOW226=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5039); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW226);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:15: ( KW_DATABASES | KW_SCHEMAS )
					int alt66=2;
					int LA66_0 = input.LA(1);
					if ( (LA66_0==KW_DATABASES) ) {
						alt66=1;
					}
					else if ( (LA66_0==KW_SCHEMAS) ) {
						alt66=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 66, 0, input);
						throw nvae;
					}

					switch (alt66) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:16: KW_DATABASES
							{
							KW_DATABASES227=(Token)match(input,KW_DATABASES,FOLLOW_KW_DATABASES_in_showStatement5042); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASES.add(KW_DATABASES227);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:29: KW_SCHEMAS
							{
							KW_SCHEMAS228=(Token)match(input,KW_SCHEMAS,FOLLOW_KW_SCHEMAS_in_showStatement5044); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMAS.add(KW_SCHEMAS228);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:41: ( KW_LIKE showStmtIdentifier )?
					int alt67=2;
					int LA67_0 = input.LA(1);
					if ( (LA67_0==KW_LIKE) ) {
						alt67=1;
					}
					switch (alt67) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:42: KW_LIKE showStmtIdentifier
							{
							KW_LIKE229=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement5048); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE229);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5050);
							showStmtIdentifier230=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier230.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1324:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1324:94: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:7: KW_SHOW (isExtended= KW_EXTENDED )? KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? (filter= showTablesFilterExpr )?
					{
					KW_SHOW231=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5069); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW231);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:15: (isExtended= KW_EXTENDED )?
					int alt68=2;
					int LA68_0 = input.LA(1);
					if ( (LA68_0==KW_EXTENDED) ) {
						alt68=1;
					}
					switch (alt68) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:16: isExtended= KW_EXTENDED
							{
							isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement5074); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

							}
							break;

					}

					KW_TABLES232=(Token)match(input,KW_TABLES,FOLLOW_KW_TABLES_in_showStatement5078); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLES.add(KW_TABLES232);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:51: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt70=2;
					int LA70_0 = input.LA(1);
					if ( (LA70_0==KW_FROM||LA70_0==KW_IN) ) {
						alt70=1;
					}
					switch (alt70) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:52: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:52: ( KW_FROM | KW_IN )
							int alt69=2;
							int LA69_0 = input.LA(1);
							if ( (LA69_0==KW_FROM) ) {
								alt69=1;
							}
							else if ( (LA69_0==KW_IN) ) {
								alt69=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 69, 0, input);
								throw nvae;
							}

							switch (alt69) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:53: KW_FROM
									{
									KW_FROM233=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement5082); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM233);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:61: KW_IN
									{
									KW_IN234=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement5084); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN234);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement5089);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:89: (filter= showTablesFilterExpr )?
					int alt71=2;
					int LA71_0 = input.LA(1);
					if ( (LA71_0==Identifier||(LA71_0 >= KW_ABORT && LA71_0 <= KW_AFTER)||LA71_0==KW_ALLOC_FRACTION||LA71_0==KW_ANALYZE||LA71_0==KW_ARCHIVE||(LA71_0 >= KW_ASC && LA71_0 <= KW_AT)||(LA71_0 >= KW_AUTOCOMMIT && LA71_0 <= KW_BEFORE)||(LA71_0 >= KW_BUCKET && LA71_0 <= KW_BUCKETS)||(LA71_0 >= KW_CACHE && LA71_0 <= KW_CASCADE)||(LA71_0 >= KW_CBO && LA71_0 <= KW_CHANGE)||(LA71_0 >= KW_CHECK && LA71_0 <= KW_COLLECTION)||(LA71_0 >= KW_COLUMNS && LA71_0 <= KW_COMMENT)||(LA71_0 >= KW_COMPACT && LA71_0 <= KW_CONCATENATE)||(LA71_0 >= KW_CONTINUE && LA71_0 <= KW_COST)||LA71_0==KW_CRON||LA71_0==KW_DATA||LA71_0==KW_DATABASES||(LA71_0 >= KW_DATETIME && LA71_0 <= KW_DCPROPERTIES)||LA71_0==KW_DEBUG||(LA71_0 >= KW_DEFAULT && LA71_0 <= KW_DEFINED)||(LA71_0 >= KW_DELIMITED && LA71_0 <= KW_DESC)||(LA71_0 >= KW_DETAIL && LA71_0 <= KW_DISABLE)||(LA71_0 >= KW_DISTRIBUTE && LA71_0 <= KW_DO)||LA71_0==KW_DOW||(LA71_0 >= KW_DUMP && LA71_0 <= KW_ELEM_TYPE)||LA71_0==KW_ENABLE||(LA71_0 >= KW_ENFORCED && LA71_0 <= KW_EVERY)||(LA71_0 >= KW_EXCLUSIVE && LA71_0 <= KW_EXECUTED)||(LA71_0 >= KW_EXPIRE_SNAPSHOTS && LA71_0 <= KW_EXPRESSION)||(LA71_0 >= KW_FIELDS && LA71_0 <= KW_FIRST)||(LA71_0 >= KW_FORMAT && LA71_0 <= KW_FORMATTED)||LA71_0==KW_FUNCTIONS||(LA71_0 >= KW_HOUR && LA71_0 <= KW_IDXPROPERTIES)||LA71_0==KW_IGNORE||(LA71_0 >= KW_INDEX && LA71_0 <= KW_INDEXES)||(LA71_0 >= KW_INPATH && LA71_0 <= KW_INPUTFORMAT)||(LA71_0 >= KW_ISOLATION && LA71_0 <= KW_JAR)||(LA71_0 >= KW_JOINCOST && LA71_0 <= KW_LAST)||(LA71_0 >= KW_LEVEL && LA71_0 <= KW_LOAD)||(LA71_0 >= KW_LOCATION && LA71_0 <= KW_LONG)||(LA71_0 >= KW_MANAGED && LA71_0 <= KW_MANAGEMENT)||(LA71_0 >= KW_MAPJOIN && LA71_0 <= KW_MATERIALIZED)||LA71_0==KW_METADATA||(LA71_0 >= KW_MINUTE && LA71_0 <= KW_MONTH)||(LA71_0 >= KW_MOVE && LA71_0 <= KW_MSCK)||(LA71_0 >= KW_NORELY && LA71_0 <= KW_NOSCAN)||LA71_0==KW_NOVALIDATE||LA71_0==KW_NULLS||LA71_0==KW_OFFSET||(LA71_0 >= KW_OPERATOR && LA71_0 <= KW_OPTION)||(LA71_0 >= KW_OUTPUTDRIVER && LA71_0 <= KW_OUTPUTFORMAT)||(LA71_0 >= KW_OVERWRITE && LA71_0 <= KW_OWNER)||(LA71_0 >= KW_PARTITIONED && LA71_0 <= KW_PATH)||(LA71_0 >= KW_PLAN && LA71_0 <= KW_POOL)||LA71_0==KW_PRINCIPALS||LA71_0==KW_PURGE||(LA71_0 >= KW_QUARTER && LA71_0 <= KW_QUERY_PARALLELISM)||LA71_0==KW_READ||(LA71_0 >= KW_REBUILD && LA71_0 <= KW_RECORDWRITER)||(LA71_0 >= KW_RELOAD && LA71_0 <= KW_RESTRICT)||LA71_0==KW_REWRITE||(LA71_0 >= KW_ROLE && LA71_0 <= KW_ROLES)||(LA71_0 >= KW_SCHEDULED && LA71_0 <= KW_SECOND)||(LA71_0 >= KW_SEMI && LA71_0 <= KW_SERVER)||(LA71_0 >= KW_SETS && LA71_0 <= KW_SKEWED)||LA71_0==KW_SNAPSHOT||(LA71_0 >= KW_SORT && LA71_0 <= KW_SSL)||(LA71_0 >= KW_STATISTICS && LA71_0 <= KW_SUMMARY)||(LA71_0 >= KW_SYSTEM_TIME && LA71_0 <= KW_SYSTEM_VERSION)||LA71_0==KW_TABLES||(LA71_0 >= KW_TBLPROPERTIES && LA71_0 <= KW_TERMINATED)||LA71_0==KW_TINYINT||LA71_0==KW_TOUCH||(LA71_0 >= KW_TRANSACTION && LA71_0 <= KW_TRANSACTIONS)||LA71_0==KW_TRIM||(LA71_0 >= KW_TYPE && LA71_0 <= KW_UNARCHIVE)||LA71_0==KW_UNDO||LA71_0==KW_UNIONTYPE||(LA71_0 >= KW_UNKNOWN && LA71_0 <= KW_UNSIGNED)||(LA71_0 >= KW_URI && LA71_0 <= KW_USE)||(LA71_0 >= KW_UTC && LA71_0 <= KW_VALIDATE)||LA71_0==KW_VALUE_TYPE||(LA71_0 >= KW_VECTORIZATION && LA71_0 <= KW_WEEK)||(LA71_0 >= KW_WHERE && LA71_0 <= KW_WHILE)||(LA71_0 >= KW_WITHIN && LA71_0 <= KW_ZONE)||LA71_0==StringLiteral||LA71_0==KW_BATCH||LA71_0==KW_DAYOFWEEK||LA71_0==KW_HOLD_DDLTIME||LA71_0==KW_NO_DROP||LA71_0==KW_OFFLINE||LA71_0==KW_PROTECTION||LA71_0==KW_READONLY||LA71_0==KW_TIMESTAMPTZ) ) {
						alt71=1;
					}
					switch (alt71) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1325:90: filter= showTablesFilterExpr
							{
							pushFollow(FOLLOW_showTablesFilterExpr_in_showStatement5096);
							filter=showTablesFilterExpr();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showTablesFilterExpr.add(filter.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: db_name, filter, isExtended
					// token labels: isExtended
					// rule labels: filter, db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
					RewriteRuleSubtreeStream stream_filter=new RewriteRuleSubtreeStream(adaptor,"rule filter",filter!=null?filter.getTree():null);
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1326:5: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:8: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( $filter)? ( $isExtended)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:25: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:47: ( $filter)?
						if ( stream_filter.hasNext() ) {
							adaptor.addChild(root_1, stream_filter.nextTree());
						}
						stream_filter.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:56: ( $isExtended)?
						if ( stream_isExtended.hasNext() ) {
							adaptor.addChild(root_1, stream_isExtended.nextNode());
						}
						stream_isExtended.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:7: KW_SHOW KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW235=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5132); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW235);

					KW_VIEWS236=(Token)match(input,KW_VIEWS,FOLLOW_KW_VIEWS_in_showStatement5134); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEWS.add(KW_VIEWS236);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:24: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt73=2;
					int LA73_0 = input.LA(1);
					if ( (LA73_0==KW_FROM||LA73_0==KW_IN) ) {
						alt73=1;
					}
					switch (alt73) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:25: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:25: ( KW_FROM | KW_IN )
							int alt72=2;
							int LA72_0 = input.LA(1);
							if ( (LA72_0==KW_FROM) ) {
								alt72=1;
							}
							else if ( (LA72_0==KW_IN) ) {
								alt72=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 72, 0, input);
								throw nvae;
							}

							switch (alt72) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:26: KW_FROM
									{
									KW_FROM237=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement5138); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM237);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:34: KW_IN
									{
									KW_IN238=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement5140); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN238);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement5145);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:62: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt74=3;
					int LA74_0 = input.LA(1);
					if ( (LA74_0==KW_LIKE) ) {
						alt74=1;
					}
					else if ( (LA74_0==Identifier||(LA74_0 >= KW_ABORT && LA74_0 <= KW_AFTER)||LA74_0==KW_ALLOC_FRACTION||LA74_0==KW_ANALYZE||LA74_0==KW_ARCHIVE||(LA74_0 >= KW_ASC && LA74_0 <= KW_AT)||(LA74_0 >= KW_AUTOCOMMIT && LA74_0 <= KW_BEFORE)||(LA74_0 >= KW_BUCKET && LA74_0 <= KW_BUCKETS)||(LA74_0 >= KW_CACHE && LA74_0 <= KW_CASCADE)||(LA74_0 >= KW_CBO && LA74_0 <= KW_CHANGE)||(LA74_0 >= KW_CHECK && LA74_0 <= KW_COLLECTION)||(LA74_0 >= KW_COLUMNS && LA74_0 <= KW_COMMENT)||(LA74_0 >= KW_COMPACT && LA74_0 <= KW_CONCATENATE)||(LA74_0 >= KW_CONTINUE && LA74_0 <= KW_COST)||LA74_0==KW_CRON||LA74_0==KW_DATA||LA74_0==KW_DATABASES||(LA74_0 >= KW_DATETIME && LA74_0 <= KW_DCPROPERTIES)||LA74_0==KW_DEBUG||(LA74_0 >= KW_DEFAULT && LA74_0 <= KW_DEFINED)||(LA74_0 >= KW_DELIMITED && LA74_0 <= KW_DESC)||(LA74_0 >= KW_DETAIL && LA74_0 <= KW_DISABLE)||(LA74_0 >= KW_DISTRIBUTE && LA74_0 <= KW_DO)||LA74_0==KW_DOW||(LA74_0 >= KW_DUMP && LA74_0 <= KW_ELEM_TYPE)||LA74_0==KW_ENABLE||(LA74_0 >= KW_ENFORCED && LA74_0 <= KW_EVERY)||(LA74_0 >= KW_EXCLUSIVE && LA74_0 <= KW_EXECUTED)||(LA74_0 >= KW_EXPIRE_SNAPSHOTS && LA74_0 <= KW_EXPRESSION)||(LA74_0 >= KW_FIELDS && LA74_0 <= KW_FIRST)||(LA74_0 >= KW_FORMAT && LA74_0 <= KW_FORMATTED)||LA74_0==KW_FUNCTIONS||(LA74_0 >= KW_HOUR && LA74_0 <= KW_IDXPROPERTIES)||LA74_0==KW_IGNORE||(LA74_0 >= KW_INDEX && LA74_0 <= KW_INDEXES)||(LA74_0 >= KW_INPATH && LA74_0 <= KW_INPUTFORMAT)||(LA74_0 >= KW_ISOLATION && LA74_0 <= KW_JAR)||(LA74_0 >= KW_JOINCOST && LA74_0 <= KW_LAST)||LA74_0==KW_LEVEL||(LA74_0 >= KW_LIMIT && LA74_0 <= KW_LOAD)||(LA74_0 >= KW_LOCATION && LA74_0 <= KW_LONG)||(LA74_0 >= KW_MANAGED && LA74_0 <= KW_MANAGEMENT)||(LA74_0 >= KW_MAPJOIN && LA74_0 <= KW_MATERIALIZED)||LA74_0==KW_METADATA||(LA74_0 >= KW_MINUTE && LA74_0 <= KW_MONTH)||(LA74_0 >= KW_MOVE && LA74_0 <= KW_MSCK)||(LA74_0 >= KW_NORELY && LA74_0 <= KW_NOSCAN)||LA74_0==KW_NOVALIDATE||LA74_0==KW_NULLS||LA74_0==KW_OFFSET||(LA74_0 >= KW_OPERATOR && LA74_0 <= KW_OPTION)||(LA74_0 >= KW_OUTPUTDRIVER && LA74_0 <= KW_OUTPUTFORMAT)||(LA74_0 >= KW_OVERWRITE && LA74_0 <= KW_OWNER)||(LA74_0 >= KW_PARTITIONED && LA74_0 <= KW_PATH)||(LA74_0 >= KW_PLAN && LA74_0 <= KW_POOL)||LA74_0==KW_PRINCIPALS||LA74_0==KW_PURGE||(LA74_0 >= KW_QUARTER && LA74_0 <= KW_QUERY_PARALLELISM)||LA74_0==KW_READ||(LA74_0 >= KW_REBUILD && LA74_0 <= KW_RECORDWRITER)||(LA74_0 >= KW_RELOAD && LA74_0 <= KW_RESTRICT)||LA74_0==KW_REWRITE||(LA74_0 >= KW_ROLE && LA74_0 <= KW_ROLES)||(LA74_0 >= KW_SCHEDULED && LA74_0 <= KW_SECOND)||(LA74_0 >= KW_SEMI && LA74_0 <= KW_SERVER)||(LA74_0 >= KW_SETS && LA74_0 <= KW_SKEWED)||LA74_0==KW_SNAPSHOT||(LA74_0 >= KW_SORT && LA74_0 <= KW_SSL)||(LA74_0 >= KW_STATISTICS && LA74_0 <= KW_SUMMARY)||(LA74_0 >= KW_SYSTEM_TIME && LA74_0 <= KW_SYSTEM_VERSION)||LA74_0==KW_TABLES||(LA74_0 >= KW_TBLPROPERTIES && LA74_0 <= KW_TERMINATED)||LA74_0==KW_TINYINT||LA74_0==KW_TOUCH||(LA74_0 >= KW_TRANSACTION && LA74_0 <= KW_TRANSACTIONS)||LA74_0==KW_TRIM||(LA74_0 >= KW_TYPE && LA74_0 <= KW_UNARCHIVE)||LA74_0==KW_UNDO||LA74_0==KW_UNIONTYPE||(LA74_0 >= KW_UNKNOWN && LA74_0 <= KW_UNSIGNED)||(LA74_0 >= KW_URI && LA74_0 <= KW_USE)||(LA74_0 >= KW_UTC && LA74_0 <= KW_VALIDATE)||LA74_0==KW_VALUE_TYPE||(LA74_0 >= KW_VECTORIZATION && LA74_0 <= KW_WEEK)||LA74_0==KW_WHILE||(LA74_0 >= KW_WITHIN && LA74_0 <= KW_ZONE)||LA74_0==StringLiteral||LA74_0==KW_BATCH||LA74_0==KW_DAYOFWEEK||LA74_0==KW_HOLD_DDLTIME||LA74_0==KW_NO_DROP||LA74_0==KW_OFFLINE||LA74_0==KW_PROTECTION||LA74_0==KW_READONLY||LA74_0==KW_TIMESTAMPTZ) ) {
						alt74=2;
					}
					switch (alt74) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:63: KW_LIKE showStmtIdentifier
							{
							KW_LIKE239=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement5150); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE239);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5152);
							showStmtIdentifier240=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier240.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:90: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5154);
							showStmtIdentifier241=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier241.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier, db_name
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1327:112: -> ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:115: ^( TOK_SHOWVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWVIEWS, "TOK_SHOWVIEWS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:131: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:152: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:7: KW_SHOW KW_MATERIALIZED KW_VIEWS ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW242=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5182); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW242);

					KW_MATERIALIZED243=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_showStatement5184); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED243);

					KW_VIEWS244=(Token)match(input,KW_VIEWS,FOLLOW_KW_VIEWS_in_showStatement5186); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VIEWS.add(KW_VIEWS244);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:40: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt76=2;
					int LA76_0 = input.LA(1);
					if ( (LA76_0==KW_FROM||LA76_0==KW_IN) ) {
						alt76=1;
					}
					switch (alt76) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:41: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:41: ( KW_FROM | KW_IN )
							int alt75=2;
							int LA75_0 = input.LA(1);
							if ( (LA75_0==KW_FROM) ) {
								alt75=1;
							}
							else if ( (LA75_0==KW_IN) ) {
								alt75=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 75, 0, input);
								throw nvae;
							}

							switch (alt75) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:42: KW_FROM
									{
									KW_FROM245=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement5190); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM245);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:50: KW_IN
									{
									KW_IN246=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement5192); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN246);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement5197);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:78: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt77=3;
					int LA77_0 = input.LA(1);
					if ( (LA77_0==KW_LIKE) ) {
						alt77=1;
					}
					else if ( (LA77_0==Identifier||(LA77_0 >= KW_ABORT && LA77_0 <= KW_AFTER)||LA77_0==KW_ALLOC_FRACTION||LA77_0==KW_ANALYZE||LA77_0==KW_ARCHIVE||(LA77_0 >= KW_ASC && LA77_0 <= KW_AT)||(LA77_0 >= KW_AUTOCOMMIT && LA77_0 <= KW_BEFORE)||(LA77_0 >= KW_BUCKET && LA77_0 <= KW_BUCKETS)||(LA77_0 >= KW_CACHE && LA77_0 <= KW_CASCADE)||(LA77_0 >= KW_CBO && LA77_0 <= KW_CHANGE)||(LA77_0 >= KW_CHECK && LA77_0 <= KW_COLLECTION)||(LA77_0 >= KW_COLUMNS && LA77_0 <= KW_COMMENT)||(LA77_0 >= KW_COMPACT && LA77_0 <= KW_CONCATENATE)||(LA77_0 >= KW_CONTINUE && LA77_0 <= KW_COST)||LA77_0==KW_CRON||LA77_0==KW_DATA||LA77_0==KW_DATABASES||(LA77_0 >= KW_DATETIME && LA77_0 <= KW_DCPROPERTIES)||LA77_0==KW_DEBUG||(LA77_0 >= KW_DEFAULT && LA77_0 <= KW_DEFINED)||(LA77_0 >= KW_DELIMITED && LA77_0 <= KW_DESC)||(LA77_0 >= KW_DETAIL && LA77_0 <= KW_DISABLE)||(LA77_0 >= KW_DISTRIBUTE && LA77_0 <= KW_DO)||LA77_0==KW_DOW||(LA77_0 >= KW_DUMP && LA77_0 <= KW_ELEM_TYPE)||LA77_0==KW_ENABLE||(LA77_0 >= KW_ENFORCED && LA77_0 <= KW_EVERY)||(LA77_0 >= KW_EXCLUSIVE && LA77_0 <= KW_EXECUTED)||(LA77_0 >= KW_EXPIRE_SNAPSHOTS && LA77_0 <= KW_EXPRESSION)||(LA77_0 >= KW_FIELDS && LA77_0 <= KW_FIRST)||(LA77_0 >= KW_FORMAT && LA77_0 <= KW_FORMATTED)||LA77_0==KW_FUNCTIONS||(LA77_0 >= KW_HOUR && LA77_0 <= KW_IDXPROPERTIES)||LA77_0==KW_IGNORE||(LA77_0 >= KW_INDEX && LA77_0 <= KW_INDEXES)||(LA77_0 >= KW_INPATH && LA77_0 <= KW_INPUTFORMAT)||(LA77_0 >= KW_ISOLATION && LA77_0 <= KW_JAR)||(LA77_0 >= KW_JOINCOST && LA77_0 <= KW_LAST)||LA77_0==KW_LEVEL||(LA77_0 >= KW_LIMIT && LA77_0 <= KW_LOAD)||(LA77_0 >= KW_LOCATION && LA77_0 <= KW_LONG)||(LA77_0 >= KW_MANAGED && LA77_0 <= KW_MANAGEMENT)||(LA77_0 >= KW_MAPJOIN && LA77_0 <= KW_MATERIALIZED)||LA77_0==KW_METADATA||(LA77_0 >= KW_MINUTE && LA77_0 <= KW_MONTH)||(LA77_0 >= KW_MOVE && LA77_0 <= KW_MSCK)||(LA77_0 >= KW_NORELY && LA77_0 <= KW_NOSCAN)||LA77_0==KW_NOVALIDATE||LA77_0==KW_NULLS||LA77_0==KW_OFFSET||(LA77_0 >= KW_OPERATOR && LA77_0 <= KW_OPTION)||(LA77_0 >= KW_OUTPUTDRIVER && LA77_0 <= KW_OUTPUTFORMAT)||(LA77_0 >= KW_OVERWRITE && LA77_0 <= KW_OWNER)||(LA77_0 >= KW_PARTITIONED && LA77_0 <= KW_PATH)||(LA77_0 >= KW_PLAN && LA77_0 <= KW_POOL)||LA77_0==KW_PRINCIPALS||LA77_0==KW_PURGE||(LA77_0 >= KW_QUARTER && LA77_0 <= KW_QUERY_PARALLELISM)||LA77_0==KW_READ||(LA77_0 >= KW_REBUILD && LA77_0 <= KW_RECORDWRITER)||(LA77_0 >= KW_RELOAD && LA77_0 <= KW_RESTRICT)||LA77_0==KW_REWRITE||(LA77_0 >= KW_ROLE && LA77_0 <= KW_ROLES)||(LA77_0 >= KW_SCHEDULED && LA77_0 <= KW_SECOND)||(LA77_0 >= KW_SEMI && LA77_0 <= KW_SERVER)||(LA77_0 >= KW_SETS && LA77_0 <= KW_SKEWED)||LA77_0==KW_SNAPSHOT||(LA77_0 >= KW_SORT && LA77_0 <= KW_SSL)||(LA77_0 >= KW_STATISTICS && LA77_0 <= KW_SUMMARY)||(LA77_0 >= KW_SYSTEM_TIME && LA77_0 <= KW_SYSTEM_VERSION)||LA77_0==KW_TABLES||(LA77_0 >= KW_TBLPROPERTIES && LA77_0 <= KW_TERMINATED)||LA77_0==KW_TINYINT||LA77_0==KW_TOUCH||(LA77_0 >= KW_TRANSACTION && LA77_0 <= KW_TRANSACTIONS)||LA77_0==KW_TRIM||(LA77_0 >= KW_TYPE && LA77_0 <= KW_UNARCHIVE)||LA77_0==KW_UNDO||LA77_0==KW_UNIONTYPE||(LA77_0 >= KW_UNKNOWN && LA77_0 <= KW_UNSIGNED)||(LA77_0 >= KW_URI && LA77_0 <= KW_USE)||(LA77_0 >= KW_UTC && LA77_0 <= KW_VALIDATE)||LA77_0==KW_VALUE_TYPE||(LA77_0 >= KW_VECTORIZATION && LA77_0 <= KW_WEEK)||LA77_0==KW_WHILE||(LA77_0 >= KW_WITHIN && LA77_0 <= KW_ZONE)||LA77_0==StringLiteral||LA77_0==KW_BATCH||LA77_0==KW_DAYOFWEEK||LA77_0==KW_HOLD_DDLTIME||LA77_0==KW_NO_DROP||LA77_0==KW_OFFLINE||LA77_0==KW_PROTECTION||LA77_0==KW_READONLY||LA77_0==KW_TIMESTAMPTZ) ) {
						alt77=2;
					}
					switch (alt77) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:79: KW_LIKE showStmtIdentifier
							{
							KW_LIKE247=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement5202); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE247);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5204);
							showStmtIdentifier248=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier248.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:106: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5206);
							showStmtIdentifier249=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier249.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier, db_name
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1328:128: -> ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:131: ^( TOK_SHOWMATERIALIZEDVIEWS ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWMATERIALIZEDVIEWS, "TOK_SHOWMATERIALIZEDVIEWS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:159: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1328:180: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:7: KW_SHOW ( KW_SORTED )? KW_COLUMNS ( KW_FROM | KW_IN ) tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					{
					KW_SHOW250=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5234); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW250);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:15: ( KW_SORTED )?
					int alt78=2;
					int LA78_0 = input.LA(1);
					if ( (LA78_0==KW_SORTED) ) {
						alt78=1;
					}
					switch (alt78) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:15: KW_SORTED
							{
							KW_SORTED251=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_showStatement5236); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED251);

							}
							break;

					}

					KW_COLUMNS252=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_showStatement5239); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COLUMNS.add(KW_COLUMNS252);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:37: ( KW_FROM | KW_IN )
					int alt79=2;
					int LA79_0 = input.LA(1);
					if ( (LA79_0==KW_FROM) ) {
						alt79=1;
					}
					else if ( (LA79_0==KW_IN) ) {
						alt79=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 79, 0, input);
						throw nvae;
					}

					switch (alt79) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:38: KW_FROM
							{
							KW_FROM253=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement5242); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM253);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:46: KW_IN
							{
							KW_IN254=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement5244); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN254);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_showStatement5247);
					tableName255=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName255.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:63: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt81=2;
					int LA81_0 = input.LA(1);
					if ( (LA81_0==KW_FROM||LA81_0==KW_IN) ) {
						alt81=1;
					}
					switch (alt81) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:64: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:64: ( KW_FROM | KW_IN )
							int alt80=2;
							int LA80_0 = input.LA(1);
							if ( (LA80_0==KW_FROM) ) {
								alt80=1;
							}
							else if ( (LA80_0==KW_IN) ) {
								alt80=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 80, 0, input);
								throw nvae;
							}

							switch (alt80) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:65: KW_FROM
									{
									KW_FROM256=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement5251); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM256);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:73: KW_IN
									{
									KW_IN257=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement5253); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN257);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement5258);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:101: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
					int alt82=3;
					int LA82_0 = input.LA(1);
					if ( (LA82_0==KW_LIKE) ) {
						alt82=1;
					}
					else if ( (LA82_0==Identifier||(LA82_0 >= KW_ABORT && LA82_0 <= KW_AFTER)||LA82_0==KW_ALLOC_FRACTION||LA82_0==KW_ANALYZE||LA82_0==KW_ARCHIVE||(LA82_0 >= KW_ASC && LA82_0 <= KW_AT)||(LA82_0 >= KW_AUTOCOMMIT && LA82_0 <= KW_BEFORE)||(LA82_0 >= KW_BUCKET && LA82_0 <= KW_BUCKETS)||(LA82_0 >= KW_CACHE && LA82_0 <= KW_CASCADE)||(LA82_0 >= KW_CBO && LA82_0 <= KW_CHANGE)||(LA82_0 >= KW_CHECK && LA82_0 <= KW_COLLECTION)||(LA82_0 >= KW_COLUMNS && LA82_0 <= KW_COMMENT)||(LA82_0 >= KW_COMPACT && LA82_0 <= KW_CONCATENATE)||(LA82_0 >= KW_CONTINUE && LA82_0 <= KW_COST)||LA82_0==KW_CRON||LA82_0==KW_DATA||LA82_0==KW_DATABASES||(LA82_0 >= KW_DATETIME && LA82_0 <= KW_DCPROPERTIES)||LA82_0==KW_DEBUG||(LA82_0 >= KW_DEFAULT && LA82_0 <= KW_DEFINED)||(LA82_0 >= KW_DELIMITED && LA82_0 <= KW_DESC)||(LA82_0 >= KW_DETAIL && LA82_0 <= KW_DISABLE)||(LA82_0 >= KW_DISTRIBUTE && LA82_0 <= KW_DO)||LA82_0==KW_DOW||(LA82_0 >= KW_DUMP && LA82_0 <= KW_ELEM_TYPE)||LA82_0==KW_ENABLE||(LA82_0 >= KW_ENFORCED && LA82_0 <= KW_EVERY)||(LA82_0 >= KW_EXCLUSIVE && LA82_0 <= KW_EXECUTED)||(LA82_0 >= KW_EXPIRE_SNAPSHOTS && LA82_0 <= KW_EXPRESSION)||(LA82_0 >= KW_FIELDS && LA82_0 <= KW_FIRST)||(LA82_0 >= KW_FORMAT && LA82_0 <= KW_FORMATTED)||LA82_0==KW_FUNCTIONS||(LA82_0 >= KW_HOUR && LA82_0 <= KW_IDXPROPERTIES)||LA82_0==KW_IGNORE||(LA82_0 >= KW_INDEX && LA82_0 <= KW_INDEXES)||(LA82_0 >= KW_INPATH && LA82_0 <= KW_INPUTFORMAT)||(LA82_0 >= KW_ISOLATION && LA82_0 <= KW_JAR)||(LA82_0 >= KW_JOINCOST && LA82_0 <= KW_LAST)||LA82_0==KW_LEVEL||(LA82_0 >= KW_LIMIT && LA82_0 <= KW_LOAD)||(LA82_0 >= KW_LOCATION && LA82_0 <= KW_LONG)||(LA82_0 >= KW_MANAGED && LA82_0 <= KW_MANAGEMENT)||(LA82_0 >= KW_MAPJOIN && LA82_0 <= KW_MATERIALIZED)||LA82_0==KW_METADATA||(LA82_0 >= KW_MINUTE && LA82_0 <= KW_MONTH)||(LA82_0 >= KW_MOVE && LA82_0 <= KW_MSCK)||(LA82_0 >= KW_NORELY && LA82_0 <= KW_NOSCAN)||LA82_0==KW_NOVALIDATE||LA82_0==KW_NULLS||LA82_0==KW_OFFSET||(LA82_0 >= KW_OPERATOR && LA82_0 <= KW_OPTION)||(LA82_0 >= KW_OUTPUTDRIVER && LA82_0 <= KW_OUTPUTFORMAT)||(LA82_0 >= KW_OVERWRITE && LA82_0 <= KW_OWNER)||(LA82_0 >= KW_PARTITIONED && LA82_0 <= KW_PATH)||(LA82_0 >= KW_PLAN && LA82_0 <= KW_POOL)||LA82_0==KW_PRINCIPALS||LA82_0==KW_PURGE||(LA82_0 >= KW_QUARTER && LA82_0 <= KW_QUERY_PARALLELISM)||LA82_0==KW_READ||(LA82_0 >= KW_REBUILD && LA82_0 <= KW_RECORDWRITER)||(LA82_0 >= KW_RELOAD && LA82_0 <= KW_RESTRICT)||LA82_0==KW_REWRITE||(LA82_0 >= KW_ROLE && LA82_0 <= KW_ROLES)||(LA82_0 >= KW_SCHEDULED && LA82_0 <= KW_SECOND)||(LA82_0 >= KW_SEMI && LA82_0 <= KW_SERVER)||(LA82_0 >= KW_SETS && LA82_0 <= KW_SKEWED)||LA82_0==KW_SNAPSHOT||(LA82_0 >= KW_SORT && LA82_0 <= KW_SSL)||(LA82_0 >= KW_STATISTICS && LA82_0 <= KW_SUMMARY)||(LA82_0 >= KW_SYSTEM_TIME && LA82_0 <= KW_SYSTEM_VERSION)||LA82_0==KW_TABLES||(LA82_0 >= KW_TBLPROPERTIES && LA82_0 <= KW_TERMINATED)||LA82_0==KW_TINYINT||LA82_0==KW_TOUCH||(LA82_0 >= KW_TRANSACTION && LA82_0 <= KW_TRANSACTIONS)||LA82_0==KW_TRIM||(LA82_0 >= KW_TYPE && LA82_0 <= KW_UNARCHIVE)||LA82_0==KW_UNDO||LA82_0==KW_UNIONTYPE||(LA82_0 >= KW_UNKNOWN && LA82_0 <= KW_UNSIGNED)||(LA82_0 >= KW_URI && LA82_0 <= KW_USE)||(LA82_0 >= KW_UTC && LA82_0 <= KW_VALIDATE)||LA82_0==KW_VALUE_TYPE||(LA82_0 >= KW_VECTORIZATION && LA82_0 <= KW_WEEK)||LA82_0==KW_WHILE||(LA82_0 >= KW_WITHIN && LA82_0 <= KW_ZONE)||LA82_0==StringLiteral||LA82_0==KW_BATCH||LA82_0==KW_DAYOFWEEK||LA82_0==KW_HOLD_DDLTIME||LA82_0==KW_NO_DROP||LA82_0==KW_OFFLINE||LA82_0==KW_PROTECTION||LA82_0==KW_READONLY||LA82_0==KW_TIMESTAMPTZ) ) {
						alt82=2;
					}
					switch (alt82) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:102: KW_LIKE showStmtIdentifier
							{
							KW_LIKE258=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement5263); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE258);

							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5265);
							showStmtIdentifier259=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier259.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1329:129: showStmtIdentifier
							{
							pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5267);
							showStmtIdentifier260=showStmtIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier260.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: tableName, db_name, showStmtIdentifier, KW_SORTED
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1330:5: -> ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ( KW_SORTED )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:8: ^( TOK_SHOWCOLUMNS tableName ( TOK_FROM $db_name)? ( showStmtIdentifier )? ( KW_SORTED )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:36: ( TOK_FROM $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"));
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:57: ( showStmtIdentifier )?
						if ( stream_showStmtIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						}
						stream_showStmtIdentifier.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:77: ( KW_SORTED )?
						if ( stream_KW_SORTED.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_SORTED.nextNode());
						}
						stream_KW_SORTED.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:7: KW_SHOW KW_FUNCTIONS ( KW_LIKE showFunctionIdentifier )?
					{
					KW_SHOW261=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5303); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW261);

					KW_FUNCTIONS262=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_showStatement5305); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS262);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:28: ( KW_LIKE showFunctionIdentifier )?
					int alt83=2;
					int LA83_0 = input.LA(1);
					if ( (LA83_0==KW_LIKE) ) {
						alt83=1;
					}
					switch (alt83) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:29: KW_LIKE showFunctionIdentifier
							{
							KW_LIKE263=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement5308); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE263);

							pushFollow(FOLLOW_showFunctionIdentifier_in_showStatement5310);
							showFunctionIdentifier264=showFunctionIdentifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_showFunctionIdentifier.add(showFunctionIdentifier264.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: KW_LIKE, showFunctionIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1331:63: -> ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:66: ^( TOK_SHOWFUNCTIONS ( KW_LIKE )? ( showFunctionIdentifier )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:86: ( KW_LIKE )?
						if ( stream_KW_LIKE.hasNext() ) {
							adaptor.addChild(root_1, stream_KW_LIKE.nextNode());
						}
						stream_KW_LIKE.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1331:95: ( showFunctionIdentifier )?
						if ( stream_showFunctionIdentifier.hasNext() ) {
							adaptor.addChild(root_1, stream_showFunctionIdentifier.nextTree());
						}
						stream_showFunctionIdentifier.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:7: KW_SHOW KW_PARTITIONS tabName= tableName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )?
					{
					KW_SHOW265=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5333); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW265);

					KW_PARTITIONS266=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_showStatement5335); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(KW_PARTITIONS266);

					pushFollow(FOLLOW_tableName_in_showStatement5339);
					tabName=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:47: ( partitionSpec )?
					int alt84=2;
					int LA84_0 = input.LA(1);
					if ( (LA84_0==KW_PARTITION) ) {
						alt84=1;
					}
					switch (alt84) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:47: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_showStatement5341);
							partitionSpec267=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec267.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:62: ( whereClause )?
					int alt85=2;
					int LA85_0 = input.LA(1);
					if ( (LA85_0==KW_WHERE) ) {
						alt85=1;
					}
					switch (alt85) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:62: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_showStatement5344);
							whereClause268=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause268.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:75: ( orderByClause )?
					int alt86=2;
					int LA86_0 = input.LA(1);
					if ( (LA86_0==KW_ORDER) ) {
						alt86=1;
					}
					switch (alt86) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:75: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_showStatement5347);
							orderByClause269=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause269.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:90: ( limitClause )?
					int alt87=2;
					int LA87_0 = input.LA(1);
					if ( (LA87_0==KW_LIMIT) ) {
						alt87=1;
					}
					switch (alt87) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:90: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_showStatement5350);
							limitClause270=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause270.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: limitClause, whereClause, tabName, orderByClause, partitionSpec
					// token labels: 
					// rule labels: tabName, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1332:103: -> ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:106: ^( TOK_SHOWPARTITIONS $tabName ( partitionSpec )? ( whereClause )? ( orderByClause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS"), root_1);
						adaptor.addChild(root_1, stream_tabName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:136: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:151: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:164: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1332:179: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:7: KW_SHOW KW_CREATE ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
					{
					KW_SHOW271=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5380); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW271);

					KW_CREATE272=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_showStatement5382); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE272);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:25: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier -> ^( TOK_SHOW_CREATEDATABASE $db_name) | KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) )
					int alt89=2;
					int LA89_0 = input.LA(1);
					if ( (LA89_0==KW_DATABASE) && (synpred12_HiveParser())) {
						alt89=1;
					}
					else if ( (LA89_0==KW_SCHEMA) && (synpred12_HiveParser())) {
						alt89=1;
					}
					else if ( (LA89_0==KW_TABLE) ) {
						alt89=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 89, 0, input);
						throw nvae;
					}

					switch (alt89) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:9: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:36: ( KW_DATABASE | KW_SCHEMA )
							int alt88=2;
							int LA88_0 = input.LA(1);
							if ( (LA88_0==KW_DATABASE) ) {
								alt88=1;
							}
							else if ( (LA88_0==KW_SCHEMA) ) {
								alt88=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 88, 0, input);
								throw nvae;
							}

							switch (alt88) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:37: KW_DATABASE
									{
									KW_DATABASE273=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement5403); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE273);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:49: KW_SCHEMA
									{
									KW_SCHEMA274=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement5405); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA274);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement5410);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							// AST REWRITE
							// elements: db_name
							// token labels: 
							// rule labels: db_name, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1334:79: -> ^( TOK_SHOW_CREATEDATABASE $db_name)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:82: ^( TOK_SHOW_CREATEDATABASE $db_name)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CREATEDATABASE, "TOK_SHOW_CREATEDATABASE"), root_1);
								adaptor.addChild(root_1, stream_db_name.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1336:9: KW_TABLE tabName= tableName
							{
							KW_TABLE275=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement5439); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE275);

							pushFollow(FOLLOW_tableName_in_showStatement5443);
							tabName=tableName();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
							// AST REWRITE
							// elements: tabName
							// token labels: 
							// rule labels: tabName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1336:36: -> ^( TOK_SHOW_CREATETABLE $tabName)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1336:39: ^( TOK_SHOW_CREATETABLE $tabName)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE"), root_1);
								adaptor.addChild(root_1, stream_tabName.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
					{
					KW_SHOW276=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5468); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW276);

					KW_TABLE277=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement5470); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE277);

					KW_EXTENDED278=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement5472); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXTENDED.add(KW_EXTENDED278);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
					int alt91=2;
					int LA91_0 = input.LA(1);
					if ( (LA91_0==KW_FROM||LA91_0==KW_IN) ) {
						alt91=1;
					}
					switch (alt91) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:37: ( KW_FROM | KW_IN ) db_name= identifier
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:37: ( KW_FROM | KW_IN )
							int alt90=2;
							int LA90_0 = input.LA(1);
							if ( (LA90_0==KW_FROM) ) {
								alt90=1;
							}
							else if ( (LA90_0==KW_IN) ) {
								alt90=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 90, 0, input);
								throw nvae;
							}

							switch (alt90) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:38: KW_FROM
									{
									KW_FROM279=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement5476); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM279);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:46: KW_IN
									{
									KW_IN280=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement5478); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_IN.add(KW_IN280);

									}
									break;

							}

							pushFollow(FOLLOW_identifier_in_showStatement5483);
							db_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(db_name.getTree());
							}
							break;

					}

					KW_LIKE281=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement5487); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIKE.add(KW_LIKE281);

					pushFollow(FOLLOW_showStmtIdentifier_in_showStatement5489);
					showStmtIdentifier282=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier282.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:101: ( partitionSpec )?
					int alt92=2;
					int LA92_0 = input.LA(1);
					if ( (LA92_0==KW_PARTITION) ) {
						alt92=1;
					}
					switch (alt92) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1338:101: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_showStatement5491);
							partitionSpec283=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec283.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: showStmtIdentifier, partitionSpec, db_name
					// token labels: 
					// rule labels: db_name, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1339:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS"), root_1);
						adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:51: ( $db_name)?
						if ( stream_db_name.hasNext() ) {
							adaptor.addChild(root_1, stream_db_name.nextTree());
						}
						stream_db_name.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1339:60: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:7: KW_SHOW KW_TBLPROPERTIES tableName ( LPAREN prptyName= StringLiteral RPAREN )?
					{
					KW_SHOW284=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5519); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW284);

					KW_TBLPROPERTIES285=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_showStatement5521); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES285);

					pushFollow(FOLLOW_tableName_in_showStatement5523);
					tableName286=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName286.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:42: ( LPAREN prptyName= StringLiteral RPAREN )?
					int alt93=2;
					int LA93_0 = input.LA(1);
					if ( (LA93_0==LPAREN) ) {
						alt93=1;
					}
					switch (alt93) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:43: LPAREN prptyName= StringLiteral RPAREN
							{
							LPAREN287=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_showStatement5526); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN287);

							prptyName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement5530); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(prptyName);

							RPAREN288=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_showStatement5532); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN288);

							}
							break;

					}

					// AST REWRITE
					// elements: tableName, prptyName
					// token labels: prptyName
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_prptyName=new RewriteRuleTokenStream(adaptor,"token prptyName",prptyName);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1340:83: -> ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:86: ^( TOK_SHOW_TBLPROPERTIES tableName ( $prptyName)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:122: ( $prptyName)?
						if ( stream_prptyName.hasNext() ) {
							adaptor.addChild(root_1, stream_prptyName.nextNode());
						}
						stream_prptyName.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:7: KW_SHOW KW_LOCKS ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
					{
					KW_SHOW289=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5554); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW289);

					KW_LOCKS290=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_showStatement5556); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCKS.add(KW_LOCKS290);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1342:7: ( ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? ) | (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) )
					int alt98=2;
					int LA98_0 = input.LA(1);
					if ( (LA98_0==KW_DATABASE) && (synpred13_HiveParser())) {
						alt98=1;
					}
					else if ( (LA98_0==KW_SCHEMA) ) {
						switch ( input.LA(2) ) {
						case Identifier:
							{
							int LA98_7 = input.LA(3);
							if ( (synpred13_HiveParser()) ) {
								alt98=1;
							}
							else if ( (true) ) {
								alt98=2;
							}

							}
							break;
						case KW_ABORT:
						case KW_ACTIVATE:
						case KW_ACTIVE:
						case KW_ADD:
						case KW_ADMIN:
						case KW_AFTER:
						case KW_ALLOC_FRACTION:
						case KW_ANALYZE:
						case KW_ARCHIVE:
						case KW_ASC:
						case KW_AST:
						case KW_AT:
						case KW_AUTOCOMMIT:
						case KW_BEFORE:
						case KW_BUCKET:
						case KW_BUCKETS:
						case KW_CACHE:
						case KW_CASCADE:
						case KW_CBO:
						case KW_CHANGE:
						case KW_CHECK:
						case KW_CLUSTER:
						case KW_CLUSTERED:
						case KW_CLUSTERSTATUS:
						case KW_COLLECTION:
						case KW_COLUMNS:
						case KW_COMMENT:
						case KW_COMPACT:
						case KW_COMPACTIONS:
						case KW_COMPUTE:
						case KW_CONCATENATE:
						case KW_CONTINUE:
						case KW_COST:
						case KW_CRON:
						case KW_DATA:
						case KW_DATABASES:
						case KW_DATETIME:
						case KW_DAY:
						case KW_DBPROPERTIES:
						case KW_DCPROPERTIES:
						case KW_DEBUG:
						case KW_DEFAULT:
						case KW_DEFERRED:
						case KW_DEFINED:
						case KW_DELIMITED:
						case KW_DEPENDENCY:
						case KW_DESC:
						case KW_DETAIL:
						case KW_DIRECTORIES:
						case KW_DIRECTORY:
						case KW_DISABLE:
						case KW_DISTRIBUTE:
						case KW_DISTRIBUTED:
						case KW_DO:
						case KW_DOW:
						case KW_DUMP:
						case KW_ELEM_TYPE:
						case KW_ENABLE:
						case KW_ENFORCED:
						case KW_ESCAPED:
						case KW_EVERY:
						case KW_EXCLUSIVE:
						case KW_EXECUTE:
						case KW_EXECUTED:
						case KW_EXPIRE_SNAPSHOTS:
						case KW_EXPLAIN:
						case KW_EXPORT:
						case KW_EXPRESSION:
						case KW_FIELDS:
						case KW_FILE:
						case KW_FILEFORMAT:
						case KW_FIRST:
						case KW_FORMAT:
						case KW_FORMATTED:
						case KW_FUNCTIONS:
						case KW_HOUR:
						case KW_ID:
						case KW_IDXPROPERTIES:
						case KW_IGNORE:
						case KW_INDEX:
						case KW_INDEXES:
						case KW_INPATH:
						case KW_INPUTDRIVER:
						case KW_INPUTFORMAT:
						case KW_ISOLATION:
						case KW_ITEMS:
						case KW_JAR:
						case KW_JOINCOST:
						case KW_KEY:
						case KW_KEYS:
						case KW_KEY_TYPE:
						case KW_KILL:
						case KW_LAST:
						case KW_LEVEL:
						case KW_LIMIT:
						case KW_LINES:
						case KW_LOAD:
						case KW_LOCATION:
						case KW_LOCK:
						case KW_LOCKS:
						case KW_LOGICAL:
						case KW_LONG:
						case KW_MANAGED:
						case KW_MANAGEDLOCATION:
						case KW_MANAGEMENT:
						case KW_MAPJOIN:
						case KW_MAPPING:
						case KW_MATCHED:
						case KW_MATERIALIZED:
						case KW_METADATA:
						case KW_MINUTE:
						case KW_MONTH:
						case KW_MOVE:
						case KW_MSCK:
						case KW_NORELY:
						case KW_NOSCAN:
						case KW_NOVALIDATE:
						case KW_NULLS:
						case KW_OFFSET:
						case KW_OPERATOR:
						case KW_OPTION:
						case KW_OUTPUTDRIVER:
						case KW_OUTPUTFORMAT:
						case KW_OVERWRITE:
						case KW_OWNER:
						case KW_PARTITIONED:
						case KW_PARTITIONS:
						case KW_PATH:
						case KW_PLAN:
						case KW_PLANS:
						case KW_PLUS:
						case KW_POOL:
						case KW_PRINCIPALS:
						case KW_PURGE:
						case KW_QUARTER:
						case KW_QUERY:
						case KW_QUERY_PARALLELISM:
						case KW_READ:
						case KW_REBUILD:
						case KW_RECORDREADER:
						case KW_RECORDWRITER:
						case KW_RELOAD:
						case KW_RELY:
						case KW_REMOTE:
						case KW_RENAME:
						case KW_REOPTIMIZATION:
						case KW_REPAIR:
						case KW_REPL:
						case KW_REPLACE:
						case KW_REPLICATION:
						case KW_RESOURCE:
						case KW_RESPECT:
						case KW_RESTRICT:
						case KW_REWRITE:
						case KW_ROLE:
						case KW_ROLES:
						case KW_SCHEDULED:
						case KW_SCHEDULING_POLICY:
						case KW_SCHEMA:
						case KW_SCHEMAS:
						case KW_SECOND:
						case KW_SEMI:
						case KW_SERDE:
						case KW_SERDEPROPERTIES:
						case KW_SERVER:
						case KW_SETS:
						case KW_SHARED:
						case KW_SHOW:
						case KW_SHOW_DATABASE:
						case KW_SKEWED:
						case KW_SNAPSHOT:
						case KW_SORT:
						case KW_SORTED:
						case KW_SPEC:
						case KW_SSL:
						case KW_STATISTICS:
						case KW_STATUS:
						case KW_STORED:
						case KW_STREAMTABLE:
						case KW_STRING:
						case KW_STRUCT:
						case KW_SUMMARY:
						case KW_SYSTEM_TIME:
						case KW_SYSTEM_VERSION:
						case KW_TABLES:
						case KW_TBLPROPERTIES:
						case KW_TEMPORARY:
						case KW_TERMINATED:
						case KW_TINYINT:
						case KW_TOUCH:
						case KW_TRANSACTION:
						case KW_TRANSACTIONAL:
						case KW_TRANSACTIONS:
						case KW_TRIM:
						case KW_TYPE:
						case KW_UNARCHIVE:
						case KW_UNDO:
						case KW_UNIONTYPE:
						case KW_UNKNOWN:
						case KW_UNLOCK:
						case KW_UNMANAGED:
						case KW_UNSET:
						case KW_UNSIGNED:
						case KW_URI:
						case KW_URL:
						case KW_USE:
						case KW_UTC:
						case KW_UTCTIMESTAMP:
						case KW_VALIDATE:
						case KW_VALUE_TYPE:
						case KW_VECTORIZATION:
						case KW_VIEW:
						case KW_VIEWS:
						case KW_WAIT:
						case KW_WEEK:
						case KW_WHILE:
						case KW_WITHIN:
						case KW_WORK:
						case KW_WORKLOAD:
						case KW_WRITE:
						case KW_YEAR:
						case KW_ZONE:
						case KW_BATCH:
						case KW_DAYOFWEEK:
						case KW_HOLD_DDLTIME:
						case KW_NO_DROP:
						case KW_OFFLINE:
						case KW_PROTECTION:
						case KW_READONLY:
						case KW_TIMESTAMPTZ:
							{
							int LA98_8 = input.LA(3);
							if ( (synpred13_HiveParser()) ) {
								alt98=1;
							}
							else if ( (true) ) {
								alt98=2;
							}

							}
							break;
						case EOF:
						case DOT:
						case KW_EXTENDED:
						case KW_PARTITION:
							{
							alt98=2;
							}
							break;
						default:
							if (state.backtracking>0) {state.failed=true; return retval;}
							int nvaeMark = input.mark();
							try {
								input.consume();
								NoViableAltException nvae =
									new NoViableAltException("", 98, 2, input);
								throw nvae;
							} finally {
								input.rewind(nvaeMark);
							}
						}
					}
					else if ( (LA98_0==EOF||LA98_0==Identifier||(LA98_0 >= KW_ABORT && LA98_0 <= KW_AFTER)||LA98_0==KW_ALLOC_FRACTION||LA98_0==KW_ANALYZE||LA98_0==KW_ARCHIVE||(LA98_0 >= KW_ASC && LA98_0 <= KW_AT)||(LA98_0 >= KW_AUTOCOMMIT && LA98_0 <= KW_BEFORE)||(LA98_0 >= KW_BUCKET && LA98_0 <= KW_BUCKETS)||(LA98_0 >= KW_CACHE && LA98_0 <= KW_CASCADE)||(LA98_0 >= KW_CBO && LA98_0 <= KW_CHANGE)||(LA98_0 >= KW_CHECK && LA98_0 <= KW_COLLECTION)||(LA98_0 >= KW_COLUMNS && LA98_0 <= KW_COMMENT)||(LA98_0 >= KW_COMPACT && LA98_0 <= KW_CONCATENATE)||(LA98_0 >= KW_CONTINUE && LA98_0 <= KW_COST)||LA98_0==KW_CRON||LA98_0==KW_DATA||LA98_0==KW_DATABASES||(LA98_0 >= KW_DATETIME && LA98_0 <= KW_DCPROPERTIES)||LA98_0==KW_DEBUG||(LA98_0 >= KW_DEFAULT && LA98_0 <= KW_DEFINED)||(LA98_0 >= KW_DELIMITED && LA98_0 <= KW_DESC)||(LA98_0 >= KW_DETAIL && LA98_0 <= KW_DISABLE)||(LA98_0 >= KW_DISTRIBUTE && LA98_0 <= KW_DO)||LA98_0==KW_DOW||(LA98_0 >= KW_DUMP && LA98_0 <= KW_ELEM_TYPE)||LA98_0==KW_ENABLE||(LA98_0 >= KW_ENFORCED && LA98_0 <= KW_EVERY)||(LA98_0 >= KW_EXCLUSIVE && LA98_0 <= KW_EXECUTED)||(LA98_0 >= KW_EXPIRE_SNAPSHOTS && LA98_0 <= KW_EXTENDED)||(LA98_0 >= KW_FIELDS && LA98_0 <= KW_FIRST)||(LA98_0 >= KW_FORMAT && LA98_0 <= KW_FORMATTED)||LA98_0==KW_FUNCTIONS||(LA98_0 >= KW_HOUR && LA98_0 <= KW_IDXPROPERTIES)||LA98_0==KW_IGNORE||(LA98_0 >= KW_INDEX && LA98_0 <= KW_INDEXES)||(LA98_0 >= KW_INPATH && LA98_0 <= KW_INPUTFORMAT)||(LA98_0 >= KW_ISOLATION && LA98_0 <= KW_JAR)||(LA98_0 >= KW_JOINCOST && LA98_0 <= KW_LAST)||LA98_0==KW_LEVEL||(LA98_0 >= KW_LIMIT && LA98_0 <= KW_LOAD)||(LA98_0 >= KW_LOCATION && LA98_0 <= KW_LONG)||(LA98_0 >= KW_MANAGED && LA98_0 <= KW_MANAGEMENT)||(LA98_0 >= KW_MAPJOIN && LA98_0 <= KW_MATERIALIZED)||LA98_0==KW_METADATA||(LA98_0 >= KW_MINUTE && LA98_0 <= KW_MONTH)||(LA98_0 >= KW_MOVE && LA98_0 <= KW_MSCK)||(LA98_0 >= KW_NORELY && LA98_0 <= KW_NOSCAN)||LA98_0==KW_NOVALIDATE||LA98_0==KW_NULLS||LA98_0==KW_OFFSET||(LA98_0 >= KW_OPERATOR && LA98_0 <= KW_OPTION)||(LA98_0 >= KW_OUTPUTDRIVER && LA98_0 <= KW_OUTPUTFORMAT)||(LA98_0 >= KW_OVERWRITE && LA98_0 <= KW_OWNER)||(LA98_0 >= KW_PARTITIONED && LA98_0 <= KW_PATH)||(LA98_0 >= KW_PLAN && LA98_0 <= KW_POOL)||LA98_0==KW_PRINCIPALS||LA98_0==KW_PURGE||(LA98_0 >= KW_QUARTER && LA98_0 <= KW_QUERY_PARALLELISM)||LA98_0==KW_READ||(LA98_0 >= KW_REBUILD && LA98_0 <= KW_RECORDWRITER)||(LA98_0 >= KW_RELOAD && LA98_0 <= KW_RESTRICT)||LA98_0==KW_REWRITE||(LA98_0 >= KW_ROLE && LA98_0 <= KW_ROLES)||(LA98_0 >= KW_SCHEDULED && LA98_0 <= KW_SCHEDULING_POLICY)||(LA98_0 >= KW_SCHEMAS && LA98_0 <= KW_SECOND)||(LA98_0 >= KW_SEMI && LA98_0 <= KW_SERVER)||(LA98_0 >= KW_SETS && LA98_0 <= KW_SKEWED)||LA98_0==KW_SNAPSHOT||(LA98_0 >= KW_SORT && LA98_0 <= KW_SSL)||(LA98_0 >= KW_STATISTICS && LA98_0 <= KW_SUMMARY)||(LA98_0 >= KW_SYSTEM_TIME && LA98_0 <= KW_SYSTEM_VERSION)||LA98_0==KW_TABLES||(LA98_0 >= KW_TBLPROPERTIES && LA98_0 <= KW_TERMINATED)||LA98_0==KW_TINYINT||LA98_0==KW_TOUCH||(LA98_0 >= KW_TRANSACTION && LA98_0 <= KW_TRANSACTIONS)||LA98_0==KW_TRIM||(LA98_0 >= KW_TYPE && LA98_0 <= KW_UNARCHIVE)||LA98_0==KW_UNDO||LA98_0==KW_UNIONTYPE||(LA98_0 >= KW_UNKNOWN && LA98_0 <= KW_UNSIGNED)||(LA98_0 >= KW_URI && LA98_0 <= KW_USE)||(LA98_0 >= KW_UTC && LA98_0 <= KW_VALIDATE)||LA98_0==KW_VALUE_TYPE||(LA98_0 >= KW_VECTORIZATION && LA98_0 <= KW_WEEK)||LA98_0==KW_WHILE||(LA98_0 >= KW_WITHIN && LA98_0 <= KW_ZONE)||LA98_0==KW_BATCH||LA98_0==KW_DAYOFWEEK||LA98_0==KW_HOLD_DDLTIME||LA98_0==KW_NO_DROP||LA98_0==KW_OFFLINE||LA98_0==KW_PROTECTION||LA98_0==KW_READONLY||LA98_0==KW_TIMESTAMPTZ) ) {
						alt98=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 98, 0, input);
						throw nvae;
					}

					switch (alt98) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:7: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) (isExtended= KW_EXTENDED )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:34: ( KW_DATABASE | KW_SCHEMA )
							int alt94=2;
							int LA94_0 = input.LA(1);
							if ( (LA94_0==KW_DATABASE) ) {
								alt94=1;
							}
							else if ( (LA94_0==KW_SCHEMA) ) {
								alt94=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 94, 0, input);
								throw nvae;
							}

							switch (alt94) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:35: KW_DATABASE
									{
									KW_DATABASE291=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement5581); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE291);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:47: KW_SCHEMA
									{
									KW_SCHEMA292=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement5583); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA292);

									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:58: (dbName= identifier )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:59: dbName= identifier
							{
							pushFollow(FOLLOW_identifier_in_showStatement5589);
							dbName=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:78: (isExtended= KW_EXTENDED )?
							int alt95=2;
							int LA95_0 = input.LA(1);
							if ( (LA95_0==KW_EXTENDED) ) {
								alt95=1;
							}
							switch (alt95) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:79: isExtended= KW_EXTENDED
									{
									isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement5595); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

									}
									break;

							}

							// AST REWRITE
							// elements: isExtended, dbName
							// token labels: isExtended
							// rule labels: dbName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
							RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1343:104: -> ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:107: ^( TOK_SHOWDBLOCKS $dbName ( $isExtended)? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDBLOCKS, "TOK_SHOWDBLOCKS"), root_1);
								adaptor.addChild(root_1, stream_dbName.nextTree());
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:134: ( $isExtended)?
								if ( stream_isExtended.hasNext() ) {
									adaptor.addChild(root_1, stream_isExtended.nextNode());
								}
								stream_isExtended.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:7: (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:7: (parttype= partTypeExpr )?
							int alt96=2;
							int LA96_0 = input.LA(1);
							if ( (LA96_0==Identifier||(LA96_0 >= KW_ABORT && LA96_0 <= KW_AFTER)||LA96_0==KW_ALLOC_FRACTION||LA96_0==KW_ANALYZE||LA96_0==KW_ARCHIVE||(LA96_0 >= KW_ASC && LA96_0 <= KW_AT)||(LA96_0 >= KW_AUTOCOMMIT && LA96_0 <= KW_BEFORE)||(LA96_0 >= KW_BUCKET && LA96_0 <= KW_BUCKETS)||(LA96_0 >= KW_CACHE && LA96_0 <= KW_CASCADE)||(LA96_0 >= KW_CBO && LA96_0 <= KW_CHANGE)||(LA96_0 >= KW_CHECK && LA96_0 <= KW_COLLECTION)||(LA96_0 >= KW_COLUMNS && LA96_0 <= KW_COMMENT)||(LA96_0 >= KW_COMPACT && LA96_0 <= KW_CONCATENATE)||(LA96_0 >= KW_CONTINUE && LA96_0 <= KW_COST)||LA96_0==KW_CRON||LA96_0==KW_DATA||LA96_0==KW_DATABASES||(LA96_0 >= KW_DATETIME && LA96_0 <= KW_DCPROPERTIES)||LA96_0==KW_DEBUG||(LA96_0 >= KW_DEFAULT && LA96_0 <= KW_DEFINED)||(LA96_0 >= KW_DELIMITED && LA96_0 <= KW_DESC)||(LA96_0 >= KW_DETAIL && LA96_0 <= KW_DISABLE)||(LA96_0 >= KW_DISTRIBUTE && LA96_0 <= KW_DO)||LA96_0==KW_DOW||(LA96_0 >= KW_DUMP && LA96_0 <= KW_ELEM_TYPE)||LA96_0==KW_ENABLE||(LA96_0 >= KW_ENFORCED && LA96_0 <= KW_EVERY)||(LA96_0 >= KW_EXCLUSIVE && LA96_0 <= KW_EXECUTED)||(LA96_0 >= KW_EXPIRE_SNAPSHOTS && LA96_0 <= KW_EXPRESSION)||(LA96_0 >= KW_FIELDS && LA96_0 <= KW_FIRST)||(LA96_0 >= KW_FORMAT && LA96_0 <= KW_FORMATTED)||LA96_0==KW_FUNCTIONS||(LA96_0 >= KW_HOUR && LA96_0 <= KW_IDXPROPERTIES)||LA96_0==KW_IGNORE||(LA96_0 >= KW_INDEX && LA96_0 <= KW_INDEXES)||(LA96_0 >= KW_INPATH && LA96_0 <= KW_INPUTFORMAT)||(LA96_0 >= KW_ISOLATION && LA96_0 <= KW_JAR)||(LA96_0 >= KW_JOINCOST && LA96_0 <= KW_LAST)||LA96_0==KW_LEVEL||(LA96_0 >= KW_LIMIT && LA96_0 <= KW_LOAD)||(LA96_0 >= KW_LOCATION && LA96_0 <= KW_LONG)||(LA96_0 >= KW_MANAGED && LA96_0 <= KW_MANAGEMENT)||(LA96_0 >= KW_MAPJOIN && LA96_0 <= KW_MATERIALIZED)||LA96_0==KW_METADATA||(LA96_0 >= KW_MINUTE && LA96_0 <= KW_MONTH)||(LA96_0 >= KW_MOVE && LA96_0 <= KW_MSCK)||(LA96_0 >= KW_NORELY && LA96_0 <= KW_NOSCAN)||LA96_0==KW_NOVALIDATE||LA96_0==KW_NULLS||LA96_0==KW_OFFSET||(LA96_0 >= KW_OPERATOR && LA96_0 <= KW_OPTION)||(LA96_0 >= KW_OUTPUTDRIVER && LA96_0 <= KW_OUTPUTFORMAT)||(LA96_0 >= KW_OVERWRITE && LA96_0 <= KW_OWNER)||(LA96_0 >= KW_PARTITIONED && LA96_0 <= KW_PATH)||(LA96_0 >= KW_PLAN && LA96_0 <= KW_POOL)||LA96_0==KW_PRINCIPALS||LA96_0==KW_PURGE||(LA96_0 >= KW_QUARTER && LA96_0 <= KW_QUERY_PARALLELISM)||LA96_0==KW_READ||(LA96_0 >= KW_REBUILD && LA96_0 <= KW_RECORDWRITER)||(LA96_0 >= KW_RELOAD && LA96_0 <= KW_RESTRICT)||LA96_0==KW_REWRITE||(LA96_0 >= KW_ROLE && LA96_0 <= KW_ROLES)||(LA96_0 >= KW_SCHEDULED && LA96_0 <= KW_SECOND)||(LA96_0 >= KW_SEMI && LA96_0 <= KW_SERVER)||(LA96_0 >= KW_SETS && LA96_0 <= KW_SKEWED)||LA96_0==KW_SNAPSHOT||(LA96_0 >= KW_SORT && LA96_0 <= KW_SSL)||(LA96_0 >= KW_STATISTICS && LA96_0 <= KW_SUMMARY)||(LA96_0 >= KW_SYSTEM_TIME && LA96_0 <= KW_SYSTEM_VERSION)||LA96_0==KW_TABLES||(LA96_0 >= KW_TBLPROPERTIES && LA96_0 <= KW_TERMINATED)||LA96_0==KW_TINYINT||LA96_0==KW_TOUCH||(LA96_0 >= KW_TRANSACTION && LA96_0 <= KW_TRANSACTIONS)||LA96_0==KW_TRIM||(LA96_0 >= KW_TYPE && LA96_0 <= KW_UNARCHIVE)||LA96_0==KW_UNDO||LA96_0==KW_UNIONTYPE||(LA96_0 >= KW_UNKNOWN && LA96_0 <= KW_UNSIGNED)||(LA96_0 >= KW_URI && LA96_0 <= KW_USE)||(LA96_0 >= KW_UTC && LA96_0 <= KW_VALIDATE)||LA96_0==KW_VALUE_TYPE||(LA96_0 >= KW_VECTORIZATION && LA96_0 <= KW_WEEK)||LA96_0==KW_WHILE||(LA96_0 >= KW_WITHIN && LA96_0 <= KW_ZONE)||LA96_0==KW_BATCH||LA96_0==KW_DAYOFWEEK||LA96_0==KW_HOLD_DDLTIME||LA96_0==KW_NO_DROP||LA96_0==KW_OFFLINE||LA96_0==KW_PROTECTION||LA96_0==KW_READONLY||LA96_0==KW_TIMESTAMPTZ) ) {
								alt96=1;
							}
							switch (alt96) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:8: parttype= partTypeExpr
									{
									pushFollow(FOLLOW_partTypeExpr_in_showStatement5629);
									parttype=partTypeExpr();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_partTypeExpr.add(parttype.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:32: (isExtended= KW_EXTENDED )?
							int alt97=2;
							int LA97_0 = input.LA(1);
							if ( (LA97_0==KW_EXTENDED) ) {
								alt97=1;
							}
							switch (alt97) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:33: isExtended= KW_EXTENDED
									{
									isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement5636); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_EXTENDED.add(isExtended);

									}
									break;

							}

							// AST REWRITE
							// elements: isExtended, parttype
							// token labels: isExtended
							// rule labels: parttype, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
							RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1345:58: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:61: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS"), root_1);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:78: ( $parttype)?
								if ( stream_parttype.hasNext() ) {
									adaptor.addChild(root_1, stream_parttype.nextTree());
								}
								stream_parttype.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1345:89: ( $isExtended)?
								if ( stream_isExtended.hasNext() ) {
									adaptor.addChild(root_1, stream_isExtended.nextNode());
								}
								stream_isExtended.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:7: KW_SHOW KW_COMPACTIONS ( ( KW_ID )=> compactionId -> ^( TOK_SHOW_COMPACTIONS compactionId ) | ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) | (parttype= partTypeExpr )? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) )
					{
					KW_SHOW293=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5668); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW293);

					KW_COMPACTIONS294=(Token)match(input,KW_COMPACTIONS,FOLLOW_KW_COMPACTIONS_in_showStatement5670); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMPACTIONS.add(KW_COMPACTIONS294);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1348:7: ( ( KW_ID )=> compactionId -> ^( TOK_SHOW_COMPACTIONS compactionId ) | ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) | (parttype= partTypeExpr )? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) )
					int alt111=3;
					alt111 = dfa111.predict(input);
					switch (alt111) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:7: ( KW_ID )=> compactionId
							{
							pushFollow(FOLLOW_compactionId_in_showStatement5692);
							compactionId295=compactionId();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_compactionId.add(compactionId295.getTree());
							// AST REWRITE
							// elements: compactionId
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1349:31: -> ^( TOK_SHOW_COMPACTIONS compactionId )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:34: ^( TOK_SHOW_COMPACTIONS compactionId )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);
								adaptor.addChild(root_1, stream_compactionId.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:7: ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:34: ( KW_DATABASE | KW_SCHEMA )
							int alt99=2;
							int LA99_0 = input.LA(1);
							if ( (LA99_0==KW_DATABASE) ) {
								alt99=1;
							}
							else if ( (LA99_0==KW_SCHEMA) ) {
								alt99=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 99, 0, input);
								throw nvae;
							}

							switch (alt99) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:35: KW_DATABASE
									{
									KW_DATABASE296=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_showStatement5725); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE296);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:47: KW_SCHEMA
									{
									KW_SCHEMA297=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_showStatement5727); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA297);

									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:58: (dbName= identifier )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:59: dbName= identifier
							{
							pushFollow(FOLLOW_identifier_in_showStatement5733);
							dbName=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:78: ( compactionPool )?
							int alt100=2;
							int LA100_0 = input.LA(1);
							if ( (LA100_0==KW_POOL) ) {
								alt100=1;
							}
							switch (alt100) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:78: compactionPool
									{
									pushFollow(FOLLOW_compactionPool_in_showStatement5736);
									compactionPool298=compactionPool();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_compactionPool.add(compactionPool298.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:94: ( compactionType )?
							int alt101=2;
							int LA101_0 = input.LA(1);
							if ( (LA101_0==KW_TYPE) ) {
								alt101=1;
							}
							switch (alt101) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:94: compactionType
									{
									pushFollow(FOLLOW_compactionType_in_showStatement5739);
									compactionType299=compactionType();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_compactionType.add(compactionType299.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:110: ( compactionStatus )?
							int alt102=2;
							int LA102_0 = input.LA(1);
							if ( (LA102_0==KW_STATUS) ) {
								alt102=1;
							}
							switch (alt102) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:110: compactionStatus
									{
									pushFollow(FOLLOW_compactionStatus_in_showStatement5742);
									compactionStatus300=compactionStatus();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_compactionStatus.add(compactionStatus300.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:128: ( orderByClause )?
							int alt103=2;
							int LA103_0 = input.LA(1);
							if ( (LA103_0==KW_ORDER) ) {
								alt103=1;
							}
							switch (alt103) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:128: orderByClause
									{
									pushFollow(FOLLOW_orderByClause_in_showStatement5745);
									orderByClause301=orderByClause();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause301.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:143: ( limitClause )?
							int alt104=2;
							int LA104_0 = input.LA(1);
							if ( (LA104_0==KW_LIMIT) ) {
								alt104=1;
							}
							switch (alt104) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:143: limitClause
									{
									pushFollow(FOLLOW_limitClause_in_showStatement5748);
									limitClause302=limitClause();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_limitClause.add(limitClause302.getTree());
									}
									break;

							}

							// AST REWRITE
							// elements: orderByClause, dbName, limitClause, compactionPool, compactionStatus, compactionType
							// token labels: 
							// rule labels: dbName, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1351:156: -> ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:159: ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);
								adaptor.addChild(root_1, stream_dbName.nextTree());
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:190: ( compactionPool )?
								if ( stream_compactionPool.hasNext() ) {
									adaptor.addChild(root_1, stream_compactionPool.nextTree());
								}
								stream_compactionPool.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:206: ( compactionType )?
								if ( stream_compactionType.hasNext() ) {
									adaptor.addChild(root_1, stream_compactionType.nextTree());
								}
								stream_compactionType.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:222: ( compactionStatus )?
								if ( stream_compactionStatus.hasNext() ) {
									adaptor.addChild(root_1, stream_compactionStatus.nextTree());
								}
								stream_compactionStatus.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:240: ( orderByClause )?
								if ( stream_orderByClause.hasNext() ) {
									adaptor.addChild(root_1, stream_orderByClause.nextTree());
								}
								stream_orderByClause.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:255: ( limitClause )?
								if ( stream_limitClause.hasNext() ) {
									adaptor.addChild(root_1, stream_limitClause.nextTree());
								}
								stream_limitClause.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;
						case 3 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:7: (parttype= partTypeExpr )? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )?
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:7: (parttype= partTypeExpr )?
							int alt105=2;
							switch ( input.LA(1) ) {
								case Identifier:
								case KW_ABORT:
								case KW_ACTIVATE:
								case KW_ACTIVE:
								case KW_ADD:
								case KW_ADMIN:
								case KW_AFTER:
								case KW_ALLOC_FRACTION:
								case KW_ANALYZE:
								case KW_ARCHIVE:
								case KW_ASC:
								case KW_AST:
								case KW_AT:
								case KW_AUTOCOMMIT:
								case KW_BEFORE:
								case KW_BUCKET:
								case KW_BUCKETS:
								case KW_CACHE:
								case KW_CASCADE:
								case KW_CBO:
								case KW_CHANGE:
								case KW_CHECK:
								case KW_CLUSTER:
								case KW_CLUSTERED:
								case KW_CLUSTERSTATUS:
								case KW_COLLECTION:
								case KW_COLUMNS:
								case KW_COMMENT:
								case KW_COMPACT:
								case KW_COMPACTIONS:
								case KW_COMPUTE:
								case KW_CONCATENATE:
								case KW_CONTINUE:
								case KW_COST:
								case KW_CRON:
								case KW_DATA:
								case KW_DATABASES:
								case KW_DATETIME:
								case KW_DAY:
								case KW_DBPROPERTIES:
								case KW_DCPROPERTIES:
								case KW_DEBUG:
								case KW_DEFAULT:
								case KW_DEFERRED:
								case KW_DEFINED:
								case KW_DELIMITED:
								case KW_DEPENDENCY:
								case KW_DESC:
								case KW_DETAIL:
								case KW_DIRECTORIES:
								case KW_DIRECTORY:
								case KW_DISABLE:
								case KW_DISTRIBUTE:
								case KW_DISTRIBUTED:
								case KW_DO:
								case KW_DOW:
								case KW_DUMP:
								case KW_ELEM_TYPE:
								case KW_ENABLE:
								case KW_ENFORCED:
								case KW_ESCAPED:
								case KW_EVERY:
								case KW_EXCLUSIVE:
								case KW_EXECUTE:
								case KW_EXECUTED:
								case KW_EXPIRE_SNAPSHOTS:
								case KW_EXPLAIN:
								case KW_EXPORT:
								case KW_EXPRESSION:
								case KW_FIELDS:
								case KW_FILE:
								case KW_FILEFORMAT:
								case KW_FIRST:
								case KW_FORMAT:
								case KW_FORMATTED:
								case KW_FUNCTIONS:
								case KW_HOUR:
								case KW_ID:
								case KW_IDXPROPERTIES:
								case KW_IGNORE:
								case KW_INDEX:
								case KW_INDEXES:
								case KW_INPATH:
								case KW_INPUTDRIVER:
								case KW_INPUTFORMAT:
								case KW_ISOLATION:
								case KW_ITEMS:
								case KW_JAR:
								case KW_JOINCOST:
								case KW_KEY:
								case KW_KEYS:
								case KW_KEY_TYPE:
								case KW_KILL:
								case KW_LAST:
								case KW_LEVEL:
								case KW_LINES:
								case KW_LOAD:
								case KW_LOCATION:
								case KW_LOCK:
								case KW_LOCKS:
								case KW_LOGICAL:
								case KW_LONG:
								case KW_MANAGED:
								case KW_MANAGEDLOCATION:
								case KW_MANAGEMENT:
								case KW_MAPJOIN:
								case KW_MAPPING:
								case KW_MATCHED:
								case KW_MATERIALIZED:
								case KW_METADATA:
								case KW_MINUTE:
								case KW_MONTH:
								case KW_MOVE:
								case KW_MSCK:
								case KW_NORELY:
								case KW_NOSCAN:
								case KW_NOVALIDATE:
								case KW_NULLS:
								case KW_OFFSET:
								case KW_OPERATOR:
								case KW_OPTION:
								case KW_OUTPUTDRIVER:
								case KW_OUTPUTFORMAT:
								case KW_OVERWRITE:
								case KW_OWNER:
								case KW_PARTITIONED:
								case KW_PARTITIONS:
								case KW_PATH:
								case KW_PLAN:
								case KW_PLANS:
								case KW_PLUS:
								case KW_PRINCIPALS:
								case KW_PURGE:
								case KW_QUARTER:
								case KW_QUERY:
								case KW_QUERY_PARALLELISM:
								case KW_READ:
								case KW_REBUILD:
								case KW_RECORDREADER:
								case KW_RECORDWRITER:
								case KW_RELOAD:
								case KW_RELY:
								case KW_REMOTE:
								case KW_RENAME:
								case KW_REOPTIMIZATION:
								case KW_REPAIR:
								case KW_REPL:
								case KW_REPLACE:
								case KW_REPLICATION:
								case KW_RESOURCE:
								case KW_RESPECT:
								case KW_RESTRICT:
								case KW_REWRITE:
								case KW_ROLE:
								case KW_ROLES:
								case KW_SCHEDULED:
								case KW_SCHEDULING_POLICY:
								case KW_SCHEMA:
								case KW_SCHEMAS:
								case KW_SECOND:
								case KW_SEMI:
								case KW_SERDE:
								case KW_SERDEPROPERTIES:
								case KW_SERVER:
								case KW_SETS:
								case KW_SHARED:
								case KW_SHOW:
								case KW_SHOW_DATABASE:
								case KW_SKEWED:
								case KW_SNAPSHOT:
								case KW_SORT:
								case KW_SORTED:
								case KW_SPEC:
								case KW_SSL:
								case KW_STATISTICS:
								case KW_STORED:
								case KW_STREAMTABLE:
								case KW_STRING:
								case KW_STRUCT:
								case KW_SUMMARY:
								case KW_SYSTEM_TIME:
								case KW_SYSTEM_VERSION:
								case KW_TABLES:
								case KW_TBLPROPERTIES:
								case KW_TEMPORARY:
								case KW_TERMINATED:
								case KW_TINYINT:
								case KW_TOUCH:
								case KW_TRANSACTION:
								case KW_TRANSACTIONAL:
								case KW_TRANSACTIONS:
								case KW_TRIM:
								case KW_UNARCHIVE:
								case KW_UNDO:
								case KW_UNIONTYPE:
								case KW_UNKNOWN:
								case KW_UNLOCK:
								case KW_UNMANAGED:
								case KW_UNSET:
								case KW_UNSIGNED:
								case KW_URI:
								case KW_URL:
								case KW_USE:
								case KW_UTC:
								case KW_UTCTIMESTAMP:
								case KW_VALIDATE:
								case KW_VALUE_TYPE:
								case KW_VECTORIZATION:
								case KW_VIEW:
								case KW_VIEWS:
								case KW_WAIT:
								case KW_WEEK:
								case KW_WHILE:
								case KW_WITHIN:
								case KW_WORK:
								case KW_WORKLOAD:
								case KW_WRITE:
								case KW_YEAR:
								case KW_ZONE:
								case KW_BATCH:
								case KW_DAYOFWEEK:
								case KW_HOLD_DDLTIME:
								case KW_NO_DROP:
								case KW_OFFLINE:
								case KW_PROTECTION:
								case KW_READONLY:
								case KW_TIMESTAMPTZ:
									{
									alt105=1;
									}
									break;
								case KW_POOL:
									{
									int LA105_2 = input.LA(2);
									if ( (LA105_2==EOF||LA105_2==DOT||LA105_2==Identifier||(LA105_2 >= KW_ABORT && LA105_2 <= KW_AFTER)||LA105_2==KW_ALLOC_FRACTION||LA105_2==KW_ANALYZE||LA105_2==KW_ARCHIVE||(LA105_2 >= KW_ASC && LA105_2 <= KW_AT)||(LA105_2 >= KW_AUTOCOMMIT && LA105_2 <= KW_BEFORE)||(LA105_2 >= KW_BUCKET && LA105_2 <= KW_BUCKETS)||(LA105_2 >= KW_CACHE && LA105_2 <= KW_CASCADE)||(LA105_2 >= KW_CBO && LA105_2 <= KW_CHANGE)||(LA105_2 >= KW_CHECK && LA105_2 <= KW_COLLECTION)||(LA105_2 >= KW_COLUMNS && LA105_2 <= KW_COMMENT)||(LA105_2 >= KW_COMPACT && LA105_2 <= KW_CONCATENATE)||(LA105_2 >= KW_CONTINUE && LA105_2 <= KW_COST)||LA105_2==KW_CRON||LA105_2==KW_DATA||LA105_2==KW_DATABASES||(LA105_2 >= KW_DATETIME && LA105_2 <= KW_DCPROPERTIES)||LA105_2==KW_DEBUG||(LA105_2 >= KW_DEFAULT && LA105_2 <= KW_DEFINED)||(LA105_2 >= KW_DELIMITED && LA105_2 <= KW_DESC)||(LA105_2 >= KW_DETAIL && LA105_2 <= KW_DISABLE)||(LA105_2 >= KW_DISTRIBUTE && LA105_2 <= KW_DO)||LA105_2==KW_DOW||(LA105_2 >= KW_DUMP && LA105_2 <= KW_ELEM_TYPE)||LA105_2==KW_ENABLE||(LA105_2 >= KW_ENFORCED && LA105_2 <= KW_EVERY)||(LA105_2 >= KW_EXCLUSIVE && LA105_2 <= KW_EXECUTED)||(LA105_2 >= KW_EXPIRE_SNAPSHOTS && LA105_2 <= KW_EXPRESSION)||(LA105_2 >= KW_FIELDS && LA105_2 <= KW_FIRST)||(LA105_2 >= KW_FORMAT && LA105_2 <= KW_FORMATTED)||LA105_2==KW_FUNCTIONS||(LA105_2 >= KW_HOUR && LA105_2 <= KW_IDXPROPERTIES)||LA105_2==KW_IGNORE||(LA105_2 >= KW_INDEX && LA105_2 <= KW_INDEXES)||(LA105_2 >= KW_INPATH && LA105_2 <= KW_INPUTFORMAT)||(LA105_2 >= KW_ISOLATION && LA105_2 <= KW_JAR)||(LA105_2 >= KW_JOINCOST && LA105_2 <= KW_LAST)||LA105_2==KW_LEVEL||(LA105_2 >= KW_LIMIT && LA105_2 <= KW_LOAD)||(LA105_2 >= KW_LOCATION && LA105_2 <= KW_LONG)||(LA105_2 >= KW_MANAGED && LA105_2 <= KW_MANAGEMENT)||(LA105_2 >= KW_MAPJOIN && LA105_2 <= KW_MATERIALIZED)||LA105_2==KW_METADATA||(LA105_2 >= KW_MINUTE && LA105_2 <= KW_MONTH)||(LA105_2 >= KW_MOVE && LA105_2 <= KW_MSCK)||(LA105_2 >= KW_NORELY && LA105_2 <= KW_NOSCAN)||LA105_2==KW_NOVALIDATE||LA105_2==KW_NULLS||LA105_2==KW_OFFSET||(LA105_2 >= KW_OPERATOR && LA105_2 <= KW_OPTION)||LA105_2==KW_ORDER||(LA105_2 >= KW_OUTPUTDRIVER && LA105_2 <= KW_OUTPUTFORMAT)||(LA105_2 >= KW_OVERWRITE && LA105_2 <= KW_PATH)||(LA105_2 >= KW_PLAN && LA105_2 <= KW_POOL)||LA105_2==KW_PRINCIPALS||LA105_2==KW_PURGE||(LA105_2 >= KW_QUARTER && LA105_2 <= KW_QUERY_PARALLELISM)||LA105_2==KW_READ||(LA105_2 >= KW_REBUILD && LA105_2 <= KW_RECORDWRITER)||(LA105_2 >= KW_RELOAD && LA105_2 <= KW_RESTRICT)||LA105_2==KW_REWRITE||(LA105_2 >= KW_ROLE && LA105_2 <= KW_ROLES)||(LA105_2 >= KW_SCHEDULED && LA105_2 <= KW_SECOND)||(LA105_2 >= KW_SEMI && LA105_2 <= KW_SERVER)||(LA105_2 >= KW_SETS && LA105_2 <= KW_SKEWED)||LA105_2==KW_SNAPSHOT||(LA105_2 >= KW_SORT && LA105_2 <= KW_SSL)||(LA105_2 >= KW_STATISTICS && LA105_2 <= KW_SUMMARY)||(LA105_2 >= KW_SYSTEM_TIME && LA105_2 <= KW_SYSTEM_VERSION)||LA105_2==KW_TABLES||(LA105_2 >= KW_TBLPROPERTIES && LA105_2 <= KW_TERMINATED)||LA105_2==KW_TINYINT||LA105_2==KW_TOUCH||(LA105_2 >= KW_TRANSACTION && LA105_2 <= KW_TRANSACTIONS)||LA105_2==KW_TRIM||(LA105_2 >= KW_TYPE && LA105_2 <= KW_UNARCHIVE)||LA105_2==KW_UNDO||LA105_2==KW_UNIONTYPE||(LA105_2 >= KW_UNKNOWN && LA105_2 <= KW_UNSIGNED)||(LA105_2 >= KW_URI && LA105_2 <= KW_USE)||(LA105_2 >= KW_UTC && LA105_2 <= KW_VALIDATE)||LA105_2==KW_VALUE_TYPE||(LA105_2 >= KW_VECTORIZATION && LA105_2 <= KW_WEEK)||LA105_2==KW_WHILE||(LA105_2 >= KW_WITHIN && LA105_2 <= KW_ZONE)||LA105_2==KW_BATCH||LA105_2==KW_DAYOFWEEK||LA105_2==KW_HOLD_DDLTIME||LA105_2==KW_NO_DROP||LA105_2==KW_OFFLINE||LA105_2==KW_PROTECTION||LA105_2==KW_READONLY||LA105_2==KW_TIMESTAMPTZ) ) {
										alt105=1;
									}
									}
									break;
								case KW_TYPE:
									{
									int LA105_3 = input.LA(2);
									if ( (LA105_3==EOF||LA105_3==DOT||LA105_3==Identifier||(LA105_3 >= KW_ABORT && LA105_3 <= KW_AFTER)||LA105_3==KW_ALLOC_FRACTION||LA105_3==KW_ANALYZE||LA105_3==KW_ARCHIVE||(LA105_3 >= KW_ASC && LA105_3 <= KW_AT)||(LA105_3 >= KW_AUTOCOMMIT && LA105_3 <= KW_BEFORE)||(LA105_3 >= KW_BUCKET && LA105_3 <= KW_BUCKETS)||(LA105_3 >= KW_CACHE && LA105_3 <= KW_CASCADE)||(LA105_3 >= KW_CBO && LA105_3 <= KW_CHANGE)||(LA105_3 >= KW_CHECK && LA105_3 <= KW_COLLECTION)||(LA105_3 >= KW_COLUMNS && LA105_3 <= KW_COMMENT)||(LA105_3 >= KW_COMPACT && LA105_3 <= KW_CONCATENATE)||(LA105_3 >= KW_CONTINUE && LA105_3 <= KW_COST)||LA105_3==KW_CRON||LA105_3==KW_DATA||LA105_3==KW_DATABASES||(LA105_3 >= KW_DATETIME && LA105_3 <= KW_DCPROPERTIES)||LA105_3==KW_DEBUG||(LA105_3 >= KW_DEFAULT && LA105_3 <= KW_DEFINED)||(LA105_3 >= KW_DELIMITED && LA105_3 <= KW_DESC)||(LA105_3 >= KW_DETAIL && LA105_3 <= KW_DISABLE)||(LA105_3 >= KW_DISTRIBUTE && LA105_3 <= KW_DO)||LA105_3==KW_DOW||(LA105_3 >= KW_DUMP && LA105_3 <= KW_ELEM_TYPE)||LA105_3==KW_ENABLE||(LA105_3 >= KW_ENFORCED && LA105_3 <= KW_EVERY)||(LA105_3 >= KW_EXCLUSIVE && LA105_3 <= KW_EXECUTED)||(LA105_3 >= KW_EXPIRE_SNAPSHOTS && LA105_3 <= KW_EXPRESSION)||(LA105_3 >= KW_FIELDS && LA105_3 <= KW_FIRST)||(LA105_3 >= KW_FORMAT && LA105_3 <= KW_FORMATTED)||LA105_3==KW_FUNCTIONS||(LA105_3 >= KW_HOUR && LA105_3 <= KW_IDXPROPERTIES)||LA105_3==KW_IGNORE||(LA105_3 >= KW_INDEX && LA105_3 <= KW_INDEXES)||(LA105_3 >= KW_INPATH && LA105_3 <= KW_INPUTFORMAT)||(LA105_3 >= KW_ISOLATION && LA105_3 <= KW_JAR)||(LA105_3 >= KW_JOINCOST && LA105_3 <= KW_LAST)||LA105_3==KW_LEVEL||(LA105_3 >= KW_LIMIT && LA105_3 <= KW_LOAD)||(LA105_3 >= KW_LOCATION && LA105_3 <= KW_LONG)||(LA105_3 >= KW_MANAGED && LA105_3 <= KW_MANAGEMENT)||(LA105_3 >= KW_MAPJOIN && LA105_3 <= KW_MATERIALIZED)||LA105_3==KW_METADATA||(LA105_3 >= KW_MINUTE && LA105_3 <= KW_MONTH)||(LA105_3 >= KW_MOVE && LA105_3 <= KW_MSCK)||(LA105_3 >= KW_NORELY && LA105_3 <= KW_NOSCAN)||LA105_3==KW_NOVALIDATE||LA105_3==KW_NULLS||LA105_3==KW_OFFSET||(LA105_3 >= KW_OPERATOR && LA105_3 <= KW_OPTION)||LA105_3==KW_ORDER||(LA105_3 >= KW_OUTPUTDRIVER && LA105_3 <= KW_OUTPUTFORMAT)||(LA105_3 >= KW_OVERWRITE && LA105_3 <= KW_PATH)||(LA105_3 >= KW_PLAN && LA105_3 <= KW_POOL)||LA105_3==KW_PRINCIPALS||LA105_3==KW_PURGE||(LA105_3 >= KW_QUARTER && LA105_3 <= KW_QUERY_PARALLELISM)||LA105_3==KW_READ||(LA105_3 >= KW_REBUILD && LA105_3 <= KW_RECORDWRITER)||(LA105_3 >= KW_RELOAD && LA105_3 <= KW_RESTRICT)||LA105_3==KW_REWRITE||(LA105_3 >= KW_ROLE && LA105_3 <= KW_ROLES)||(LA105_3 >= KW_SCHEDULED && LA105_3 <= KW_SECOND)||(LA105_3 >= KW_SEMI && LA105_3 <= KW_SERVER)||(LA105_3 >= KW_SETS && LA105_3 <= KW_SKEWED)||LA105_3==KW_SNAPSHOT||(LA105_3 >= KW_SORT && LA105_3 <= KW_SSL)||(LA105_3 >= KW_STATISTICS && LA105_3 <= KW_SUMMARY)||(LA105_3 >= KW_SYSTEM_TIME && LA105_3 <= KW_SYSTEM_VERSION)||LA105_3==KW_TABLES||(LA105_3 >= KW_TBLPROPERTIES && LA105_3 <= KW_TERMINATED)||LA105_3==KW_TINYINT||LA105_3==KW_TOUCH||(LA105_3 >= KW_TRANSACTION && LA105_3 <= KW_TRANSACTIONS)||LA105_3==KW_TRIM||(LA105_3 >= KW_TYPE && LA105_3 <= KW_UNARCHIVE)||LA105_3==KW_UNDO||LA105_3==KW_UNIONTYPE||(LA105_3 >= KW_UNKNOWN && LA105_3 <= KW_UNSIGNED)||(LA105_3 >= KW_URI && LA105_3 <= KW_USE)||(LA105_3 >= KW_UTC && LA105_3 <= KW_VALIDATE)||LA105_3==KW_VALUE_TYPE||(LA105_3 >= KW_VECTORIZATION && LA105_3 <= KW_WEEK)||LA105_3==KW_WHILE||(LA105_3 >= KW_WITHIN && LA105_3 <= KW_ZONE)||LA105_3==KW_BATCH||LA105_3==KW_DAYOFWEEK||LA105_3==KW_HOLD_DDLTIME||LA105_3==KW_NO_DROP||LA105_3==KW_OFFLINE||LA105_3==KW_PROTECTION||LA105_3==KW_READONLY||LA105_3==KW_TIMESTAMPTZ) ) {
										alt105=1;
									}
									}
									break;
								case KW_STATUS:
									{
									int LA105_4 = input.LA(2);
									if ( (LA105_4==EOF||LA105_4==DOT||LA105_4==Identifier||(LA105_4 >= KW_ABORT && LA105_4 <= KW_AFTER)||LA105_4==KW_ALLOC_FRACTION||LA105_4==KW_ANALYZE||LA105_4==KW_ARCHIVE||(LA105_4 >= KW_ASC && LA105_4 <= KW_AT)||(LA105_4 >= KW_AUTOCOMMIT && LA105_4 <= KW_BEFORE)||(LA105_4 >= KW_BUCKET && LA105_4 <= KW_BUCKETS)||(LA105_4 >= KW_CACHE && LA105_4 <= KW_CASCADE)||(LA105_4 >= KW_CBO && LA105_4 <= KW_CHANGE)||(LA105_4 >= KW_CHECK && LA105_4 <= KW_COLLECTION)||(LA105_4 >= KW_COLUMNS && LA105_4 <= KW_COMMENT)||(LA105_4 >= KW_COMPACT && LA105_4 <= KW_CONCATENATE)||(LA105_4 >= KW_CONTINUE && LA105_4 <= KW_COST)||LA105_4==KW_CRON||LA105_4==KW_DATA||LA105_4==KW_DATABASES||(LA105_4 >= KW_DATETIME && LA105_4 <= KW_DCPROPERTIES)||LA105_4==KW_DEBUG||(LA105_4 >= KW_DEFAULT && LA105_4 <= KW_DEFINED)||(LA105_4 >= KW_DELIMITED && LA105_4 <= KW_DESC)||(LA105_4 >= KW_DETAIL && LA105_4 <= KW_DISABLE)||(LA105_4 >= KW_DISTRIBUTE && LA105_4 <= KW_DO)||LA105_4==KW_DOW||(LA105_4 >= KW_DUMP && LA105_4 <= KW_ELEM_TYPE)||LA105_4==KW_ENABLE||(LA105_4 >= KW_ENFORCED && LA105_4 <= KW_EVERY)||(LA105_4 >= KW_EXCLUSIVE && LA105_4 <= KW_EXECUTED)||(LA105_4 >= KW_EXPIRE_SNAPSHOTS && LA105_4 <= KW_EXPRESSION)||(LA105_4 >= KW_FIELDS && LA105_4 <= KW_FIRST)||(LA105_4 >= KW_FORMAT && LA105_4 <= KW_FORMATTED)||LA105_4==KW_FUNCTIONS||(LA105_4 >= KW_HOUR && LA105_4 <= KW_IDXPROPERTIES)||LA105_4==KW_IGNORE||(LA105_4 >= KW_INDEX && LA105_4 <= KW_INDEXES)||(LA105_4 >= KW_INPATH && LA105_4 <= KW_INPUTFORMAT)||(LA105_4 >= KW_ISOLATION && LA105_4 <= KW_JAR)||(LA105_4 >= KW_JOINCOST && LA105_4 <= KW_LAST)||LA105_4==KW_LEVEL||(LA105_4 >= KW_LIMIT && LA105_4 <= KW_LOAD)||(LA105_4 >= KW_LOCATION && LA105_4 <= KW_LONG)||(LA105_4 >= KW_MANAGED && LA105_4 <= KW_MANAGEMENT)||(LA105_4 >= KW_MAPJOIN && LA105_4 <= KW_MATERIALIZED)||LA105_4==KW_METADATA||(LA105_4 >= KW_MINUTE && LA105_4 <= KW_MONTH)||(LA105_4 >= KW_MOVE && LA105_4 <= KW_MSCK)||(LA105_4 >= KW_NORELY && LA105_4 <= KW_NOSCAN)||LA105_4==KW_NOVALIDATE||LA105_4==KW_NULLS||LA105_4==KW_OFFSET||(LA105_4 >= KW_OPERATOR && LA105_4 <= KW_OPTION)||LA105_4==KW_ORDER||(LA105_4 >= KW_OUTPUTDRIVER && LA105_4 <= KW_OUTPUTFORMAT)||(LA105_4 >= KW_OVERWRITE && LA105_4 <= KW_PATH)||(LA105_4 >= KW_PLAN && LA105_4 <= KW_POOL)||LA105_4==KW_PRINCIPALS||LA105_4==KW_PURGE||(LA105_4 >= KW_QUARTER && LA105_4 <= KW_QUERY_PARALLELISM)||LA105_4==KW_READ||(LA105_4 >= KW_REBUILD && LA105_4 <= KW_RECORDWRITER)||(LA105_4 >= KW_RELOAD && LA105_4 <= KW_RESTRICT)||LA105_4==KW_REWRITE||(LA105_4 >= KW_ROLE && LA105_4 <= KW_ROLES)||(LA105_4 >= KW_SCHEDULED && LA105_4 <= KW_SECOND)||(LA105_4 >= KW_SEMI && LA105_4 <= KW_SERVER)||(LA105_4 >= KW_SETS && LA105_4 <= KW_SKEWED)||LA105_4==KW_SNAPSHOT||(LA105_4 >= KW_SORT && LA105_4 <= KW_SSL)||(LA105_4 >= KW_STATISTICS && LA105_4 <= KW_SUMMARY)||(LA105_4 >= KW_SYSTEM_TIME && LA105_4 <= KW_SYSTEM_VERSION)||LA105_4==KW_TABLES||(LA105_4 >= KW_TBLPROPERTIES && LA105_4 <= KW_TERMINATED)||LA105_4==KW_TINYINT||LA105_4==KW_TOUCH||(LA105_4 >= KW_TRANSACTION && LA105_4 <= KW_TRANSACTIONS)||LA105_4==KW_TRIM||(LA105_4 >= KW_TYPE && LA105_4 <= KW_UNARCHIVE)||LA105_4==KW_UNDO||LA105_4==KW_UNIONTYPE||(LA105_4 >= KW_UNKNOWN && LA105_4 <= KW_UNSIGNED)||(LA105_4 >= KW_URI && LA105_4 <= KW_USE)||(LA105_4 >= KW_UTC && LA105_4 <= KW_VALIDATE)||LA105_4==KW_VALUE_TYPE||(LA105_4 >= KW_VECTORIZATION && LA105_4 <= KW_WEEK)||LA105_4==KW_WHILE||(LA105_4 >= KW_WITHIN && LA105_4 <= KW_ZONE)||LA105_4==KW_BATCH||LA105_4==KW_DAYOFWEEK||LA105_4==KW_HOLD_DDLTIME||LA105_4==KW_NO_DROP||LA105_4==KW_OFFLINE||LA105_4==KW_PROTECTION||LA105_4==KW_READONLY||LA105_4==KW_TIMESTAMPTZ) ) {
										alt105=1;
									}
									}
									break;
								case KW_LIMIT:
									{
									int LA105_5 = input.LA(2);
									if ( (LA105_5==EOF||LA105_5==DOT||LA105_5==Identifier||(LA105_5 >= KW_ABORT && LA105_5 <= KW_AFTER)||LA105_5==KW_ALLOC_FRACTION||LA105_5==KW_ANALYZE||LA105_5==KW_ARCHIVE||(LA105_5 >= KW_ASC && LA105_5 <= KW_AT)||(LA105_5 >= KW_AUTOCOMMIT && LA105_5 <= KW_BEFORE)||(LA105_5 >= KW_BUCKET && LA105_5 <= KW_BUCKETS)||(LA105_5 >= KW_CACHE && LA105_5 <= KW_CASCADE)||(LA105_5 >= KW_CBO && LA105_5 <= KW_CHANGE)||(LA105_5 >= KW_CHECK && LA105_5 <= KW_COLLECTION)||(LA105_5 >= KW_COLUMNS && LA105_5 <= KW_COMMENT)||(LA105_5 >= KW_COMPACT && LA105_5 <= KW_CONCATENATE)||(LA105_5 >= KW_CONTINUE && LA105_5 <= KW_COST)||LA105_5==KW_CRON||LA105_5==KW_DATA||LA105_5==KW_DATABASES||(LA105_5 >= KW_DATETIME && LA105_5 <= KW_DCPROPERTIES)||LA105_5==KW_DEBUG||(LA105_5 >= KW_DEFAULT && LA105_5 <= KW_DEFINED)||(LA105_5 >= KW_DELIMITED && LA105_5 <= KW_DESC)||(LA105_5 >= KW_DETAIL && LA105_5 <= KW_DISABLE)||(LA105_5 >= KW_DISTRIBUTE && LA105_5 <= KW_DO)||LA105_5==KW_DOW||(LA105_5 >= KW_DUMP && LA105_5 <= KW_ELEM_TYPE)||LA105_5==KW_ENABLE||(LA105_5 >= KW_ENFORCED && LA105_5 <= KW_EVERY)||(LA105_5 >= KW_EXCLUSIVE && LA105_5 <= KW_EXECUTED)||(LA105_5 >= KW_EXPIRE_SNAPSHOTS && LA105_5 <= KW_EXPRESSION)||(LA105_5 >= KW_FIELDS && LA105_5 <= KW_FIRST)||(LA105_5 >= KW_FORMAT && LA105_5 <= KW_FORMATTED)||LA105_5==KW_FUNCTIONS||(LA105_5 >= KW_HOUR && LA105_5 <= KW_IDXPROPERTIES)||LA105_5==KW_IGNORE||(LA105_5 >= KW_INDEX && LA105_5 <= KW_INDEXES)||(LA105_5 >= KW_INPATH && LA105_5 <= KW_INPUTFORMAT)||(LA105_5 >= KW_ISOLATION && LA105_5 <= KW_JAR)||(LA105_5 >= KW_JOINCOST && LA105_5 <= KW_LAST)||LA105_5==KW_LEVEL||(LA105_5 >= KW_LIMIT && LA105_5 <= KW_LOAD)||(LA105_5 >= KW_LOCATION && LA105_5 <= KW_LONG)||(LA105_5 >= KW_MANAGED && LA105_5 <= KW_MANAGEMENT)||(LA105_5 >= KW_MAPJOIN && LA105_5 <= KW_MATERIALIZED)||LA105_5==KW_METADATA||(LA105_5 >= KW_MINUTE && LA105_5 <= KW_MONTH)||(LA105_5 >= KW_MOVE && LA105_5 <= KW_MSCK)||(LA105_5 >= KW_NORELY && LA105_5 <= KW_NOSCAN)||LA105_5==KW_NOVALIDATE||LA105_5==KW_NULLS||LA105_5==KW_OFFSET||(LA105_5 >= KW_OPERATOR && LA105_5 <= KW_OPTION)||LA105_5==KW_ORDER||(LA105_5 >= KW_OUTPUTDRIVER && LA105_5 <= KW_OUTPUTFORMAT)||(LA105_5 >= KW_OVERWRITE && LA105_5 <= KW_PATH)||(LA105_5 >= KW_PLAN && LA105_5 <= KW_POOL)||LA105_5==KW_PRINCIPALS||LA105_5==KW_PURGE||(LA105_5 >= KW_QUARTER && LA105_5 <= KW_QUERY_PARALLELISM)||LA105_5==KW_READ||(LA105_5 >= KW_REBUILD && LA105_5 <= KW_RECORDWRITER)||(LA105_5 >= KW_RELOAD && LA105_5 <= KW_RESTRICT)||LA105_5==KW_REWRITE||(LA105_5 >= KW_ROLE && LA105_5 <= KW_ROLES)||(LA105_5 >= KW_SCHEDULED && LA105_5 <= KW_SECOND)||(LA105_5 >= KW_SEMI && LA105_5 <= KW_SERVER)||(LA105_5 >= KW_SETS && LA105_5 <= KW_SKEWED)||LA105_5==KW_SNAPSHOT||(LA105_5 >= KW_SORT && LA105_5 <= KW_SSL)||(LA105_5 >= KW_STATISTICS && LA105_5 <= KW_SUMMARY)||(LA105_5 >= KW_SYSTEM_TIME && LA105_5 <= KW_SYSTEM_VERSION)||LA105_5==KW_TABLES||(LA105_5 >= KW_TBLPROPERTIES && LA105_5 <= KW_TERMINATED)||LA105_5==KW_TINYINT||LA105_5==KW_TOUCH||(LA105_5 >= KW_TRANSACTION && LA105_5 <= KW_TRANSACTIONS)||LA105_5==KW_TRIM||(LA105_5 >= KW_TYPE && LA105_5 <= KW_UNARCHIVE)||LA105_5==KW_UNDO||LA105_5==KW_UNIONTYPE||(LA105_5 >= KW_UNKNOWN && LA105_5 <= KW_UNSIGNED)||(LA105_5 >= KW_URI && LA105_5 <= KW_USE)||(LA105_5 >= KW_UTC && LA105_5 <= KW_VALIDATE)||LA105_5==KW_VALUE_TYPE||(LA105_5 >= KW_VECTORIZATION && LA105_5 <= KW_WEEK)||LA105_5==KW_WHILE||(LA105_5 >= KW_WITHIN && LA105_5 <= KW_ZONE)||LA105_5==KW_BATCH||LA105_5==KW_DAYOFWEEK||LA105_5==KW_HOLD_DDLTIME||LA105_5==KW_NO_DROP||LA105_5==KW_OFFLINE||LA105_5==KW_PROTECTION||LA105_5==KW_READONLY||LA105_5==KW_TIMESTAMPTZ) ) {
										alt105=1;
									}
									}
									break;
							}
							switch (alt105) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:8: parttype= partTypeExpr
									{
									pushFollow(FOLLOW_partTypeExpr_in_showStatement5792);
									parttype=partTypeExpr();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_partTypeExpr.add(parttype.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:32: ( compactionPool )?
							int alt106=2;
							int LA106_0 = input.LA(1);
							if ( (LA106_0==KW_POOL) ) {
								alt106=1;
							}
							switch (alt106) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:32: compactionPool
									{
									pushFollow(FOLLOW_compactionPool_in_showStatement5796);
									compactionPool303=compactionPool();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_compactionPool.add(compactionPool303.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:48: ( compactionType )?
							int alt107=2;
							int LA107_0 = input.LA(1);
							if ( (LA107_0==KW_TYPE) ) {
								alt107=1;
							}
							switch (alt107) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:48: compactionType
									{
									pushFollow(FOLLOW_compactionType_in_showStatement5799);
									compactionType304=compactionType();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_compactionType.add(compactionType304.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:64: ( compactionStatus )?
							int alt108=2;
							int LA108_0 = input.LA(1);
							if ( (LA108_0==KW_STATUS) ) {
								alt108=1;
							}
							switch (alt108) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:64: compactionStatus
									{
									pushFollow(FOLLOW_compactionStatus_in_showStatement5802);
									compactionStatus305=compactionStatus();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_compactionStatus.add(compactionStatus305.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:82: ( orderByClause )?
							int alt109=2;
							int LA109_0 = input.LA(1);
							if ( (LA109_0==KW_ORDER) ) {
								alt109=1;
							}
							switch (alt109) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:82: orderByClause
									{
									pushFollow(FOLLOW_orderByClause_in_showStatement5805);
									orderByClause306=orderByClause();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause306.getTree());
									}
									break;

							}

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:97: ( limitClause )?
							int alt110=2;
							int LA110_0 = input.LA(1);
							if ( (LA110_0==KW_LIMIT) ) {
								alt110=1;
							}
							switch (alt110) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:97: limitClause
									{
									pushFollow(FOLLOW_limitClause_in_showStatement5808);
									limitClause307=limitClause();
									state._fsp--;
									if (state.failed) return retval;
									if ( state.backtracking==0 ) stream_limitClause.add(limitClause307.getTree());
									}
									break;

							}

							// AST REWRITE
							// elements: parttype, compactionType, limitClause, compactionStatus, compactionPool, orderByClause
							// token labels: 
							// rule labels: parttype, retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.getTree():null);
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1353:110: -> ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:113: ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_COMPACTIONS, "TOK_SHOW_COMPACTIONS"), root_1);
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:137: ( $parttype)?
								if ( stream_parttype.hasNext() ) {
									adaptor.addChild(root_1, stream_parttype.nextTree());
								}
								stream_parttype.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:147: ( compactionPool )?
								if ( stream_compactionPool.hasNext() ) {
									adaptor.addChild(root_1, stream_compactionPool.nextTree());
								}
								stream_compactionPool.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:163: ( compactionType )?
								if ( stream_compactionType.hasNext() ) {
									adaptor.addChild(root_1, stream_compactionType.nextTree());
								}
								stream_compactionType.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:179: ( compactionStatus )?
								if ( stream_compactionStatus.hasNext() ) {
									adaptor.addChild(root_1, stream_compactionStatus.nextTree());
								}
								stream_compactionStatus.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:197: ( orderByClause )?
								if ( stream_orderByClause.hasNext() ) {
									adaptor.addChild(root_1, stream_orderByClause.nextTree());
								}
								stream_orderByClause.reset();

								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:212: ( limitClause )?
								if ( stream_limitClause.hasNext() ) {
									adaptor.addChild(root_1, stream_limitClause.nextTree());
								}
								stream_limitClause.reset();

								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}
							break;

					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1355:7: KW_SHOW KW_TRANSACTIONS
					{
					KW_SHOW308=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5850); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW308);

					KW_TRANSACTIONS309=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_showStatement5852); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS309);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1355:31: -> ^( TOK_SHOW_TRANSACTIONS )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1355:34: ^( TOK_SHOW_TRANSACTIONS )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_TRANSACTIONS, "TOK_SHOW_TRANSACTIONS"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1356:7: KW_SHOW KW_CONF StringLiteral
					{
					KW_SHOW310=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5866); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW310);

					KW_CONF311=(Token)match(input,KW_CONF,FOLLOW_KW_CONF_in_showStatement5868); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONF.add(KW_CONF311);

					StringLiteral312=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement5870); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral312);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1356:37: -> ^( TOK_SHOWCONF StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1356:40: ^( TOK_SHOWCONF StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWCONF, "TOK_SHOWCONF"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1357:7: KW_SHOW KW_RESOURCE ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) )
					{
					KW_SHOW313=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5886); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW313);

					KW_RESOURCE314=(Token)match(input,KW_RESOURCE,FOLLOW_KW_RESOURCE_in_showStatement5888); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RESOURCE.add(KW_RESOURCE314);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:7: ( ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) ) | ( KW_PLANS -> ^( TOK_SHOW_RP ) ) )
					int alt112=2;
					int LA112_0 = input.LA(1);
					if ( (LA112_0==KW_PLAN) ) {
						alt112=1;
					}
					else if ( (LA112_0==KW_PLANS) ) {
						alt112=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 112, 0, input);
						throw nvae;
					}

					switch (alt112) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:9: ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:9: ( KW_PLAN rp_name= identifier -> ^( TOK_SHOW_RP $rp_name) )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:10: KW_PLAN rp_name= identifier
							{
							KW_PLAN315=(Token)match(input,KW_PLAN,FOLLOW_KW_PLAN_in_showStatement5907); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PLAN.add(KW_PLAN315);

							pushFollow(FOLLOW_identifier_in_showStatement5911);
							rp_name=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(rp_name.getTree());
							// AST REWRITE
							// elements: rp_name
							// token labels: 
							// rule labels: retval, rp_name
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
							RewriteRuleSubtreeStream stream_rp_name=new RewriteRuleSubtreeStream(adaptor,"rule rp_name",rp_name!=null?rp_name.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1359:37: -> ^( TOK_SHOW_RP $rp_name)
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1359:40: ^( TOK_SHOW_RP $rp_name)
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_RP, "TOK_SHOW_RP"), root_1);
								adaptor.addChild(root_1, stream_rp_name.nextTree());
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:11: ( KW_PLANS -> ^( TOK_SHOW_RP ) )
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:11: ( KW_PLANS -> ^( TOK_SHOW_RP ) )
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:12: KW_PLANS
							{
							KW_PLANS316=(Token)match(input,KW_PLANS,FOLLOW_KW_PLANS_in_showStatement5934); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PLANS.add(KW_PLANS316);

							// AST REWRITE
							// elements: 
							// token labels: 
							// rule labels: retval
							// token list labels: 
							// rule list labels: 
							// wildcard labels: 
							if ( state.backtracking==0 ) {
							retval.tree = root_0;
							RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

							root_0 = (ASTNode)adaptor.nil();
							// 1360:21: -> ^( TOK_SHOW_RP )
							{
								// org/apache/hadoop/hive/ql/parse/HiveParser.g:1360:24: ^( TOK_SHOW_RP )
								{
								ASTNode root_1 = (ASTNode)adaptor.nil();
								root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_RP, "TOK_SHOW_RP"), root_1);
								adaptor.addChild(root_0, root_1);
								}

							}


							retval.tree = root_0;
							}

							}

							}
							break;

					}

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:7: KW_SHOW ( KW_DATACONNECTORS )
					{
					KW_SHOW317=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement5957); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW317);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:15: ( KW_DATACONNECTORS )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:16: KW_DATACONNECTORS
					{
					KW_DATACONNECTORS318=(Token)match(input,KW_DATACONNECTORS,FOLLOW_KW_DATACONNECTORS_in_showStatement5960); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATACONNECTORS.add(KW_DATACONNECTORS318);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1362:35: -> ^( TOK_SHOWDATACONNECTORS )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1362:38: ^( TOK_SHOWDATACONNECTORS )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOWDATACONNECTORS, "TOK_SHOWDATACONNECTORS"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showStatement"


	public static class showTablesFilterExpr_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showTablesFilterExpr"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1365:1: showTablesFilterExpr : ( KW_WHERE identifier EQUAL StringLiteral -> ^( TOK_TABLE_TYPE identifier StringLiteral ) | KW_LIKE showStmtIdentifier | showStmtIdentifier -> showStmtIdentifier );
	public final HiveParser.showTablesFilterExpr_return showTablesFilterExpr() throws RecognitionException {
		HiveParser.showTablesFilterExpr_return retval = new HiveParser.showTablesFilterExpr_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHERE319=null;
		Token EQUAL321=null;
		Token StringLiteral322=null;
		Token KW_LIKE323=null;
		ParserRuleReturnScope identifier320 =null;
		ParserRuleReturnScope showStmtIdentifier324 =null;
		ParserRuleReturnScope showStmtIdentifier325 =null;

		ASTNode KW_WHERE319_tree=null;
		ASTNode EQUAL321_tree=null;
		ASTNode StringLiteral322_tree=null;
		ASTNode KW_LIKE323_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
		RewriteRuleTokenStream stream_KW_WHERE=new RewriteRuleTokenStream(adaptor,"token KW_WHERE");
		RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("show tables filter expr", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:5: ( KW_WHERE identifier EQUAL StringLiteral -> ^( TOK_TABLE_TYPE identifier StringLiteral ) | KW_LIKE showStmtIdentifier | showStmtIdentifier -> showStmtIdentifier )
			int alt114=3;
			switch ( input.LA(1) ) {
			case KW_WHERE:
				{
				alt114=1;
				}
				break;
			case KW_LIKE:
				{
				alt114=2;
				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AST:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DCPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPIRE_SNAPSHOTS:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_ID:
			case KW_IDXPROPERTIES:
			case KW_IGNORE:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGED:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_REMOTE:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESPECT:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SPEC:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_SYSTEM_TIME:
			case KW_SYSTEM_VERSION:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_TRIM:
			case KW_TYPE:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNKNOWN:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_URL:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WITHIN:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case StringLiteral:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt114=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 114, 0, input);
				throw nvae;
			}
			switch (alt114) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:7: KW_WHERE identifier EQUAL StringLiteral
					{
					KW_WHERE319=(Token)match(input,KW_WHERE,FOLLOW_KW_WHERE_in_showTablesFilterExpr5994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WHERE.add(KW_WHERE319);

					pushFollow(FOLLOW_identifier_in_showTablesFilterExpr5996);
					identifier320=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier320.getTree());
					EQUAL321=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_showTablesFilterExpr5998); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL321);

					StringLiteral322=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showTablesFilterExpr6000); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral322);

					// AST REWRITE
					// elements: identifier, StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1369:5: -> ^( TOK_TABLE_TYPE identifier StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:8: ^( TOK_TABLE_TYPE identifier StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:7: KW_LIKE showStmtIdentifier
					{
					root_0 = (ASTNode)adaptor.nil();


					KW_LIKE323=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showTablesFilterExpr6022); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					KW_LIKE323_tree = (ASTNode)adaptor.create(KW_LIKE323);
					adaptor.addChild(root_0, KW_LIKE323_tree);
					}

					pushFollow(FOLLOW_showStmtIdentifier_in_showTablesFilterExpr6024);
					showStmtIdentifier324=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, showStmtIdentifier324.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1370:34: showStmtIdentifier
					{
					pushFollow(FOLLOW_showStmtIdentifier_in_showTablesFilterExpr6026);
					showStmtIdentifier325=showStmtIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_showStmtIdentifier.add(showStmtIdentifier325.getTree());
					// AST REWRITE
					// elements: showStmtIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1371:5: -> showStmtIdentifier
					{
						adaptor.addChild(root_0, stream_showStmtIdentifier.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showTablesFilterExpr"


	public static class lockStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1374:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
	public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
		HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_LOCK326=null;
		Token KW_TABLE327=null;
		ParserRuleReturnScope tableName328 =null;
		ParserRuleReturnScope partitionSpec329 =null;
		ParserRuleReturnScope lockMode330 =null;

		ASTNode KW_LOCK326_tree=null;
		ASTNode KW_TABLE327_tree=null;
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("lock statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
			{
			KW_LOCK326=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockStatement6061); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK326);

			KW_TABLE327=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_lockStatement6063); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE327);

			pushFollow(FOLLOW_tableName_in_lockStatement6065);
			tableName328=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName328.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:34: ( partitionSpec )?
			int alt115=2;
			int LA115_0 = input.LA(1);
			if ( (LA115_0==KW_PARTITION) ) {
				alt115=1;
			}
			switch (alt115) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:34: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_lockStatement6067);
					partitionSpec329=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec329.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_lockMode_in_lockStatement6070);
			lockMode330=lockMode();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_lockMode.add(lockMode330.getTree());
			// AST REWRITE
			// elements: partitionSpec, lockMode, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1377:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_1, stream_lockMode.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1377:96: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockStatement"


	public static class lockDatabase_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockDatabase"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1380:1: lockDatabase : KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) ;
	public final HiveParser.lockDatabase_return lockDatabase() throws RecognitionException {
		HiveParser.lockDatabase_return retval = new HiveParser.lockDatabase_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_LOCK331=null;
		Token KW_DATABASE332=null;
		Token KW_SCHEMA333=null;
		ParserRuleReturnScope dbName =null;
		ParserRuleReturnScope lockMode334 =null;

		ASTNode KW_LOCK331_tree=null;
		ASTNode KW_DATABASE332_tree=null;
		ASTNode KW_SCHEMA333_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");

		 pushMsg("lock database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:5: ( KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode -> ^( TOK_LOCKDB $dbName lockMode ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:7: KW_LOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) lockMode
			{
			KW_LOCK331=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockDatabase6110); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK331);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:15: ( KW_DATABASE | KW_SCHEMA )
			int alt116=2;
			int LA116_0 = input.LA(1);
			if ( (LA116_0==KW_DATABASE) ) {
				alt116=1;
			}
			else if ( (LA116_0==KW_SCHEMA) ) {
				alt116=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 116, 0, input);
				throw nvae;
			}

			switch (alt116) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:16: KW_DATABASE
					{
					KW_DATABASE332=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_lockDatabase6113); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE332);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:28: KW_SCHEMA
					{
					KW_SCHEMA333=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_lockDatabase6115); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA333);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:39: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:40: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_lockDatabase6121);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			pushFollow(FOLLOW_lockMode_in_lockDatabase6124);
			lockMode334=lockMode();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_lockMode.add(lockMode334.getTree());
			// AST REWRITE
			// elements: dbName, lockMode
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1383:68: -> ^( TOK_LOCKDB $dbName lockMode )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:71: ^( TOK_LOCKDB $dbName lockMode )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LOCKDB, "TOK_LOCKDB"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_1, stream_lockMode.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockDatabase"


	public static class lockMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "lockMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
	public final HiveParser.lockMode_return lockMode() throws RecognitionException {
		HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token set335=null;

		ASTNode set335_tree=null;

		 pushMsg("lock mode", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:5: ( KW_SHARED | KW_EXCLUSIVE )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:
			{
			root_0 = (ASTNode)adaptor.nil();


			set335=input.LT(1);
			if ( input.LA(1)==KW_EXCLUSIVE||input.LA(1)==KW_SHARED ) {
				input.consume();
				if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set335));
				state.errorRecovery=false;
				state.failed=false;
			}
			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				MismatchedSetException mse = new MismatchedSetException(null,input);
				throw mse;
			}
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "lockMode"


	public static class unlockStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unlockStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1392:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
	public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
		HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNLOCK336=null;
		Token KW_TABLE337=null;
		ParserRuleReturnScope tableName338 =null;
		ParserRuleReturnScope partitionSpec339 =null;

		ASTNode KW_UNLOCK336_tree=null;
		ASTNode KW_TABLE337_tree=null;
		RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("unlock statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
			{
			KW_UNLOCK336=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockStatement6193); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK336);

			KW_TABLE337=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_unlockStatement6195); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE337);

			pushFollow(FOLLOW_tableName_in_unlockStatement6197);
			tableName338=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName338.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:36: ( partitionSpec )?
			int alt117=2;
			int LA117_0 = input.LA(1);
			if ( (LA117_0==KW_PARTITION) ) {
				alt117=1;
			}
			switch (alt117) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:36: partitionSpec
					{
					pushFollow(FOLLOW_partitionSpec_in_unlockStatement6199);
					partitionSpec339=partitionSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec339.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableName, partitionSpec
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1395:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1395:83: ( partitionSpec )?
				if ( stream_partitionSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSpec.nextTree());
				}
				stream_partitionSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unlockStatement"


	public static class unlockDatabase_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unlockDatabase"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1398:1: unlockDatabase : KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) -> ^( TOK_UNLOCKDB $dbName) ;
	public final HiveParser.unlockDatabase_return unlockDatabase() throws RecognitionException {
		HiveParser.unlockDatabase_return retval = new HiveParser.unlockDatabase_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNLOCK340=null;
		Token KW_DATABASE341=null;
		Token KW_SCHEMA342=null;
		ParserRuleReturnScope dbName =null;

		ASTNode KW_UNLOCK340_tree=null;
		ASTNode KW_DATABASE341_tree=null;
		ASTNode KW_SCHEMA342_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("unlock database statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:5: ( KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) -> ^( TOK_UNLOCKDB $dbName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:7: KW_UNLOCK ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier )
			{
			KW_UNLOCK340=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockDatabase6239); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNLOCK.add(KW_UNLOCK340);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:17: ( KW_DATABASE | KW_SCHEMA )
			int alt118=2;
			int LA118_0 = input.LA(1);
			if ( (LA118_0==KW_DATABASE) ) {
				alt118=1;
			}
			else if ( (LA118_0==KW_SCHEMA) ) {
				alt118=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 118, 0, input);
				throw nvae;
			}

			switch (alt118) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:18: KW_DATABASE
					{
					KW_DATABASE341=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_unlockDatabase6242); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE341);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:30: KW_SCHEMA
					{
					KW_SCHEMA342=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_unlockDatabase6244); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA342);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:41: (dbName= identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:42: dbName= identifier
			{
			pushFollow(FOLLOW_identifier_in_unlockDatabase6250);
			dbName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(dbName.getTree());
			}

			// AST REWRITE
			// elements: dbName
			// token labels: 
			// rule labels: dbName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1401:61: -> ^( TOK_UNLOCKDB $dbName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1401:64: ^( TOK_UNLOCKDB $dbName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNLOCKDB, "TOK_UNLOCKDB"), root_1);
				adaptor.addChild(root_1, stream_dbName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unlockDatabase"


	public static class createRoleStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createRoleStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
	public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
		HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE343=null;
		Token KW_ROLE344=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_CREATE343_tree=null;
		ASTNode KW_ROLE344_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("create role", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1407:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1407:7: KW_CREATE KW_ROLE roleName= identifier
			{
			KW_CREATE343=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createRoleStatement6287); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE343);

			KW_ROLE344=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_createRoleStatement6289); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE344);

			pushFollow(FOLLOW_identifier_in_createRoleStatement6293);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1408:5: -> ^( TOK_CREATEROLE $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:8: ^( TOK_CREATEROLE $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createRoleStatement"


	public static class dropRoleStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropRoleStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
	public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
		HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP345=null;
		Token KW_ROLE346=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_DROP345_tree=null;
		ASTNode KW_ROLE346_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("drop role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1414:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1414:7: KW_DROP KW_ROLE roleName= identifier
			{
			KW_DROP345=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropRoleStatement6333); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP345);

			KW_ROLE346=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_dropRoleStatement6335); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE346);

			pushFollow(FOLLOW_identifier_in_dropRoleStatement6339);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1415:5: -> ^( TOK_DROPROLE $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:8: ^( TOK_DROPROLE $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPROLE, "TOK_DROPROLE"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropRoleStatement"


	public static class grantPrivileges_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantPrivileges"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1418:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) ;
	public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
		HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT347=null;
		Token KW_TO349=null;
		ParserRuleReturnScope privList =null;
		ParserRuleReturnScope privilegeObject348 =null;
		ParserRuleReturnScope principalSpecification350 =null;
		ParserRuleReturnScope withGrantOption351 =null;

		ASTNode KW_GRANT347_tree=null;
		ASTNode KW_TO349_tree=null;
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleSubtreeStream stream_withGrantOption=new RewriteRuleSubtreeStream(adaptor,"rule withGrantOption");
		RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
		RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("grant privileges", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( withGrantOption )?
			{
			KW_GRANT347=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantPrivileges6379); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT347);

			pushFollow(FOLLOW_privilegeList_in_grantPrivileges6383);
			privList=privilegeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeList.add(privList.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:7: ( privilegeObject )?
			int alt119=2;
			int LA119_0 = input.LA(1);
			if ( (LA119_0==KW_ON) ) {
				alt119=1;
			}
			switch (alt119) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:7: privilegeObject
					{
					pushFollow(FOLLOW_privilegeObject_in_grantPrivileges6391);
					privilegeObject348=privilegeObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject348.getTree());
					}
					break;

			}

			KW_TO349=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantPrivileges6400); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO349);

			pushFollow(FOLLOW_principalSpecification_in_grantPrivileges6402);
			principalSpecification350=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification350.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:7: ( withGrantOption )?
			int alt120=2;
			int LA120_0 = input.LA(1);
			if ( (LA120_0==KW_WITH) ) {
				alt120=1;
			}
			switch (alt120) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1424:7: withGrantOption
					{
					pushFollow(FOLLOW_withGrantOption_in_grantPrivileges6410);
					withGrantOption351=withGrantOption();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withGrantOption.add(withGrantOption351.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: privList, withGrantOption, principalSpecification, privilegeObject
			// token labels: 
			// rule labels: privList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_privList=new RewriteRuleSubtreeStream(adaptor,"rule privList",privList!=null?privList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1425:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withGrantOption )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT, "TOK_GRANT"), root_1);
				adaptor.addChild(root_1, stream_privList.nextTree());
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:53: ( privilegeObject )?
				if ( stream_privilegeObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeObject.nextTree());
				}
				stream_privilegeObject.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:70: ( withGrantOption )?
				if ( stream_withGrantOption.hasNext() ) {
					adaptor.addChild(root_1, stream_withGrantOption.nextTree());
				}
				stream_withGrantOption.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantPrivileges"


	public static class revokePrivileges_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "revokePrivileges"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:1: revokePrivileges : KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) ;
	public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
		HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REVOKE352=null;
		Token KW_FROM356=null;
		ParserRuleReturnScope grantOptionFor353 =null;
		ParserRuleReturnScope privilegeList354 =null;
		ParserRuleReturnScope privilegeObject355 =null;
		ParserRuleReturnScope principalSpecification357 =null;

		ASTNode KW_REVOKE352_tree=null;
		ASTNode KW_FROM356_tree=null;
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
		RewriteRuleSubtreeStream stream_grantOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule grantOptionFor");
		RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
		RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("revoke privileges", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:5: ( KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:7: KW_REVOKE ( grantOptionFor )? privilegeList ( privilegeObject )? KW_FROM principalSpecification
			{
			KW_REVOKE352=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokePrivileges6459); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE352);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:17: ( grantOptionFor )?
			int alt121=2;
			int LA121_0 = input.LA(1);
			if ( (LA121_0==KW_GRANT) ) {
				alt121=1;
			}
			switch (alt121) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:17: grantOptionFor
					{
					pushFollow(FOLLOW_grantOptionFor_in_revokePrivileges6461);
					grantOptionFor353=grantOptionFor();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_grantOptionFor.add(grantOptionFor353.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_privilegeList_in_revokePrivileges6464);
			privilegeList354=privilegeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeList.add(privilegeList354.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:47: ( privilegeObject )?
			int alt122=2;
			int LA122_0 = input.LA(1);
			if ( (LA122_0==KW_ON) ) {
				alt122=1;
			}
			switch (alt122) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1431:47: privilegeObject
					{
					pushFollow(FOLLOW_privilegeObject_in_revokePrivileges6466);
					privilegeObject355=privilegeObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeObject.add(privilegeObject355.getTree());
					}
					break;

			}

			KW_FROM356=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokePrivileges6469); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM356);

			pushFollow(FOLLOW_principalSpecification_in_revokePrivileges6471);
			principalSpecification357=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification357.getTree());
			// AST REWRITE
			// elements: grantOptionFor, principalSpecification, privilegeList, privilegeObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1432:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ( grantOptionFor )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REVOKE, "TOK_REVOKE"), root_1);
				adaptor.addChild(root_1, stream_privilegeList.nextTree());
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:58: ( privilegeObject )?
				if ( stream_privilegeObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeObject.nextTree());
				}
				stream_privilegeObject.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1432:75: ( grantOptionFor )?
				if ( stream_grantOptionFor.hasNext() ) {
					adaptor.addChild(root_1, stream_grantOptionFor.nextTree());
				}
				stream_grantOptionFor.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "revokePrivileges"


	public static class grantRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:1: grantRole : KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) ;
	public final HiveParser.grantRole_return grantRole() throws RecognitionException {
		HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT358=null;
		Token KW_ROLE359=null;
		Token COMMA361=null;
		Token KW_TO363=null;
		ParserRuleReturnScope identifier360 =null;
		ParserRuleReturnScope identifier362 =null;
		ParserRuleReturnScope principalSpecification364 =null;
		ParserRuleReturnScope withAdminOption365 =null;

		ASTNode KW_GRANT358_tree=null;
		ASTNode KW_ROLE359_tree=null;
		ASTNode COMMA361_tree=null;
		ASTNode KW_TO363_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_withAdminOption=new RewriteRuleSubtreeStream(adaptor,"rule withAdminOption");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("grant role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:5: ( KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )? -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:7: KW_GRANT ( KW_ROLE )? identifier ( COMMA identifier )* KW_TO principalSpecification ( withAdminOption )?
			{
			KW_GRANT358=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantRole6518); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT358);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:16: ( KW_ROLE )?
			int alt123=2;
			int LA123_0 = input.LA(1);
			if ( (LA123_0==KW_ROLE) ) {
				int LA123_1 = input.LA(2);
				if ( (LA123_1==Identifier||(LA123_1 >= KW_ABORT && LA123_1 <= KW_AFTER)||LA123_1==KW_ALLOC_FRACTION||LA123_1==KW_ANALYZE||LA123_1==KW_ARCHIVE||(LA123_1 >= KW_ASC && LA123_1 <= KW_AT)||(LA123_1 >= KW_AUTOCOMMIT && LA123_1 <= KW_BEFORE)||(LA123_1 >= KW_BUCKET && LA123_1 <= KW_BUCKETS)||(LA123_1 >= KW_CACHE && LA123_1 <= KW_CASCADE)||(LA123_1 >= KW_CBO && LA123_1 <= KW_CHANGE)||(LA123_1 >= KW_CHECK && LA123_1 <= KW_COLLECTION)||(LA123_1 >= KW_COLUMNS && LA123_1 <= KW_COMMENT)||(LA123_1 >= KW_COMPACT && LA123_1 <= KW_CONCATENATE)||(LA123_1 >= KW_CONTINUE && LA123_1 <= KW_COST)||LA123_1==KW_CRON||LA123_1==KW_DATA||LA123_1==KW_DATABASES||(LA123_1 >= KW_DATETIME && LA123_1 <= KW_DCPROPERTIES)||LA123_1==KW_DEBUG||(LA123_1 >= KW_DEFAULT && LA123_1 <= KW_DEFINED)||(LA123_1 >= KW_DELIMITED && LA123_1 <= KW_DESC)||(LA123_1 >= KW_DETAIL && LA123_1 <= KW_DISABLE)||(LA123_1 >= KW_DISTRIBUTE && LA123_1 <= KW_DO)||LA123_1==KW_DOW||(LA123_1 >= KW_DUMP && LA123_1 <= KW_ELEM_TYPE)||LA123_1==KW_ENABLE||(LA123_1 >= KW_ENFORCED && LA123_1 <= KW_EVERY)||(LA123_1 >= KW_EXCLUSIVE && LA123_1 <= KW_EXECUTED)||(LA123_1 >= KW_EXPIRE_SNAPSHOTS && LA123_1 <= KW_EXPRESSION)||(LA123_1 >= KW_FIELDS && LA123_1 <= KW_FIRST)||(LA123_1 >= KW_FORMAT && LA123_1 <= KW_FORMATTED)||LA123_1==KW_FUNCTIONS||(LA123_1 >= KW_HOUR && LA123_1 <= KW_IDXPROPERTIES)||LA123_1==KW_IGNORE||(LA123_1 >= KW_INDEX && LA123_1 <= KW_INDEXES)||(LA123_1 >= KW_INPATH && LA123_1 <= KW_INPUTFORMAT)||(LA123_1 >= KW_ISOLATION && LA123_1 <= KW_JAR)||(LA123_1 >= KW_JOINCOST && LA123_1 <= KW_LAST)||LA123_1==KW_LEVEL||(LA123_1 >= KW_LIMIT && LA123_1 <= KW_LOAD)||(LA123_1 >= KW_LOCATION && LA123_1 <= KW_LONG)||(LA123_1 >= KW_MANAGED && LA123_1 <= KW_MANAGEMENT)||(LA123_1 >= KW_MAPJOIN && LA123_1 <= KW_MATERIALIZED)||LA123_1==KW_METADATA||(LA123_1 >= KW_MINUTE && LA123_1 <= KW_MONTH)||(LA123_1 >= KW_MOVE && LA123_1 <= KW_MSCK)||(LA123_1 >= KW_NORELY && LA123_1 <= KW_NOSCAN)||LA123_1==KW_NOVALIDATE||LA123_1==KW_NULLS||LA123_1==KW_OFFSET||(LA123_1 >= KW_OPERATOR && LA123_1 <= KW_OPTION)||(LA123_1 >= KW_OUTPUTDRIVER && LA123_1 <= KW_OUTPUTFORMAT)||(LA123_1 >= KW_OVERWRITE && LA123_1 <= KW_OWNER)||(LA123_1 >= KW_PARTITIONED && LA123_1 <= KW_PATH)||(LA123_1 >= KW_PLAN && LA123_1 <= KW_POOL)||LA123_1==KW_PRINCIPALS||LA123_1==KW_PURGE||(LA123_1 >= KW_QUARTER && LA123_1 <= KW_QUERY_PARALLELISM)||LA123_1==KW_READ||(LA123_1 >= KW_REBUILD && LA123_1 <= KW_RECORDWRITER)||(LA123_1 >= KW_RELOAD && LA123_1 <= KW_RESTRICT)||LA123_1==KW_REWRITE||(LA123_1 >= KW_ROLE && LA123_1 <= KW_ROLES)||(LA123_1 >= KW_SCHEDULED && LA123_1 <= KW_SECOND)||(LA123_1 >= KW_SEMI && LA123_1 <= KW_SERVER)||(LA123_1 >= KW_SETS && LA123_1 <= KW_SKEWED)||LA123_1==KW_SNAPSHOT||(LA123_1 >= KW_SORT && LA123_1 <= KW_SSL)||(LA123_1 >= KW_STATISTICS && LA123_1 <= KW_SUMMARY)||(LA123_1 >= KW_SYSTEM_TIME && LA123_1 <= KW_SYSTEM_VERSION)||LA123_1==KW_TABLES||(LA123_1 >= KW_TBLPROPERTIES && LA123_1 <= KW_TERMINATED)||LA123_1==KW_TINYINT||LA123_1==KW_TOUCH||(LA123_1 >= KW_TRANSACTION && LA123_1 <= KW_TRANSACTIONS)||LA123_1==KW_TRIM||(LA123_1 >= KW_TYPE && LA123_1 <= KW_UNARCHIVE)||LA123_1==KW_UNDO||LA123_1==KW_UNIONTYPE||(LA123_1 >= KW_UNKNOWN && LA123_1 <= KW_UNSIGNED)||(LA123_1 >= KW_URI && LA123_1 <= KW_USE)||(LA123_1 >= KW_UTC && LA123_1 <= KW_VALIDATE)||LA123_1==KW_VALUE_TYPE||(LA123_1 >= KW_VECTORIZATION && LA123_1 <= KW_WEEK)||LA123_1==KW_WHILE||(LA123_1 >= KW_WITHIN && LA123_1 <= KW_ZONE)||LA123_1==KW_BATCH||LA123_1==KW_DAYOFWEEK||LA123_1==KW_HOLD_DDLTIME||LA123_1==KW_NO_DROP||LA123_1==KW_OFFLINE||LA123_1==KW_PROTECTION||LA123_1==KW_READONLY||LA123_1==KW_TIMESTAMPTZ) ) {
					alt123=1;
				}
			}
			switch (alt123) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:16: KW_ROLE
					{
					KW_ROLE359=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_grantRole6520); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE359);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_grantRole6523);
			identifier360=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier360.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:36: ( COMMA identifier )*
			loop124:
			while (true) {
				int alt124=2;
				int LA124_0 = input.LA(1);
				if ( (LA124_0==COMMA) ) {
					alt124=1;
				}

				switch (alt124) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:37: COMMA identifier
					{
					COMMA361=(Token)match(input,COMMA,FOLLOW_COMMA_in_grantRole6526); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA361);

					pushFollow(FOLLOW_identifier_in_grantRole6528);
					identifier362=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier362.getTree());
					}
					break;

				default :
					break loop124;
				}
			}

			KW_TO363=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantRole6532); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TO.add(KW_TO363);

			pushFollow(FOLLOW_principalSpecification_in_grantRole6534);
			principalSpecification364=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification364.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:85: ( withAdminOption )?
			int alt125=2;
			int LA125_0 = input.LA(1);
			if ( (LA125_0==KW_WITH) ) {
				alt125=1;
			}
			switch (alt125) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:85: withAdminOption
					{
					pushFollow(FOLLOW_withAdminOption_in_grantRole6536);
					withAdminOption365=withAdminOption();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withAdminOption.add(withAdminOption365.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: identifier, withAdminOption, principalSpecification
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1439:5: -> ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:8: ^( TOK_GRANT_ROLE principalSpecification ( withAdminOption )? ( identifier )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE"), root_1);
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:48: ( withAdminOption )?
				if ( stream_withAdminOption.hasNext() ) {
					adaptor.addChild(root_1, stream_withAdminOption.nextTree());
				}
				stream_withAdminOption.reset();

				if ( !(stream_identifier.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_1, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantRole"


	public static class revokeRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "revokeRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1442:1: revokeRole : KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) ;
	public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
		HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_REVOKE366=null;
		Token KW_ROLE368=null;
		Token COMMA370=null;
		Token KW_FROM372=null;
		ParserRuleReturnScope adminOptionFor367 =null;
		ParserRuleReturnScope identifier369 =null;
		ParserRuleReturnScope identifier371 =null;
		ParserRuleReturnScope principalSpecification373 =null;

		ASTNode KW_REVOKE366_tree=null;
		ASTNode KW_ROLE368_tree=null;
		ASTNode COMMA370_tree=null;
		ASTNode KW_FROM372_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_adminOptionFor=new RewriteRuleSubtreeStream(adaptor,"rule adminOptionFor");
		RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");

		pushMsg("revoke role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:5: ( KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:7: KW_REVOKE ( adminOptionFor )? ( KW_ROLE )? identifier ( COMMA identifier )* KW_FROM principalSpecification
			{
			KW_REVOKE366=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokeRole6582); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REVOKE.add(KW_REVOKE366);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:17: ( adminOptionFor )?
			int alt126=2;
			int LA126_0 = input.LA(1);
			if ( (LA126_0==KW_ADMIN) ) {
				int LA126_1 = input.LA(2);
				if ( (LA126_1==KW_OPTION) ) {
					alt126=1;
				}
			}
			switch (alt126) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:17: adminOptionFor
					{
					pushFollow(FOLLOW_adminOptionFor_in_revokeRole6584);
					adminOptionFor367=adminOptionFor();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_adminOptionFor.add(adminOptionFor367.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:33: ( KW_ROLE )?
			int alt127=2;
			int LA127_0 = input.LA(1);
			if ( (LA127_0==KW_ROLE) ) {
				int LA127_1 = input.LA(2);
				if ( (LA127_1==Identifier||(LA127_1 >= KW_ABORT && LA127_1 <= KW_AFTER)||LA127_1==KW_ALLOC_FRACTION||LA127_1==KW_ANALYZE||LA127_1==KW_ARCHIVE||(LA127_1 >= KW_ASC && LA127_1 <= KW_AT)||(LA127_1 >= KW_AUTOCOMMIT && LA127_1 <= KW_BEFORE)||(LA127_1 >= KW_BUCKET && LA127_1 <= KW_BUCKETS)||(LA127_1 >= KW_CACHE && LA127_1 <= KW_CASCADE)||(LA127_1 >= KW_CBO && LA127_1 <= KW_CHANGE)||(LA127_1 >= KW_CHECK && LA127_1 <= KW_COLLECTION)||(LA127_1 >= KW_COLUMNS && LA127_1 <= KW_COMMENT)||(LA127_1 >= KW_COMPACT && LA127_1 <= KW_CONCATENATE)||(LA127_1 >= KW_CONTINUE && LA127_1 <= KW_COST)||LA127_1==KW_CRON||LA127_1==KW_DATA||LA127_1==KW_DATABASES||(LA127_1 >= KW_DATETIME && LA127_1 <= KW_DCPROPERTIES)||LA127_1==KW_DEBUG||(LA127_1 >= KW_DEFAULT && LA127_1 <= KW_DEFINED)||(LA127_1 >= KW_DELIMITED && LA127_1 <= KW_DESC)||(LA127_1 >= KW_DETAIL && LA127_1 <= KW_DISABLE)||(LA127_1 >= KW_DISTRIBUTE && LA127_1 <= KW_DO)||LA127_1==KW_DOW||(LA127_1 >= KW_DUMP && LA127_1 <= KW_ELEM_TYPE)||LA127_1==KW_ENABLE||(LA127_1 >= KW_ENFORCED && LA127_1 <= KW_EVERY)||(LA127_1 >= KW_EXCLUSIVE && LA127_1 <= KW_EXECUTED)||(LA127_1 >= KW_EXPIRE_SNAPSHOTS && LA127_1 <= KW_EXPRESSION)||(LA127_1 >= KW_FIELDS && LA127_1 <= KW_FIRST)||(LA127_1 >= KW_FORMAT && LA127_1 <= KW_FORMATTED)||LA127_1==KW_FUNCTIONS||(LA127_1 >= KW_HOUR && LA127_1 <= KW_IDXPROPERTIES)||LA127_1==KW_IGNORE||(LA127_1 >= KW_INDEX && LA127_1 <= KW_INDEXES)||(LA127_1 >= KW_INPATH && LA127_1 <= KW_INPUTFORMAT)||(LA127_1 >= KW_ISOLATION && LA127_1 <= KW_JAR)||(LA127_1 >= KW_JOINCOST && LA127_1 <= KW_LAST)||LA127_1==KW_LEVEL||(LA127_1 >= KW_LIMIT && LA127_1 <= KW_LOAD)||(LA127_1 >= KW_LOCATION && LA127_1 <= KW_LONG)||(LA127_1 >= KW_MANAGED && LA127_1 <= KW_MANAGEMENT)||(LA127_1 >= KW_MAPJOIN && LA127_1 <= KW_MATERIALIZED)||LA127_1==KW_METADATA||(LA127_1 >= KW_MINUTE && LA127_1 <= KW_MONTH)||(LA127_1 >= KW_MOVE && LA127_1 <= KW_MSCK)||(LA127_1 >= KW_NORELY && LA127_1 <= KW_NOSCAN)||LA127_1==KW_NOVALIDATE||LA127_1==KW_NULLS||LA127_1==KW_OFFSET||(LA127_1 >= KW_OPERATOR && LA127_1 <= KW_OPTION)||(LA127_1 >= KW_OUTPUTDRIVER && LA127_1 <= KW_OUTPUTFORMAT)||(LA127_1 >= KW_OVERWRITE && LA127_1 <= KW_OWNER)||(LA127_1 >= KW_PARTITIONED && LA127_1 <= KW_PATH)||(LA127_1 >= KW_PLAN && LA127_1 <= KW_POOL)||LA127_1==KW_PRINCIPALS||LA127_1==KW_PURGE||(LA127_1 >= KW_QUARTER && LA127_1 <= KW_QUERY_PARALLELISM)||LA127_1==KW_READ||(LA127_1 >= KW_REBUILD && LA127_1 <= KW_RECORDWRITER)||(LA127_1 >= KW_RELOAD && LA127_1 <= KW_RESTRICT)||LA127_1==KW_REWRITE||(LA127_1 >= KW_ROLE && LA127_1 <= KW_ROLES)||(LA127_1 >= KW_SCHEDULED && LA127_1 <= KW_SECOND)||(LA127_1 >= KW_SEMI && LA127_1 <= KW_SERVER)||(LA127_1 >= KW_SETS && LA127_1 <= KW_SKEWED)||LA127_1==KW_SNAPSHOT||(LA127_1 >= KW_SORT && LA127_1 <= KW_SSL)||(LA127_1 >= KW_STATISTICS && LA127_1 <= KW_SUMMARY)||(LA127_1 >= KW_SYSTEM_TIME && LA127_1 <= KW_SYSTEM_VERSION)||LA127_1==KW_TABLES||(LA127_1 >= KW_TBLPROPERTIES && LA127_1 <= KW_TERMINATED)||LA127_1==KW_TINYINT||LA127_1==KW_TOUCH||(LA127_1 >= KW_TRANSACTION && LA127_1 <= KW_TRANSACTIONS)||LA127_1==KW_TRIM||(LA127_1 >= KW_TYPE && LA127_1 <= KW_UNARCHIVE)||LA127_1==KW_UNDO||LA127_1==KW_UNIONTYPE||(LA127_1 >= KW_UNKNOWN && LA127_1 <= KW_UNSIGNED)||(LA127_1 >= KW_URI && LA127_1 <= KW_USE)||(LA127_1 >= KW_UTC && LA127_1 <= KW_VALIDATE)||LA127_1==KW_VALUE_TYPE||(LA127_1 >= KW_VECTORIZATION && LA127_1 <= KW_WEEK)||LA127_1==KW_WHILE||(LA127_1 >= KW_WITHIN && LA127_1 <= KW_ZONE)||LA127_1==KW_BATCH||LA127_1==KW_DAYOFWEEK||LA127_1==KW_HOLD_DDLTIME||LA127_1==KW_NO_DROP||LA127_1==KW_OFFLINE||LA127_1==KW_PROTECTION||LA127_1==KW_READONLY||LA127_1==KW_TIMESTAMPTZ) ) {
					alt127=1;
				}
			}
			switch (alt127) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:33: KW_ROLE
					{
					KW_ROLE368=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_revokeRole6587); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE368);

					}
					break;

			}

			pushFollow(FOLLOW_identifier_in_revokeRole6590);
			identifier369=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier369.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:53: ( COMMA identifier )*
			loop128:
			while (true) {
				int alt128=2;
				int LA128_0 = input.LA(1);
				if ( (LA128_0==COMMA) ) {
					alt128=1;
				}

				switch (alt128) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:54: COMMA identifier
					{
					COMMA370=(Token)match(input,COMMA,FOLLOW_COMMA_in_revokeRole6593); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA370);

					pushFollow(FOLLOW_identifier_in_revokeRole6595);
					identifier371=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier371.getTree());
					}
					break;

				default :
					break loop128;
				}
			}

			KW_FROM372=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokeRole6599); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM372);

			pushFollow(FOLLOW_principalSpecification_in_revokeRole6601);
			principalSpecification373=principalSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalSpecification.add(principalSpecification373.getTree());
			// AST REWRITE
			// elements: principalSpecification, identifier, adminOptionFor
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1446:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1446:8: ^( TOK_REVOKE_ROLE principalSpecification ( adminOptionFor )? ( identifier )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE"), root_1);
				adaptor.addChild(root_1, stream_principalSpecification.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1446:49: ( adminOptionFor )?
				if ( stream_adminOptionFor.hasNext() ) {
					adaptor.addChild(root_1, stream_adminOptionFor.nextTree());
				}
				stream_adminOptionFor.reset();

				if ( !(stream_identifier.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_1, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "revokeRole"


	public static class showRoleGrants_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRoleGrants"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1449:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
	public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
		HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW374=null;
		Token KW_ROLE375=null;
		Token KW_GRANT376=null;
		ParserRuleReturnScope principalName377 =null;

		ASTNode KW_SHOW374_tree=null;
		ASTNode KW_ROLE375_tree=null;
		ASTNode KW_GRANT376_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		pushMsg("show role grants", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:7: KW_SHOW KW_ROLE KW_GRANT principalName
			{
			KW_SHOW374=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoleGrants6646); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW374);

			KW_ROLE375=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_showRoleGrants6648); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE375);

			KW_GRANT376=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showRoleGrants6650); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT376);

			pushFollow(FOLLOW_principalName_in_showRoleGrants6652);
			principalName377=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName377.getTree());
			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1453:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1453:8: ^( TOK_SHOW_ROLE_GRANT principalName )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT"), root_1);
				adaptor.addChild(root_1, stream_principalName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRoleGrants"


	public static class showRoles_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRoles"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1457:1: showRoles : KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) ;
	public final HiveParser.showRoles_return showRoles() throws RecognitionException {
		HiveParser.showRoles_return retval = new HiveParser.showRoles_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW378=null;
		Token KW_ROLES379=null;

		ASTNode KW_SHOW378_tree=null;
		ASTNode KW_ROLES379_tree=null;
		RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");

		pushMsg("show roles", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:5: ( KW_SHOW KW_ROLES -> ^( TOK_SHOW_ROLES ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1460:7: KW_SHOW KW_ROLES
			{
			KW_SHOW378=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoles6692); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW378);

			KW_ROLES379=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showRoles6694); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES379);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1461:5: -> ^( TOK_SHOW_ROLES )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1461:8: ^( TOK_SHOW_ROLES )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLES, "TOK_SHOW_ROLES"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRoles"


	public static class showCurrentRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showCurrentRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1464:1: showCurrentRole : KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_CURRENT_ROLE ) ;
	public final HiveParser.showCurrentRole_return showCurrentRole() throws RecognitionException {
		HiveParser.showCurrentRole_return retval = new HiveParser.showCurrentRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW380=null;
		Token KW_CURRENT381=null;
		Token KW_ROLES382=null;

		ASTNode KW_SHOW380_tree=null;
		ASTNode KW_CURRENT381_tree=null;
		ASTNode KW_ROLES382_tree=null;
		RewriteRuleTokenStream stream_KW_ROLES=new RewriteRuleTokenStream(adaptor,"token KW_ROLES");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_CURRENT=new RewriteRuleTokenStream(adaptor,"token KW_CURRENT");

		pushMsg("show current role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1467:5: ( KW_SHOW KW_CURRENT KW_ROLES -> ^( TOK_SHOW_CURRENT_ROLE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1467:7: KW_SHOW KW_CURRENT KW_ROLES
			{
			KW_SHOW380=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showCurrentRole6731); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW380);

			KW_CURRENT381=(Token)match(input,KW_CURRENT,FOLLOW_KW_CURRENT_in_showCurrentRole6733); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CURRENT.add(KW_CURRENT381);

			KW_ROLES382=(Token)match(input,KW_ROLES,FOLLOW_KW_ROLES_in_showCurrentRole6735); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLES.add(KW_ROLES382);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1468:5: -> ^( TOK_SHOW_CURRENT_ROLE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1468:8: ^( TOK_SHOW_CURRENT_ROLE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_CURRENT_ROLE, "TOK_SHOW_CURRENT_ROLE"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showCurrentRole"


	public static class setRole_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setRole"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1471:1: setRole : KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) ) ;
	public final HiveParser.setRole_return setRole() throws RecognitionException {
		HiveParser.setRole_return retval = new HiveParser.setRole_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token all=null;
		Token none=null;
		Token KW_SET383=null;
		Token KW_ROLE384=null;
		ParserRuleReturnScope identifier385 =null;

		ASTNode all_tree=null;
		ASTNode none_tree=null;
		ASTNode KW_SET383_tree=null;
		ASTNode KW_ROLE384_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_NONE=new RewriteRuleTokenStream(adaptor,"token KW_NONE");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("set role", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:5: ( KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:7: KW_SET KW_ROLE ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) )
			{
			KW_SET383=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setRole6772); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET383);

			KW_ROLE384=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_setRole6774); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE384);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1475:5: ( ( KW_ALL )=> (all= KW_ALL ) -> ^( TOK_SET_ROLE Identifier[$all.text] ) | ( KW_NONE )=> (none= KW_NONE ) -> ^( TOK_SET_ROLE Identifier[$none.text] ) | identifier -> ^( TOK_SET_ROLE identifier ) )
			int alt129=3;
			int LA129_0 = input.LA(1);
			if ( (LA129_0==KW_ALL) && (synpred16_HiveParser())) {
				alt129=1;
			}
			else if ( (LA129_0==KW_NONE) && (synpred17_HiveParser())) {
				alt129=2;
			}
			else if ( (LA129_0==Identifier||(LA129_0 >= KW_ABORT && LA129_0 <= KW_AFTER)||LA129_0==KW_ALLOC_FRACTION||LA129_0==KW_ANALYZE||LA129_0==KW_ARCHIVE||(LA129_0 >= KW_ASC && LA129_0 <= KW_AT)||(LA129_0 >= KW_AUTOCOMMIT && LA129_0 <= KW_BEFORE)||(LA129_0 >= KW_BUCKET && LA129_0 <= KW_BUCKETS)||(LA129_0 >= KW_CACHE && LA129_0 <= KW_CASCADE)||(LA129_0 >= KW_CBO && LA129_0 <= KW_CHANGE)||(LA129_0 >= KW_CHECK && LA129_0 <= KW_COLLECTION)||(LA129_0 >= KW_COLUMNS && LA129_0 <= KW_COMMENT)||(LA129_0 >= KW_COMPACT && LA129_0 <= KW_CONCATENATE)||(LA129_0 >= KW_CONTINUE && LA129_0 <= KW_COST)||LA129_0==KW_CRON||LA129_0==KW_DATA||LA129_0==KW_DATABASES||(LA129_0 >= KW_DATETIME && LA129_0 <= KW_DCPROPERTIES)||LA129_0==KW_DEBUG||(LA129_0 >= KW_DEFAULT && LA129_0 <= KW_DEFINED)||(LA129_0 >= KW_DELIMITED && LA129_0 <= KW_DESC)||(LA129_0 >= KW_DETAIL && LA129_0 <= KW_DISABLE)||(LA129_0 >= KW_DISTRIBUTE && LA129_0 <= KW_DO)||LA129_0==KW_DOW||(LA129_0 >= KW_DUMP && LA129_0 <= KW_ELEM_TYPE)||LA129_0==KW_ENABLE||(LA129_0 >= KW_ENFORCED && LA129_0 <= KW_EVERY)||(LA129_0 >= KW_EXCLUSIVE && LA129_0 <= KW_EXECUTED)||(LA129_0 >= KW_EXPIRE_SNAPSHOTS && LA129_0 <= KW_EXPRESSION)||(LA129_0 >= KW_FIELDS && LA129_0 <= KW_FIRST)||(LA129_0 >= KW_FORMAT && LA129_0 <= KW_FORMATTED)||LA129_0==KW_FUNCTIONS||(LA129_0 >= KW_HOUR && LA129_0 <= KW_IDXPROPERTIES)||LA129_0==KW_IGNORE||(LA129_0 >= KW_INDEX && LA129_0 <= KW_INDEXES)||(LA129_0 >= KW_INPATH && LA129_0 <= KW_INPUTFORMAT)||(LA129_0 >= KW_ISOLATION && LA129_0 <= KW_JAR)||(LA129_0 >= KW_JOINCOST && LA129_0 <= KW_LAST)||LA129_0==KW_LEVEL||(LA129_0 >= KW_LIMIT && LA129_0 <= KW_LOAD)||(LA129_0 >= KW_LOCATION && LA129_0 <= KW_LONG)||(LA129_0 >= KW_MANAGED && LA129_0 <= KW_MANAGEMENT)||(LA129_0 >= KW_MAPJOIN && LA129_0 <= KW_MATERIALIZED)||LA129_0==KW_METADATA||(LA129_0 >= KW_MINUTE && LA129_0 <= KW_MONTH)||(LA129_0 >= KW_MOVE && LA129_0 <= KW_MSCK)||(LA129_0 >= KW_NORELY && LA129_0 <= KW_NOSCAN)||LA129_0==KW_NOVALIDATE||LA129_0==KW_NULLS||LA129_0==KW_OFFSET||(LA129_0 >= KW_OPERATOR && LA129_0 <= KW_OPTION)||(LA129_0 >= KW_OUTPUTDRIVER && LA129_0 <= KW_OUTPUTFORMAT)||(LA129_0 >= KW_OVERWRITE && LA129_0 <= KW_OWNER)||(LA129_0 >= KW_PARTITIONED && LA129_0 <= KW_PATH)||(LA129_0 >= KW_PLAN && LA129_0 <= KW_POOL)||LA129_0==KW_PRINCIPALS||LA129_0==KW_PURGE||(LA129_0 >= KW_QUARTER && LA129_0 <= KW_QUERY_PARALLELISM)||LA129_0==KW_READ||(LA129_0 >= KW_REBUILD && LA129_0 <= KW_RECORDWRITER)||(LA129_0 >= KW_RELOAD && LA129_0 <= KW_RESTRICT)||LA129_0==KW_REWRITE||(LA129_0 >= KW_ROLE && LA129_0 <= KW_ROLES)||(LA129_0 >= KW_SCHEDULED && LA129_0 <= KW_SECOND)||(LA129_0 >= KW_SEMI && LA129_0 <= KW_SERVER)||(LA129_0 >= KW_SETS && LA129_0 <= KW_SKEWED)||LA129_0==KW_SNAPSHOT||(LA129_0 >= KW_SORT && LA129_0 <= KW_SSL)||(LA129_0 >= KW_STATISTICS && LA129_0 <= KW_SUMMARY)||(LA129_0 >= KW_SYSTEM_TIME && LA129_0 <= KW_SYSTEM_VERSION)||LA129_0==KW_TABLES||(LA129_0 >= KW_TBLPROPERTIES && LA129_0 <= KW_TERMINATED)||LA129_0==KW_TINYINT||LA129_0==KW_TOUCH||(LA129_0 >= KW_TRANSACTION && LA129_0 <= KW_TRANSACTIONS)||LA129_0==KW_TRIM||(LA129_0 >= KW_TYPE && LA129_0 <= KW_UNARCHIVE)||LA129_0==KW_UNDO||LA129_0==KW_UNIONTYPE||(LA129_0 >= KW_UNKNOWN && LA129_0 <= KW_UNSIGNED)||(LA129_0 >= KW_URI && LA129_0 <= KW_USE)||(LA129_0 >= KW_UTC && LA129_0 <= KW_VALIDATE)||LA129_0==KW_VALUE_TYPE||(LA129_0 >= KW_VECTORIZATION && LA129_0 <= KW_WEEK)||LA129_0==KW_WHILE||(LA129_0 >= KW_WITHIN && LA129_0 <= KW_ZONE)||LA129_0==KW_BATCH||LA129_0==KW_DAYOFWEEK||LA129_0==KW_HOLD_DDLTIME||LA129_0==KW_NO_DROP||LA129_0==KW_OFFLINE||LA129_0==KW_PROTECTION||LA129_0==KW_READONLY||LA129_0==KW_TIMESTAMPTZ) ) {
				alt129=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 129, 0, input);
				throw nvae;
			}

			switch (alt129) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:5: ( KW_ALL )=> (all= KW_ALL )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:17: (all= KW_ALL )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:18: all= KW_ALL
					{
					all=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setRole6795); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(all);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1476:30: -> ^( TOK_SET_ROLE Identifier[$all.text] )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:33: ^( TOK_SET_ROLE Identifier[$all.text] )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_ROLE, "TOK_SET_ROLE"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(Identifier, (all!=null?all.getText():null)));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:5: ( KW_NONE )=> (none= KW_NONE )
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:18: (none= KW_NONE )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:19: none= KW_NONE
					{
					none=(Token)match(input,KW_NONE,FOLLOW_KW_NONE_in_setRole6826); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NONE.add(none);

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1478:33: -> ^( TOK_SET_ROLE Identifier[$none.text] )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:36: ^( TOK_SET_ROLE Identifier[$none.text] )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_ROLE, "TOK_SET_ROLE"), root_1);
						adaptor.addChild(root_1, (ASTNode)adaptor.create(Identifier, (none!=null?none.getText():null)));
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1480:5: identifier
					{
					pushFollow(FOLLOW_identifier_in_setRole6848);
					identifier385=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier385.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1480:16: -> ^( TOK_SET_ROLE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1480:19: ^( TOK_SET_ROLE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_ROLE, "TOK_SET_ROLE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setRole"


	public static class showGrants_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showGrants"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1484:1: showGrants : KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) ;
	public final HiveParser.showGrants_return showGrants() throws RecognitionException {
		HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW386=null;
		Token KW_GRANT387=null;
		Token KW_ON389=null;
		ParserRuleReturnScope principalName388 =null;
		ParserRuleReturnScope privilegeIncludeColObject390 =null;

		ASTNode KW_SHOW386_tree=null;
		ASTNode KW_GRANT387_tree=null;
		ASTNode KW_ON389_tree=null;
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_privilegeIncludeColObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeIncludeColObject");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		pushMsg("show grants", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:5: ( KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:7: KW_SHOW KW_GRANT ( principalName )? ( KW_ON privilegeIncludeColObject )?
			{
			KW_SHOW386=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showGrants6889); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW386);

			KW_GRANT387=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showGrants6891); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT387);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:24: ( principalName )?
			int alt130=2;
			int LA130_0 = input.LA(1);
			if ( (LA130_0==KW_GROUP||LA130_0==KW_ROLE||LA130_0==KW_USER) ) {
				alt130=1;
			}
			switch (alt130) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:24: principalName
					{
					pushFollow(FOLLOW_principalName_in_showGrants6893);
					principalName388=principalName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalName.add(principalName388.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:39: ( KW_ON privilegeIncludeColObject )?
			int alt131=2;
			int LA131_0 = input.LA(1);
			if ( (LA131_0==KW_ON) ) {
				alt131=1;
			}
			switch (alt131) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1487:40: KW_ON privilegeIncludeColObject
					{
					KW_ON389=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_showGrants6897); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON389);

					pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants6899);
					privilegeIncludeColObject390=privilegeIncludeColObject();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privilegeIncludeColObject.add(privilegeIncludeColObject390.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: principalName, privilegeIncludeColObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1488:5: -> ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:8: ^( TOK_SHOW_GRANT ( principalName )? ( privilegeIncludeColObject )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:25: ( principalName )?
				if ( stream_principalName.hasNext() ) {
					adaptor.addChild(root_1, stream_principalName.nextTree());
				}
				stream_principalName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:40: ( privilegeIncludeColObject )?
				if ( stream_privilegeIncludeColObject.hasNext() ) {
					adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());
				}
				stream_privilegeIncludeColObject.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showGrants"


	public static class showRolePrincipals_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showRolePrincipals"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1491:1: showRolePrincipals : KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) ;
	public final HiveParser.showRolePrincipals_return showRolePrincipals() throws RecognitionException {
		HiveParser.showRolePrincipals_return retval = new HiveParser.showRolePrincipals_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SHOW391=null;
		Token KW_PRINCIPALS392=null;
		ParserRuleReturnScope roleName =null;

		ASTNode KW_SHOW391_tree=null;
		ASTNode KW_PRINCIPALS392_tree=null;
		RewriteRuleTokenStream stream_KW_PRINCIPALS=new RewriteRuleTokenStream(adaptor,"token KW_PRINCIPALS");
		RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		pushMsg("show role principals", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1494:5: ( KW_SHOW KW_PRINCIPALS roleName= identifier -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1494:7: KW_SHOW KW_PRINCIPALS roleName= identifier
			{
			KW_SHOW391=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRolePrincipals6944); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SHOW.add(KW_SHOW391);

			KW_PRINCIPALS392=(Token)match(input,KW_PRINCIPALS,FOLLOW_KW_PRINCIPALS_in_showRolePrincipals6946); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PRINCIPALS.add(KW_PRINCIPALS392);

			pushFollow(FOLLOW_identifier_in_showRolePrincipals6950);
			roleName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(roleName.getTree());
			// AST REWRITE
			// elements: roleName
			// token labels: 
			// rule labels: roleName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1495:5: -> ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1495:8: ^( TOK_SHOW_ROLE_PRINCIPALS $roleName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SHOW_ROLE_PRINCIPALS, "TOK_SHOW_ROLE_PRINCIPALS"), root_1);
				adaptor.addChild(root_1, stream_roleName.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showRolePrincipals"


	public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeIncludeColObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1499:1: privilegeIncludeColObject : ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) );
	public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
		HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALL393=null;
		ParserRuleReturnScope privObjectCols394 =null;

		ASTNode KW_ALL393_tree=null;
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleSubtreeStream stream_privObjectCols=new RewriteRuleSubtreeStream(adaptor,"rule privObjectCols");

		pushMsg("privilege object including columns", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1502:5: ( ( KW_ALL )=> KW_ALL -> ^( TOK_RESOURCE_ALL ) | privObjectCols -> ^( TOK_PRIV_OBJECT_COL privObjectCols ) )
			int alt132=2;
			int LA132_0 = input.LA(1);
			if ( (LA132_0==KW_ALL) && (synpred18_HiveParser())) {
				alt132=1;
			}
			else if ( (LA132_0==Identifier||(LA132_0 >= KW_ABORT && LA132_0 <= KW_AFTER)||LA132_0==KW_ALLOC_FRACTION||LA132_0==KW_ANALYZE||LA132_0==KW_ARCHIVE||(LA132_0 >= KW_ASC && LA132_0 <= KW_AT)||(LA132_0 >= KW_AUTOCOMMIT && LA132_0 <= KW_BEFORE)||(LA132_0 >= KW_BUCKET && LA132_0 <= KW_BUCKETS)||(LA132_0 >= KW_CACHE && LA132_0 <= KW_CASCADE)||(LA132_0 >= KW_CBO && LA132_0 <= KW_CHANGE)||(LA132_0 >= KW_CHECK && LA132_0 <= KW_COLLECTION)||(LA132_0 >= KW_COLUMNS && LA132_0 <= KW_COMMENT)||(LA132_0 >= KW_COMPACT && LA132_0 <= KW_CONCATENATE)||(LA132_0 >= KW_CONTINUE && LA132_0 <= KW_COST)||LA132_0==KW_CRON||(LA132_0 >= KW_DATA && LA132_0 <= KW_DATABASES)||(LA132_0 >= KW_DATETIME && LA132_0 <= KW_DCPROPERTIES)||LA132_0==KW_DEBUG||(LA132_0 >= KW_DEFAULT && LA132_0 <= KW_DEFINED)||(LA132_0 >= KW_DELIMITED && LA132_0 <= KW_DESC)||(LA132_0 >= KW_DETAIL && LA132_0 <= KW_DISABLE)||(LA132_0 >= KW_DISTRIBUTE && LA132_0 <= KW_DO)||LA132_0==KW_DOW||(LA132_0 >= KW_DUMP && LA132_0 <= KW_ELEM_TYPE)||LA132_0==KW_ENABLE||(LA132_0 >= KW_ENFORCED && LA132_0 <= KW_EVERY)||(LA132_0 >= KW_EXCLUSIVE && LA132_0 <= KW_EXECUTED)||(LA132_0 >= KW_EXPIRE_SNAPSHOTS && LA132_0 <= KW_EXPRESSION)||(LA132_0 >= KW_FIELDS && LA132_0 <= KW_FIRST)||(LA132_0 >= KW_FORMAT && LA132_0 <= KW_FORMATTED)||LA132_0==KW_FUNCTIONS||(LA132_0 >= KW_HOUR && LA132_0 <= KW_IDXPROPERTIES)||LA132_0==KW_IGNORE||(LA132_0 >= KW_INDEX && LA132_0 <= KW_INDEXES)||(LA132_0 >= KW_INPATH && LA132_0 <= KW_INPUTFORMAT)||(LA132_0 >= KW_ISOLATION && LA132_0 <= KW_JAR)||(LA132_0 >= KW_JOINCOST && LA132_0 <= KW_LAST)||LA132_0==KW_LEVEL||(LA132_0 >= KW_LIMIT && LA132_0 <= KW_LOAD)||(LA132_0 >= KW_LOCATION && LA132_0 <= KW_LONG)||(LA132_0 >= KW_MANAGED && LA132_0 <= KW_MANAGEMENT)||(LA132_0 >= KW_MAPJOIN && LA132_0 <= KW_MATERIALIZED)||LA132_0==KW_METADATA||(LA132_0 >= KW_MINUTE && LA132_0 <= KW_MONTH)||(LA132_0 >= KW_MOVE && LA132_0 <= KW_MSCK)||(LA132_0 >= KW_NORELY && LA132_0 <= KW_NOSCAN)||LA132_0==KW_NOVALIDATE||LA132_0==KW_NULLS||LA132_0==KW_OFFSET||(LA132_0 >= KW_OPERATOR && LA132_0 <= KW_OPTION)||(LA132_0 >= KW_OUTPUTDRIVER && LA132_0 <= KW_OUTPUTFORMAT)||(LA132_0 >= KW_OVERWRITE && LA132_0 <= KW_OWNER)||(LA132_0 >= KW_PARTITIONED && LA132_0 <= KW_PATH)||(LA132_0 >= KW_PLAN && LA132_0 <= KW_POOL)||LA132_0==KW_PRINCIPALS||LA132_0==KW_PURGE||(LA132_0 >= KW_QUARTER && LA132_0 <= KW_QUERY_PARALLELISM)||LA132_0==KW_READ||(LA132_0 >= KW_REBUILD && LA132_0 <= KW_RECORDWRITER)||(LA132_0 >= KW_RELOAD && LA132_0 <= KW_RESTRICT)||LA132_0==KW_REWRITE||(LA132_0 >= KW_ROLE && LA132_0 <= KW_ROLES)||(LA132_0 >= KW_SCHEDULED && LA132_0 <= KW_SECOND)||(LA132_0 >= KW_SEMI && LA132_0 <= KW_SERVER)||(LA132_0 >= KW_SETS && LA132_0 <= KW_SKEWED)||LA132_0==KW_SNAPSHOT||(LA132_0 >= KW_SORT && LA132_0 <= KW_SSL)||(LA132_0 >= KW_STATISTICS && LA132_0 <= KW_SUMMARY)||(LA132_0 >= KW_SYSTEM_TIME && LA132_0 <= KW_TABLES)||(LA132_0 >= KW_TBLPROPERTIES && LA132_0 <= KW_TERMINATED)||LA132_0==KW_TINYINT||LA132_0==KW_TOUCH||(LA132_0 >= KW_TRANSACTION && LA132_0 <= KW_TRANSACTIONS)||LA132_0==KW_TRIM||(LA132_0 >= KW_TYPE && LA132_0 <= KW_UNARCHIVE)||LA132_0==KW_UNDO||LA132_0==KW_UNIONTYPE||(LA132_0 >= KW_UNKNOWN && LA132_0 <= KW_UNSIGNED)||(LA132_0 >= KW_URI && LA132_0 <= KW_USE)||(LA132_0 >= KW_UTC && LA132_0 <= KW_VALIDATE)||LA132_0==KW_VALUE_TYPE||(LA132_0 >= KW_VECTORIZATION && LA132_0 <= KW_WEEK)||LA132_0==KW_WHILE||(LA132_0 >= KW_WITHIN && LA132_0 <= KW_ZONE)||LA132_0==KW_BATCH||LA132_0==KW_DAYOFWEEK||LA132_0==KW_HOLD_DDLTIME||LA132_0==KW_NO_DROP||LA132_0==KW_OFFLINE||LA132_0==KW_PROTECTION||LA132_0==KW_READONLY||LA132_0==KW_TIMESTAMPTZ) ) {
				alt132=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 132, 0, input);
				throw nvae;
			}

			switch (alt132) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1502:7: ( KW_ALL )=> KW_ALL
					{
					KW_ALL393=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeIncludeColObject6997); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL393);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1502:26: -> ^( TOK_RESOURCE_ALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1502:29: ^( TOK_RESOURCE_ALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_ALL, "TOK_RESOURCE_ALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:7: privObjectCols
					{
					pushFollow(FOLLOW_privObjectCols_in_privilegeIncludeColObject7011);
					privObjectCols394=privObjectCols();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privObjectCols.add(privObjectCols394.getTree());
					// AST REWRITE
					// elements: privObjectCols
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1503:22: -> ^( TOK_PRIV_OBJECT_COL privObjectCols )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:25: ^( TOK_PRIV_OBJECT_COL privObjectCols )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL"), root_1);
						adaptor.addChild(root_1, stream_privObjectCols.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeIncludeColObject"


	public static class privilegeObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1506:1: privilegeObject : KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) ;
	public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
		HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ON395=null;
		ParserRuleReturnScope privObject396 =null;

		ASTNode KW_ON395_tree=null;
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_privObject=new RewriteRuleSubtreeStream(adaptor,"rule privObject");

		pushMsg("privilege object", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1509:5: ( KW_ON privObject -> ^( TOK_PRIV_OBJECT privObject ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1509:7: KW_ON privObject
			{
			KW_ON395=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_privilegeObject7046); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON395);

			pushFollow(FOLLOW_privObject_in_privilegeObject7048);
			privObject396=privObject();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privObject.add(privObject396.getTree());
			// AST REWRITE
			// elements: privObject
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1509:24: -> ^( TOK_PRIV_OBJECT privObject )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1509:27: ^( TOK_PRIV_OBJECT privObject )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT"), root_1);
				adaptor.addChild(root_1, stream_privObject.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeObject"


	public static class privObject_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privObject"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1513:1: privObject : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
	public final HiveParser.privObject_return privObject() throws RecognitionException {
		HiveParser.privObject_return retval = new HiveParser.privObject_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_DATABASE397=null;
		Token KW_SCHEMA398=null;
		Token KW_TABLE400=null;
		Token KW_URI403=null;
		Token KW_SERVER404=null;
		ParserRuleReturnScope identifier399 =null;
		ParserRuleReturnScope tableName401 =null;
		ParserRuleReturnScope partitionSpec402 =null;
		ParserRuleReturnScope identifier405 =null;

		ASTNode path_tree=null;
		ASTNode KW_DATABASE397_tree=null;
		ASTNode KW_SCHEMA398_tree=null;
		ASTNode KW_TABLE400_tree=null;
		ASTNode KW_URI403_tree=null;
		ASTNode KW_SERVER404_tree=null;
		RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
			int alt136=4;
			switch ( input.LA(1) ) {
			case KW_DATABASE:
				{
				alt136=1;
				}
				break;
			case KW_SCHEMA:
				{
				int LA136_2 = input.LA(2);
				if ( (LA136_2==Identifier||(LA136_2 >= KW_ABORT && LA136_2 <= KW_AFTER)||LA136_2==KW_ALLOC_FRACTION||LA136_2==KW_ANALYZE||LA136_2==KW_ARCHIVE||(LA136_2 >= KW_ASC && LA136_2 <= KW_AT)||(LA136_2 >= KW_AUTOCOMMIT && LA136_2 <= KW_BEFORE)||(LA136_2 >= KW_BUCKET && LA136_2 <= KW_BUCKETS)||(LA136_2 >= KW_CACHE && LA136_2 <= KW_CASCADE)||(LA136_2 >= KW_CBO && LA136_2 <= KW_CHANGE)||(LA136_2 >= KW_CHECK && LA136_2 <= KW_COLLECTION)||(LA136_2 >= KW_COLUMNS && LA136_2 <= KW_COMMENT)||(LA136_2 >= KW_COMPACT && LA136_2 <= KW_CONCATENATE)||(LA136_2 >= KW_CONTINUE && LA136_2 <= KW_COST)||LA136_2==KW_CRON||LA136_2==KW_DATA||LA136_2==KW_DATABASES||(LA136_2 >= KW_DATETIME && LA136_2 <= KW_DCPROPERTIES)||LA136_2==KW_DEBUG||(LA136_2 >= KW_DEFAULT && LA136_2 <= KW_DEFINED)||(LA136_2 >= KW_DELIMITED && LA136_2 <= KW_DESC)||(LA136_2 >= KW_DETAIL && LA136_2 <= KW_DISABLE)||(LA136_2 >= KW_DISTRIBUTE && LA136_2 <= KW_DO)||LA136_2==KW_DOW||(LA136_2 >= KW_DUMP && LA136_2 <= KW_ELEM_TYPE)||LA136_2==KW_ENABLE||(LA136_2 >= KW_ENFORCED && LA136_2 <= KW_EVERY)||(LA136_2 >= KW_EXCLUSIVE && LA136_2 <= KW_EXECUTED)||(LA136_2 >= KW_EXPIRE_SNAPSHOTS && LA136_2 <= KW_EXPRESSION)||(LA136_2 >= KW_FIELDS && LA136_2 <= KW_FIRST)||(LA136_2 >= KW_FORMAT && LA136_2 <= KW_FORMATTED)||LA136_2==KW_FUNCTIONS||(LA136_2 >= KW_HOUR && LA136_2 <= KW_IDXPROPERTIES)||LA136_2==KW_IGNORE||(LA136_2 >= KW_INDEX && LA136_2 <= KW_INDEXES)||(LA136_2 >= KW_INPATH && LA136_2 <= KW_INPUTFORMAT)||(LA136_2 >= KW_ISOLATION && LA136_2 <= KW_JAR)||(LA136_2 >= KW_JOINCOST && LA136_2 <= KW_LAST)||LA136_2==KW_LEVEL||(LA136_2 >= KW_LIMIT && LA136_2 <= KW_LOAD)||(LA136_2 >= KW_LOCATION && LA136_2 <= KW_LONG)||(LA136_2 >= KW_MANAGED && LA136_2 <= KW_MANAGEMENT)||(LA136_2 >= KW_MAPJOIN && LA136_2 <= KW_MATERIALIZED)||LA136_2==KW_METADATA||(LA136_2 >= KW_MINUTE && LA136_2 <= KW_MONTH)||(LA136_2 >= KW_MOVE && LA136_2 <= KW_MSCK)||(LA136_2 >= KW_NORELY && LA136_2 <= KW_NOSCAN)||LA136_2==KW_NOVALIDATE||LA136_2==KW_NULLS||LA136_2==KW_OFFSET||(LA136_2 >= KW_OPERATOR && LA136_2 <= KW_OPTION)||(LA136_2 >= KW_OUTPUTDRIVER && LA136_2 <= KW_OUTPUTFORMAT)||(LA136_2 >= KW_OVERWRITE && LA136_2 <= KW_OWNER)||(LA136_2 >= KW_PARTITIONED && LA136_2 <= KW_PATH)||(LA136_2 >= KW_PLAN && LA136_2 <= KW_POOL)||LA136_2==KW_PRINCIPALS||LA136_2==KW_PURGE||(LA136_2 >= KW_QUARTER && LA136_2 <= KW_QUERY_PARALLELISM)||LA136_2==KW_READ||(LA136_2 >= KW_REBUILD && LA136_2 <= KW_RECORDWRITER)||(LA136_2 >= KW_RELOAD && LA136_2 <= KW_RESTRICT)||LA136_2==KW_REWRITE||(LA136_2 >= KW_ROLE && LA136_2 <= KW_ROLES)||(LA136_2 >= KW_SCHEDULED && LA136_2 <= KW_SECOND)||(LA136_2 >= KW_SEMI && LA136_2 <= KW_SERVER)||(LA136_2 >= KW_SETS && LA136_2 <= KW_SKEWED)||LA136_2==KW_SNAPSHOT||(LA136_2 >= KW_SORT && LA136_2 <= KW_SSL)||(LA136_2 >= KW_STATISTICS && LA136_2 <= KW_SUMMARY)||(LA136_2 >= KW_SYSTEM_TIME && LA136_2 <= KW_SYSTEM_VERSION)||LA136_2==KW_TABLES||(LA136_2 >= KW_TBLPROPERTIES && LA136_2 <= KW_TERMINATED)||LA136_2==KW_TINYINT||LA136_2==KW_TOUCH||(LA136_2 >= KW_TRANSACTION && LA136_2 <= KW_TRANSACTIONS)||LA136_2==KW_TRIM||(LA136_2 >= KW_TYPE && LA136_2 <= KW_UNARCHIVE)||LA136_2==KW_UNDO||LA136_2==KW_UNIONTYPE||(LA136_2 >= KW_UNKNOWN && LA136_2 <= KW_UNSIGNED)||(LA136_2 >= KW_URI && LA136_2 <= KW_USE)||(LA136_2 >= KW_UTC && LA136_2 <= KW_VALIDATE)||LA136_2==KW_VALUE_TYPE||(LA136_2 >= KW_VECTORIZATION && LA136_2 <= KW_WEEK)||LA136_2==KW_WHILE||(LA136_2 >= KW_WITHIN && LA136_2 <= KW_ZONE)||LA136_2==KW_BATCH||LA136_2==KW_DAYOFWEEK||LA136_2==KW_HOLD_DDLTIME||LA136_2==KW_NO_DROP||LA136_2==KW_OFFLINE||LA136_2==KW_PROTECTION||LA136_2==KW_READONLY||LA136_2==KW_TIMESTAMPTZ) ) {
					alt136=1;
				}
				else if ( (LA136_2==DOT||LA136_2==KW_FROM||LA136_2==KW_PARTITION||LA136_2==KW_TO) ) {
					alt136=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 136, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AST:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DCPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPIRE_SNAPSHOTS:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_ID:
			case KW_IDXPROPERTIES:
			case KW_IGNORE:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGED:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_REMOTE:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESPECT:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SPEC:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_SYSTEM_TIME:
			case KW_SYSTEM_VERSION:
			case KW_TABLE:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_TRIM:
			case KW_TYPE:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNKNOWN:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URL:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WITHIN:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt136=2;
				}
				break;
			case KW_URI:
				{
				int LA136_5 = input.LA(2);
				if ( (LA136_5==DOT||LA136_5==KW_FROM||LA136_5==KW_PARTITION||LA136_5==KW_TO) ) {
					alt136=2;
				}
				else if ( (LA136_5==StringLiteral) ) {
					alt136=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 136, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_SERVER:
				{
				int LA136_6 = input.LA(2);
				if ( (LA136_6==DOT||LA136_6==KW_FROM||LA136_6==KW_PARTITION||LA136_6==KW_TO) ) {
					alt136=2;
				}
				else if ( (LA136_6==Identifier||(LA136_6 >= KW_ABORT && LA136_6 <= KW_AFTER)||LA136_6==KW_ALLOC_FRACTION||LA136_6==KW_ANALYZE||LA136_6==KW_ARCHIVE||(LA136_6 >= KW_ASC && LA136_6 <= KW_AT)||(LA136_6 >= KW_AUTOCOMMIT && LA136_6 <= KW_BEFORE)||(LA136_6 >= KW_BUCKET && LA136_6 <= KW_BUCKETS)||(LA136_6 >= KW_CACHE && LA136_6 <= KW_CASCADE)||(LA136_6 >= KW_CBO && LA136_6 <= KW_CHANGE)||(LA136_6 >= KW_CHECK && LA136_6 <= KW_COLLECTION)||(LA136_6 >= KW_COLUMNS && LA136_6 <= KW_COMMENT)||(LA136_6 >= KW_COMPACT && LA136_6 <= KW_CONCATENATE)||(LA136_6 >= KW_CONTINUE && LA136_6 <= KW_COST)||LA136_6==KW_CRON||LA136_6==KW_DATA||LA136_6==KW_DATABASES||(LA136_6 >= KW_DATETIME && LA136_6 <= KW_DCPROPERTIES)||LA136_6==KW_DEBUG||(LA136_6 >= KW_DEFAULT && LA136_6 <= KW_DEFINED)||(LA136_6 >= KW_DELIMITED && LA136_6 <= KW_DESC)||(LA136_6 >= KW_DETAIL && LA136_6 <= KW_DISABLE)||(LA136_6 >= KW_DISTRIBUTE && LA136_6 <= KW_DO)||LA136_6==KW_DOW||(LA136_6 >= KW_DUMP && LA136_6 <= KW_ELEM_TYPE)||LA136_6==KW_ENABLE||(LA136_6 >= KW_ENFORCED && LA136_6 <= KW_EVERY)||(LA136_6 >= KW_EXCLUSIVE && LA136_6 <= KW_EXECUTED)||(LA136_6 >= KW_EXPIRE_SNAPSHOTS && LA136_6 <= KW_EXPRESSION)||(LA136_6 >= KW_FIELDS && LA136_6 <= KW_FIRST)||(LA136_6 >= KW_FORMAT && LA136_6 <= KW_FORMATTED)||LA136_6==KW_FUNCTIONS||(LA136_6 >= KW_HOUR && LA136_6 <= KW_IDXPROPERTIES)||LA136_6==KW_IGNORE||(LA136_6 >= KW_INDEX && LA136_6 <= KW_INDEXES)||(LA136_6 >= KW_INPATH && LA136_6 <= KW_INPUTFORMAT)||(LA136_6 >= KW_ISOLATION && LA136_6 <= KW_JAR)||(LA136_6 >= KW_JOINCOST && LA136_6 <= KW_LAST)||LA136_6==KW_LEVEL||(LA136_6 >= KW_LIMIT && LA136_6 <= KW_LOAD)||(LA136_6 >= KW_LOCATION && LA136_6 <= KW_LONG)||(LA136_6 >= KW_MANAGED && LA136_6 <= KW_MANAGEMENT)||(LA136_6 >= KW_MAPJOIN && LA136_6 <= KW_MATERIALIZED)||LA136_6==KW_METADATA||(LA136_6 >= KW_MINUTE && LA136_6 <= KW_MONTH)||(LA136_6 >= KW_MOVE && LA136_6 <= KW_MSCK)||(LA136_6 >= KW_NORELY && LA136_6 <= KW_NOSCAN)||LA136_6==KW_NOVALIDATE||LA136_6==KW_NULLS||LA136_6==KW_OFFSET||(LA136_6 >= KW_OPERATOR && LA136_6 <= KW_OPTION)||(LA136_6 >= KW_OUTPUTDRIVER && LA136_6 <= KW_OUTPUTFORMAT)||(LA136_6 >= KW_OVERWRITE && LA136_6 <= KW_OWNER)||(LA136_6 >= KW_PARTITIONED && LA136_6 <= KW_PATH)||(LA136_6 >= KW_PLAN && LA136_6 <= KW_POOL)||LA136_6==KW_PRINCIPALS||LA136_6==KW_PURGE||(LA136_6 >= KW_QUARTER && LA136_6 <= KW_QUERY_PARALLELISM)||LA136_6==KW_READ||(LA136_6 >= KW_REBUILD && LA136_6 <= KW_RECORDWRITER)||(LA136_6 >= KW_RELOAD && LA136_6 <= KW_RESTRICT)||LA136_6==KW_REWRITE||(LA136_6 >= KW_ROLE && LA136_6 <= KW_ROLES)||(LA136_6 >= KW_SCHEDULED && LA136_6 <= KW_SECOND)||(LA136_6 >= KW_SEMI && LA136_6 <= KW_SERVER)||(LA136_6 >= KW_SETS && LA136_6 <= KW_SKEWED)||LA136_6==KW_SNAPSHOT||(LA136_6 >= KW_SORT && LA136_6 <= KW_SSL)||(LA136_6 >= KW_STATISTICS && LA136_6 <= KW_SUMMARY)||(LA136_6 >= KW_SYSTEM_TIME && LA136_6 <= KW_SYSTEM_VERSION)||LA136_6==KW_TABLES||(LA136_6 >= KW_TBLPROPERTIES && LA136_6 <= KW_TERMINATED)||LA136_6==KW_TINYINT||LA136_6==KW_TOUCH||(LA136_6 >= KW_TRANSACTION && LA136_6 <= KW_TRANSACTIONS)||LA136_6==KW_TRIM||(LA136_6 >= KW_TYPE && LA136_6 <= KW_UNARCHIVE)||LA136_6==KW_UNDO||LA136_6==KW_UNIONTYPE||(LA136_6 >= KW_UNKNOWN && LA136_6 <= KW_UNSIGNED)||(LA136_6 >= KW_URI && LA136_6 <= KW_USE)||(LA136_6 >= KW_UTC && LA136_6 <= KW_VALIDATE)||LA136_6==KW_VALUE_TYPE||(LA136_6 >= KW_VECTORIZATION && LA136_6 <= KW_WEEK)||LA136_6==KW_WHILE||(LA136_6 >= KW_WITHIN && LA136_6 <= KW_ZONE)||LA136_6==KW_BATCH||LA136_6==KW_DAYOFWEEK||LA136_6==KW_HOLD_DDLTIME||LA136_6==KW_NO_DROP||LA136_6==KW_OFFLINE||LA136_6==KW_PROTECTION||LA136_6==KW_READONLY||LA136_6==KW_TIMESTAMPTZ) ) {
					alt136=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 136, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 136, 0, input);
				throw nvae;
			}
			switch (alt136) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:7: ( KW_DATABASE | KW_SCHEMA ) identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:7: ( KW_DATABASE | KW_SCHEMA )
					int alt133=2;
					int LA133_0 = input.LA(1);
					if ( (LA133_0==KW_DATABASE) ) {
						alt133=1;
					}
					else if ( (LA133_0==KW_SCHEMA) ) {
						alt133=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 133, 0, input);
						throw nvae;
					}

					switch (alt133) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:8: KW_DATABASE
							{
							KW_DATABASE397=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObject7075); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE397);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:20: KW_SCHEMA
							{
							KW_SCHEMA398=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObject7077); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA398);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_privObject7080);
					identifier399=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier399.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1514:42: -> ^( TOK_DB_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:45: ^( TOK_DB_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:7: ( KW_TABLE )? tableName ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:7: ( KW_TABLE )?
					int alt134=2;
					int LA134_0 = input.LA(1);
					if ( (LA134_0==KW_TABLE) ) {
						alt134=1;
					}
					switch (alt134) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:7: KW_TABLE
							{
							KW_TABLE400=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObject7096); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE400);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_privObject7099);
					tableName401=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName401.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:27: ( partitionSpec )?
					int alt135=2;
					int LA135_0 = input.LA(1);
					if ( (LA135_0==KW_PARTITION) ) {
						alt135=1;
					}
					switch (alt135) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:27: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_privObject7101);
							partitionSpec402=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec402.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: tableName, partitionSpec
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1515:42: -> ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:45: ^( TOK_TABLE_TYPE tableName ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1515:72: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1516:7: KW_URI (path= StringLiteral )
					{
					KW_URI403=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObject7121); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI403);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1516:14: (path= StringLiteral )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1516:15: path= StringLiteral
					{
					path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObject7126); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(path);

					}

					// AST REWRITE
					// elements: path
					// token labels: path
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1516:35: -> ^( TOK_URI_TYPE $path)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1516:39: ^( TOK_URI_TYPE $path)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);
						adaptor.addChild(root_1, stream_path.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:7: KW_SERVER identifier
					{
					KW_SERVER404=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObject7145); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER404);

					pushFollow(FOLLOW_identifier_in_privObject7147);
					identifier405=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier405.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1517:28: -> ^( TOK_SERVER_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:31: ^( TOK_SERVER_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privObject"


	public static class privObjectCols_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privObjectCols"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1520:1: privObjectCols : ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) );
	public final HiveParser.privObjectCols_return privObjectCols() throws RecognitionException {
		HiveParser.privObjectCols_return retval = new HiveParser.privObjectCols_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token path=null;
		Token KW_DATABASE406=null;
		Token KW_SCHEMA407=null;
		Token KW_TABLE409=null;
		Token LPAREN411=null;
		Token RPAREN412=null;
		Token KW_URI414=null;
		Token KW_SERVER415=null;
		ParserRuleReturnScope cols =null;
		ParserRuleReturnScope identifier408 =null;
		ParserRuleReturnScope tableName410 =null;
		ParserRuleReturnScope partitionSpec413 =null;
		ParserRuleReturnScope identifier416 =null;

		ASTNode path_tree=null;
		ASTNode KW_DATABASE406_tree=null;
		ASTNode KW_SCHEMA407_tree=null;
		ASTNode KW_TABLE409_tree=null;
		ASTNode LPAREN411_tree=null;
		ASTNode RPAREN412_tree=null;
		ASTNode KW_URI414_tree=null;
		ASTNode KW_SERVER415_tree=null;
		RewriteRuleTokenStream stream_KW_SERVER=new RewriteRuleTokenStream(adaptor,"token KW_SERVER");
		RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
		RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_URI=new RewriteRuleTokenStream(adaptor,"token KW_URI");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:5: ( ( KW_DATABASE | KW_SCHEMA ) identifier -> ^( TOK_DB_TYPE identifier ) | ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? ) | KW_URI (path= StringLiteral ) -> ^( TOK_URI_TYPE $path) | KW_SERVER identifier -> ^( TOK_SERVER_TYPE identifier ) )
			int alt141=4;
			switch ( input.LA(1) ) {
			case KW_DATABASE:
				{
				alt141=1;
				}
				break;
			case KW_SCHEMA:
				{
				int LA141_2 = input.LA(2);
				if ( (LA141_2==Identifier||(LA141_2 >= KW_ABORT && LA141_2 <= KW_AFTER)||LA141_2==KW_ALLOC_FRACTION||LA141_2==KW_ANALYZE||LA141_2==KW_ARCHIVE||(LA141_2 >= KW_ASC && LA141_2 <= KW_AT)||(LA141_2 >= KW_AUTOCOMMIT && LA141_2 <= KW_BEFORE)||(LA141_2 >= KW_BUCKET && LA141_2 <= KW_BUCKETS)||(LA141_2 >= KW_CACHE && LA141_2 <= KW_CASCADE)||(LA141_2 >= KW_CBO && LA141_2 <= KW_CHANGE)||(LA141_2 >= KW_CHECK && LA141_2 <= KW_COLLECTION)||(LA141_2 >= KW_COLUMNS && LA141_2 <= KW_COMMENT)||(LA141_2 >= KW_COMPACT && LA141_2 <= KW_CONCATENATE)||(LA141_2 >= KW_CONTINUE && LA141_2 <= KW_COST)||LA141_2==KW_CRON||LA141_2==KW_DATA||LA141_2==KW_DATABASES||(LA141_2 >= KW_DATETIME && LA141_2 <= KW_DCPROPERTIES)||LA141_2==KW_DEBUG||(LA141_2 >= KW_DEFAULT && LA141_2 <= KW_DEFINED)||(LA141_2 >= KW_DELIMITED && LA141_2 <= KW_DESC)||(LA141_2 >= KW_DETAIL && LA141_2 <= KW_DISABLE)||(LA141_2 >= KW_DISTRIBUTE && LA141_2 <= KW_DO)||LA141_2==KW_DOW||(LA141_2 >= KW_DUMP && LA141_2 <= KW_ELEM_TYPE)||LA141_2==KW_ENABLE||(LA141_2 >= KW_ENFORCED && LA141_2 <= KW_EVERY)||(LA141_2 >= KW_EXCLUSIVE && LA141_2 <= KW_EXECUTED)||(LA141_2 >= KW_EXPIRE_SNAPSHOTS && LA141_2 <= KW_EXPRESSION)||(LA141_2 >= KW_FIELDS && LA141_2 <= KW_FIRST)||(LA141_2 >= KW_FORMAT && LA141_2 <= KW_FORMATTED)||LA141_2==KW_FUNCTIONS||(LA141_2 >= KW_HOUR && LA141_2 <= KW_IDXPROPERTIES)||LA141_2==KW_IGNORE||(LA141_2 >= KW_INDEX && LA141_2 <= KW_INDEXES)||(LA141_2 >= KW_INPATH && LA141_2 <= KW_INPUTFORMAT)||(LA141_2 >= KW_ISOLATION && LA141_2 <= KW_JAR)||(LA141_2 >= KW_JOINCOST && LA141_2 <= KW_LAST)||LA141_2==KW_LEVEL||(LA141_2 >= KW_LIMIT && LA141_2 <= KW_LOAD)||(LA141_2 >= KW_LOCATION && LA141_2 <= KW_LONG)||(LA141_2 >= KW_MANAGED && LA141_2 <= KW_MANAGEMENT)||(LA141_2 >= KW_MAPJOIN && LA141_2 <= KW_MATERIALIZED)||LA141_2==KW_METADATA||(LA141_2 >= KW_MINUTE && LA141_2 <= KW_MONTH)||(LA141_2 >= KW_MOVE && LA141_2 <= KW_MSCK)||(LA141_2 >= KW_NORELY && LA141_2 <= KW_NOSCAN)||LA141_2==KW_NOVALIDATE||LA141_2==KW_NULLS||LA141_2==KW_OFFSET||(LA141_2 >= KW_OPERATOR && LA141_2 <= KW_OPTION)||(LA141_2 >= KW_OUTPUTDRIVER && LA141_2 <= KW_OUTPUTFORMAT)||(LA141_2 >= KW_OVERWRITE && LA141_2 <= KW_OWNER)||(LA141_2 >= KW_PARTITIONED && LA141_2 <= KW_PATH)||(LA141_2 >= KW_PLAN && LA141_2 <= KW_POOL)||LA141_2==KW_PRINCIPALS||LA141_2==KW_PURGE||(LA141_2 >= KW_QUARTER && LA141_2 <= KW_QUERY_PARALLELISM)||LA141_2==KW_READ||(LA141_2 >= KW_REBUILD && LA141_2 <= KW_RECORDWRITER)||(LA141_2 >= KW_RELOAD && LA141_2 <= KW_RESTRICT)||LA141_2==KW_REWRITE||(LA141_2 >= KW_ROLE && LA141_2 <= KW_ROLES)||(LA141_2 >= KW_SCHEDULED && LA141_2 <= KW_SECOND)||(LA141_2 >= KW_SEMI && LA141_2 <= KW_SERVER)||(LA141_2 >= KW_SETS && LA141_2 <= KW_SKEWED)||LA141_2==KW_SNAPSHOT||(LA141_2 >= KW_SORT && LA141_2 <= KW_SSL)||(LA141_2 >= KW_STATISTICS && LA141_2 <= KW_SUMMARY)||(LA141_2 >= KW_SYSTEM_TIME && LA141_2 <= KW_SYSTEM_VERSION)||LA141_2==KW_TABLES||(LA141_2 >= KW_TBLPROPERTIES && LA141_2 <= KW_TERMINATED)||LA141_2==KW_TINYINT||LA141_2==KW_TOUCH||(LA141_2 >= KW_TRANSACTION && LA141_2 <= KW_TRANSACTIONS)||LA141_2==KW_TRIM||(LA141_2 >= KW_TYPE && LA141_2 <= KW_UNARCHIVE)||LA141_2==KW_UNDO||LA141_2==KW_UNIONTYPE||(LA141_2 >= KW_UNKNOWN && LA141_2 <= KW_UNSIGNED)||(LA141_2 >= KW_URI && LA141_2 <= KW_USE)||(LA141_2 >= KW_UTC && LA141_2 <= KW_VALIDATE)||LA141_2==KW_VALUE_TYPE||(LA141_2 >= KW_VECTORIZATION && LA141_2 <= KW_WEEK)||LA141_2==KW_WHILE||(LA141_2 >= KW_WITHIN && LA141_2 <= KW_ZONE)||LA141_2==KW_BATCH||LA141_2==KW_DAYOFWEEK||LA141_2==KW_HOLD_DDLTIME||LA141_2==KW_NO_DROP||LA141_2==KW_OFFLINE||LA141_2==KW_PROTECTION||LA141_2==KW_READONLY||LA141_2==KW_TIMESTAMPTZ) ) {
					alt141=1;
				}
				else if ( (LA141_2==EOF||LA141_2==DOT||LA141_2==KW_PARTITION||LA141_2==LPAREN) ) {
					alt141=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 141, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AST:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DCPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPIRE_SNAPSHOTS:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_ID:
			case KW_IDXPROPERTIES:
			case KW_IGNORE:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGED:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_REMOTE:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESPECT:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SPEC:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_SYSTEM_TIME:
			case KW_SYSTEM_VERSION:
			case KW_TABLE:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_TRIM:
			case KW_TYPE:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNKNOWN:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URL:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WITHIN:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt141=2;
				}
				break;
			case KW_URI:
				{
				int LA141_5 = input.LA(2);
				if ( (LA141_5==EOF||LA141_5==DOT||LA141_5==KW_PARTITION||LA141_5==LPAREN) ) {
					alt141=2;
				}
				else if ( (LA141_5==StringLiteral) ) {
					alt141=3;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 141, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_SERVER:
				{
				int LA141_6 = input.LA(2);
				if ( (LA141_6==EOF||LA141_6==DOT||LA141_6==KW_PARTITION||LA141_6==LPAREN) ) {
					alt141=2;
				}
				else if ( (LA141_6==Identifier||(LA141_6 >= KW_ABORT && LA141_6 <= KW_AFTER)||LA141_6==KW_ALLOC_FRACTION||LA141_6==KW_ANALYZE||LA141_6==KW_ARCHIVE||(LA141_6 >= KW_ASC && LA141_6 <= KW_AT)||(LA141_6 >= KW_AUTOCOMMIT && LA141_6 <= KW_BEFORE)||(LA141_6 >= KW_BUCKET && LA141_6 <= KW_BUCKETS)||(LA141_6 >= KW_CACHE && LA141_6 <= KW_CASCADE)||(LA141_6 >= KW_CBO && LA141_6 <= KW_CHANGE)||(LA141_6 >= KW_CHECK && LA141_6 <= KW_COLLECTION)||(LA141_6 >= KW_COLUMNS && LA141_6 <= KW_COMMENT)||(LA141_6 >= KW_COMPACT && LA141_6 <= KW_CONCATENATE)||(LA141_6 >= KW_CONTINUE && LA141_6 <= KW_COST)||LA141_6==KW_CRON||LA141_6==KW_DATA||LA141_6==KW_DATABASES||(LA141_6 >= KW_DATETIME && LA141_6 <= KW_DCPROPERTIES)||LA141_6==KW_DEBUG||(LA141_6 >= KW_DEFAULT && LA141_6 <= KW_DEFINED)||(LA141_6 >= KW_DELIMITED && LA141_6 <= KW_DESC)||(LA141_6 >= KW_DETAIL && LA141_6 <= KW_DISABLE)||(LA141_6 >= KW_DISTRIBUTE && LA141_6 <= KW_DO)||LA141_6==KW_DOW||(LA141_6 >= KW_DUMP && LA141_6 <= KW_ELEM_TYPE)||LA141_6==KW_ENABLE||(LA141_6 >= KW_ENFORCED && LA141_6 <= KW_EVERY)||(LA141_6 >= KW_EXCLUSIVE && LA141_6 <= KW_EXECUTED)||(LA141_6 >= KW_EXPIRE_SNAPSHOTS && LA141_6 <= KW_EXPRESSION)||(LA141_6 >= KW_FIELDS && LA141_6 <= KW_FIRST)||(LA141_6 >= KW_FORMAT && LA141_6 <= KW_FORMATTED)||LA141_6==KW_FUNCTIONS||(LA141_6 >= KW_HOUR && LA141_6 <= KW_IDXPROPERTIES)||LA141_6==KW_IGNORE||(LA141_6 >= KW_INDEX && LA141_6 <= KW_INDEXES)||(LA141_6 >= KW_INPATH && LA141_6 <= KW_INPUTFORMAT)||(LA141_6 >= KW_ISOLATION && LA141_6 <= KW_JAR)||(LA141_6 >= KW_JOINCOST && LA141_6 <= KW_LAST)||LA141_6==KW_LEVEL||(LA141_6 >= KW_LIMIT && LA141_6 <= KW_LOAD)||(LA141_6 >= KW_LOCATION && LA141_6 <= KW_LONG)||(LA141_6 >= KW_MANAGED && LA141_6 <= KW_MANAGEMENT)||(LA141_6 >= KW_MAPJOIN && LA141_6 <= KW_MATERIALIZED)||LA141_6==KW_METADATA||(LA141_6 >= KW_MINUTE && LA141_6 <= KW_MONTH)||(LA141_6 >= KW_MOVE && LA141_6 <= KW_MSCK)||(LA141_6 >= KW_NORELY && LA141_6 <= KW_NOSCAN)||LA141_6==KW_NOVALIDATE||LA141_6==KW_NULLS||LA141_6==KW_OFFSET||(LA141_6 >= KW_OPERATOR && LA141_6 <= KW_OPTION)||(LA141_6 >= KW_OUTPUTDRIVER && LA141_6 <= KW_OUTPUTFORMAT)||(LA141_6 >= KW_OVERWRITE && LA141_6 <= KW_OWNER)||(LA141_6 >= KW_PARTITIONED && LA141_6 <= KW_PATH)||(LA141_6 >= KW_PLAN && LA141_6 <= KW_POOL)||LA141_6==KW_PRINCIPALS||LA141_6==KW_PURGE||(LA141_6 >= KW_QUARTER && LA141_6 <= KW_QUERY_PARALLELISM)||LA141_6==KW_READ||(LA141_6 >= KW_REBUILD && LA141_6 <= KW_RECORDWRITER)||(LA141_6 >= KW_RELOAD && LA141_6 <= KW_RESTRICT)||LA141_6==KW_REWRITE||(LA141_6 >= KW_ROLE && LA141_6 <= KW_ROLES)||(LA141_6 >= KW_SCHEDULED && LA141_6 <= KW_SECOND)||(LA141_6 >= KW_SEMI && LA141_6 <= KW_SERVER)||(LA141_6 >= KW_SETS && LA141_6 <= KW_SKEWED)||LA141_6==KW_SNAPSHOT||(LA141_6 >= KW_SORT && LA141_6 <= KW_SSL)||(LA141_6 >= KW_STATISTICS && LA141_6 <= KW_SUMMARY)||(LA141_6 >= KW_SYSTEM_TIME && LA141_6 <= KW_SYSTEM_VERSION)||LA141_6==KW_TABLES||(LA141_6 >= KW_TBLPROPERTIES && LA141_6 <= KW_TERMINATED)||LA141_6==KW_TINYINT||LA141_6==KW_TOUCH||(LA141_6 >= KW_TRANSACTION && LA141_6 <= KW_TRANSACTIONS)||LA141_6==KW_TRIM||(LA141_6 >= KW_TYPE && LA141_6 <= KW_UNARCHIVE)||LA141_6==KW_UNDO||LA141_6==KW_UNIONTYPE||(LA141_6 >= KW_UNKNOWN && LA141_6 <= KW_UNSIGNED)||(LA141_6 >= KW_URI && LA141_6 <= KW_USE)||(LA141_6 >= KW_UTC && LA141_6 <= KW_VALIDATE)||LA141_6==KW_VALUE_TYPE||(LA141_6 >= KW_VECTORIZATION && LA141_6 <= KW_WEEK)||LA141_6==KW_WHILE||(LA141_6 >= KW_WITHIN && LA141_6 <= KW_ZONE)||LA141_6==KW_BATCH||LA141_6==KW_DAYOFWEEK||LA141_6==KW_HOLD_DDLTIME||LA141_6==KW_NO_DROP||LA141_6==KW_OFFLINE||LA141_6==KW_PROTECTION||LA141_6==KW_READONLY||LA141_6==KW_TIMESTAMPTZ) ) {
					alt141=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 141, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 141, 0, input);
				throw nvae;
			}
			switch (alt141) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:7: ( KW_DATABASE | KW_SCHEMA ) identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:7: ( KW_DATABASE | KW_SCHEMA )
					int alt137=2;
					int LA137_0 = input.LA(1);
					if ( (LA137_0==KW_DATABASE) ) {
						alt137=1;
					}
					else if ( (LA137_0==KW_SCHEMA) ) {
						alt137=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 137, 0, input);
						throw nvae;
					}

					switch (alt137) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:8: KW_DATABASE
							{
							KW_DATABASE406=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privObjectCols7173); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DATABASE.add(KW_DATABASE406);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:20: KW_SCHEMA
							{
							KW_SCHEMA407=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_privObjectCols7175); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SCHEMA.add(KW_SCHEMA407);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_privObjectCols7178);
					identifier408=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier408.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1521:42: -> ^( TOK_DB_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1521:45: ^( TOK_DB_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DB_TYPE, "TOK_DB_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:7: ( KW_TABLE )? tableName ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:7: ( KW_TABLE )?
					int alt138=2;
					int LA138_0 = input.LA(1);
					if ( (LA138_0==KW_TABLE) ) {
						alt138=1;
					}
					switch (alt138) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:7: KW_TABLE
							{
							KW_TABLE409=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privObjectCols7194); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE409);

							}
							break;

					}

					pushFollow(FOLLOW_tableName_in_privObjectCols7197);
					tableName410=tableName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableName.add(tableName410.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:27: ( LPAREN cols= columnNameList RPAREN )?
					int alt139=2;
					int LA139_0 = input.LA(1);
					if ( (LA139_0==LPAREN) ) {
						alt139=1;
					}
					switch (alt139) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:28: LPAREN cols= columnNameList RPAREN
							{
							LPAREN411=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privObjectCols7200); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN411);

							pushFollow(FOLLOW_columnNameList_in_privObjectCols7204);
							cols=columnNameList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());
							RPAREN412=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privObjectCols7206); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN412);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:64: ( partitionSpec )?
					int alt140=2;
					int LA140_0 = input.LA(1);
					if ( (LA140_0==KW_PARTITION) ) {
						alt140=1;
					}
					switch (alt140) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:64: partitionSpec
							{
							pushFollow(FOLLOW_partitionSpec_in_privObjectCols7210);
							partitionSpec413=partitionSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSpec.add(partitionSpec413.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: cols, partitionSpec, tableName
					// token labels: 
					// rule labels: cols, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1522:79: -> ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:82: ^( TOK_TABLE_TYPE tableName ( $cols)? ( partitionSpec )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLE_TYPE, "TOK_TABLE_TYPE"), root_1);
						adaptor.addChild(root_1, stream_tableName.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:110: ( $cols)?
						if ( stream_cols.hasNext() ) {
							adaptor.addChild(root_1, stream_cols.nextTree());
						}
						stream_cols.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:116: ( partitionSpec )?
						if ( stream_partitionSpec.hasNext() ) {
							adaptor.addChild(root_1, stream_partitionSpec.nextTree());
						}
						stream_partitionSpec.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1523:7: KW_URI (path= StringLiteral )
					{
					KW_URI414=(Token)match(input,KW_URI,FOLLOW_KW_URI_in_privObjectCols7234); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_URI.add(KW_URI414);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1523:14: (path= StringLiteral )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1523:15: path= StringLiteral
					{
					path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_privObjectCols7239); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(path);

					}

					// AST REWRITE
					// elements: path
					// token labels: path
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1523:35: -> ^( TOK_URI_TYPE $path)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1523:39: ^( TOK_URI_TYPE $path)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_URI_TYPE, "TOK_URI_TYPE"), root_1);
						adaptor.addChild(root_1, stream_path.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:7: KW_SERVER identifier
					{
					KW_SERVER415=(Token)match(input,KW_SERVER,FOLLOW_KW_SERVER_in_privObjectCols7258); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERVER.add(KW_SERVER415);

					pushFollow(FOLLOW_identifier_in_privObjectCols7260);
					identifier416=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier416.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1524:28: -> ^( TOK_SERVER_TYPE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1524:31: ^( TOK_SERVER_TYPE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERVER_TYPE, "TOK_SERVER_TYPE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privObjectCols"


	public static class privilegeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
	public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
		HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA418=null;
		ParserRuleReturnScope privlegeDef417 =null;
		ParserRuleReturnScope privlegeDef419 =null;

		ASTNode COMMA418_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_privlegeDef=new RewriteRuleSubtreeStream(adaptor,"rule privlegeDef");

		pushMsg("grant privilege list", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:7: privlegeDef ( COMMA privlegeDef )*
			{
			pushFollow(FOLLOW_privlegeDef_in_privilegeList7295);
			privlegeDef417=privlegeDef();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef417.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:19: ( COMMA privlegeDef )*
			loop142:
			while (true) {
				int alt142=2;
				int LA142_0 = input.LA(1);
				if ( (LA142_0==COMMA) ) {
					alt142=1;
				}

				switch (alt142) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1530:20: COMMA privlegeDef
					{
					COMMA418=(Token)match(input,COMMA,FOLLOW_COMMA_in_privilegeList7298); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA418);

					pushFollow(FOLLOW_privlegeDef_in_privilegeList7300);
					privlegeDef419=privlegeDef();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_privlegeDef.add(privlegeDef419.getTree());
					}
					break;

				default :
					break loop142;
				}
			}

			// AST REWRITE
			// elements: privlegeDef
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1531:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1531:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST"), root_1);
				if ( !(stream_privlegeDef.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_privlegeDef.hasNext() ) {
					adaptor.addChild(root_1, stream_privlegeDef.nextTree());
				}
				stream_privlegeDef.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeList"


	public static class privlegeDef_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privlegeDef"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1534:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
	public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
		HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN421=null;
		Token RPAREN422=null;
		ParserRuleReturnScope cols =null;
		ParserRuleReturnScope privilegeType420 =null;

		ASTNode LPAREN421_tree=null;
		ASTNode RPAREN422_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_privilegeType=new RewriteRuleSubtreeStream(adaptor,"rule privilegeType");

		pushMsg("grant privilege", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1537:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1537:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
			{
			pushFollow(FOLLOW_privilegeType_in_privlegeDef7342);
			privilegeType420=privilegeType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_privilegeType.add(privilegeType420.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1537:21: ( LPAREN cols= columnNameList RPAREN )?
			int alt143=2;
			int LA143_0 = input.LA(1);
			if ( (LA143_0==LPAREN) ) {
				alt143=1;
			}
			switch (alt143) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1537:22: LPAREN cols= columnNameList RPAREN
					{
					LPAREN421=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privlegeDef7345); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN421);

					pushFollow(FOLLOW_columnNameList_in_privlegeDef7349);
					cols=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(cols.getTree());
					RPAREN422=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privlegeDef7351); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN422);

					}
					break;

			}

			// AST REWRITE
			// elements: cols, privilegeType
			// token labels: 
			// rule labels: cols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1538:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1538:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE"), root_1);
				adaptor.addChild(root_1, stream_privilegeType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1538:39: ( $cols)?
				if ( stream_cols.hasNext() ) {
					adaptor.addChild(root_1, stream_cols.nextTree());
				}
				stream_cols.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privlegeDef"


	public static class privilegeType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "privilegeType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1541:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) );
	public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
		HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALL423=null;
		Token KW_ALTER424=null;
		Token KW_UPDATE425=null;
		Token KW_CREATE426=null;
		Token KW_DROP427=null;
		Token KW_LOCK428=null;
		Token KW_SELECT429=null;
		Token KW_SHOW_DATABASE430=null;
		Token KW_INSERT431=null;
		Token KW_DELETE432=null;

		ASTNode KW_ALL423_tree=null;
		ASTNode KW_ALTER424_tree=null;
		ASTNode KW_UPDATE425_tree=null;
		ASTNode KW_CREATE426_tree=null;
		ASTNode KW_DROP427_tree=null;
		ASTNode KW_LOCK428_tree=null;
		ASTNode KW_SELECT429_tree=null;
		ASTNode KW_SHOW_DATABASE430_tree=null;
		ASTNode KW_INSERT431_tree=null;
		ASTNode KW_DELETE432_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_SHOW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_SHOW_DATABASE");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_SELECT=new RewriteRuleTokenStream(adaptor,"token KW_SELECT");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");

		pushMsg("privilege type", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) | KW_INSERT -> ^( TOK_PRIV_INSERT ) | KW_DELETE -> ^( TOK_PRIV_DELETE ) )
			int alt144=10;
			switch ( input.LA(1) ) {
			case KW_ALL:
				{
				alt144=1;
				}
				break;
			case KW_ALTER:
				{
				alt144=2;
				}
				break;
			case KW_UPDATE:
				{
				alt144=3;
				}
				break;
			case KW_CREATE:
				{
				alt144=4;
				}
				break;
			case KW_DROP:
				{
				alt144=5;
				}
				break;
			case KW_LOCK:
				{
				alt144=6;
				}
				break;
			case KW_SELECT:
				{
				alt144=7;
				}
				break;
			case KW_SHOW_DATABASE:
				{
				alt144=8;
				}
				break;
			case KW_INSERT:
				{
				alt144=9;
				}
				break;
			case KW_DELETE:
				{
				alt144=10;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 144, 0, input);
				throw nvae;
			}
			switch (alt144) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:7: KW_ALL
					{
					KW_ALL423=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeType7396); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL423);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1544:14: -> ^( TOK_PRIV_ALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1544:17: ^( TOK_PRIV_ALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:7: KW_ALTER
					{
					KW_ALTER424=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_privilegeType7410); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER424);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1545:16: -> ^( TOK_PRIV_ALTER_METADATA )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1545:19: ^( TOK_PRIV_ALTER_METADATA )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:7: KW_UPDATE
					{
					KW_UPDATE425=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_privilegeType7424); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE425);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1546:17: -> ^( TOK_PRIV_ALTER_DATA )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:20: ^( TOK_PRIV_ALTER_DATA )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:7: KW_CREATE
					{
					KW_CREATE426=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_privilegeType7438); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE426);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1547:17: -> ^( TOK_PRIV_CREATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1547:20: ^( TOK_PRIV_CREATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:7: KW_DROP
					{
					KW_DROP427=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_privilegeType7452); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP427);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1548:15: -> ^( TOK_PRIV_DROP )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1548:18: ^( TOK_PRIV_DROP )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:7: KW_LOCK
					{
					KW_LOCK428=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_privilegeType7466); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCK.add(KW_LOCK428);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1549:15: -> ^( TOK_PRIV_LOCK )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:18: ^( TOK_PRIV_LOCK )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:7: KW_SELECT
					{
					KW_SELECT429=(Token)match(input,KW_SELECT,FOLLOW_KW_SELECT_in_privilegeType7480); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SELECT.add(KW_SELECT429);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1550:17: -> ^( TOK_PRIV_SELECT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:20: ^( TOK_PRIV_SELECT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1551:7: KW_SHOW_DATABASE
					{
					KW_SHOW_DATABASE430=(Token)match(input,KW_SHOW_DATABASE,FOLLOW_KW_SHOW_DATABASE_in_privilegeType7494); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE430);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1551:24: -> ^( TOK_PRIV_SHOW_DATABASE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1551:27: ^( TOK_PRIV_SHOW_DATABASE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:7: KW_INSERT
					{
					KW_INSERT431=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_privilegeType7508); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT431);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1552:17: -> ^( TOK_PRIV_INSERT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:20: ^( TOK_PRIV_INSERT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_INSERT, "TOK_PRIV_INSERT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:7: KW_DELETE
					{
					KW_DELETE432=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_privilegeType7522); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE432);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1553:17: -> ^( TOK_PRIV_DELETE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1553:20: ^( TOK_PRIV_DELETE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRIV_DELETE, "TOK_PRIV_DELETE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "privilegeType"


	public static class principalSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "principalSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1556:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
	public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
		HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA434=null;
		ParserRuleReturnScope principalName433 =null;
		ParserRuleReturnScope principalName435 =null;

		ASTNode COMMA434_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");

		 pushMsg("user/group/role name list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:7: principalName ( COMMA principalName )*
			{
			pushFollow(FOLLOW_principalName_in_principalSpecification7555);
			principalName433=principalName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_principalName.add(principalName433.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:21: ( COMMA principalName )*
			loop145:
			while (true) {
				int alt145=2;
				int LA145_0 = input.LA(1);
				if ( (LA145_0==COMMA) ) {
					alt145=1;
				}

				switch (alt145) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:22: COMMA principalName
					{
					COMMA434=(Token)match(input,COMMA,FOLLOW_COMMA_in_principalSpecification7558); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA434);

					pushFollow(FOLLOW_principalName_in_principalSpecification7560);
					principalName435=principalName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalName.add(principalName435.getTree());
					}
					break;

				default :
					break loop145;
				}
			}

			// AST REWRITE
			// elements: principalName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1559:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME"), root_1);
				if ( !(stream_principalName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_principalName.hasNext() ) {
					adaptor.addChild(root_1, stream_principalName.nextTree());
				}
				stream_principalName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "principalSpecification"


	public static class principalName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "principalName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:1: principalName : ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
	public final HiveParser.principalName_return principalName() throws RecognitionException {
		HiveParser.principalName_return retval = new HiveParser.principalName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_USER436=null;
		Token KW_GROUP438=null;
		Token KW_ROLE440=null;
		ParserRuleReturnScope principalIdentifier437 =null;
		ParserRuleReturnScope principalIdentifier439 =null;
		ParserRuleReturnScope identifier441 =null;

		ASTNode KW_USER436_tree=null;
		ASTNode KW_GROUP438_tree=null;
		ASTNode KW_ROLE440_tree=null;
		RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
		RewriteRuleTokenStream stream_KW_USER=new RewriteRuleTokenStream(adaptor,"token KW_USER");
		RewriteRuleTokenStream stream_KW_GROUP=new RewriteRuleTokenStream(adaptor,"token KW_GROUP");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_principalIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule principalIdentifier");

		pushMsg("user|group|role name", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:5: ( KW_USER principalIdentifier -> ^( TOK_USER principalIdentifier ) | KW_GROUP principalIdentifier -> ^( TOK_GROUP principalIdentifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
			int alt146=3;
			switch ( input.LA(1) ) {
			case KW_USER:
				{
				alt146=1;
				}
				break;
			case KW_GROUP:
				{
				alt146=2;
				}
				break;
			case KW_ROLE:
				{
				alt146=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 146, 0, input);
				throw nvae;
			}
			switch (alt146) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:7: KW_USER principalIdentifier
					{
					KW_USER436=(Token)match(input,KW_USER,FOLLOW_KW_USER_in_principalName7598); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_USER.add(KW_USER436);

					pushFollow(FOLLOW_principalIdentifier_in_principalName7600);
					principalIdentifier437=principalIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier437.getTree());
					// AST REWRITE
					// elements: principalIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1565:35: -> ^( TOK_USER principalIdentifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:38: ^( TOK_USER principalIdentifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_USER, "TOK_USER"), root_1);
						adaptor.addChild(root_1, stream_principalIdentifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:7: KW_GROUP principalIdentifier
					{
					KW_GROUP438=(Token)match(input,KW_GROUP,FOLLOW_KW_GROUP_in_principalName7616); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_GROUP.add(KW_GROUP438);

					pushFollow(FOLLOW_principalIdentifier_in_principalName7618);
					principalIdentifier439=principalIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_principalIdentifier.add(principalIdentifier439.getTree());
					// AST REWRITE
					// elements: principalIdentifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1566:36: -> ^( TOK_GROUP principalIdentifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:39: ^( TOK_GROUP principalIdentifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GROUP, "TOK_GROUP"), root_1);
						adaptor.addChild(root_1, stream_principalIdentifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1567:7: KW_ROLE identifier
					{
					KW_ROLE440=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_principalName7634); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ROLE.add(KW_ROLE440);

					pushFollow(FOLLOW_identifier_in_principalName7636);
					identifier441=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier441.getTree());
					// AST REWRITE
					// elements: identifier
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1567:26: -> ^( TOK_ROLE identifier )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1567:29: ^( TOK_ROLE identifier )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ROLE, "TOK_ROLE"), root_1);
						adaptor.addChild(root_1, stream_identifier.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "principalName"


	public static class withGrantOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withGrantOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1570:1: withGrantOption : KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
	public final HiveParser.withGrantOption_return withGrantOption() throws RecognitionException {
		HiveParser.withGrantOption_return retval = new HiveParser.withGrantOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH442=null;
		Token KW_GRANT443=null;
		Token KW_OPTION444=null;

		ASTNode KW_WITH442_tree=null;
		ASTNode KW_GRANT443_tree=null;
		ASTNode KW_OPTION444_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

		pushMsg("with grant option", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:5: ( KW_WITH KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:7: KW_WITH KW_GRANT KW_OPTION
			{
			KW_WITH442=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withGrantOption7671); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH442);

			KW_GRANT443=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_withGrantOption7673); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT443);

			KW_OPTION444=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withGrantOption7675); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION444);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1574:5: -> ^( TOK_GRANT_WITH_OPTION )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1574:8: ^( TOK_GRANT_WITH_OPTION )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withGrantOption"


	public static class grantOptionFor_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "grantOptionFor"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:1: grantOptionFor : KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) ;
	public final HiveParser.grantOptionFor_return grantOptionFor() throws RecognitionException {
		HiveParser.grantOptionFor_return retval = new HiveParser.grantOptionFor_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_GRANT445=null;
		Token KW_OPTION446=null;
		Token KW_FOR447=null;

		ASTNode KW_GRANT445_tree=null;
		ASTNode KW_OPTION446_tree=null;
		ASTNode KW_FOR447_tree=null;
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");

		pushMsg("grant option for", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1580:5: ( KW_GRANT KW_OPTION KW_FOR -> ^( TOK_GRANT_OPTION_FOR ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1580:7: KW_GRANT KW_OPTION KW_FOR
			{
			KW_GRANT445=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantOptionFor7712); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_GRANT.add(KW_GRANT445);

			KW_OPTION446=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_grantOptionFor7714); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION446);

			KW_FOR447=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_grantOptionFor7716); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR447);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1581:5: -> ^( TOK_GRANT_OPTION_FOR )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:8: ^( TOK_GRANT_OPTION_FOR )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_OPTION_FOR, "TOK_GRANT_OPTION_FOR"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "grantOptionFor"


	public static class adminOptionFor_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "adminOptionFor"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1584:1: adminOptionFor : KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) ;
	public final HiveParser.adminOptionFor_return adminOptionFor() throws RecognitionException {
		HiveParser.adminOptionFor_return retval = new HiveParser.adminOptionFor_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ADMIN448=null;
		Token KW_OPTION449=null;
		Token KW_FOR450=null;

		ASTNode KW_ADMIN448_tree=null;
		ASTNode KW_OPTION449_tree=null;
		ASTNode KW_FOR450_tree=null;
		RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
		RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

		pushMsg("admin option for", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1587:5: ( KW_ADMIN KW_OPTION KW_FOR -> ^( TOK_ADMIN_OPTION_FOR ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1587:7: KW_ADMIN KW_OPTION KW_FOR
			{
			KW_ADMIN448=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_adminOptionFor7749); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN448);

			KW_OPTION449=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_adminOptionFor7751); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION449);

			KW_FOR450=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_adminOptionFor7753); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOR.add(KW_FOR450);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1588:5: -> ^( TOK_ADMIN_OPTION_FOR )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:8: ^( TOK_ADMIN_OPTION_FOR )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ADMIN_OPTION_FOR, "TOK_ADMIN_OPTION_FOR"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "adminOptionFor"


	public static class withAdminOption_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withAdminOption"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1591:1: withAdminOption : KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) ;
	public final HiveParser.withAdminOption_return withAdminOption() throws RecognitionException {
		HiveParser.withAdminOption_return retval = new HiveParser.withAdminOption_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH451=null;
		Token KW_ADMIN452=null;
		Token KW_OPTION453=null;

		ASTNode KW_WITH451_tree=null;
		ASTNode KW_ADMIN452_tree=null;
		ASTNode KW_OPTION453_tree=null;
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
		RewriteRuleTokenStream stream_KW_ADMIN=new RewriteRuleTokenStream(adaptor,"token KW_ADMIN");

		pushMsg("with admin option", state);
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1594:5: ( KW_WITH KW_ADMIN KW_OPTION -> ^( TOK_GRANT_WITH_ADMIN_OPTION ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1594:7: KW_WITH KW_ADMIN KW_OPTION
			{
			KW_WITH451=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withAdminOption7786); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH451);

			KW_ADMIN452=(Token)match(input,KW_ADMIN,FOLLOW_KW_ADMIN_in_withAdminOption7788); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ADMIN.add(KW_ADMIN452);

			KW_OPTION453=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withAdminOption7790); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_OPTION.add(KW_OPTION453);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1595:5: -> ^( TOK_GRANT_WITH_ADMIN_OPTION )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1595:8: ^( TOK_GRANT_WITH_ADMIN_OPTION )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_GRANT_WITH_ADMIN_OPTION, "TOK_GRANT_WITH_ADMIN_OPTION"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) {popMsg(state);}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withAdminOption"


	public static class metastoreCheck_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "metastoreCheck"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1598:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName (opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )? )? ) -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $opt)? ( partitionSelectorSpec )? ) ;
	public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
		HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token repair=null;
		Token opt=null;
		Token parts=null;
		Token KW_MSCK454=null;
		Token KW_TABLE455=null;
		ParserRuleReturnScope tableName456 =null;
		ParserRuleReturnScope partitionSelectorSpec457 =null;

		ASTNode repair_tree=null;
		ASTNode opt_tree=null;
		ASTNode parts_tree=null;
		ASTNode KW_MSCK454_tree=null;
		ASTNode KW_TABLE455_tree=null;
		RewriteRuleTokenStream stream_KW_REPAIR=new RewriteRuleTokenStream(adaptor,"token KW_REPAIR");
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SYNC=new RewriteRuleTokenStream(adaptor,"token KW_SYNC");
		RewriteRuleTokenStream stream_KW_MSCK=new RewriteRuleTokenStream(adaptor,"token KW_MSCK");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
		RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
		RewriteRuleSubtreeStream stream_partitionSelectorSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSelectorSpec");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("metastore check statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName (opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )? )? ) -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $opt)? ( partitionSelectorSpec )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE tableName (opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )? )? )
			{
			KW_MSCK454=(Token)match(input,KW_MSCK,FOLLOW_KW_MSCK_in_metastoreCheck7827); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MSCK.add(KW_MSCK454);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:15: (repair= KW_REPAIR )?
			int alt147=2;
			int LA147_0 = input.LA(1);
			if ( (LA147_0==KW_REPAIR) ) {
				alt147=1;
			}
			switch (alt147) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:16: repair= KW_REPAIR
					{
					repair=(Token)match(input,KW_REPAIR,FOLLOW_KW_REPAIR_in_metastoreCheck7832); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REPAIR.add(repair);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:7: ( KW_TABLE tableName (opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )? )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1602:8: KW_TABLE tableName (opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )? )?
			{
			KW_TABLE455=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_metastoreCheck7843); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE455);

			pushFollow(FOLLOW_tableName_in_metastoreCheck7845);
			tableName456=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName456.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:9: (opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )? )?
			int alt150=2;
			int LA150_0 = input.LA(1);
			if ( (LA150_0==KW_ADD||LA150_0==KW_DROP||LA150_0==KW_SYNC) ) {
				alt150=1;
			}
			switch (alt150) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:10: opt= ( KW_ADD | KW_DROP | KW_SYNC ) (parts= KW_PARTITIONS ) ( partitionSelectorSpec )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:14: ( KW_ADD | KW_DROP | KW_SYNC )
					int alt148=3;
					switch ( input.LA(1) ) {
					case KW_ADD:
						{
						alt148=1;
						}
						break;
					case KW_DROP:
						{
						alt148=2;
						}
						break;
					case KW_SYNC:
						{
						alt148=3;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 148, 0, input);
						throw nvae;
					}
					switch (alt148) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:15: KW_ADD
							{
							opt=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_metastoreCheck7859); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_ADD.add(opt);

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:22: KW_DROP
							{
							opt=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_metastoreCheck7861); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DROP.add(opt);

							}
							break;
						case 3 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:30: KW_SYNC
							{
							opt=(Token)match(input,KW_SYNC,FOLLOW_KW_SYNC_in_metastoreCheck7863); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SYNC.add(opt);

							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:39: (parts= KW_PARTITIONS )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:40: parts= KW_PARTITIONS
					{
					parts=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_metastoreCheck7869); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PARTITIONS.add(parts);

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:61: ( partitionSelectorSpec )?
					int alt149=2;
					int LA149_0 = input.LA(1);
					if ( (LA149_0==LPAREN) ) {
						alt149=1;
					}
					switch (alt149) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1603:62: partitionSelectorSpec
							{
							pushFollow(FOLLOW_partitionSelectorSpec_in_metastoreCheck7873);
							partitionSelectorSpec457=partitionSelectorSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_partitionSelectorSpec.add(partitionSelectorSpec457.getTree());
							}
							break;

					}

					}
					break;

			}

			}

			// AST REWRITE
			// elements: repair, tableName, opt, partitionSelectorSpec
			// token labels: repair, opt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_repair=new RewriteRuleTokenStream(adaptor,"token repair",repair);
			RewriteRuleTokenStream stream_opt=new RewriteRuleTokenStream(adaptor,"token opt",opt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1604:5: -> ^( TOK_MSCK ( $repair)? ( tableName )? ( $opt)? ( partitionSelectorSpec )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:8: ^( TOK_MSCK ( $repair)? ( tableName )? ( $opt)? ( partitionSelectorSpec )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MSCK, "TOK_MSCK"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:20: ( $repair)?
				if ( stream_repair.hasNext() ) {
					adaptor.addChild(root_1, stream_repair.nextNode());
				}
				stream_repair.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:28: ( tableName )?
				if ( stream_tableName.hasNext() ) {
					adaptor.addChild(root_1, stream_tableName.nextTree());
				}
				stream_tableName.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:40: ( $opt)?
				if ( stream_opt.hasNext() ) {
					adaptor.addChild(root_1, stream_opt.nextNode());
				}
				stream_opt.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:45: ( partitionSelectorSpec )?
				if ( stream_partitionSelectorSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_partitionSelectorSpec.nextTree());
				}
				stream_partitionSelectorSpec.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "metastoreCheck"


	public static class resourceList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resourceList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:1: resourceList : resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) ;
	public final HiveParser.resourceList_return resourceList() throws RecognitionException {
		HiveParser.resourceList_return retval = new HiveParser.resourceList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA459=null;
		ParserRuleReturnScope resource458 =null;
		ParserRuleReturnScope resource460 =null;

		ASTNode COMMA459_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_resource=new RewriteRuleSubtreeStream(adaptor,"rule resource");

		 pushMsg("resource list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:3: ( resource ( COMMA resource )* -> ^( TOK_RESOURCE_LIST ( resource )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:3: resource ( COMMA resource )*
			{
			pushFollow(FOLLOW_resource_in_resourceList7931);
			resource458=resource();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_resource.add(resource458.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:12: ( COMMA resource )*
			loop151:
			while (true) {
				int alt151=2;
				int LA151_0 = input.LA(1);
				if ( (LA151_0==COMMA) ) {
					alt151=1;
				}

				switch (alt151) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:13: COMMA resource
					{
					COMMA459=(Token)match(input,COMMA,FOLLOW_COMMA_in_resourceList7934); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA459);

					pushFollow(FOLLOW_resource_in_resourceList7936);
					resource460=resource();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_resource.add(resource460.getTree());
					}
					break;

				default :
					break loop151;
				}
			}

			// AST REWRITE
			// elements: resource
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1611:30: -> ^( TOK_RESOURCE_LIST ( resource )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:33: ^( TOK_RESOURCE_LIST ( resource )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_LIST, "TOK_RESOURCE_LIST"), root_1);
				if ( !(stream_resource.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_resource.hasNext() ) {
					adaptor.addChild(root_1, stream_resource.nextTree());
				}
				stream_resource.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resourceList"


	public static class resource_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resource"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:1: resource : resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) ;
	public final HiveParser.resource_return resource() throws RecognitionException {
		HiveParser.resource_return retval = new HiveParser.resource_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token resPath=null;
		ParserRuleReturnScope resType =null;

		ASTNode resPath_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleSubtreeStream stream_resourceType=new RewriteRuleSubtreeStream(adaptor,"rule resourceType");

		 pushMsg("resource", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1617:3: (resType= resourceType resPath= StringLiteral -> ^( TOK_RESOURCE_URI $resType $resPath) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:3: resType= resourceType resPath= StringLiteral
			{
			pushFollow(FOLLOW_resourceType_in_resource7974);
			resType=resourceType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_resourceType.add(resType.getTree());
			resPath=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_resource7978); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(resPath);

			// AST REWRITE
			// elements: resType, resPath
			// token labels: resPath
			// rule labels: resType, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_resPath=new RewriteRuleTokenStream(adaptor,"token resPath",resPath);
			RewriteRuleSubtreeStream stream_resType=new RewriteRuleSubtreeStream(adaptor,"rule resType",resType!=null?resType.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1618:46: -> ^( TOK_RESOURCE_URI $resType $resPath)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:49: ^( TOK_RESOURCE_URI $resType $resPath)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RESOURCE_URI, "TOK_RESOURCE_URI"), root_1);
				adaptor.addChild(root_1, stream_resType.nextTree());
				adaptor.addChild(root_1, stream_resPath.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resource"


	public static class resourceType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "resourceType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:1: resourceType : ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) );
	public final HiveParser.resourceType_return resourceType() throws RecognitionException {
		HiveParser.resourceType_return retval = new HiveParser.resourceType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_JAR461=null;
		Token KW_FILE462=null;
		Token KW_ARCHIVE463=null;

		ASTNode KW_JAR461_tree=null;
		ASTNode KW_FILE462_tree=null;
		ASTNode KW_ARCHIVE463_tree=null;
		RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
		RewriteRuleTokenStream stream_KW_JAR=new RewriteRuleTokenStream(adaptor,"token KW_JAR");
		RewriteRuleTokenStream stream_KW_FILE=new RewriteRuleTokenStream(adaptor,"token KW_FILE");

		 pushMsg("resource type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1624:3: ( KW_JAR -> ^( TOK_JAR ) | KW_FILE -> ^( TOK_FILE ) | KW_ARCHIVE -> ^( TOK_ARCHIVE ) )
			int alt152=3;
			switch ( input.LA(1) ) {
			case KW_JAR:
				{
				alt152=1;
				}
				break;
			case KW_FILE:
				{
				alt152=2;
				}
				break;
			case KW_ARCHIVE:
				{
				alt152=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 152, 0, input);
				throw nvae;
			}
			switch (alt152) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:3: KW_JAR
					{
					KW_JAR461=(Token)match(input,KW_JAR,FOLLOW_KW_JAR_in_resourceType8015); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_JAR.add(KW_JAR461);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1625:10: -> ^( TOK_JAR )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:13: ^( TOK_JAR )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_JAR, "TOK_JAR"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1627:3: KW_FILE
					{
					KW_FILE462=(Token)match(input,KW_FILE,FOLLOW_KW_FILE_in_resourceType8029); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FILE.add(KW_FILE462);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1627:11: -> ^( TOK_FILE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1627:14: ^( TOK_FILE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILE, "TOK_FILE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:3: KW_ARCHIVE
					{
					KW_ARCHIVE463=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_resourceType8043); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ARCHIVE.add(KW_ARCHIVE463);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1629:14: -> ^( TOK_ARCHIVE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1629:17: ^( TOK_ARCHIVE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ARCHIVE, "TOK_ARCHIVE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "resourceType"


	public static class createFunctionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createFunctionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1632:1: createFunctionStatement : KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) ;
	public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
		HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token KW_CREATE464=null;
		Token KW_FUNCTION465=null;
		Token KW_AS467=null;
		Token StringLiteral468=null;
		Token KW_USING469=null;
		ParserRuleReturnScope rList =null;
		ParserRuleReturnScope functionIdentifier466 =null;

		ASTNode temp_tree=null;
		ASTNode KW_CREATE464_tree=null;
		ASTNode KW_FUNCTION465_tree=null;
		ASTNode KW_AS467_tree=null;
		ASTNode StringLiteral468_tree=null;
		ASTNode KW_USING469_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");
		RewriteRuleSubtreeStream stream_resourceList=new RewriteRuleSubtreeStream(adaptor,"rule resourceList");

		 pushMsg("create function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:5: ( KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )? -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY ) -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:7: KW_CREATE (temp= KW_TEMPORARY )? KW_FUNCTION functionIdentifier KW_AS StringLiteral ( KW_USING rList= resourceList )?
			{
			KW_CREATE464=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createFunctionStatement8074); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE464);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:17: (temp= KW_TEMPORARY )?
			int alt153=2;
			int LA153_0 = input.LA(1);
			if ( (LA153_0==KW_TEMPORARY) ) {
				alt153=1;
			}
			switch (alt153) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1635:18: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createFunctionStatement8079); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			KW_FUNCTION465=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_createFunctionStatement8083); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION465);

			pushFollow(FOLLOW_functionIdentifier_in_createFunctionStatement8085);
			functionIdentifier466=functionIdentifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier466.getTree());
			KW_AS467=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createFunctionStatement8087); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS467);

			StringLiteral468=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createFunctionStatement8089); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral468);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1636:7: ( KW_USING rList= resourceList )?
			int alt154=2;
			int LA154_0 = input.LA(1);
			if ( (LA154_0==KW_USING) ) {
				alt154=1;
			}
			switch (alt154) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1636:8: KW_USING rList= resourceList
					{
					KW_USING469=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_createFunctionStatement8098); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING469);

					pushFollow(FOLLOW_resourceList_in_createFunctionStatement8102);
					rList=resourceList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_resourceList.add(rList.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: StringLiteral, rList, rList, StringLiteral, functionIdentifier, functionIdentifier
			// token labels: 
			// rule labels: rList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_rList=new RewriteRuleSubtreeStream(adaptor,"rule rList",rList!=null?rList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1637:5: -> {$temp != null}? ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
			if (temp != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? TOK_TEMPORARY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:80: ( $rList)?
				if ( stream_rList.hasNext() ) {
					adaptor.addChild(root_1, stream_rList.nextTree());
				}
				stream_rList.reset();

				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1638:5: -> ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1638:25: ^( TOK_CREATEFUNCTION functionIdentifier StringLiteral ( $rList)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1638:80: ( $rList)?
				if ( stream_rList.hasNext() ) {
					adaptor.addChild(root_1, stream_rList.nextTree());
				}
				stream_rList.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createFunctionStatement"


	public static class dropFunctionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropFunctionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1641:1: dropFunctionStatement : KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) ;
	public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
		HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token temp=null;
		Token KW_DROP470=null;
		Token KW_FUNCTION471=null;
		ParserRuleReturnScope ifExists472 =null;
		ParserRuleReturnScope functionIdentifier473 =null;

		ASTNode temp_tree=null;
		ASTNode KW_DROP470_tree=null;
		ASTNode KW_FUNCTION471_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
		RewriteRuleSubtreeStream stream_functionIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule functionIdentifier");

		 pushMsg("drop function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:5: ( KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY ) -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:7: KW_DROP (temp= KW_TEMPORARY )? KW_FUNCTION ( ifExists )? functionIdentifier
			{
			KW_DROP470=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropFunctionStatement8188); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP470);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:15: (temp= KW_TEMPORARY )?
			int alt155=2;
			int LA155_0 = input.LA(1);
			if ( (LA155_0==KW_TEMPORARY) ) {
				alt155=1;
			}
			switch (alt155) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:16: temp= KW_TEMPORARY
					{
					temp=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropFunctionStatement8193); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(temp);

					}
					break;

			}

			KW_FUNCTION471=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_dropFunctionStatement8197); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION471);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:48: ( ifExists )?
			int alt156=2;
			int LA156_0 = input.LA(1);
			if ( (LA156_0==KW_IF) ) {
				alt156=1;
			}
			switch (alt156) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1644:48: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropFunctionStatement8199);
					ifExists472=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists472.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_functionIdentifier_in_dropFunctionStatement8202);
			functionIdentifier473=functionIdentifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_functionIdentifier.add(functionIdentifier473.getTree());
			// AST REWRITE
			// elements: functionIdentifier, ifExists, functionIdentifier, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1645:5: -> {$temp != null}? ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
			if (temp != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? TOK_TEMPORARY )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1645:63: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_TEMPORARY, "TOK_TEMPORARY"));
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 1646:5: -> ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1646:25: ^( TOK_DROPFUNCTION functionIdentifier ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION"), root_1);
				adaptor.addChild(root_1, stream_functionIdentifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1646:63: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropFunctionStatement"


	public static class reloadFunctionsStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "reloadFunctionsStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1649:1: reloadFunctionsStatement : KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION ) -> ^( TOK_RELOADFUNCTIONS ) ;
	public final HiveParser.reloadFunctionsStatement_return reloadFunctionsStatement() throws RecognitionException {
		HiveParser.reloadFunctionsStatement_return retval = new HiveParser.reloadFunctionsStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RELOAD474=null;
		Token KW_FUNCTIONS475=null;
		Token KW_FUNCTION476=null;

		ASTNode KW_RELOAD474_tree=null;
		ASTNode KW_FUNCTIONS475_tree=null;
		ASTNode KW_FUNCTION476_tree=null;
		RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
		RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
		RewriteRuleTokenStream stream_KW_RELOAD=new RewriteRuleTokenStream(adaptor,"token KW_RELOAD");

		 pushMsg("reload functions statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1652:5: ( KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION ) -> ^( TOK_RELOADFUNCTIONS ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1652:7: KW_RELOAD ( KW_FUNCTIONS | KW_FUNCTION )
			{
			KW_RELOAD474=(Token)match(input,KW_RELOAD,FOLLOW_KW_RELOAD_in_reloadFunctionsStatement8280); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_RELOAD.add(KW_RELOAD474);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1652:17: ( KW_FUNCTIONS | KW_FUNCTION )
			int alt157=2;
			int LA157_0 = input.LA(1);
			if ( (LA157_0==KW_FUNCTIONS) ) {
				alt157=1;
			}
			else if ( (LA157_0==KW_FUNCTION) ) {
				alt157=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 157, 0, input);
				throw nvae;
			}

			switch (alt157) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1652:18: KW_FUNCTIONS
					{
					KW_FUNCTIONS475=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement8283); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTIONS.add(KW_FUNCTIONS475);

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1652:31: KW_FUNCTION
					{
					KW_FUNCTION476=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement8285); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FUNCTION.add(KW_FUNCTION476);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1652:44: -> ^( TOK_RELOADFUNCTIONS )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1652:47: ^( TOK_RELOADFUNCTIONS )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RELOADFUNCTIONS, "TOK_RELOADFUNCTIONS"), root_1);
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "reloadFunctionsStatement"


	public static class createMacroStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createMacroStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1654:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
	public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
		HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE477=null;
		Token KW_TEMPORARY478=null;
		Token KW_MACRO479=null;
		Token Identifier480=null;
		Token LPAREN481=null;
		Token RPAREN483=null;
		ParserRuleReturnScope columnNameTypeList482 =null;
		ParserRuleReturnScope expression484 =null;

		ASTNode KW_CREATE477_tree=null;
		ASTNode KW_TEMPORARY478_tree=null;
		ASTNode KW_MACRO479_tree=null;
		ASTNode Identifier480_tree=null;
		ASTNode LPAREN481_tree=null;
		ASTNode RPAREN483_tree=null;
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");

		 pushMsg("create macro statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1657:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
			{
			KW_CREATE477=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMacroStatement8314); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE477);

			KW_TEMPORARY478=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createMacroStatement8316); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY478);

			KW_MACRO479=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_createMacroStatement8318); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO479);

			Identifier480=(Token)match(input,Identifier,FOLLOW_Identifier_in_createMacroStatement8320); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Identifier.add(Identifier480);

			LPAREN481=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createMacroStatement8328); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN481);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:14: ( columnNameTypeList )?
			int alt158=2;
			int LA158_0 = input.LA(1);
			if ( (LA158_0==Identifier||(LA158_0 >= KW_ABORT && LA158_0 <= KW_AFTER)||LA158_0==KW_ALLOC_FRACTION||LA158_0==KW_ANALYZE||LA158_0==KW_ARCHIVE||(LA158_0 >= KW_ASC && LA158_0 <= KW_AT)||(LA158_0 >= KW_AUTOCOMMIT && LA158_0 <= KW_BEFORE)||(LA158_0 >= KW_BUCKET && LA158_0 <= KW_BUCKETS)||(LA158_0 >= KW_CACHE && LA158_0 <= KW_CASCADE)||(LA158_0 >= KW_CBO && LA158_0 <= KW_CHANGE)||(LA158_0 >= KW_CHECK && LA158_0 <= KW_COLLECTION)||(LA158_0 >= KW_COLUMNS && LA158_0 <= KW_COMMENT)||(LA158_0 >= KW_COMPACT && LA158_0 <= KW_CONCATENATE)||(LA158_0 >= KW_CONTINUE && LA158_0 <= KW_COST)||LA158_0==KW_CRON||LA158_0==KW_DATA||LA158_0==KW_DATABASES||(LA158_0 >= KW_DATETIME && LA158_0 <= KW_DCPROPERTIES)||LA158_0==KW_DEBUG||(LA158_0 >= KW_DEFAULT && LA158_0 <= KW_DEFINED)||(LA158_0 >= KW_DELIMITED && LA158_0 <= KW_DESC)||(LA158_0 >= KW_DETAIL && LA158_0 <= KW_DISABLE)||(LA158_0 >= KW_DISTRIBUTE && LA158_0 <= KW_DO)||LA158_0==KW_DOW||(LA158_0 >= KW_DUMP && LA158_0 <= KW_ELEM_TYPE)||LA158_0==KW_ENABLE||(LA158_0 >= KW_ENFORCED && LA158_0 <= KW_EVERY)||(LA158_0 >= KW_EXCLUSIVE && LA158_0 <= KW_EXECUTED)||(LA158_0 >= KW_EXPIRE_SNAPSHOTS && LA158_0 <= KW_EXPRESSION)||(LA158_0 >= KW_FIELDS && LA158_0 <= KW_FIRST)||(LA158_0 >= KW_FORMAT && LA158_0 <= KW_FORMATTED)||LA158_0==KW_FUNCTIONS||(LA158_0 >= KW_HOUR && LA158_0 <= KW_IDXPROPERTIES)||LA158_0==KW_IGNORE||(LA158_0 >= KW_INDEX && LA158_0 <= KW_INDEXES)||(LA158_0 >= KW_INPATH && LA158_0 <= KW_INPUTFORMAT)||(LA158_0 >= KW_ISOLATION && LA158_0 <= KW_JAR)||(LA158_0 >= KW_JOINCOST && LA158_0 <= KW_LAST)||LA158_0==KW_LEVEL||(LA158_0 >= KW_LIMIT && LA158_0 <= KW_LOAD)||(LA158_0 >= KW_LOCATION && LA158_0 <= KW_LONG)||(LA158_0 >= KW_MANAGED && LA158_0 <= KW_MANAGEMENT)||(LA158_0 >= KW_MAPJOIN && LA158_0 <= KW_MATERIALIZED)||LA158_0==KW_METADATA||(LA158_0 >= KW_MINUTE && LA158_0 <= KW_MONTH)||(LA158_0 >= KW_MOVE && LA158_0 <= KW_MSCK)||(LA158_0 >= KW_NORELY && LA158_0 <= KW_NOSCAN)||LA158_0==KW_NOVALIDATE||LA158_0==KW_NULLS||LA158_0==KW_OFFSET||(LA158_0 >= KW_OPERATOR && LA158_0 <= KW_OPTION)||(LA158_0 >= KW_OUTPUTDRIVER && LA158_0 <= KW_OUTPUTFORMAT)||(LA158_0 >= KW_OVERWRITE && LA158_0 <= KW_OWNER)||(LA158_0 >= KW_PARTITIONED && LA158_0 <= KW_PATH)||(LA158_0 >= KW_PLAN && LA158_0 <= KW_POOL)||LA158_0==KW_PRINCIPALS||LA158_0==KW_PURGE||(LA158_0 >= KW_QUARTER && LA158_0 <= KW_QUERY_PARALLELISM)||LA158_0==KW_READ||(LA158_0 >= KW_REBUILD && LA158_0 <= KW_RECORDWRITER)||(LA158_0 >= KW_RELOAD && LA158_0 <= KW_RESTRICT)||LA158_0==KW_REWRITE||(LA158_0 >= KW_ROLE && LA158_0 <= KW_ROLES)||(LA158_0 >= KW_SCHEDULED && LA158_0 <= KW_SECOND)||(LA158_0 >= KW_SEMI && LA158_0 <= KW_SERVER)||(LA158_0 >= KW_SETS && LA158_0 <= KW_SKEWED)||LA158_0==KW_SNAPSHOT||(LA158_0 >= KW_SORT && LA158_0 <= KW_SSL)||(LA158_0 >= KW_STATISTICS && LA158_0 <= KW_SUMMARY)||(LA158_0 >= KW_SYSTEM_TIME && LA158_0 <= KW_SYSTEM_VERSION)||LA158_0==KW_TABLES||(LA158_0 >= KW_TBLPROPERTIES && LA158_0 <= KW_TERMINATED)||LA158_0==KW_TINYINT||LA158_0==KW_TOUCH||(LA158_0 >= KW_TRANSACTION && LA158_0 <= KW_TRANSACTIONS)||LA158_0==KW_TRIM||(LA158_0 >= KW_TYPE && LA158_0 <= KW_UNARCHIVE)||LA158_0==KW_UNDO||LA158_0==KW_UNIONTYPE||(LA158_0 >= KW_UNKNOWN && LA158_0 <= KW_UNSIGNED)||(LA158_0 >= KW_URI && LA158_0 <= KW_USE)||(LA158_0 >= KW_UTC && LA158_0 <= KW_VALIDATE)||LA158_0==KW_VALUE_TYPE||(LA158_0 >= KW_VECTORIZATION && LA158_0 <= KW_WEEK)||LA158_0==KW_WHILE||(LA158_0 >= KW_WITHIN && LA158_0 <= KW_ZONE)||LA158_0==KW_BATCH||LA158_0==KW_DAYOFWEEK||LA158_0==KW_HOLD_DDLTIME||LA158_0==KW_NO_DROP||LA158_0==KW_OFFLINE||LA158_0==KW_PROTECTION||LA158_0==KW_READONLY||LA158_0==KW_TIMESTAMPTZ) ) {
				alt158=1;
			}
			switch (alt158) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1658:14: columnNameTypeList
					{
					pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement8330);
					columnNameTypeList482=columnNameTypeList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeList.add(columnNameTypeList482.getTree());
					}
					break;

			}

			RPAREN483=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createMacroStatement8333); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN483);

			pushFollow(FOLLOW_expression_in_createMacroStatement8335);
			expression484=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression484.getTree());
			// AST REWRITE
			// elements: Identifier, expression, columnNameTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1659:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1659:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO"), root_1);
				adaptor.addChild(root_1, stream_Identifier.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1659:37: ( columnNameTypeList )?
				if ( stream_columnNameTypeList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());
				}
				stream_columnNameTypeList.reset();

				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createMacroStatement"


	public static class dropMacroStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropMacroStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1662:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
	public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
		HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP485=null;
		Token KW_TEMPORARY486=null;
		Token KW_MACRO487=null;
		Token Identifier489=null;
		ParserRuleReturnScope ifExists488 =null;

		ASTNode KW_DROP485_tree=null;
		ASTNode KW_TEMPORARY486_tree=null;
		ASTNode KW_MACRO487_tree=null;
		ASTNode Identifier489_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
		RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
		RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop macro statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
			{
			KW_DROP485=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMacroStatement8379); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP485);

			KW_TEMPORARY486=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropMacroStatement8381); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TEMPORARY.add(KW_TEMPORARY486);

			KW_MACRO487=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_dropMacroStatement8383); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MACRO.add(KW_MACRO487);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:37: ( ifExists )?
			int alt159=2;
			int LA159_0 = input.LA(1);
			if ( (LA159_0==KW_IF) ) {
				alt159=1;
			}
			switch (alt159) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1665:37: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropMacroStatement8385);
					ifExists488=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists488.getTree());
					}
					break;

			}

			Identifier489=(Token)match(input,Identifier,FOLLOW_Identifier_in_dropMacroStatement8388); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Identifier.add(Identifier489);

			// AST REWRITE
			// elements: Identifier, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1666:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1666:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO"), root_1);
				adaptor.addChild(root_1, stream_Identifier.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1666:35: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropMacroStatement"


	public static class createViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1669:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
	public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
		HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE490=null;
		Token KW_VIEW492=null;
		Token LPAREN494=null;
		Token RPAREN496=null;
		Token KW_AS500=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope orReplace491 =null;
		ParserRuleReturnScope ifNotExists493 =null;
		ParserRuleReturnScope columnNameCommentList495 =null;
		ParserRuleReturnScope tableComment497 =null;
		ParserRuleReturnScope viewPartition498 =null;
		ParserRuleReturnScope tablePropertiesPrefixed499 =null;
		ParserRuleReturnScope selectStatementWithCTE501 =null;

		ASTNode KW_CREATE490_tree=null;
		ASTNode KW_VIEW492_tree=null;
		ASTNode LPAREN494_tree=null;
		ASTNode RPAREN496_tree=null;
		ASTNode KW_AS500_tree=null;
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_columnNameCommentList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameCommentList");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_orReplace=new RewriteRuleSubtreeStream(adaptor,"rule orReplace");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");


		    pushMsg("create view statement", state);

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
			{
			KW_CREATE490=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createViewStatement8430); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE490);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:17: ( orReplace )?
			int alt160=2;
			int LA160_0 = input.LA(1);
			if ( (LA160_0==KW_OR) ) {
				alt160=1;
			}
			switch (alt160) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:18: orReplace
					{
					pushFollow(FOLLOW_orReplace_in_createViewStatement8433);
					orReplace491=orReplace();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orReplace.add(orReplace491.getTree());
					}
					break;

			}

			KW_VIEW492=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createViewStatement8437); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW492);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:38: ( ifNotExists )?
			int alt161=2;
			int LA161_0 = input.LA(1);
			if ( (LA161_0==KW_IF) ) {
				alt161=1;
			}
			switch (alt161) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:39: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createViewStatement8440);
					ifNotExists493=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists493.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createViewStatement8446);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:9: ( LPAREN columnNameCommentList RPAREN )?
			int alt162=2;
			int LA162_0 = input.LA(1);
			if ( (LA162_0==LPAREN) ) {
				alt162=1;
			}
			switch (alt162) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:10: LPAREN columnNameCommentList RPAREN
					{
					LPAREN494=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createViewStatement8457); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN494);

					pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement8459);
					columnNameCommentList495=columnNameCommentList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameCommentList.add(columnNameCommentList495.getTree());
					RPAREN496=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createViewStatement8461); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN496);

					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:48: ( tableComment )?
			int alt163=2;
			int LA163_0 = input.LA(1);
			if ( (LA163_0==KW_COMMENT) ) {
				alt163=1;
			}
			switch (alt163) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:48: tableComment
					{
					pushFollow(FOLLOW_tableComment_in_createViewStatement8465);
					tableComment497=tableComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableComment.add(tableComment497.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:62: ( viewPartition )?
			int alt164=2;
			int LA164_0 = input.LA(1);
			if ( (LA164_0==KW_PARTITIONED) ) {
				alt164=1;
			}
			switch (alt164) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:62: viewPartition
					{
					pushFollow(FOLLOW_viewPartition_in_createViewStatement8468);
					viewPartition498=viewPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition498.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1676:9: ( tablePropertiesPrefixed )?
			int alt165=2;
			int LA165_0 = input.LA(1);
			if ( (LA165_0==KW_TBLPROPERTIES) ) {
				alt165=1;
			}
			switch (alt165) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1676:9: tablePropertiesPrefixed
					{
					pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement8479);
					tablePropertiesPrefixed499=tablePropertiesPrefixed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed499.getTree());
					}
					break;

			}

			KW_AS500=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createViewStatement8490); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS500);

			pushFollow(FOLLOW_selectStatementWithCTE_in_createViewStatement8500);
			selectStatementWithCTE501=selectStatementWithCTE();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE501.getTree());
			// AST REWRITE
			// elements: tablePropertiesPrefixed, columnNameCommentList, selectStatementWithCTE, orReplace, viewPartition, name, ifNotExists, tableComment
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1679:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1679:31: ( orReplace )?
				if ( stream_orReplace.hasNext() ) {
					adaptor.addChild(root_1, stream_orReplace.nextTree());
				}
				stream_orReplace.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1680:10: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:10: ( columnNameCommentList )?
				if ( stream_columnNameCommentList.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());
				}
				stream_columnNameCommentList.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1682:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1683:10: ( viewPartition )?
				if ( stream_viewPartition.hasNext() ) {
					adaptor.addChild(root_1, stream_viewPartition.nextTree());
				}
				stream_viewPartition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1684:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createViewStatement"


	public static class viewPartition_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewPartition"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1689:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
	public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
		HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITIONED502=null;
		Token KW_ON503=null;
		Token LPAREN504=null;
		Token RPAREN506=null;
		ParserRuleReturnScope columnNameList505 =null;

		ASTNode KW_PARTITIONED502_tree=null;
		ASTNode KW_ON503_tree=null;
		ASTNode LPAREN504_tree=null;
		ASTNode RPAREN506_tree=null;
		RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1692:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
			{
			KW_PARTITIONED502=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_viewPartition8623); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED502);

			KW_ON503=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewPartition8625); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON503);

			LPAREN504=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewPartition8627); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN504);

			pushFollow(FOLLOW_columnNameList_in_viewPartition8629);
			columnNameList505=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList505.getTree());
			RPAREN506=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewPartition8631); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN506);

			// AST REWRITE
			// elements: columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1693:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1693:8: ^( TOK_VIEWPARTCOLS columnNameList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewPartition"


	public static class viewOrganization_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewOrganization"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1696:1: viewOrganization : ( viewClusterSpec | viewComplexSpec );
	public final HiveParser.viewOrganization_return viewOrganization() throws RecognitionException {
		HiveParser.viewOrganization_return retval = new HiveParser.viewOrganization_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope viewClusterSpec507 =null;
		ParserRuleReturnScope viewComplexSpec508 =null;


		 pushMsg("view organization specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1699:5: ( viewClusterSpec | viewComplexSpec )
			int alt166=2;
			int LA166_0 = input.LA(1);
			if ( (LA166_0==KW_CLUSTERED) ) {
				alt166=1;
			}
			else if ( (LA166_0==KW_DISTRIBUTED) ) {
				alt166=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 166, 0, input);
				throw nvae;
			}

			switch (alt166) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1699:7: viewClusterSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_viewClusterSpec_in_viewOrganization8670);
					viewClusterSpec507=viewClusterSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, viewClusterSpec507.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1700:7: viewComplexSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_viewComplexSpec_in_viewOrganization8678);
					viewComplexSpec508=viewComplexSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, viewComplexSpec508.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewOrganization"


	public static class viewClusterSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewClusterSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1703:1: viewClusterSpec : KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWCLUSTERCOLS columnNameList ) ;
	public final HiveParser.viewClusterSpec_return viewClusterSpec() throws RecognitionException {
		HiveParser.viewClusterSpec_return retval = new HiveParser.viewClusterSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CLUSTERED509=null;
		Token KW_ON510=null;
		Token LPAREN511=null;
		Token RPAREN513=null;
		ParserRuleReturnScope columnNameList512 =null;

		ASTNode KW_CLUSTERED509_tree=null;
		ASTNode KW_ON510_tree=null;
		ASTNode LPAREN511_tree=null;
		ASTNode RPAREN513_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view cluster specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1706:5: ( KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWCLUSTERCOLS columnNameList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1706:7: KW_CLUSTERED KW_ON LPAREN columnNameList RPAREN
			{
			KW_CLUSTERED509=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_viewClusterSpec8705); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED509);

			KW_ON510=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewClusterSpec8707); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON510);

			LPAREN511=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewClusterSpec8709); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN511);

			pushFollow(FOLLOW_columnNameList_in_viewClusterSpec8711);
			columnNameList512=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(columnNameList512.getTree());
			RPAREN513=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewClusterSpec8713); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN513);

			// AST REWRITE
			// elements: columnNameList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1707:5: -> ^( TOK_VIEWCLUSTERCOLS columnNameList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1707:8: ^( TOK_VIEWCLUSTERCOLS columnNameList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWCLUSTERCOLS, "TOK_VIEWCLUSTERCOLS"), root_1);
				adaptor.addChild(root_1, stream_columnNameList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewClusterSpec"


	public static class viewComplexSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewComplexSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1710:1: viewComplexSpec : viewDistSpec viewSortSpec ;
	public final HiveParser.viewComplexSpec_return viewComplexSpec() throws RecognitionException {
		HiveParser.viewComplexSpec_return retval = new HiveParser.viewComplexSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope viewDistSpec514 =null;
		ParserRuleReturnScope viewSortSpec515 =null;


		 pushMsg("view complex specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1713:5: ( viewDistSpec viewSortSpec )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1713:7: viewDistSpec viewSortSpec
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_viewDistSpec_in_viewComplexSpec8752);
			viewDistSpec514=viewDistSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, viewDistSpec514.getTree());

			pushFollow(FOLLOW_viewSortSpec_in_viewComplexSpec8754);
			viewSortSpec515=viewSortSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, viewSortSpec515.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewComplexSpec"


	public static class viewDistSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewDistSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:1: viewDistSpec : KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWDISTRIBUTECOLS $colList) ;
	public final HiveParser.viewDistSpec_return viewDistSpec() throws RecognitionException {
		HiveParser.viewDistSpec_return retval = new HiveParser.viewDistSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DISTRIBUTED516=null;
		Token KW_ON517=null;
		Token LPAREN518=null;
		Token RPAREN519=null;
		ParserRuleReturnScope colList =null;

		ASTNode KW_DISTRIBUTED516_tree=null;
		ASTNode KW_ON517_tree=null;
		ASTNode LPAREN518_tree=null;
		ASTNode RPAREN519_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_DISTRIBUTED=new RewriteRuleTokenStream(adaptor,"token KW_DISTRIBUTED");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view distribute specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:5: ( KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWDISTRIBUTECOLS $colList) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1719:7: KW_DISTRIBUTED KW_ON LPAREN colList= columnNameList RPAREN
			{
			KW_DISTRIBUTED516=(Token)match(input,KW_DISTRIBUTED,FOLLOW_KW_DISTRIBUTED_in_viewDistSpec8781); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DISTRIBUTED.add(KW_DISTRIBUTED516);

			KW_ON517=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewDistSpec8783); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON517);

			LPAREN518=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewDistSpec8785); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN518);

			pushFollow(FOLLOW_columnNameList_in_viewDistSpec8789);
			colList=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(colList.getTree());
			RPAREN519=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewDistSpec8791); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN519);

			// AST REWRITE
			// elements: colList
			// token labels: 
			// rule labels: colList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colList=new RewriteRuleSubtreeStream(adaptor,"rule colList",colList!=null?colList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1720:5: -> ^( TOK_VIEWDISTRIBUTECOLS $colList)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1720:8: ^( TOK_VIEWDISTRIBUTECOLS $colList)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWDISTRIBUTECOLS, "TOK_VIEWDISTRIBUTECOLS"), root_1);
				adaptor.addChild(root_1, stream_colList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewDistSpec"


	public static class viewSortSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "viewSortSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:1: viewSortSpec : KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWSORTCOLS $colList) ;
	public final HiveParser.viewSortSpec_return viewSortSpec() throws RecognitionException {
		HiveParser.viewSortSpec_return retval = new HiveParser.viewSortSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SORTED520=null;
		Token KW_ON521=null;
		Token LPAREN522=null;
		Token RPAREN523=null;
		ParserRuleReturnScope colList =null;

		ASTNode KW_SORTED520_tree=null;
		ASTNode KW_ON521_tree=null;
		ASTNode LPAREN522_tree=null;
		ASTNode RPAREN523_tree=null;
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("view sort specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:5: ( KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN -> ^( TOK_VIEWSORTCOLS $colList) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1726:7: KW_SORTED KW_ON LPAREN colList= columnNameList RPAREN
			{
			KW_SORTED520=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_viewSortSpec8831); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED520);

			KW_ON521=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewSortSpec8833); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON521);

			LPAREN522=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewSortSpec8835); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN522);

			pushFollow(FOLLOW_columnNameList_in_viewSortSpec8839);
			colList=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(colList.getTree());
			RPAREN523=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewSortSpec8841); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN523);

			// AST REWRITE
			// elements: colList
			// token labels: 
			// rule labels: colList, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colList=new RewriteRuleSubtreeStream(adaptor,"rule colList",colList!=null?colList.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1727:5: -> ^( TOK_VIEWSORTCOLS $colList)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1727:8: ^( TOK_VIEWSORTCOLS $colList)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VIEWSORTCOLS, "TOK_VIEWSORTCOLS"), root_1);
				adaptor.addChild(root_1, stream_colList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "viewSortSpec"


	public static class dropViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1730:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
	public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
		HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP524=null;
		Token KW_VIEW525=null;
		ParserRuleReturnScope ifExists526 =null;
		ParserRuleReturnScope viewName527 =null;

		ASTNode KW_DROP524_tree=null;
		ASTNode KW_VIEW525_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:7: KW_DROP KW_VIEW ( ifExists )? viewName
			{
			KW_DROP524=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropViewStatement8881); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP524);

			KW_VIEW525=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropViewStatement8883); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW525);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:23: ( ifExists )?
			int alt167=2;
			int LA167_0 = input.LA(1);
			if ( (LA167_0==KW_IF) ) {
				alt167=1;
			}
			switch (alt167) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:23: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropViewStatement8885);
					ifExists526=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists526.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_viewName_in_dropViewStatement8888);
			viewName527=viewName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_viewName.add(viewName527.getTree());
			// AST REWRITE
			// elements: ifExists, viewName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1733:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW"), root_1);
				adaptor.addChild(root_1, stream_viewName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:69: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropViewStatement"


	public static class createMaterializedViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createMaterializedViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:1: createMaterializedViewStatement : KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) ;
	public final HiveParser.createMaterializedViewStatement_return createMaterializedViewStatement() throws RecognitionException {
		HiveParser.createMaterializedViewStatement_return retval = new HiveParser.createMaterializedViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE528=null;
		Token KW_MATERIALIZED529=null;
		Token KW_VIEW530=null;
		Token KW_AS540=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope ifNotExists531 =null;
		ParserRuleReturnScope rewriteDisabled532 =null;
		ParserRuleReturnScope tableComment533 =null;
		ParserRuleReturnScope viewPartition534 =null;
		ParserRuleReturnScope viewOrganization535 =null;
		ParserRuleReturnScope tableRowFormat536 =null;
		ParserRuleReturnScope tableFileFormat537 =null;
		ParserRuleReturnScope tableLocation538 =null;
		ParserRuleReturnScope tablePropertiesPrefixed539 =null;
		ParserRuleReturnScope selectStatementWithCTE541 =null;

		ASTNode KW_CREATE528_tree=null;
		ASTNode KW_MATERIALIZED529_tree=null;
		ASTNode KW_VIEW530_tree=null;
		ASTNode KW_AS540_tree=null;
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_selectStatementWithCTE=new RewriteRuleSubtreeStream(adaptor,"rule selectStatementWithCTE");
		RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
		RewriteRuleSubtreeStream stream_rewriteDisabled=new RewriteRuleSubtreeStream(adaptor,"rule rewriteDisabled");
		RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
		RewriteRuleSubtreeStream stream_viewOrganization=new RewriteRuleSubtreeStream(adaptor,"rule viewOrganization");
		RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");


		    pushMsg("create materialized view statement", state);

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1741:5: ( KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1741:7: KW_CREATE KW_MATERIALIZED KW_VIEW ( ifNotExists )? name= tableName ( rewriteDisabled )? ( tableComment )? ( viewPartition )? ( viewOrganization )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? KW_AS selectStatementWithCTE
			{
			KW_CREATE528=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMaterializedViewStatement8926); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE528);

			KW_MATERIALIZED529=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement8928); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED529);

			KW_VIEW530=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createMaterializedViewStatement8930); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW530);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1741:41: ( ifNotExists )?
			int alt168=2;
			int LA168_0 = input.LA(1);
			if ( (LA168_0==KW_IF) ) {
				alt168=1;
			}
			switch (alt168) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1741:42: ifNotExists
					{
					pushFollow(FOLLOW_ifNotExists_in_createMaterializedViewStatement8933);
					ifNotExists531=ifNotExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists531.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableName_in_createMaterializedViewStatement8939);
			name=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(name.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:9: ( rewriteDisabled )?
			int alt169=2;
			int LA169_0 = input.LA(1);
			if ( (LA169_0==KW_DISABLE) ) {
				alt169=1;
			}
			switch (alt169) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:9: rewriteDisabled
					{
					pushFollow(FOLLOW_rewriteDisabled_in_createMaterializedViewStatement8949);
					rewriteDisabled532=rewriteDisabled();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rewriteDisabled.add(rewriteDisabled532.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:26: ( tableComment )?
			int alt170=2;
			int LA170_0 = input.LA(1);
			if ( (LA170_0==KW_COMMENT) ) {
				alt170=1;
			}
			switch (alt170) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:26: tableComment
					{
					pushFollow(FOLLOW_tableComment_in_createMaterializedViewStatement8952);
					tableComment533=tableComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableComment.add(tableComment533.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:40: ( viewPartition )?
			int alt171=2;
			int LA171_0 = input.LA(1);
			if ( (LA171_0==KW_PARTITIONED) ) {
				alt171=1;
			}
			switch (alt171) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:40: viewPartition
					{
					pushFollow(FOLLOW_viewPartition_in_createMaterializedViewStatement8955);
					viewPartition534=viewPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewPartition.add(viewPartition534.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:55: ( viewOrganization )?
			int alt172=2;
			int LA172_0 = input.LA(1);
			if ( (LA172_0==KW_CLUSTERED||LA172_0==KW_DISTRIBUTED) ) {
				alt172=1;
			}
			switch (alt172) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1742:55: viewOrganization
					{
					pushFollow(FOLLOW_viewOrganization_in_createMaterializedViewStatement8958);
					viewOrganization535=viewOrganization();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_viewOrganization.add(viewOrganization535.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:9: ( tableRowFormat )?
			int alt173=2;
			int LA173_0 = input.LA(1);
			if ( (LA173_0==KW_ROW) ) {
				alt173=1;
			}
			switch (alt173) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:9: tableRowFormat
					{
					pushFollow(FOLLOW_tableRowFormat_in_createMaterializedViewStatement8969);
					tableRowFormat536=tableRowFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat536.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:25: ( tableFileFormat )?
			int alt174=2;
			int LA174_0 = input.LA(1);
			if ( (LA174_0==KW_STORED) ) {
				alt174=1;
			}
			switch (alt174) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:25: tableFileFormat
					{
					pushFollow(FOLLOW_tableFileFormat_in_createMaterializedViewStatement8972);
					tableFileFormat537=tableFileFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat537.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:42: ( tableLocation )?
			int alt175=2;
			int LA175_0 = input.LA(1);
			if ( (LA175_0==KW_LOCATION) ) {
				alt175=1;
			}
			switch (alt175) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1743:42: tableLocation
					{
					pushFollow(FOLLOW_tableLocation_in_createMaterializedViewStatement8975);
					tableLocation538=tableLocation();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableLocation.add(tableLocation538.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:9: ( tablePropertiesPrefixed )?
			int alt176=2;
			int LA176_0 = input.LA(1);
			if ( (LA176_0==KW_TBLPROPERTIES) ) {
				alt176=1;
			}
			switch (alt176) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:9: tablePropertiesPrefixed
					{
					pushFollow(FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement8986);
					tablePropertiesPrefixed539=tablePropertiesPrefixed();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed539.getTree());
					}
					break;

			}

			KW_AS540=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createMaterializedViewStatement8989); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS540);

			pushFollow(FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement8991);
			selectStatementWithCTE541=selectStatementWithCTE();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatementWithCTE.add(selectStatementWithCTE541.getTree());
			// AST REWRITE
			// elements: ifNotExists, name, tablePropertiesPrefixed, tableLocation, rewriteDisabled, tableComment, viewPartition, tableRowFormat, viewOrganization, selectStatementWithCTE, tableFileFormat
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1745:5: -> ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1745:8: ^( TOK_CREATE_MATERIALIZED_VIEW $name ( ifNotExists )? ( rewriteDisabled )? ( tableComment )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( viewPartition )? ( viewOrganization )? ( tablePropertiesPrefixed )? selectStatementWithCTE )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATE_MATERIALIZED_VIEW, "TOK_CREATE_MATERIALIZED_VIEW"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1746:10: ( ifNotExists )?
				if ( stream_ifNotExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifNotExists.nextTree());
				}
				stream_ifNotExists.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:10: ( rewriteDisabled )?
				if ( stream_rewriteDisabled.hasNext() ) {
					adaptor.addChild(root_1, stream_rewriteDisabled.nextTree());
				}
				stream_rewriteDisabled.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1748:10: ( tableComment )?
				if ( stream_tableComment.hasNext() ) {
					adaptor.addChild(root_1, stream_tableComment.nextTree());
				}
				stream_tableComment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1749:10: ( tableRowFormat )?
				if ( stream_tableRowFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
				}
				stream_tableRowFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1750:10: ( tableFileFormat )?
				if ( stream_tableFileFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
				}
				stream_tableFileFormat.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1751:10: ( tableLocation )?
				if ( stream_tableLocation.hasNext() ) {
					adaptor.addChild(root_1, stream_tableLocation.nextTree());
				}
				stream_tableLocation.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1752:10: ( viewPartition )?
				if ( stream_viewPartition.hasNext() ) {
					adaptor.addChild(root_1, stream_viewPartition.nextTree());
				}
				stream_viewPartition.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:10: ( viewOrganization )?
				if ( stream_viewOrganization.hasNext() ) {
					adaptor.addChild(root_1, stream_viewOrganization.nextTree());
				}
				stream_viewOrganization.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1754:10: ( tablePropertiesPrefixed )?
				if ( stream_tablePropertiesPrefixed.hasNext() ) {
					adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());
				}
				stream_tablePropertiesPrefixed.reset();

				adaptor.addChild(root_1, stream_selectStatementWithCTE.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createMaterializedViewStatement"


	public static class dropMaterializedViewStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropMaterializedViewStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1759:1: dropMaterializedViewStatement : KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? ) ;
	public final HiveParser.dropMaterializedViewStatement_return dropMaterializedViewStatement() throws RecognitionException {
		HiveParser.dropMaterializedViewStatement_return retval = new HiveParser.dropMaterializedViewStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP542=null;
		Token KW_MATERIALIZED543=null;
		Token KW_VIEW544=null;
		ParserRuleReturnScope ifExists545 =null;
		ParserRuleReturnScope viewName546 =null;

		ASTNode KW_DROP542_tree=null;
		ASTNode KW_MATERIALIZED543_tree=null;
		ASTNode KW_VIEW544_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
		RewriteRuleTokenStream stream_KW_MATERIALIZED=new RewriteRuleTokenStream(adaptor,"token KW_MATERIALIZED");
		RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
		RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");

		 pushMsg("drop materialized view statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1762:5: ( KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1762:7: KW_DROP KW_MATERIALIZED KW_VIEW ( ifExists )? viewName
			{
			KW_DROP542=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMaterializedViewStatement9159); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP542);

			KW_MATERIALIZED543=(Token)match(input,KW_MATERIALIZED,FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement9161); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATERIALIZED.add(KW_MATERIALIZED543);

			KW_VIEW544=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropMaterializedViewStatement9163); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VIEW.add(KW_VIEW544);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1762:39: ( ifExists )?
			int alt177=2;
			int LA177_0 = input.LA(1);
			if ( (LA177_0==KW_IF) ) {
				alt177=1;
			}
			switch (alt177) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1762:39: ifExists
					{
					pushFollow(FOLLOW_ifExists_in_dropMaterializedViewStatement9165);
					ifExists545=ifExists();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_ifExists.add(ifExists545.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_viewName_in_dropMaterializedViewStatement9168);
			viewName546=viewName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_viewName.add(viewName546.getTree());
			// AST REWRITE
			// elements: viewName, ifExists
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1762:58: -> ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1762:61: ^( TOK_DROP_MATERIALIZED_VIEW viewName ( ifExists )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROP_MATERIALIZED_VIEW, "TOK_DROP_MATERIALIZED_VIEW"), root_1);
				adaptor.addChild(root_1, stream_viewName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1762:99: ( ifExists )?
				if ( stream_ifExists.hasNext() ) {
					adaptor.addChild(root_1, stream_ifExists.nextTree());
				}
				stream_ifExists.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropMaterializedViewStatement"


	public static class createScheduledQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createScheduledQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1765:1: createScheduledQueryStatement : KW_CREATE KW_SCHEDULED KW_QUERY name= identifier scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec -> ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec ) ;
	public final HiveParser.createScheduledQueryStatement_return createScheduledQueryStatement() throws RecognitionException {
		HiveParser.createScheduledQueryStatement_return retval = new HiveParser.createScheduledQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CREATE547=null;
		Token KW_SCHEDULED548=null;
		Token KW_QUERY549=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope scheduleSpec550 =null;
		ParserRuleReturnScope executedAsSpec551 =null;
		ParserRuleReturnScope enableSpecification552 =null;
		ParserRuleReturnScope definedAsSpec553 =null;

		ASTNode KW_CREATE547_tree=null;
		ASTNode KW_SCHEDULED548_tree=null;
		ASTNode KW_QUERY549_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEDULED=new RewriteRuleTokenStream(adaptor,"token KW_SCHEDULED");
		RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_definedAsSpec=new RewriteRuleSubtreeStream(adaptor,"rule definedAsSpec");
		RewriteRuleSubtreeStream stream_scheduleSpec=new RewriteRuleSubtreeStream(adaptor,"rule scheduleSpec");
		RewriteRuleSubtreeStream stream_enableSpecification=new RewriteRuleSubtreeStream(adaptor,"rule enableSpecification");
		RewriteRuleSubtreeStream stream_executedAsSpec=new RewriteRuleSubtreeStream(adaptor,"rule executedAsSpec");

		 pushMsg("create scheduled query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:5: ( KW_CREATE KW_SCHEDULED KW_QUERY name= identifier scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec -> ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:7: KW_CREATE KW_SCHEDULED KW_QUERY name= identifier scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec
			{
			KW_CREATE547=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createScheduledQueryStatement9206); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CREATE.add(KW_CREATE547);

			KW_SCHEDULED548=(Token)match(input,KW_SCHEDULED,FOLLOW_KW_SCHEDULED_in_createScheduledQueryStatement9208); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SCHEDULED.add(KW_SCHEDULED548);

			KW_QUERY549=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_createScheduledQueryStatement9210); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY549);

			pushFollow(FOLLOW_identifier_in_createScheduledQueryStatement9214);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			pushFollow(FOLLOW_scheduleSpec_in_createScheduledQueryStatement9224);
			scheduleSpec550=scheduleSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_scheduleSpec.add(scheduleSpec550.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1770:9: ( executedAsSpec )?
			int alt178=2;
			int LA178_0 = input.LA(1);
			if ( (LA178_0==KW_EXECUTED) ) {
				alt178=1;
			}
			switch (alt178) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1770:9: executedAsSpec
					{
					pushFollow(FOLLOW_executedAsSpec_in_createScheduledQueryStatement9234);
					executedAsSpec551=executedAsSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_executedAsSpec.add(executedAsSpec551.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1771:9: ( enableSpecification )?
			int alt179=2;
			int LA179_0 = input.LA(1);
			if ( (LA179_0==KW_DISABLE||LA179_0==KW_ENABLE) ) {
				alt179=1;
			}
			switch (alt179) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1771:9: enableSpecification
					{
					pushFollow(FOLLOW_enableSpecification_in_createScheduledQueryStatement9245);
					enableSpecification552=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_enableSpecification.add(enableSpecification552.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_definedAsSpec_in_createScheduledQueryStatement9256);
			definedAsSpec553=definedAsSpec();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_definedAsSpec.add(definedAsSpec553.getTree());
			// AST REWRITE
			// elements: definedAsSpec, name, scheduleSpec, executedAsSpec, enableSpecification
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1773:5: -> ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:8: ^( TOK_CREATE_SCHEDULED_QUERY $name scheduleSpec ( executedAsSpec )? ( enableSpecification )? definedAsSpec )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CREATE_SCHEDULED_QUERY, "TOK_CREATE_SCHEDULED_QUERY"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_1, stream_scheduleSpec.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:13: ( executedAsSpec )?
				if ( stream_executedAsSpec.hasNext() ) {
					adaptor.addChild(root_1, stream_executedAsSpec.nextTree());
				}
				stream_executedAsSpec.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1777:13: ( enableSpecification )?
				if ( stream_enableSpecification.hasNext() ) {
					adaptor.addChild(root_1, stream_enableSpecification.nextTree());
				}
				stream_enableSpecification.reset();

				adaptor.addChild(root_1, stream_definedAsSpec.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createScheduledQueryStatement"


	public static class dropScheduledQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "dropScheduledQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:1: dropScheduledQueryStatement : KW_DROP KW_SCHEDULED KW_QUERY name= identifier -> ^( TOK_DROP_SCHEDULED_QUERY $name) ;
	public final HiveParser.dropScheduledQueryStatement_return dropScheduledQueryStatement() throws RecognitionException {
		HiveParser.dropScheduledQueryStatement_return retval = new HiveParser.dropScheduledQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DROP554=null;
		Token KW_SCHEDULED555=null;
		Token KW_QUERY556=null;
		ParserRuleReturnScope name =null;

		ASTNode KW_DROP554_tree=null;
		ASTNode KW_SCHEDULED555_tree=null;
		ASTNode KW_QUERY556_tree=null;
		RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
		RewriteRuleTokenStream stream_KW_SCHEDULED=new RewriteRuleTokenStream(adaptor,"token KW_SCHEDULED");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("drop scheduled query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:5: ( KW_DROP KW_SCHEDULED KW_QUERY name= identifier -> ^( TOK_DROP_SCHEDULED_QUERY $name) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:7: KW_DROP KW_SCHEDULED KW_QUERY name= identifier
			{
			KW_DROP554=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropScheduledQueryStatement9375); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DROP.add(KW_DROP554);

			KW_SCHEDULED555=(Token)match(input,KW_SCHEDULED,FOLLOW_KW_SCHEDULED_in_dropScheduledQueryStatement9377); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SCHEDULED.add(KW_SCHEDULED555);

			KW_QUERY556=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_dropScheduledQueryStatement9379); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY556);

			pushFollow(FOLLOW_identifier_in_dropScheduledQueryStatement9383);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			// AST REWRITE
			// elements: name
			// token labels: 
			// rule labels: name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1786:5: -> ^( TOK_DROP_SCHEDULED_QUERY $name)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1786:8: ^( TOK_DROP_SCHEDULED_QUERY $name)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DROP_SCHEDULED_QUERY, "TOK_DROP_SCHEDULED_QUERY"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "dropScheduledQueryStatement"


	public static class alterScheduledQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterScheduledQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1792:1: alterScheduledQueryStatement : KW_ALTER KW_SCHEDULED KW_QUERY name= identifier mod= alterScheduledQueryChange -> ^( TOK_ALTER_SCHEDULED_QUERY $name $mod) ;
	public final HiveParser.alterScheduledQueryStatement_return alterScheduledQueryStatement() throws RecognitionException {
		HiveParser.alterScheduledQueryStatement_return retval = new HiveParser.alterScheduledQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ALTER557=null;
		Token KW_SCHEDULED558=null;
		Token KW_QUERY559=null;
		ParserRuleReturnScope name =null;
		ParserRuleReturnScope mod =null;

		ASTNode KW_ALTER557_tree=null;
		ASTNode KW_SCHEDULED558_tree=null;
		ASTNode KW_QUERY559_tree=null;
		RewriteRuleTokenStream stream_KW_SCHEDULED=new RewriteRuleTokenStream(adaptor,"token KW_SCHEDULED");
		RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_alterScheduledQueryChange=new RewriteRuleSubtreeStream(adaptor,"rule alterScheduledQueryChange");

		 pushMsg("alter scheduled query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:5: ( KW_ALTER KW_SCHEDULED KW_QUERY name= identifier mod= alterScheduledQueryChange -> ^( TOK_ALTER_SCHEDULED_QUERY $name $mod) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1795:7: KW_ALTER KW_SCHEDULED KW_QUERY name= identifier mod= alterScheduledQueryChange
			{
			KW_ALTER557=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterScheduledQueryStatement9445); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ALTER.add(KW_ALTER557);

			KW_SCHEDULED558=(Token)match(input,KW_SCHEDULED,FOLLOW_KW_SCHEDULED_in_alterScheduledQueryStatement9447); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SCHEDULED.add(KW_SCHEDULED558);

			KW_QUERY559=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_alterScheduledQueryStatement9449); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY559);

			pushFollow(FOLLOW_identifier_in_alterScheduledQueryStatement9453);
			name=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(name.getTree());
			pushFollow(FOLLOW_alterScheduledQueryChange_in_alterScheduledQueryStatement9469);
			mod=alterScheduledQueryChange();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_alterScheduledQueryChange.add(mod.getTree());
			// AST REWRITE
			// elements: name, mod
			// token labels: 
			// rule labels: mod, name, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_mod=new RewriteRuleSubtreeStream(adaptor,"rule mod",mod!=null?mod.getTree():null);
			RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1797:5: -> ^( TOK_ALTER_SCHEDULED_QUERY $name $mod)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:8: ^( TOK_ALTER_SCHEDULED_QUERY $name $mod)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTER_SCHEDULED_QUERY, "TOK_ALTER_SCHEDULED_QUERY"), root_1);
				adaptor.addChild(root_1, stream_name.nextTree());
				adaptor.addChild(root_1, stream_mod.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterScheduledQueryStatement"


	public static class alterScheduledQueryChange_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterScheduledQueryChange"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1803:1: alterScheduledQueryChange : ( scheduleSpec | executedAsSpec | enableSpecification | definedAsSpec | KW_EXECUTE -> ^( TOK_EXECUTE ) );
	public final HiveParser.alterScheduledQueryChange_return alterScheduledQueryChange() throws RecognitionException {
		HiveParser.alterScheduledQueryChange_return retval = new HiveParser.alterScheduledQueryChange_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_EXECUTE564=null;
		ParserRuleReturnScope scheduleSpec560 =null;
		ParserRuleReturnScope executedAsSpec561 =null;
		ParserRuleReturnScope enableSpecification562 =null;
		ParserRuleReturnScope definedAsSpec563 =null;

		ASTNode KW_EXECUTE564_tree=null;
		RewriteRuleTokenStream stream_KW_EXECUTE=new RewriteRuleTokenStream(adaptor,"token KW_EXECUTE");

		 pushMsg("alter scheduled query change", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:5: ( scheduleSpec | executedAsSpec | enableSpecification | definedAsSpec | KW_EXECUTE -> ^( TOK_EXECUTE ) )
			int alt180=5;
			switch ( input.LA(1) ) {
			case KW_CRON:
			case KW_EVERY:
				{
				alt180=1;
				}
				break;
			case KW_EXECUTED:
				{
				alt180=2;
				}
				break;
			case KW_DISABLE:
			case KW_ENABLE:
				{
				alt180=3;
				}
				break;
			case KW_AS:
			case KW_DEFINED:
				{
				alt180=4;
				}
				break;
			case KW_EXECUTE:
				{
				alt180=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 180, 0, input);
				throw nvae;
			}
			switch (alt180) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1806:7: scheduleSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_scheduleSpec_in_alterScheduledQueryChange9545);
					scheduleSpec560=scheduleSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, scheduleSpec560.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:7: executedAsSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_executedAsSpec_in_alterScheduledQueryChange9553);
					executedAsSpec561=executedAsSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, executedAsSpec561.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1808:7: enableSpecification
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enableSpecification_in_alterScheduledQueryChange9561);
					enableSpecification562=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enableSpecification562.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1809:7: definedAsSpec
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_definedAsSpec_in_alterScheduledQueryChange9569);
					definedAsSpec563=definedAsSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, definedAsSpec563.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:7: KW_EXECUTE
					{
					KW_EXECUTE564=(Token)match(input,KW_EXECUTE,FOLLOW_KW_EXECUTE_in_alterScheduledQueryChange9577); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXECUTE.add(KW_EXECUTE564);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1810:18: -> ^( TOK_EXECUTE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:21: ^( TOK_EXECUTE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXECUTE, "TOK_EXECUTE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterScheduledQueryChange"


	public static class scheduleSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "scheduleSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1813:1: scheduleSpec : ( KW_CRON cronString= StringLiteral -> ^( TOK_CRON $cronString) | KW_EVERY (value= Number )? qualifier= intervalQualifiers ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )? -> ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? ) );
	public final HiveParser.scheduleSpec_return scheduleSpec() throws RecognitionException {
		HiveParser.scheduleSpec_return retval = new HiveParser.scheduleSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token cronString=null;
		Token value=null;
		Token offsetTs=null;
		Token KW_CRON565=null;
		Token KW_EVERY566=null;
		Token KW_AT567=null;
		Token KW_OFFSET568=null;
		Token KW_BY569=null;
		ParserRuleReturnScope qualifier =null;

		ASTNode cronString_tree=null;
		ASTNode value_tree=null;
		ASTNode offsetTs_tree=null;
		ASTNode KW_CRON565_tree=null;
		ASTNode KW_EVERY566_tree=null;
		ASTNode KW_AT567_tree=null;
		ASTNode KW_OFFSET568_tree=null;
		ASTNode KW_BY569_tree=null;
		RewriteRuleTokenStream stream_KW_CRON=new RewriteRuleTokenStream(adaptor,"token KW_CRON");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_OFFSET=new RewriteRuleTokenStream(adaptor,"token KW_OFFSET");
		RewriteRuleTokenStream stream_KW_EVERY=new RewriteRuleTokenStream(adaptor,"token KW_EVERY");
		RewriteRuleTokenStream stream_KW_AT=new RewriteRuleTokenStream(adaptor,"token KW_AT");
		RewriteRuleSubtreeStream stream_intervalQualifiers=new RewriteRuleSubtreeStream(adaptor,"rule intervalQualifiers");

		 pushMsg("schedule specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:9: ( KW_CRON cronString= StringLiteral -> ^( TOK_CRON $cronString) | KW_EVERY (value= Number )? qualifier= intervalQualifiers ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )? -> ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? ) )
			int alt184=2;
			int LA184_0 = input.LA(1);
			if ( (LA184_0==KW_CRON) ) {
				alt184=1;
			}
			else if ( (LA184_0==KW_EVERY) ) {
				alt184=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 184, 0, input);
				throw nvae;
			}

			switch (alt184) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:11: KW_CRON cronString= StringLiteral
					{
					KW_CRON565=(Token)match(input,KW_CRON,FOLLOW_KW_CRON_in_scheduleSpec9614); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CRON.add(KW_CRON565);

					cronString=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_scheduleSpec9618); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(cronString);

					// AST REWRITE
					// elements: cronString
					// token labels: cronString
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_cronString=new RewriteRuleTokenStream(adaptor,"token cronString",cronString);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1816:44: -> ^( TOK_CRON $cronString)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1816:47: ^( TOK_CRON $cronString)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CRON, "TOK_CRON"), root_1);
						adaptor.addChild(root_1, stream_cronString.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:11: KW_EVERY (value= Number )? qualifier= intervalQualifiers ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )?
					{
					KW_EVERY566=(Token)match(input,KW_EVERY,FOLLOW_KW_EVERY_in_scheduleSpec9639); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EVERY.add(KW_EVERY566);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:25: (value= Number )?
					int alt181=2;
					int LA181_0 = input.LA(1);
					if ( (LA181_0==Number) ) {
						alt181=1;
					}
					switch (alt181) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1817:25: value= Number
							{
							value=(Token)match(input,Number,FOLLOW_Number_in_scheduleSpec9643); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(value);

							}
							break;

					}

					pushFollow(FOLLOW_intervalQualifiers_in_scheduleSpec9648);
					qualifier=intervalQualifiers();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_intervalQualifiers.add(qualifier.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:9: ( ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral )?
					int alt183=2;
					int LA183_0 = input.LA(1);
					if ( (LA183_0==KW_AT||LA183_0==KW_OFFSET) ) {
						alt183=1;
					}
					switch (alt183) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:10: ( KW_AT | KW_OFFSET KW_BY ) offsetTs= StringLiteral
							{
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:10: ( KW_AT | KW_OFFSET KW_BY )
							int alt182=2;
							int LA182_0 = input.LA(1);
							if ( (LA182_0==KW_AT) ) {
								alt182=1;
							}
							else if ( (LA182_0==KW_OFFSET) ) {
								alt182=2;
							}

							else {
								if (state.backtracking>0) {state.failed=true; return retval;}
								NoViableAltException nvae =
									new NoViableAltException("", 182, 0, input);
								throw nvae;
							}

							switch (alt182) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:11: KW_AT
									{
									KW_AT567=(Token)match(input,KW_AT,FOLLOW_KW_AT_in_scheduleSpec9660); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_AT.add(KW_AT567);

									}
									break;
								case 2 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:17: KW_OFFSET KW_BY
									{
									KW_OFFSET568=(Token)match(input,KW_OFFSET,FOLLOW_KW_OFFSET_in_scheduleSpec9662); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_OFFSET.add(KW_OFFSET568);

									KW_BY569=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_scheduleSpec9664); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY569);

									}
									break;

							}

							offsetTs=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_scheduleSpec9669); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(offsetTs);

							}
							break;

					}

					// AST REWRITE
					// elements: value, offsetTs, qualifier
					// token labels: offsetTs, value
					// rule labels: qualifier, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offsetTs=new RewriteRuleTokenStream(adaptor,"token offsetTs",offsetTs);
					RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
					RewriteRuleSubtreeStream stream_qualifier=new RewriteRuleSubtreeStream(adaptor,"rule qualifier",qualifier!=null?qualifier.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1818:59: -> ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:62: ^( TOK_SCHEDULE ^( TOK_EVERY ( $value)? ) $qualifier ( $offsetTs)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SCHEDULE, "TOK_SCHEDULE"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:77: ^( TOK_EVERY ( $value)? )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EVERY, "TOK_EVERY"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:90: ( $value)?
						if ( stream_value.hasNext() ) {
							adaptor.addChild(root_2, stream_value.nextNode());
						}
						stream_value.reset();

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_1, stream_qualifier.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:110: ( $offsetTs)?
						if ( stream_offsetTs.hasNext() ) {
							adaptor.addChild(root_1, stream_offsetTs.nextNode());
						}
						stream_offsetTs.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "scheduleSpec"


	public static class executedAsSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "executedAsSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1821:1: executedAsSpec : KW_EXECUTED KW_AS executedAs= StringLiteral -> ^( TOK_EXECUTED_AS $executedAs) ;
	public final HiveParser.executedAsSpec_return executedAsSpec() throws RecognitionException {
		HiveParser.executedAsSpec_return retval = new HiveParser.executedAsSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token executedAs=null;
		Token KW_EXECUTED570=null;
		Token KW_AS571=null;

		ASTNode executedAs_tree=null;
		ASTNode KW_EXECUTED570_tree=null;
		ASTNode KW_AS571_tree=null;
		RewriteRuleTokenStream stream_KW_EXECUTED=new RewriteRuleTokenStream(adaptor,"token KW_EXECUTED");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");

		 pushMsg("executedAs specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:9: ( KW_EXECUTED KW_AS executedAs= StringLiteral -> ^( TOK_EXECUTED_AS $executedAs) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:11: KW_EXECUTED KW_AS executedAs= StringLiteral
			{
			KW_EXECUTED570=(Token)match(input,KW_EXECUTED,FOLLOW_KW_EXECUTED_in_executedAsSpec9727); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_EXECUTED.add(KW_EXECUTED570);

			KW_AS571=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_executedAsSpec9729); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS571);

			executedAs=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_executedAsSpec9733); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(executedAs);

			// AST REWRITE
			// elements: executedAs
			// token labels: executedAs
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_executedAs=new RewriteRuleTokenStream(adaptor,"token executedAs",executedAs);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1824:54: -> ^( TOK_EXECUTED_AS $executedAs)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1824:57: ^( TOK_EXECUTED_AS $executedAs)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXECUTED_AS, "TOK_EXECUTED_AS"), root_1);
				adaptor.addChild(root_1, stream_executedAs.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "executedAsSpec"


	public static class definedAsSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "definedAsSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1827:1: definedAsSpec : ( KW_DEFINED )? KW_AS statement -> ^( TOK_QUERY statement ) ;
	public final HiveParser.definedAsSpec_return definedAsSpec() throws RecognitionException {
		HiveParser.definedAsSpec_return retval = new HiveParser.definedAsSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DEFINED572=null;
		Token KW_AS573=null;
		ParserRuleReturnScope statement574 =null;

		ASTNode KW_DEFINED572_tree=null;
		ASTNode KW_AS573_tree=null;
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_DEFINED=new RewriteRuleTokenStream(adaptor,"token KW_DEFINED");
		RewriteRuleSubtreeStream stream_statement=new RewriteRuleSubtreeStream(adaptor,"rule statement");

		 pushMsg("definedAs specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:9: ( ( KW_DEFINED )? KW_AS statement -> ^( TOK_QUERY statement ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:11: ( KW_DEFINED )? KW_AS statement
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:11: ( KW_DEFINED )?
			int alt185=2;
			int LA185_0 = input.LA(1);
			if ( (LA185_0==KW_DEFINED) ) {
				alt185=1;
			}
			switch (alt185) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:11: KW_DEFINED
					{
					KW_DEFINED572=(Token)match(input,KW_DEFINED,FOLLOW_KW_DEFINED_in_definedAsSpec9777); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DEFINED.add(KW_DEFINED572);

					}
					break;

			}

			KW_AS573=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_definedAsSpec9780); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS573);

			pushFollow(FOLLOW_statement_in_definedAsSpec9782);
			statement574=statement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_statement.add(statement574.getTree());
			// AST REWRITE
			// elements: statement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1830:39: -> ^( TOK_QUERY statement )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:42: ^( TOK_QUERY statement )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				adaptor.addChild(root_1, stream_statement.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "definedAsSpec"


	public static class showFunctionIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showFunctionIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1833:1: showFunctionIdentifier : ( functionIdentifier | StringLiteral );
	public final HiveParser.showFunctionIdentifier_return showFunctionIdentifier() throws RecognitionException {
		HiveParser.showFunctionIdentifier_return retval = new HiveParser.showFunctionIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token StringLiteral576=null;
		ParserRuleReturnScope functionIdentifier575 =null;

		ASTNode StringLiteral576_tree=null;

		 pushMsg("identifier for show function statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1836:5: ( functionIdentifier | StringLiteral )
			int alt186=2;
			int LA186_0 = input.LA(1);
			if ( (LA186_0==Identifier||(LA186_0 >= KW_ABORT && LA186_0 <= KW_AFTER)||LA186_0==KW_ALLOC_FRACTION||LA186_0==KW_ANALYZE||LA186_0==KW_ARCHIVE||(LA186_0 >= KW_ASC && LA186_0 <= KW_AT)||(LA186_0 >= KW_AUTOCOMMIT && LA186_0 <= KW_BEFORE)||(LA186_0 >= KW_BUCKET && LA186_0 <= KW_BUCKETS)||(LA186_0 >= KW_CACHE && LA186_0 <= KW_CASCADE)||(LA186_0 >= KW_CBO && LA186_0 <= KW_CHANGE)||(LA186_0 >= KW_CHECK && LA186_0 <= KW_COLLECTION)||(LA186_0 >= KW_COLUMNS && LA186_0 <= KW_COMMENT)||(LA186_0 >= KW_COMPACT && LA186_0 <= KW_CONCATENATE)||(LA186_0 >= KW_CONTINUE && LA186_0 <= KW_COST)||LA186_0==KW_CRON||LA186_0==KW_DATA||LA186_0==KW_DATABASES||(LA186_0 >= KW_DATETIME && LA186_0 <= KW_DCPROPERTIES)||LA186_0==KW_DEBUG||(LA186_0 >= KW_DEFAULT && LA186_0 <= KW_DEFINED)||(LA186_0 >= KW_DELIMITED && LA186_0 <= KW_DESC)||(LA186_0 >= KW_DETAIL && LA186_0 <= KW_DISABLE)||(LA186_0 >= KW_DISTRIBUTE && LA186_0 <= KW_DO)||LA186_0==KW_DOW||(LA186_0 >= KW_DUMP && LA186_0 <= KW_ELEM_TYPE)||LA186_0==KW_ENABLE||(LA186_0 >= KW_ENFORCED && LA186_0 <= KW_EVERY)||(LA186_0 >= KW_EXCLUSIVE && LA186_0 <= KW_EXECUTED)||(LA186_0 >= KW_EXPIRE_SNAPSHOTS && LA186_0 <= KW_EXPRESSION)||(LA186_0 >= KW_FIELDS && LA186_0 <= KW_FIRST)||(LA186_0 >= KW_FORMAT && LA186_0 <= KW_FORMATTED)||LA186_0==KW_FUNCTIONS||(LA186_0 >= KW_HOUR && LA186_0 <= KW_IDXPROPERTIES)||LA186_0==KW_IGNORE||(LA186_0 >= KW_INDEX && LA186_0 <= KW_INDEXES)||(LA186_0 >= KW_INPATH && LA186_0 <= KW_INPUTFORMAT)||(LA186_0 >= KW_ISOLATION && LA186_0 <= KW_JAR)||(LA186_0 >= KW_JOINCOST && LA186_0 <= KW_LAST)||LA186_0==KW_LEVEL||(LA186_0 >= KW_LIMIT && LA186_0 <= KW_LOAD)||(LA186_0 >= KW_LOCATION && LA186_0 <= KW_LONG)||(LA186_0 >= KW_MANAGED && LA186_0 <= KW_MANAGEMENT)||(LA186_0 >= KW_MAPJOIN && LA186_0 <= KW_MATERIALIZED)||LA186_0==KW_METADATA||(LA186_0 >= KW_MINUTE && LA186_0 <= KW_MONTH)||(LA186_0 >= KW_MOVE && LA186_0 <= KW_MSCK)||(LA186_0 >= KW_NORELY && LA186_0 <= KW_NOSCAN)||LA186_0==KW_NOVALIDATE||LA186_0==KW_NULLS||LA186_0==KW_OFFSET||(LA186_0 >= KW_OPERATOR && LA186_0 <= KW_OPTION)||(LA186_0 >= KW_OUTPUTDRIVER && LA186_0 <= KW_OUTPUTFORMAT)||(LA186_0 >= KW_OVERWRITE && LA186_0 <= KW_OWNER)||(LA186_0 >= KW_PARTITIONED && LA186_0 <= KW_PATH)||(LA186_0 >= KW_PLAN && LA186_0 <= KW_POOL)||LA186_0==KW_PRINCIPALS||LA186_0==KW_PURGE||(LA186_0 >= KW_QUARTER && LA186_0 <= KW_QUERY_PARALLELISM)||LA186_0==KW_READ||(LA186_0 >= KW_REBUILD && LA186_0 <= KW_RECORDWRITER)||(LA186_0 >= KW_RELOAD && LA186_0 <= KW_RESTRICT)||LA186_0==KW_REWRITE||(LA186_0 >= KW_ROLE && LA186_0 <= KW_ROLES)||(LA186_0 >= KW_SCHEDULED && LA186_0 <= KW_SECOND)||(LA186_0 >= KW_SEMI && LA186_0 <= KW_SERVER)||(LA186_0 >= KW_SETS && LA186_0 <= KW_SKEWED)||LA186_0==KW_SNAPSHOT||(LA186_0 >= KW_SORT && LA186_0 <= KW_SSL)||(LA186_0 >= KW_STATISTICS && LA186_0 <= KW_SUMMARY)||(LA186_0 >= KW_SYSTEM_TIME && LA186_0 <= KW_SYSTEM_VERSION)||LA186_0==KW_TABLES||(LA186_0 >= KW_TBLPROPERTIES && LA186_0 <= KW_TERMINATED)||LA186_0==KW_TINYINT||LA186_0==KW_TOUCH||(LA186_0 >= KW_TRANSACTION && LA186_0 <= KW_TRANSACTIONS)||LA186_0==KW_TRIM||(LA186_0 >= KW_TYPE && LA186_0 <= KW_UNARCHIVE)||LA186_0==KW_UNDO||LA186_0==KW_UNIONTYPE||(LA186_0 >= KW_UNKNOWN && LA186_0 <= KW_UNSIGNED)||(LA186_0 >= KW_URI && LA186_0 <= KW_USE)||(LA186_0 >= KW_UTC && LA186_0 <= KW_VALIDATE)||LA186_0==KW_VALUE_TYPE||(LA186_0 >= KW_VECTORIZATION && LA186_0 <= KW_WEEK)||LA186_0==KW_WHILE||(LA186_0 >= KW_WITHIN && LA186_0 <= KW_ZONE)||LA186_0==KW_BATCH||LA186_0==KW_DAYOFWEEK||LA186_0==KW_HOLD_DDLTIME||LA186_0==KW_NO_DROP||LA186_0==KW_OFFLINE||LA186_0==KW_PROTECTION||LA186_0==KW_READONLY||LA186_0==KW_TIMESTAMPTZ) ) {
				alt186=1;
			}
			else if ( (LA186_0==StringLiteral) ) {
				alt186=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 186, 0, input);
				throw nvae;
			}

			switch (alt186) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1836:7: functionIdentifier
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_functionIdentifier_in_showFunctionIdentifier9821);
					functionIdentifier575=functionIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, functionIdentifier575.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:7: StringLiteral
					{
					root_0 = (ASTNode)adaptor.nil();


					StringLiteral576=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showFunctionIdentifier9829); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					StringLiteral576_tree = (ASTNode)adaptor.create(StringLiteral576);
					adaptor.addChild(root_0, StringLiteral576_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showFunctionIdentifier"


	public static class showStmtIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "showStmtIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1840:1: showStmtIdentifier : ( identifier | StringLiteral );
	public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
		HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token StringLiteral578=null;
		ParserRuleReturnScope identifier577 =null;

		ASTNode StringLiteral578_tree=null;

		 pushMsg("identifier for show statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1843:5: ( identifier | StringLiteral )
			int alt187=2;
			int LA187_0 = input.LA(1);
			if ( (LA187_0==Identifier||(LA187_0 >= KW_ABORT && LA187_0 <= KW_AFTER)||LA187_0==KW_ALLOC_FRACTION||LA187_0==KW_ANALYZE||LA187_0==KW_ARCHIVE||(LA187_0 >= KW_ASC && LA187_0 <= KW_AT)||(LA187_0 >= KW_AUTOCOMMIT && LA187_0 <= KW_BEFORE)||(LA187_0 >= KW_BUCKET && LA187_0 <= KW_BUCKETS)||(LA187_0 >= KW_CACHE && LA187_0 <= KW_CASCADE)||(LA187_0 >= KW_CBO && LA187_0 <= KW_CHANGE)||(LA187_0 >= KW_CHECK && LA187_0 <= KW_COLLECTION)||(LA187_0 >= KW_COLUMNS && LA187_0 <= KW_COMMENT)||(LA187_0 >= KW_COMPACT && LA187_0 <= KW_CONCATENATE)||(LA187_0 >= KW_CONTINUE && LA187_0 <= KW_COST)||LA187_0==KW_CRON||LA187_0==KW_DATA||LA187_0==KW_DATABASES||(LA187_0 >= KW_DATETIME && LA187_0 <= KW_DCPROPERTIES)||LA187_0==KW_DEBUG||(LA187_0 >= KW_DEFAULT && LA187_0 <= KW_DEFINED)||(LA187_0 >= KW_DELIMITED && LA187_0 <= KW_DESC)||(LA187_0 >= KW_DETAIL && LA187_0 <= KW_DISABLE)||(LA187_0 >= KW_DISTRIBUTE && LA187_0 <= KW_DO)||LA187_0==KW_DOW||(LA187_0 >= KW_DUMP && LA187_0 <= KW_ELEM_TYPE)||LA187_0==KW_ENABLE||(LA187_0 >= KW_ENFORCED && LA187_0 <= KW_EVERY)||(LA187_0 >= KW_EXCLUSIVE && LA187_0 <= KW_EXECUTED)||(LA187_0 >= KW_EXPIRE_SNAPSHOTS && LA187_0 <= KW_EXPRESSION)||(LA187_0 >= KW_FIELDS && LA187_0 <= KW_FIRST)||(LA187_0 >= KW_FORMAT && LA187_0 <= KW_FORMATTED)||LA187_0==KW_FUNCTIONS||(LA187_0 >= KW_HOUR && LA187_0 <= KW_IDXPROPERTIES)||LA187_0==KW_IGNORE||(LA187_0 >= KW_INDEX && LA187_0 <= KW_INDEXES)||(LA187_0 >= KW_INPATH && LA187_0 <= KW_INPUTFORMAT)||(LA187_0 >= KW_ISOLATION && LA187_0 <= KW_JAR)||(LA187_0 >= KW_JOINCOST && LA187_0 <= KW_LAST)||LA187_0==KW_LEVEL||(LA187_0 >= KW_LIMIT && LA187_0 <= KW_LOAD)||(LA187_0 >= KW_LOCATION && LA187_0 <= KW_LONG)||(LA187_0 >= KW_MANAGED && LA187_0 <= KW_MANAGEMENT)||(LA187_0 >= KW_MAPJOIN && LA187_0 <= KW_MATERIALIZED)||LA187_0==KW_METADATA||(LA187_0 >= KW_MINUTE && LA187_0 <= KW_MONTH)||(LA187_0 >= KW_MOVE && LA187_0 <= KW_MSCK)||(LA187_0 >= KW_NORELY && LA187_0 <= KW_NOSCAN)||LA187_0==KW_NOVALIDATE||LA187_0==KW_NULLS||LA187_0==KW_OFFSET||(LA187_0 >= KW_OPERATOR && LA187_0 <= KW_OPTION)||(LA187_0 >= KW_OUTPUTDRIVER && LA187_0 <= KW_OUTPUTFORMAT)||(LA187_0 >= KW_OVERWRITE && LA187_0 <= KW_OWNER)||(LA187_0 >= KW_PARTITIONED && LA187_0 <= KW_PATH)||(LA187_0 >= KW_PLAN && LA187_0 <= KW_POOL)||LA187_0==KW_PRINCIPALS||LA187_0==KW_PURGE||(LA187_0 >= KW_QUARTER && LA187_0 <= KW_QUERY_PARALLELISM)||LA187_0==KW_READ||(LA187_0 >= KW_REBUILD && LA187_0 <= KW_RECORDWRITER)||(LA187_0 >= KW_RELOAD && LA187_0 <= KW_RESTRICT)||LA187_0==KW_REWRITE||(LA187_0 >= KW_ROLE && LA187_0 <= KW_ROLES)||(LA187_0 >= KW_SCHEDULED && LA187_0 <= KW_SECOND)||(LA187_0 >= KW_SEMI && LA187_0 <= KW_SERVER)||(LA187_0 >= KW_SETS && LA187_0 <= KW_SKEWED)||LA187_0==KW_SNAPSHOT||(LA187_0 >= KW_SORT && LA187_0 <= KW_SSL)||(LA187_0 >= KW_STATISTICS && LA187_0 <= KW_SUMMARY)||(LA187_0 >= KW_SYSTEM_TIME && LA187_0 <= KW_SYSTEM_VERSION)||LA187_0==KW_TABLES||(LA187_0 >= KW_TBLPROPERTIES && LA187_0 <= KW_TERMINATED)||LA187_0==KW_TINYINT||LA187_0==KW_TOUCH||(LA187_0 >= KW_TRANSACTION && LA187_0 <= KW_TRANSACTIONS)||LA187_0==KW_TRIM||(LA187_0 >= KW_TYPE && LA187_0 <= KW_UNARCHIVE)||LA187_0==KW_UNDO||LA187_0==KW_UNIONTYPE||(LA187_0 >= KW_UNKNOWN && LA187_0 <= KW_UNSIGNED)||(LA187_0 >= KW_URI && LA187_0 <= KW_USE)||(LA187_0 >= KW_UTC && LA187_0 <= KW_VALIDATE)||LA187_0==KW_VALUE_TYPE||(LA187_0 >= KW_VECTORIZATION && LA187_0 <= KW_WEEK)||LA187_0==KW_WHILE||(LA187_0 >= KW_WITHIN && LA187_0 <= KW_ZONE)||LA187_0==KW_BATCH||LA187_0==KW_DAYOFWEEK||LA187_0==KW_HOLD_DDLTIME||LA187_0==KW_NO_DROP||LA187_0==KW_OFFLINE||LA187_0==KW_PROTECTION||LA187_0==KW_READONLY||LA187_0==KW_TIMESTAMPTZ) ) {
				alt187=1;
			}
			else if ( (LA187_0==StringLiteral) ) {
				alt187=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 187, 0, input);
				throw nvae;
			}

			switch (alt187) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1843:7: identifier
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_identifier_in_showStmtIdentifier9856);
					identifier577=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier577.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1844:7: StringLiteral
					{
					root_0 = (ASTNode)adaptor.nil();


					StringLiteral578=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStmtIdentifier9864); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					StringLiteral578_tree = (ASTNode)adaptor.create(StringLiteral578);
					adaptor.addChild(root_0, StringLiteral578_tree);
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "showStmtIdentifier"


	public static class tableComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1847:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
	public final HiveParser.tableComment_return tableComment() throws RecognitionException {
		HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT579=null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT579_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

		 pushMsg("table's comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:7: KW_COMMENT comment= StringLiteral
			{
			KW_COMMENT579=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_tableComment9897); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT579);

			comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableComment9901); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

			// AST REWRITE
			// elements: comment
			// token labels: comment
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1851:41: -> ^( TOK_TABLECOMMENT $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:44: ^( TOK_TABLECOMMENT $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT"), root_1);
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableComment"


	public static class createTablePartitionSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1854:1: createTablePartitionSpec : ( KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN -> {$opt1.tree != null}? $opt1 -> $opt2| KW_PARTITIONED KW_BY KW_SPEC LPAREN (spec= partitionTransformSpec ) RPAREN -> ^( TOK_TABLEPARTCOLSBYSPEC $spec) );
	public final HiveParser.createTablePartitionSpec_return createTablePartitionSpec() throws RecognitionException {
		HiveParser.createTablePartitionSpec_return retval = new HiveParser.createTablePartitionSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PARTITIONED580=null;
		Token KW_BY581=null;
		Token LPAREN582=null;
		Token RPAREN583=null;
		Token KW_PARTITIONED584=null;
		Token KW_BY585=null;
		Token KW_SPEC586=null;
		Token LPAREN587=null;
		Token RPAREN588=null;
		ParserRuleReturnScope opt1 =null;
		ParserRuleReturnScope opt2 =null;
		ParserRuleReturnScope spec =null;

		ASTNode KW_PARTITIONED580_tree=null;
		ASTNode KW_BY581_tree=null;
		ASTNode LPAREN582_tree=null;
		ASTNode RPAREN583_tree=null;
		ASTNode KW_PARTITIONED584_tree=null;
		ASTNode KW_BY585_tree=null;
		ASTNode KW_SPEC586_tree=null;
		ASTNode LPAREN587_tree=null;
		ASTNode RPAREN588_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_SPEC=new RewriteRuleTokenStream(adaptor,"token KW_SPEC");
		RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_createTablePartitionColumnSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionColumnSpec");
		RewriteRuleSubtreeStream stream_partitionTransformSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionTransformSpec");
		RewriteRuleSubtreeStream stream_createTablePartitionColumnTypeSpec=new RewriteRuleSubtreeStream(adaptor,"rule createTablePartitionColumnTypeSpec");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:5: ( KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN -> {$opt1.tree != null}? $opt1 -> $opt2| KW_PARTITIONED KW_BY KW_SPEC LPAREN (spec= partitionTransformSpec ) RPAREN -> ^( TOK_TABLEPARTCOLSBYSPEC $spec) )
			int alt189=2;
			int LA189_0 = input.LA(1);
			if ( (LA189_0==KW_PARTITIONED) ) {
				int LA189_1 = input.LA(2);
				if ( (LA189_1==KW_BY) ) {
					int LA189_2 = input.LA(3);
					if ( (LA189_2==LPAREN) ) {
						alt189=1;
					}
					else if ( (LA189_2==KW_SPEC) ) {
						alt189=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 189, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 189, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 189, 0, input);
				throw nvae;
			}

			switch (alt189) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:7: KW_PARTITIONED KW_BY LPAREN (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec ) RPAREN
					{
					KW_PARTITIONED580=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec9938); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED580);

					KW_BY581=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_createTablePartitionSpec9940); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY581);

					LPAREN582=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTablePartitionSpec9942); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN582);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:35: (opt1= createTablePartitionColumnTypeSpec |opt2= createTablePartitionColumnSpec )
					int alt188=2;
					int LA188_0 = input.LA(1);
					if ( (LA188_0==Identifier) ) {
						int LA188_1 = input.LA(2);
						if ( (LA188_1==KW_ARRAY||(LA188_1 >= KW_BIGINT && LA188_1 <= KW_BOOLEAN)||LA188_1==KW_CHAR||(LA188_1 >= KW_DATE && LA188_1 <= KW_DATETIME)||LA188_1==KW_DECIMAL||LA188_1==KW_DOUBLE||LA188_1==KW_FLOAT||LA188_1==KW_INT||LA188_1==KW_MAP||LA188_1==KW_REAL||LA188_1==KW_SMALLINT||(LA188_1 >= KW_STRING && LA188_1 <= KW_STRUCT)||(LA188_1 >= KW_TIMESTAMP && LA188_1 <= KW_TINYINT)||LA188_1==KW_UNIONTYPE||LA188_1==KW_VARCHAR) ) {
							alt188=1;
						}
						else if ( (LA188_1==COMMA||LA188_1==RPAREN) ) {
							alt188=2;
						}

						else {
							if (state.backtracking>0) {state.failed=true; return retval;}
							int nvaeMark = input.mark();
							try {
								input.consume();
								NoViableAltException nvae =
									new NoViableAltException("", 188, 1, input);
								throw nvae;
							} finally {
								input.rewind(nvaeMark);
							}
						}

					}
					else if ( ((LA188_0 >= KW_ABORT && LA188_0 <= KW_AFTER)||LA188_0==KW_ALLOC_FRACTION||LA188_0==KW_ANALYZE||LA188_0==KW_ARCHIVE||(LA188_0 >= KW_ASC && LA188_0 <= KW_AT)||(LA188_0 >= KW_AUTOCOMMIT && LA188_0 <= KW_BEFORE)||(LA188_0 >= KW_BUCKET && LA188_0 <= KW_BUCKETS)||(LA188_0 >= KW_CACHE && LA188_0 <= KW_CASCADE)||(LA188_0 >= KW_CBO && LA188_0 <= KW_CHANGE)||(LA188_0 >= KW_CHECK && LA188_0 <= KW_COLLECTION)||(LA188_0 >= KW_COLUMNS && LA188_0 <= KW_COMMENT)||(LA188_0 >= KW_COMPACT && LA188_0 <= KW_CONCATENATE)||(LA188_0 >= KW_CONTINUE && LA188_0 <= KW_COST)||LA188_0==KW_CRON||LA188_0==KW_DATA||LA188_0==KW_DATABASES||(LA188_0 >= KW_DATETIME && LA188_0 <= KW_DCPROPERTIES)||LA188_0==KW_DEBUG||(LA188_0 >= KW_DEFAULT && LA188_0 <= KW_DEFINED)||(LA188_0 >= KW_DELIMITED && LA188_0 <= KW_DESC)||(LA188_0 >= KW_DETAIL && LA188_0 <= KW_DISABLE)||(LA188_0 >= KW_DISTRIBUTE && LA188_0 <= KW_DO)||LA188_0==KW_DOW||(LA188_0 >= KW_DUMP && LA188_0 <= KW_ELEM_TYPE)||LA188_0==KW_ENABLE||(LA188_0 >= KW_ENFORCED && LA188_0 <= KW_EVERY)||(LA188_0 >= KW_EXCLUSIVE && LA188_0 <= KW_EXECUTED)||(LA188_0 >= KW_EXPIRE_SNAPSHOTS && LA188_0 <= KW_EXPRESSION)||(LA188_0 >= KW_FIELDS && LA188_0 <= KW_FIRST)||(LA188_0 >= KW_FORMAT && LA188_0 <= KW_FORMATTED)||LA188_0==KW_FUNCTIONS||(LA188_0 >= KW_HOUR && LA188_0 <= KW_IDXPROPERTIES)||LA188_0==KW_IGNORE||(LA188_0 >= KW_INDEX && LA188_0 <= KW_INDEXES)||(LA188_0 >= KW_INPATH && LA188_0 <= KW_INPUTFORMAT)||(LA188_0 >= KW_ISOLATION && LA188_0 <= KW_JAR)||(LA188_0 >= KW_JOINCOST && LA188_0 <= KW_LAST)||LA188_0==KW_LEVEL||(LA188_0 >= KW_LIMIT && LA188_0 <= KW_LOAD)||(LA188_0 >= KW_LOCATION && LA188_0 <= KW_LONG)||(LA188_0 >= KW_MANAGED && LA188_0 <= KW_MANAGEMENT)||(LA188_0 >= KW_MAPJOIN && LA188_0 <= KW_MATERIALIZED)||LA188_0==KW_METADATA||(LA188_0 >= KW_MINUTE && LA188_0 <= KW_MONTH)||(LA188_0 >= KW_MOVE && LA188_0 <= KW_MSCK)||(LA188_0 >= KW_NORELY && LA188_0 <= KW_NOSCAN)||LA188_0==KW_NOVALIDATE||LA188_0==KW_NULLS||LA188_0==KW_OFFSET||(LA188_0 >= KW_OPERATOR && LA188_0 <= KW_OPTION)||(LA188_0 >= KW_OUTPUTDRIVER && LA188_0 <= KW_OUTPUTFORMAT)||(LA188_0 >= KW_OVERWRITE && LA188_0 <= KW_OWNER)||(LA188_0 >= KW_PARTITIONED && LA188_0 <= KW_PATH)||(LA188_0 >= KW_PLAN && LA188_0 <= KW_POOL)||LA188_0==KW_PRINCIPALS||LA188_0==KW_PURGE||(LA188_0 >= KW_QUARTER && LA188_0 <= KW_QUERY_PARALLELISM)||LA188_0==KW_READ||(LA188_0 >= KW_REBUILD && LA188_0 <= KW_RECORDWRITER)||(LA188_0 >= KW_RELOAD && LA188_0 <= KW_RESTRICT)||LA188_0==KW_REWRITE||(LA188_0 >= KW_ROLE && LA188_0 <= KW_ROLES)||(LA188_0 >= KW_SCHEDULED && LA188_0 <= KW_SECOND)||(LA188_0 >= KW_SEMI && LA188_0 <= KW_SERVER)||(LA188_0 >= KW_SETS && LA188_0 <= KW_SKEWED)||LA188_0==KW_SNAPSHOT||(LA188_0 >= KW_SORT && LA188_0 <= KW_SSL)||(LA188_0 >= KW_STATISTICS && LA188_0 <= KW_SUMMARY)||(LA188_0 >= KW_SYSTEM_TIME && LA188_0 <= KW_SYSTEM_VERSION)||LA188_0==KW_TABLES||(LA188_0 >= KW_TBLPROPERTIES && LA188_0 <= KW_TERMINATED)||LA188_0==KW_TINYINT||LA188_0==KW_TOUCH||(LA188_0 >= KW_TRANSACTION && LA188_0 <= KW_TRANSACTIONS)||LA188_0==KW_TRIM||(LA188_0 >= KW_TYPE && LA188_0 <= KW_UNARCHIVE)||LA188_0==KW_UNDO||LA188_0==KW_UNIONTYPE||(LA188_0 >= KW_UNKNOWN && LA188_0 <= KW_UNSIGNED)||(LA188_0 >= KW_URI && LA188_0 <= KW_USE)||(LA188_0 >= KW_UTC && LA188_0 <= KW_VALIDATE)||LA188_0==KW_VALUE_TYPE||(LA188_0 >= KW_VECTORIZATION && LA188_0 <= KW_WEEK)||LA188_0==KW_WHILE||(LA188_0 >= KW_WITHIN && LA188_0 <= KW_ZONE)||LA188_0==KW_BATCH||LA188_0==KW_DAYOFWEEK||LA188_0==KW_HOLD_DDLTIME||LA188_0==KW_NO_DROP||LA188_0==KW_OFFLINE||LA188_0==KW_PROTECTION||LA188_0==KW_READONLY||LA188_0==KW_TIMESTAMPTZ) ) {
						int LA188_2 = input.LA(2);
						if ( (LA188_2==KW_ARRAY||(LA188_2 >= KW_BIGINT && LA188_2 <= KW_BOOLEAN)||LA188_2==KW_CHAR||(LA188_2 >= KW_DATE && LA188_2 <= KW_DATETIME)||LA188_2==KW_DECIMAL||LA188_2==KW_DOUBLE||LA188_2==KW_FLOAT||LA188_2==KW_INT||LA188_2==KW_MAP||LA188_2==KW_REAL||LA188_2==KW_SMALLINT||(LA188_2 >= KW_STRING && LA188_2 <= KW_STRUCT)||(LA188_2 >= KW_TIMESTAMP && LA188_2 <= KW_TINYINT)||LA188_2==KW_UNIONTYPE||LA188_2==KW_VARCHAR) ) {
							alt188=1;
						}
						else if ( (LA188_2==COMMA||LA188_2==RPAREN) ) {
							alt188=2;
						}

						else {
							if (state.backtracking>0) {state.failed=true; return retval;}
							int nvaeMark = input.mark();
							try {
								input.consume();
								NoViableAltException nvae =
									new NoViableAltException("", 188, 2, input);
								throw nvae;
							} finally {
								input.rewind(nvaeMark);
							}
						}

					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 188, 0, input);
						throw nvae;
					}

					switch (alt188) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:36: opt1= createTablePartitionColumnTypeSpec
							{
							pushFollow(FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec9949);
							opt1=createTablePartitionColumnTypeSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_createTablePartitionColumnTypeSpec.add(opt1.getTree());
							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:80: opt2= createTablePartitionColumnSpec
							{
							pushFollow(FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec9957);
							opt2=createTablePartitionColumnSpec();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_createTablePartitionColumnSpec.add(opt2.getTree());
							}
							break;

					}

					RPAREN583=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTablePartitionSpec9960); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN583);

					// AST REWRITE
					// elements: opt1, opt2
					// token labels: 
					// rule labels: opt1, opt2, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_opt1=new RewriteRuleSubtreeStream(adaptor,"rule opt1",opt1!=null?opt1.getTree():null);
					RewriteRuleSubtreeStream stream_opt2=new RewriteRuleSubtreeStream(adaptor,"rule opt2",opt2!=null?opt2.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1858:5: -> {$opt1.tree != null}? $opt1
					if ((opt1!=null?((ASTNode)opt1.getTree()):null) != null) {
						adaptor.addChild(root_0, stream_opt1.nextTree());
					}

					else // 1859:5: -> $opt2
					{
						adaptor.addChild(root_0, stream_opt2.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:7: KW_PARTITIONED KW_BY KW_SPEC LPAREN (spec= partitionTransformSpec ) RPAREN
					{
					KW_PARTITIONED584=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec9988); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PARTITIONED.add(KW_PARTITIONED584);

					KW_BY585=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_createTablePartitionSpec9990); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY585);

					KW_SPEC586=(Token)match(input,KW_SPEC,FOLLOW_KW_SPEC_in_createTablePartitionSpec9992); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SPEC.add(KW_SPEC586);

					LPAREN587=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTablePartitionSpec9994); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN587);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:43: (spec= partitionTransformSpec )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1860:44: spec= partitionTransformSpec
					{
					pushFollow(FOLLOW_partitionTransformSpec_in_createTablePartitionSpec10001);
					spec=partitionTransformSpec();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_partitionTransformSpec.add(spec.getTree());
					}

					RPAREN588=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTablePartitionSpec10004); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN588);

					// AST REWRITE
					// elements: spec
					// token labels: 
					// rule labels: spec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_spec=new RewriteRuleSubtreeStream(adaptor,"rule spec",spec!=null?spec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1861:5: -> ^( TOK_TABLEPARTCOLSBYSPEC $spec)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1861:8: ^( TOK_TABLEPARTCOLSBYSPEC $spec)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLSBYSPEC, "TOK_TABLEPARTCOLSBYSPEC"), root_1);
						adaptor.addChild(root_1, stream_spec.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionSpec"


	public static class createTablePartitionColumnTypeSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionColumnTypeSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1864:1: createTablePartitionColumnTypeSpec : columnNameTypeConstraint ( COMMA columnNameTypeConstraint )* -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ ) ;
	public final HiveParser.createTablePartitionColumnTypeSpec_return createTablePartitionColumnTypeSpec() throws RecognitionException {
		HiveParser.createTablePartitionColumnTypeSpec_return retval = new HiveParser.createTablePartitionColumnTypeSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA590=null;
		ParserRuleReturnScope columnNameTypeConstraint589 =null;
		ParserRuleReturnScope columnNameTypeConstraint591 =null;

		ASTNode COMMA590_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTypeConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeConstraint");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:5: ( columnNameTypeConstraint ( COMMA columnNameTypeConstraint )* -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:7: columnNameTypeConstraint ( COMMA columnNameTypeConstraint )*
			{
			pushFollow(FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec10044);
			columnNameTypeConstraint589=columnNameTypeConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeConstraint.add(columnNameTypeConstraint589.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:32: ( COMMA columnNameTypeConstraint )*
			loop190:
			while (true) {
				int alt190=2;
				int LA190_0 = input.LA(1);
				if ( (LA190_0==COMMA) ) {
					alt190=1;
				}

				switch (alt190) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:33: COMMA columnNameTypeConstraint
					{
					COMMA590=(Token)match(input,COMMA,FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec10047); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA590);

					pushFollow(FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec10049);
					columnNameTypeConstraint591=columnNameTypeConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeConstraint.add(columnNameTypeConstraint591.getTree());
					}
					break;

				default :
					break loop190;
				}
			}

			// AST REWRITE
			// elements: columnNameTypeConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1868:5: -> ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1868:8: ^( TOK_TABLEPARTCOLS ( columnNameTypeConstraint )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS"), root_1);
				if ( !(stream_columnNameTypeConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTypeConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeConstraint.nextTree());
				}
				stream_columnNameTypeConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionColumnTypeSpec"


	public static class createTablePartitionColumnSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createTablePartitionColumnSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1871:1: createTablePartitionColumnSpec : columnName ( COMMA columnName )* -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ ) ;
	public final HiveParser.createTablePartitionColumnSpec_return createTablePartitionColumnSpec() throws RecognitionException {
		HiveParser.createTablePartitionColumnSpec_return retval = new HiveParser.createTablePartitionColumnSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA593=null;
		ParserRuleReturnScope columnName592 =null;
		ParserRuleReturnScope columnName594 =null;

		ASTNode COMMA593_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("create table partition specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:7: columnName ( COMMA columnName )*
			{
			pushFollow(FOLLOW_columnName_in_createTablePartitionColumnSpec10091);
			columnName592=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(columnName592.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:18: ( COMMA columnName )*
			loop191:
			while (true) {
				int alt191=2;
				int LA191_0 = input.LA(1);
				if ( (LA191_0==COMMA) ) {
					alt191=1;
				}

				switch (alt191) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:19: COMMA columnName
					{
					COMMA593=(Token)match(input,COMMA,FOLLOW_COMMA_in_createTablePartitionColumnSpec10094); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA593);

					pushFollow(FOLLOW_columnName_in_createTablePartitionColumnSpec10096);
					columnName594=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName594.getTree());
					}
					break;

				default :
					break loop191;
				}
			}

			// AST REWRITE
			// elements: columnName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1875:5: -> ^( TOK_TABLEPARTCOLNAMES ( columnName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:8: ^( TOK_TABLEPARTCOLNAMES ( columnName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPARTCOLNAMES, "TOK_TABLEPARTCOLNAMES"), root_1);
				if ( !(stream_columnName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnName.hasNext() ) {
					adaptor.addChild(root_1, stream_columnName.nextTree());
				}
				stream_columnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createTablePartitionColumnSpec"


	public static class partitionTransformSpec_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partitionTransformSpec"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:1: partitionTransformSpec : columnNameTransformConstraint ( COMMA columnNameTransformConstraint )* -> ( columnNameTransformConstraint )+ ;
	public final HiveParser.partitionTransformSpec_return partitionTransformSpec() throws RecognitionException {
		HiveParser.partitionTransformSpec_return retval = new HiveParser.partitionTransformSpec_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA596=null;
		ParserRuleReturnScope columnNameTransformConstraint595 =null;
		ParserRuleReturnScope columnNameTransformConstraint597 =null;

		ASTNode COMMA596_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTransformConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTransformConstraint");

		 pushMsg("create table partition by specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:5: ( columnNameTransformConstraint ( COMMA columnNameTransformConstraint )* -> ( columnNameTransformConstraint )+ )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:7: columnNameTransformConstraint ( COMMA columnNameTransformConstraint )*
			{
			pushFollow(FOLLOW_columnNameTransformConstraint_in_partitionTransformSpec10138);
			columnNameTransformConstraint595=columnNameTransformConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTransformConstraint.add(columnNameTransformConstraint595.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:37: ( COMMA columnNameTransformConstraint )*
			loop192:
			while (true) {
				int alt192=2;
				int LA192_0 = input.LA(1);
				if ( (LA192_0==COMMA) ) {
					alt192=1;
				}

				switch (alt192) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:38: COMMA columnNameTransformConstraint
					{
					COMMA596=(Token)match(input,COMMA,FOLLOW_COMMA_in_partitionTransformSpec10141); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA596);

					pushFollow(FOLLOW_columnNameTransformConstraint_in_partitionTransformSpec10143);
					columnNameTransformConstraint597=columnNameTransformConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTransformConstraint.add(columnNameTransformConstraint597.getTree());
					}
					break;

				default :
					break loop192;
				}
			}

			// AST REWRITE
			// elements: columnNameTransformConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1882:5: -> ( columnNameTransformConstraint )+
			{
				if ( !(stream_columnNameTransformConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTransformConstraint.hasNext() ) {
					adaptor.addChild(root_0, stream_columnNameTransformConstraint.nextTree());
				}
				stream_columnNameTransformConstraint.reset();

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partitionTransformSpec"


	public static class columnNameTransformConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTransformConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:1: columnNameTransformConstraint : partitionTransformType -> ^( TOK_TABCOL partitionTransformType ) ;
	public final HiveParser.columnNameTransformConstraint_return columnNameTransformConstraint() throws RecognitionException {
		HiveParser.columnNameTransformConstraint_return retval = new HiveParser.columnNameTransformConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope partitionTransformType598 =null;

		RewriteRuleSubtreeStream stream_partitionTransformType=new RewriteRuleSubtreeStream(adaptor,"rule partitionTransformType");

		 pushMsg("column transform specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:5: ( partitionTransformType -> ^( TOK_TABCOL partitionTransformType ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:7: partitionTransformType
			{
			pushFollow(FOLLOW_partitionTransformType_in_columnNameTransformConstraint10181);
			partitionTransformType598=partitionTransformType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_partitionTransformType.add(partitionTransformType598.getTree());
			// AST REWRITE
			// elements: partitionTransformType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1889:5: -> ^( TOK_TABCOL partitionTransformType )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1889:8: ^( TOK_TABCOL partitionTransformType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_partitionTransformType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTransformConstraint"


	public static class partitionTransformType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "partitionTransformType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:1: partitionTransformType : ( columnName -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_IDENTITY columnName ) | KW_YEAR LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_YEAR columnName ) | KW_MONTH LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_MONTH columnName ) | KW_DAY LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_DAY columnName ) | KW_HOUR LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_HOUR columnName ) | KW_TRUNCATE LPAREN value= Number COMMA columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_TRUNCATE $value columnName ) | KW_BUCKET LPAREN value= Number COMMA columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_BUCKET $value columnName ) );
	public final HiveParser.partitionTransformType_return partitionTransformType() throws RecognitionException {
		HiveParser.partitionTransformType_return retval = new HiveParser.partitionTransformType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token value=null;
		Token KW_YEAR600=null;
		Token LPAREN601=null;
		Token RPAREN603=null;
		Token KW_MONTH604=null;
		Token LPAREN605=null;
		Token RPAREN607=null;
		Token KW_DAY608=null;
		Token LPAREN609=null;
		Token RPAREN611=null;
		Token KW_HOUR612=null;
		Token LPAREN613=null;
		Token RPAREN615=null;
		Token KW_TRUNCATE616=null;
		Token LPAREN617=null;
		Token COMMA618=null;
		Token RPAREN620=null;
		Token KW_BUCKET621=null;
		Token LPAREN622=null;
		Token COMMA623=null;
		Token RPAREN625=null;
		ParserRuleReturnScope columnName599 =null;
		ParserRuleReturnScope columnName602 =null;
		ParserRuleReturnScope columnName606 =null;
		ParserRuleReturnScope columnName610 =null;
		ParserRuleReturnScope columnName614 =null;
		ParserRuleReturnScope columnName619 =null;
		ParserRuleReturnScope columnName624 =null;

		ASTNode value_tree=null;
		ASTNode KW_YEAR600_tree=null;
		ASTNode LPAREN601_tree=null;
		ASTNode RPAREN603_tree=null;
		ASTNode KW_MONTH604_tree=null;
		ASTNode LPAREN605_tree=null;
		ASTNode RPAREN607_tree=null;
		ASTNode KW_DAY608_tree=null;
		ASTNode LPAREN609_tree=null;
		ASTNode RPAREN611_tree=null;
		ASTNode KW_HOUR612_tree=null;
		ASTNode LPAREN613_tree=null;
		ASTNode RPAREN615_tree=null;
		ASTNode KW_TRUNCATE616_tree=null;
		ASTNode LPAREN617_tree=null;
		ASTNode COMMA618_tree=null;
		ASTNode RPAREN620_tree=null;
		ASTNode KW_BUCKET621_tree=null;
		ASTNode LPAREN622_tree=null;
		ASTNode COMMA623_tree=null;
		ASTNode RPAREN625_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_HOUR=new RewriteRuleTokenStream(adaptor,"token KW_HOUR");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_DAY=new RewriteRuleTokenStream(adaptor,"token KW_DAY");
		RewriteRuleTokenStream stream_KW_MONTH=new RewriteRuleTokenStream(adaptor,"token KW_MONTH");
		RewriteRuleTokenStream stream_KW_TRUNCATE=new RewriteRuleTokenStream(adaptor,"token KW_TRUNCATE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_YEAR=new RewriteRuleTokenStream(adaptor,"token KW_YEAR");
		RewriteRuleTokenStream stream_KW_BUCKET=new RewriteRuleTokenStream(adaptor,"token KW_BUCKET");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		pushMsg("partitition transform type specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1895:5: ( columnName -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_IDENTITY columnName ) | KW_YEAR LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_YEAR columnName ) | KW_MONTH LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_MONTH columnName ) | KW_DAY LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_DAY columnName ) | KW_HOUR LPAREN columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_HOUR columnName ) | KW_TRUNCATE LPAREN value= Number COMMA columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_TRUNCATE $value columnName ) | KW_BUCKET LPAREN value= Number COMMA columnName RPAREN -> {containExcludedCharForCreateTableColumnName($columnName.text)}? -> ^( TOK_BUCKET $value columnName ) )
			int alt193=7;
			switch ( input.LA(1) ) {
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AST:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DBPROPERTIES:
			case KW_DCPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPIRE_SNAPSHOTS:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_ID:
			case KW_IDXPROPERTIES:
			case KW_IGNORE:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGED:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_REMOTE:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESPECT:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SPEC:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_SYSTEM_TIME:
			case KW_SYSTEM_VERSION:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_TRIM:
			case KW_TYPE:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNKNOWN:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_URL:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WITHIN:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt193=1;
				}
				break;
			case KW_YEAR:
				{
				int LA193_2 = input.LA(2);
				if ( (LA193_2==LPAREN) ) {
					alt193=2;
				}
				else if ( (LA193_2==COMMA||LA193_2==RPAREN) ) {
					alt193=1;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 193, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_MONTH:
				{
				int LA193_3 = input.LA(2);
				if ( (LA193_3==LPAREN) ) {
					alt193=3;
				}
				else if ( (LA193_3==COMMA||LA193_3==RPAREN) ) {
					alt193=1;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 193, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_DAY:
				{
				int LA193_4 = input.LA(2);
				if ( (LA193_4==LPAREN) ) {
					alt193=4;
				}
				else if ( (LA193_4==COMMA||LA193_4==RPAREN) ) {
					alt193=1;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 193, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_HOUR:
				{
				int LA193_5 = input.LA(2);
				if ( (LA193_5==LPAREN) ) {
					alt193=5;
				}
				else if ( (LA193_5==COMMA||LA193_5==RPAREN) ) {
					alt193=1;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 193, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_BUCKET:
				{
				int LA193_6 = input.LA(2);
				if ( (LA193_6==LPAREN) ) {
					alt193=7;
				}
				else if ( (LA193_6==COMMA||LA193_6==RPAREN) ) {
					alt193=1;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 193, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TRUNCATE:
				{
				alt193=6;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 193, 0, input);
				throw nvae;
			}
			switch (alt193) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1895:7: columnName
					{
					pushFollow(FOLLOW_columnName_in_partitionTransformType10220);
					columnName599=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName599.getTree());
					// AST REWRITE
					// elements: columnName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1896:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName599!=null?input.toString(columnName599.start,columnName599.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1897:5: -> ^( TOK_IDENTITY columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1897:9: ^( TOK_IDENTITY columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_IDENTITY, "TOK_IDENTITY"), root_1);
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1898:7: KW_YEAR LPAREN columnName RPAREN
					{
					KW_YEAR600=(Token)match(input,KW_YEAR,FOLLOW_KW_YEAR_in_partitionTransformType10251); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_YEAR.add(KW_YEAR600);

					LPAREN601=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_partitionTransformType10253); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN601);

					pushFollow(FOLLOW_columnName_in_partitionTransformType10255);
					columnName602=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName602.getTree());
					RPAREN603=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_partitionTransformType10257); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN603);

					// AST REWRITE
					// elements: columnName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1899:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName602!=null?input.toString(columnName602.start,columnName602.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1900:5: -> ^( TOK_YEAR columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:9: ^( TOK_YEAR columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_YEAR, "TOK_YEAR"), root_1);
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1901:7: KW_MONTH LPAREN columnName RPAREN
					{
					KW_MONTH604=(Token)match(input,KW_MONTH,FOLLOW_KW_MONTH_in_partitionTransformType10288); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MONTH.add(KW_MONTH604);

					LPAREN605=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_partitionTransformType10290); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN605);

					pushFollow(FOLLOW_columnName_in_partitionTransformType10292);
					columnName606=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName606.getTree());
					RPAREN607=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_partitionTransformType10294); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN607);

					// AST REWRITE
					// elements: columnName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1902:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName606!=null?input.toString(columnName606.start,columnName606.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1903:5: -> ^( TOK_MONTH columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1903:9: ^( TOK_MONTH columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MONTH, "TOK_MONTH"), root_1);
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1904:7: KW_DAY LPAREN columnName RPAREN
					{
					KW_DAY608=(Token)match(input,KW_DAY,FOLLOW_KW_DAY_in_partitionTransformType10325); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DAY.add(KW_DAY608);

					LPAREN609=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_partitionTransformType10327); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN609);

					pushFollow(FOLLOW_columnName_in_partitionTransformType10329);
					columnName610=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName610.getTree());
					RPAREN611=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_partitionTransformType10331); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN611);

					// AST REWRITE
					// elements: columnName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1905:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName610!=null?input.toString(columnName610.start,columnName610.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1906:5: -> ^( TOK_DAY columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1906:9: ^( TOK_DAY columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DAY, "TOK_DAY"), root_1);
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1907:7: KW_HOUR LPAREN columnName RPAREN
					{
					KW_HOUR612=(Token)match(input,KW_HOUR,FOLLOW_KW_HOUR_in_partitionTransformType10362); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_HOUR.add(KW_HOUR612);

					LPAREN613=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_partitionTransformType10364); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN613);

					pushFollow(FOLLOW_columnName_in_partitionTransformType10366);
					columnName614=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName614.getTree());
					RPAREN615=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_partitionTransformType10368); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN615);

					// AST REWRITE
					// elements: columnName
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1908:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName614!=null?input.toString(columnName614.start,columnName614.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1909:5: -> ^( TOK_HOUR columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1909:9: ^( TOK_HOUR columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_HOUR, "TOK_HOUR"), root_1);
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1910:7: KW_TRUNCATE LPAREN value= Number COMMA columnName RPAREN
					{
					KW_TRUNCATE616=(Token)match(input,KW_TRUNCATE,FOLLOW_KW_TRUNCATE_in_partitionTransformType10399); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TRUNCATE.add(KW_TRUNCATE616);

					LPAREN617=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_partitionTransformType10401); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN617);

					value=(Token)match(input,Number,FOLLOW_Number_in_partitionTransformType10407); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(value);

					COMMA618=(Token)match(input,COMMA,FOLLOW_COMMA_in_partitionTransformType10409); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA618);

					pushFollow(FOLLOW_columnName_in_partitionTransformType10411);
					columnName619=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName619.getTree());
					RPAREN620=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_partitionTransformType10413); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN620);

					// AST REWRITE
					// elements: columnName, value
					// token labels: value
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1911:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName619!=null?input.toString(columnName619.start,columnName619.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1912:5: -> ^( TOK_TRUNCATE $value columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1912:9: ^( TOK_TRUNCATE $value columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TRUNCATE, "TOK_TRUNCATE"), root_1);
						adaptor.addChild(root_1, stream_value.nextNode());
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1913:7: KW_BUCKET LPAREN value= Number COMMA columnName RPAREN
					{
					KW_BUCKET621=(Token)match(input,KW_BUCKET,FOLLOW_KW_BUCKET_in_partitionTransformType10447); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BUCKET.add(KW_BUCKET621);

					LPAREN622=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_partitionTransformType10449); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN622);

					value=(Token)match(input,Number,FOLLOW_Number_in_partitionTransformType10455); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(value);

					COMMA623=(Token)match(input,COMMA,FOLLOW_COMMA_in_partitionTransformType10457); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA623);

					pushFollow(FOLLOW_columnName_in_partitionTransformType10459);
					columnName624=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName624.getTree());
					RPAREN625=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_partitionTransformType10461); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN625);

					// AST REWRITE
					// elements: columnName, value
					// token labels: value
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1914:5: -> {containExcludedCharForCreateTableColumnName($columnName.text)}?
					if (containExcludedCharForCreateTableColumnName((columnName624!=null?input.toString(columnName624.start,columnName624.stop):null))) {
						adaptor.addChild(root_0, throwColumnNameException());
					}

					else // 1915:5: -> ^( TOK_BUCKET $value columnName )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1915:9: ^( TOK_BUCKET $value columnName )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_BUCKET, "TOK_BUCKET"), root_1);
						adaptor.addChild(root_1, stream_value.nextNode());
						adaptor.addChild(root_1, stream_columnName.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "partitionTransformType"


	public static class tableBuckets_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableBuckets"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1918:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) ;
	public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
		HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token num=null;
		Token KW_CLUSTERED626=null;
		Token KW_BY627=null;
		Token LPAREN628=null;
		Token RPAREN629=null;
		Token KW_SORTED630=null;
		Token KW_BY631=null;
		Token LPAREN632=null;
		Token RPAREN633=null;
		Token KW_INTO634=null;
		Token KW_BUCKETS635=null;
		ParserRuleReturnScope bucketCols =null;
		ParserRuleReturnScope sortCols =null;

		ASTNode num_tree=null;
		ASTNode KW_CLUSTERED626_tree=null;
		ASTNode KW_BY627_tree=null;
		ASTNode LPAREN628_tree=null;
		ASTNode RPAREN629_tree=null;
		ASTNode KW_SORTED630_tree=null;
		ASTNode KW_BY631_tree=null;
		ASTNode LPAREN632_tree=null;
		ASTNode RPAREN633_tree=null;
		ASTNode KW_INTO634_tree=null;
		ASTNode KW_BUCKETS635_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
		RewriteRuleSubtreeStream stream_columnNameOrderList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrderList");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("table buckets specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1921:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1922:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
			{
			KW_CLUSTERED626=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_tableBuckets10520); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CLUSTERED.add(KW_CLUSTERED626);

			KW_BY627=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets10522); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY627);

			LPAREN628=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets10524); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN628);

			pushFollow(FOLLOW_columnNameList_in_tableBuckets10528);
			bucketCols=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(bucketCols.getTree());
			RPAREN629=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets10530); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN629);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1922:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
			int alt194=2;
			int LA194_0 = input.LA(1);
			if ( (LA194_0==KW_SORTED) ) {
				alt194=1;
			}
			switch (alt194) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1922:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
					{
					KW_SORTED630=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_tableBuckets10533); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SORTED.add(KW_SORTED630);

					KW_BY631=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets10535); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY631);

					LPAREN632=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets10537); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN632);

					pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets10541);
					sortCols=columnNameOrderList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameOrderList.add(sortCols.getTree());
					RPAREN633=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets10543); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN633);

					}
					break;

			}

			KW_INTO634=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_tableBuckets10547); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO634);

			num=(Token)match(input,Number,FOLLOW_Number_in_tableBuckets10551); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Number.add(num);

			KW_BUCKETS635=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_tableBuckets10553); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BUCKETS.add(KW_BUCKETS635);

			// AST REWRITE
			// elements: bucketCols, sortCols, num
			// token labels: num
			// rule labels: bucketCols, sortCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
			RewriteRuleSubtreeStream stream_bucketCols=new RewriteRuleSubtreeStream(adaptor,"rule bucketCols",bucketCols!=null?bucketCols.getTree():null);
			RewriteRuleSubtreeStream stream_sortCols=new RewriteRuleSubtreeStream(adaptor,"rule sortCols",sortCols!=null?sortCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1923:5: -> ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1923:8: ^( TOK_ALTERTABLE_BUCKETS $bucketCols ( $sortCols)? $num)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ALTERTABLE_BUCKETS, "TOK_ALTERTABLE_BUCKETS"), root_1);
				adaptor.addChild(root_1, stream_bucketCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1923:46: ( $sortCols)?
				if ( stream_sortCols.hasNext() ) {
					adaptor.addChild(root_1, stream_sortCols.nextTree());
				}
				stream_sortCols.reset();

				adaptor.addChild(root_1, stream_num.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableBuckets"


	public static class tableSkewed_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableSkewed"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1926:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
	public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
		HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SKEWED636=null;
		Token KW_BY637=null;
		Token LPAREN638=null;
		Token RPAREN639=null;
		Token KW_ON640=null;
		Token LPAREN641=null;
		Token RPAREN642=null;
		ParserRuleReturnScope skewedCols =null;
		ParserRuleReturnScope skewedValues =null;
		ParserRuleReturnScope storedAsDirs643 =null;

		ASTNode KW_SKEWED636_tree=null;
		ASTNode KW_BY637_tree=null;
		ASTNode LPAREN638_tree=null;
		ASTNode RPAREN639_tree=null;
		ASTNode KW_ON640_tree=null;
		ASTNode LPAREN641_tree=null;
		ASTNode RPAREN642_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleSubtreeStream stream_skewedValueElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueElement");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
		RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");

		 pushMsg("table skewed specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1929:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( ( storedAsDirs )=> storedAsDirs )?
			{
			KW_SKEWED636=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_tableSkewed10605); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SKEWED.add(KW_SKEWED636);

			KW_BY637=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableSkewed10607); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY637);

			LPAREN638=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed10609); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN638);

			pushFollow(FOLLOW_columnNameList_in_tableSkewed10613);
			skewedCols=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameList.add(skewedCols.getTree());
			RPAREN639=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed10615); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN639);

			KW_ON640=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_tableSkewed10617); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON640);

			LPAREN641=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed10619); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN641);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:75: (skewedValues= skewedValueElement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:76: skewedValues= skewedValueElement
			{
			pushFollow(FOLLOW_skewedValueElement_in_tableSkewed10624);
			skewedValues=skewedValueElement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedValueElement.add(skewedValues.getTree());
			}

			RPAREN642=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed10627); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN642);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:116: ( ( storedAsDirs )=> storedAsDirs )?
			int alt195=2;
			int LA195_0 = input.LA(1);
			if ( (LA195_0==KW_STORED) ) {
				int LA195_1 = input.LA(2);
				if ( (LA195_1==KW_AS) ) {
					int LA195_7 = input.LA(3);
					if ( (LA195_7==KW_DIRECTORIES) ) {
						int LA195_9 = input.LA(4);
						if ( (synpred19_HiveParser()) ) {
							alt195=1;
						}
					}
				}
			}
			switch (alt195) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:117: ( storedAsDirs )=> storedAsDirs
					{
					pushFollow(FOLLOW_storedAsDirs_in_tableSkewed10636);
					storedAsDirs643=storedAsDirs();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_storedAsDirs.add(storedAsDirs643.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: storedAsDirs, skewedCols, skewedValues
			// token labels: 
			// rule labels: skewedCols, skewedValues, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_skewedCols=new RewriteRuleSubtreeStream(adaptor,"rule skewedCols",skewedCols!=null?skewedCols.getTree():null);
			RewriteRuleSubtreeStream stream_skewedValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedValues",skewedValues!=null?skewedValues.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1931:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1931:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED"), root_1);
				adaptor.addChild(root_1, stream_skewedCols.nextTree());
				adaptor.addChild(root_1, stream_skewedValues.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1931:52: ( storedAsDirs )?
				if ( stream_storedAsDirs.hasNext() ) {
					adaptor.addChild(root_1, stream_storedAsDirs.nextTree());
				}
				stream_storedAsDirs.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableSkewed"


	public static class rowFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1934:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
	public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
		HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope rowFormatSerde644 =null;
		ParserRuleReturnScope rowFormatDelimited645 =null;

		RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
		RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");

		 pushMsg("serde specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
			int alt196=3;
			int LA196_0 = input.LA(1);
			if ( (LA196_0==KW_ROW) ) {
				int LA196_1 = input.LA(2);
				if ( (LA196_1==KW_FORMAT) ) {
					int LA196_28 = input.LA(3);
					if ( (LA196_28==KW_SERDE) ) {
						alt196=1;
					}
					else if ( (LA196_28==KW_DELIMITED) ) {
						alt196=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 196, 28, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 196, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}
			else if ( (LA196_0==EOF||LA196_0==COMMA||LA196_0==KW_CLUSTER||LA196_0==KW_DISTRIBUTE||LA196_0==KW_EXCEPT||LA196_0==KW_FROM||LA196_0==KW_GROUP||LA196_0==KW_HAVING||LA196_0==KW_INSERT||LA196_0==KW_INTERSECT||LA196_0==KW_LATERAL||LA196_0==KW_LIMIT||LA196_0==KW_MAP||LA196_0==KW_MINUS||LA196_0==KW_ORDER||LA196_0==KW_QUALIFY||(LA196_0 >= KW_RECORDREADER && LA196_0 <= KW_REDUCE)||LA196_0==KW_SELECT||LA196_0==KW_SORT||LA196_0==KW_UNION||LA196_0==KW_USING||LA196_0==KW_WHERE||LA196_0==KW_WINDOW||LA196_0==RPAREN) ) {
				alt196=3;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 196, 0, input);
				throw nvae;
			}

			switch (alt196) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:7: rowFormatSerde
					{
					pushFollow(FOLLOW_rowFormatSerde_in_rowFormat10684);
					rowFormatSerde644=rowFormatSerde();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde644.getTree());
					// AST REWRITE
					// elements: rowFormatSerde
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1937:22: -> ^( TOK_SERDE rowFormatSerde )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1937:25: ^( TOK_SERDE rowFormatSerde )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:7: rowFormatDelimited
					{
					pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat10700);
					rowFormatDelimited645=rowFormatDelimited();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited645.getTree());
					// AST REWRITE
					// elements: rowFormatDelimited
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1938:26: -> ^( TOK_SERDE rowFormatDelimited )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1938:29: ^( TOK_SERDE rowFormatDelimited )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1939:9: -> ^( TOK_SERDE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1939:12: ^( TOK_SERDE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDE, "TOK_SERDE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormat"


	public static class recordReader_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "recordReader"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1942:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
	public final HiveParser.recordReader_return recordReader() throws RecognitionException {
		HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RECORDREADER646=null;
		Token StringLiteral647=null;

		ASTNode KW_RECORDREADER646_tree=null;
		ASTNode StringLiteral647_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_RECORDREADER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDREADER");

		 pushMsg("record reader specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1945:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
			int alt197=2;
			int LA197_0 = input.LA(1);
			if ( (LA197_0==KW_RECORDREADER) ) {
				alt197=1;
			}
			else if ( (LA197_0==EOF||LA197_0==COMMA||LA197_0==KW_CLUSTER||LA197_0==KW_DISTRIBUTE||LA197_0==KW_EXCEPT||LA197_0==KW_FROM||LA197_0==KW_GROUP||LA197_0==KW_HAVING||LA197_0==KW_INSERT||LA197_0==KW_INTERSECT||LA197_0==KW_LATERAL||LA197_0==KW_LIMIT||LA197_0==KW_MAP||LA197_0==KW_MINUS||LA197_0==KW_ORDER||LA197_0==KW_QUALIFY||LA197_0==KW_REDUCE||LA197_0==KW_SELECT||LA197_0==KW_SORT||LA197_0==KW_UNION||LA197_0==KW_WHERE||LA197_0==KW_WINDOW||LA197_0==RPAREN) ) {
				alt197=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 197, 0, input);
				throw nvae;
			}

			switch (alt197) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1945:7: KW_RECORDREADER StringLiteral
					{
					KW_RECORDREADER646=(Token)match(input,KW_RECORDREADER,FOLLOW_KW_RECORDREADER_in_recordReader10749); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RECORDREADER.add(KW_RECORDREADER646);

					StringLiteral647=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordReader10751); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral647);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1945:37: -> ^( TOK_RECORDREADER StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1945:40: ^( TOK_RECORDREADER StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1946:9: -> ^( TOK_RECORDREADER )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1946:12: ^( TOK_RECORDREADER )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "recordReader"


	public static class recordWriter_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "recordWriter"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1949:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
	public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
		HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RECORDWRITER648=null;
		Token StringLiteral649=null;

		ASTNode KW_RECORDWRITER648_tree=null;
		ASTNode StringLiteral649_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_RECORDWRITER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDWRITER");

		 pushMsg("record writer specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1952:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
			int alt198=2;
			int LA198_0 = input.LA(1);
			if ( (LA198_0==KW_RECORDWRITER) ) {
				alt198=1;
			}
			else if ( (LA198_0==KW_USING) ) {
				alt198=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 198, 0, input);
				throw nvae;
			}

			switch (alt198) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1952:7: KW_RECORDWRITER StringLiteral
					{
					KW_RECORDWRITER648=(Token)match(input,KW_RECORDWRITER,FOLLOW_KW_RECORDWRITER_in_recordWriter10800); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RECORDWRITER.add(KW_RECORDWRITER648);

					StringLiteral649=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordWriter10802); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral649);

					// AST REWRITE
					// elements: StringLiteral
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1952:37: -> ^( TOK_RECORDWRITER StringLiteral )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1952:40: ^( TOK_RECORDWRITER StringLiteral )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:9: 
					{
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1953:9: -> ^( TOK_RECORDWRITER )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1953:12: ^( TOK_RECORDWRITER )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "recordWriter"


	public static class rowFormatSerde_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormatSerde"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1956:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
	public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
		HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token name=null;
		Token KW_ROW650=null;
		Token KW_FORMAT651=null;
		Token KW_SERDE652=null;
		Token KW_WITH653=null;
		Token KW_SERDEPROPERTIES654=null;
		ParserRuleReturnScope serdeprops =null;

		ASTNode name_tree=null;
		ASTNode KW_ROW650_tree=null;
		ASTNode KW_FORMAT651_tree=null;
		ASTNode KW_SERDE652_tree=null;
		ASTNode KW_WITH653_tree=null;
		ASTNode KW_SERDEPROPERTIES654_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
		RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("serde format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1959:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1959:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
			{
			KW_ROW650=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatSerde10851); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW650);

			KW_FORMAT651=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatSerde10853); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT651);

			KW_SERDE652=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_rowFormatSerde10855); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SERDE.add(KW_SERDE652);

			name=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_rowFormatSerde10859); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(name);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1959:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
			int alt199=2;
			int LA199_0 = input.LA(1);
			if ( (LA199_0==KW_WITH) ) {
				alt199=1;
			}
			switch (alt199) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1959:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
					{
					KW_WITH653=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_rowFormatSerde10862); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH653);

					KW_SERDEPROPERTIES654=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10864); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES654);

					pushFollow(FOLLOW_tableProperties_in_rowFormatSerde10868);
					serdeprops=tableProperties();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: name, serdeprops
			// token labels: name
			// rule labels: serdeprops, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
			RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1960:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDENAME, "TOK_SERDENAME"), root_1);
				adaptor.addChild(root_1, stream_name.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1960:31: ( $serdeprops)?
				if ( stream_serdeprops.hasNext() ) {
					adaptor.addChild(root_1, stream_serdeprops.nextTree());
				}
				stream_serdeprops.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormatSerde"


	public static class rowFormatDelimited_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rowFormatDelimited"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1963:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) ;
	public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
		HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ROW655=null;
		Token KW_FORMAT656=null;
		Token KW_DELIMITED657=null;
		ParserRuleReturnScope tableRowFormatFieldIdentifier658 =null;
		ParserRuleReturnScope tableRowFormatCollItemsIdentifier659 =null;
		ParserRuleReturnScope tableRowFormatMapKeysIdentifier660 =null;
		ParserRuleReturnScope tableRowFormatLinesIdentifier661 =null;
		ParserRuleReturnScope tableRowNullFormat662 =null;

		ASTNode KW_ROW655_tree=null;
		ASTNode KW_FORMAT656_tree=null;
		ASTNode KW_DELIMITED657_tree=null;
		RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
		RewriteRuleTokenStream stream_KW_DELIMITED=new RewriteRuleTokenStream(adaptor,"token KW_DELIMITED");
		RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
		RewriteRuleSubtreeStream stream_tableRowNullFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowNullFormat");
		RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatFieldIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatCollItemsIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatMapKeysIdentifier");
		RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatLinesIdentifier");

		 pushMsg("serde properties specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1966:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )?
			{
			KW_ROW655=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatDelimited10920); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROW.add(KW_ROW655);

			KW_FORMAT656=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatDelimited10922); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FORMAT.add(KW_FORMAT656);

			KW_DELIMITED657=(Token)match(input,KW_DELIMITED,FOLLOW_KW_DELIMITED_in_rowFormatDelimited10924); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DELIMITED.add(KW_DELIMITED657);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:37: ( tableRowFormatFieldIdentifier )?
			int alt200=2;
			int LA200_0 = input.LA(1);
			if ( (LA200_0==KW_FIELDS) ) {
				alt200=1;
			}
			switch (alt200) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:37: tableRowFormatFieldIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10926);
					tableRowFormatFieldIdentifier658=tableRowFormatFieldIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier658.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:68: ( tableRowFormatCollItemsIdentifier )?
			int alt201=2;
			int LA201_0 = input.LA(1);
			if ( (LA201_0==KW_COLLECTION) ) {
				alt201=1;
			}
			switch (alt201) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:68: tableRowFormatCollItemsIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10929);
					tableRowFormatCollItemsIdentifier659=tableRowFormatCollItemsIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier659.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:103: ( tableRowFormatMapKeysIdentifier )?
			int alt202=2;
			alt202 = dfa202.predict(input);
			switch (alt202) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:103: tableRowFormatMapKeysIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10932);
					tableRowFormatMapKeysIdentifier660=tableRowFormatMapKeysIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier660.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:136: ( tableRowFormatLinesIdentifier )?
			int alt203=2;
			int LA203_0 = input.LA(1);
			if ( (LA203_0==KW_LINES) ) {
				alt203=1;
			}
			switch (alt203) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:136: tableRowFormatLinesIdentifier
					{
					pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10935);
					tableRowFormatLinesIdentifier661=tableRowFormatLinesIdentifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier661.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:167: ( tableRowNullFormat )?
			int alt204=2;
			int LA204_0 = input.LA(1);
			if ( (LA204_0==KW_NULL) ) {
				alt204=1;
			}
			switch (alt204) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1967:167: tableRowNullFormat
					{
					pushFollow(FOLLOW_tableRowNullFormat_in_rowFormatDelimited10938);
					tableRowNullFormat662=tableRowNullFormat();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableRowNullFormat.add(tableRowNullFormat662.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tableRowFormatLinesIdentifier, tableRowFormatMapKeysIdentifier, tableRowNullFormat, tableRowFormatCollItemsIdentifier, tableRowFormatFieldIdentifier
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1968:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ( tableRowNullFormat )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:25: ( tableRowFormatFieldIdentifier )?
				if ( stream_tableRowFormatFieldIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());
				}
				stream_tableRowFormatFieldIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:56: ( tableRowFormatCollItemsIdentifier )?
				if ( stream_tableRowFormatCollItemsIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());
				}
				stream_tableRowFormatCollItemsIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:91: ( tableRowFormatMapKeysIdentifier )?
				if ( stream_tableRowFormatMapKeysIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());
				}
				stream_tableRowFormatMapKeysIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:124: ( tableRowFormatLinesIdentifier )?
				if ( stream_tableRowFormatLinesIdentifier.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());
				}
				stream_tableRowFormatLinesIdentifier.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1968:155: ( tableRowNullFormat )?
				if ( stream_tableRowNullFormat.hasNext() ) {
					adaptor.addChild(root_1, stream_tableRowNullFormat.nextTree());
				}
				stream_tableRowNullFormat.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rowFormatDelimited"


	public static class tableRowFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1971:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
	public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
		HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope rowFormatDelimited663 =null;
		ParserRuleReturnScope rowFormatSerde664 =null;

		RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
		RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");

		 pushMsg("table row format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1974:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
			int alt205=2;
			int LA205_0 = input.LA(1);
			if ( (LA205_0==KW_ROW) ) {
				int LA205_1 = input.LA(2);
				if ( (LA205_1==KW_FORMAT) ) {
					int LA205_2 = input.LA(3);
					if ( (LA205_2==KW_DELIMITED) ) {
						alt205=1;
					}
					else if ( (LA205_2==KW_SERDE) ) {
						alt205=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 205, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 205, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 205, 0, input);
				throw nvae;
			}

			switch (alt205) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1975:7: rowFormatDelimited
					{
					pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat10997);
					rowFormatDelimited663=rowFormatDelimited();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatDelimited.add(rowFormatDelimited663.getTree());
					// AST REWRITE
					// elements: rowFormatDelimited
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1976:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1976:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT"), root_1);
						adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1977:7: rowFormatSerde
					{
					pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat11017);
					rowFormatSerde664=rowFormatSerde();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_rowFormatSerde.add(rowFormatSerde664.getTree());
					// AST REWRITE
					// elements: rowFormatSerde
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1978:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1978:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER"), root_1);
						adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormat"


	public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePropertiesPrefixed"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1981:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
	public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
		HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_TBLPROPERTIES665=null;
		ParserRuleReturnScope tableProperties666 =null;

		ASTNode KW_TBLPROPERTIES665_tree=null;

		 pushMsg("table properties with prefix", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1984:5: ( KW_TBLPROPERTIES ! tableProperties )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1985:9: KW_TBLPROPERTIES ! tableProperties
			{
			root_0 = (ASTNode)adaptor.nil();


			KW_TBLPROPERTIES665=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed11064); if (state.failed) return retval;
			pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed11067);
			tableProperties666=tableProperties();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, tableProperties666.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePropertiesPrefixed"


	public static class tableProperties_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableProperties"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1988:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
	public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
		HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN667=null;
		Token RPAREN669=null;
		ParserRuleReturnScope tablePropertiesList668 =null;

		ASTNode LPAREN667_tree=null;
		ASTNode RPAREN669_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_tablePropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesList");

		 pushMsg("table properties", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1991:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:7: LPAREN tablePropertiesList RPAREN
			{
			LPAREN667=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableProperties11100); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN667);

			pushFollow(FOLLOW_tablePropertiesList_in_tableProperties11102);
			tablePropertiesList668=tablePropertiesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tablePropertiesList.add(tablePropertiesList668.getTree());
			RPAREN669=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableProperties11104); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN669);

			// AST REWRITE
			// elements: tablePropertiesList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 1992:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:1992:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES"), root_1);
				adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableProperties"


	public static class tablePropertiesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tablePropertiesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:1995:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
	public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
		HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA671=null;
		Token COMMA674=null;
		ParserRuleReturnScope keyValueProperty670 =null;
		ParserRuleReturnScope keyValueProperty672 =null;
		ParserRuleReturnScope keyProperty673 =null;
		ParserRuleReturnScope keyProperty675 =null;

		ASTNode COMMA671_tree=null;
		ASTNode COMMA674_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
		RewriteRuleSubtreeStream stream_keyProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyProperty");

		 pushMsg("table properties list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:1998:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
			int alt208=2;
			int LA208_0 = input.LA(1);
			if ( (LA208_0==StringLiteral) ) {
				int LA208_1 = input.LA(2);
				if ( (LA208_1==EQUAL) ) {
					alt208=1;
				}
				else if ( (LA208_1==COMMA||LA208_1==RPAREN) ) {
					alt208=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 208, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 208, 0, input);
				throw nvae;
			}

			switch (alt208) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1999:7: keyValueProperty ( COMMA keyValueProperty )*
					{
					pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList11145);
					keyValueProperty670=keyValueProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty670.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:1999:24: ( COMMA keyValueProperty )*
					loop206:
					while (true) {
						int alt206=2;
						int LA206_0 = input.LA(1);
						if ( (LA206_0==COMMA) ) {
							alt206=1;
						}

						switch (alt206) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:1999:25: COMMA keyValueProperty
							{
							COMMA671=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList11148); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA671);

							pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList11150);
							keyValueProperty672=keyValueProperty();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_keyValueProperty.add(keyValueProperty672.getTree());
							}
							break;

						default :
							break loop206;
						}
					}

					// AST REWRITE
					// elements: keyValueProperty
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 1999:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:1999:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);
						if ( !(stream_keyValueProperty.hasNext()) ) {
							throw new RewriteEarlyExitException();
						}
						while ( stream_keyValueProperty.hasNext() ) {
							adaptor.addChild(root_1, stream_keyValueProperty.nextTree());
						}
						stream_keyValueProperty.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:7: keyProperty ( COMMA keyProperty )*
					{
					pushFollow(FOLLOW_keyProperty_in_tablePropertiesList11175);
					keyProperty673=keyProperty();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty673.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:19: ( COMMA keyProperty )*
					loop207:
					while (true) {
						int alt207=2;
						int LA207_0 = input.LA(1);
						if ( (LA207_0==COMMA) ) {
							alt207=1;
						}

						switch (alt207) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:20: COMMA keyProperty
							{
							COMMA674=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList11178); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA674);

							pushFollow(FOLLOW_keyProperty_in_tablePropertiesList11180);
							keyProperty675=keyProperty();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_keyProperty.add(keyProperty675.getTree());
							}
							break;

						default :
							break loop207;
						}
					}

					// AST REWRITE
					// elements: keyProperty
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2001:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2001:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST"), root_1);
						if ( !(stream_keyProperty.hasNext()) ) {
							throw new RewriteEarlyExitException();
						}
						while ( stream_keyProperty.hasNext() ) {
							adaptor.addChild(root_1, stream_keyProperty.nextTree());
						}
						stream_keyProperty.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tablePropertiesList"


	public static class keyValueProperty_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "keyValueProperty"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2004:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
	public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
		HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token key=null;
		Token value=null;
		Token EQUAL676=null;

		ASTNode key_tree=null;
		ASTNode value_tree=null;
		ASTNode EQUAL676_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");

		 pushMsg("specifying key/value property", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2007:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2008:7: key= StringLiteral EQUAL value= StringLiteral
			{
			key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty11226); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(key);

			EQUAL676=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_keyValueProperty11228); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL676);

			value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty11232); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(value);

			// AST REWRITE
			// elements: key, value
			// token labels: value, key
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
			RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2008:51: -> ^( TOK_TABLEPROPERTY $key $value)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2008:54: ^( TOK_TABLEPROPERTY $key $value)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);
				adaptor.addChild(root_1, stream_key.nextNode());
				adaptor.addChild(root_1, stream_value.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "keyValueProperty"


	public static class keyProperty_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "keyProperty"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2011:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
	public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
		HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token key=null;

		ASTNode key_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

		 pushMsg("specifying key property", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2014:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2015:7: key= StringLiteral
			{
			key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyProperty11279); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(key);

			// AST REWRITE
			// elements: key
			// token labels: key
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2015:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2015:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY"), root_1);
				adaptor.addChild(root_1, stream_key.nextNode());
				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL"));
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "keyProperty"


	public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatFieldIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2018:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
	public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token fldIdnt=null;
		Token fldEscape=null;
		Token KW_FIELDS677=null;
		Token KW_TERMINATED678=null;
		Token KW_BY679=null;
		Token KW_ESCAPED680=null;
		Token KW_BY681=null;

		ASTNode fldIdnt_tree=null;
		ASTNode fldEscape_tree=null;
		ASTNode KW_FIELDS677_tree=null;
		ASTNode KW_TERMINATED678_tree=null;
		ASTNode KW_BY679_tree=null;
		ASTNode KW_ESCAPED680_tree=null;
		ASTNode KW_BY681_tree=null;
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_ESCAPED=new RewriteRuleTokenStream(adaptor,"token KW_ESCAPED");
		RewriteRuleTokenStream stream_KW_FIELDS=new RewriteRuleTokenStream(adaptor,"token KW_FIELDS");

		 pushMsg("table row format's field separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2021:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
			{
			KW_FIELDS677=(Token)match(input,KW_FIELDS,FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier11323); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FIELDS.add(KW_FIELDS677);

			KW_TERMINATED678=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier11325); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED678);

			KW_BY679=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11327); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY679);

			fldIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11331); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(fldIdnt);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
			int alt209=2;
			int LA209_0 = input.LA(1);
			if ( (LA209_0==KW_ESCAPED) ) {
				alt209=1;
			}
			switch (alt209) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2022:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
					{
					KW_ESCAPED680=(Token)match(input,KW_ESCAPED,FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier11334); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ESCAPED.add(KW_ESCAPED680);

					KW_BY681=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11336); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY681);

					fldEscape=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11340); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(fldEscape);

					}
					break;

			}

			// AST REWRITE
			// elements: fldIdnt, fldEscape
			// token labels: fldIdnt, fldEscape
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_fldIdnt=new RewriteRuleTokenStream(adaptor,"token fldIdnt",fldIdnt);
			RewriteRuleTokenStream stream_fldEscape=new RewriteRuleTokenStream(adaptor,"token fldEscape",fldEscape);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2023:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD"), root_1);
				adaptor.addChild(root_1, stream_fldIdnt.nextNode());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2023:44: ( $fldEscape)?
				if ( stream_fldEscape.hasNext() ) {
					adaptor.addChild(root_1, stream_fldEscape.nextNode());
				}
				stream_fldEscape.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatFieldIdentifier"


	public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatCollItemsIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2026:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
	public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatCollItemsIdentifier_return retval = new HiveParser.tableRowFormatCollItemsIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token collIdnt=null;
		Token KW_COLLECTION682=null;
		Token KW_ITEMS683=null;
		Token KW_TERMINATED684=null;
		Token KW_BY685=null;

		ASTNode collIdnt_tree=null;
		ASTNode KW_COLLECTION682_tree=null;
		ASTNode KW_ITEMS683_tree=null;
		ASTNode KW_TERMINATED684_tree=null;
		ASTNode KW_BY685_tree=null;
		RewriteRuleTokenStream stream_KW_COLLECTION=new RewriteRuleTokenStream(adaptor,"token KW_COLLECTION");
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_ITEMS=new RewriteRuleTokenStream(adaptor,"token KW_ITEMS");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

		 pushMsg("table row format's column separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2029:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2030:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
			{
			KW_COLLECTION682=(Token)match(input,KW_COLLECTION,FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier11392); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COLLECTION.add(KW_COLLECTION682);

			KW_ITEMS683=(Token)match(input,KW_ITEMS,FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier11394); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ITEMS.add(KW_ITEMS683);

			KW_TERMINATED684=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier11396); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED684);

			KW_BY685=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier11398); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY685);

			collIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier11402); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(collIdnt);

			// AST REWRITE
			// elements: collIdnt
			// token labels: collIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_collIdnt=new RewriteRuleTokenStream(adaptor,"token collIdnt",collIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2031:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2031:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS"), root_1);
				adaptor.addChild(root_1, stream_collIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatCollItemsIdentifier"


	public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatMapKeysIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2034:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
	public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token mapKeysIdnt=null;
		Token KW_MAP686=null;
		Token KW_KEYS687=null;
		Token KW_TERMINATED688=null;
		Token KW_BY689=null;

		ASTNode mapKeysIdnt_tree=null;
		ASTNode KW_MAP686_tree=null;
		ASTNode KW_KEYS687_tree=null;
		ASTNode KW_TERMINATED688_tree=null;
		ASTNode KW_BY689_tree=null;
		RewriteRuleTokenStream stream_KW_KEYS=new RewriteRuleTokenStream(adaptor,"token KW_KEYS");
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");

		 pushMsg("table row format's map key separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2037:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2038:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
			{
			KW_MAP686=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11448); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP686);

			KW_KEYS687=(Token)match(input,KW_KEYS,FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11450); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEYS.add(KW_KEYS687);

			KW_TERMINATED688=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11452); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED688);

			KW_BY689=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11454); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY689);

			mapKeysIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11458); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(mapKeysIdnt);

			// AST REWRITE
			// elements: mapKeysIdnt
			// token labels: mapKeysIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_mapKeysIdnt=new RewriteRuleTokenStream(adaptor,"token mapKeysIdnt",mapKeysIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2039:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2039:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS"), root_1);
				adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatMapKeysIdentifier"


	public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowFormatLinesIdentifier"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2042:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
	public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier() throws RecognitionException {
		HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token linesIdnt=null;
		Token KW_LINES690=null;
		Token KW_TERMINATED691=null;
		Token KW_BY692=null;

		ASTNode linesIdnt_tree=null;
		ASTNode KW_LINES690_tree=null;
		ASTNode KW_TERMINATED691_tree=null;
		ASTNode KW_BY692_tree=null;
		RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LINES=new RewriteRuleTokenStream(adaptor,"token KW_LINES");

		 pushMsg("table row format's line separator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2045:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2046:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
			{
			KW_LINES690=(Token)match(input,KW_LINES,FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11504); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LINES.add(KW_LINES690);

			KW_TERMINATED691=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11506); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TERMINATED.add(KW_TERMINATED691);

			KW_BY692=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11508); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY692);

			linesIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11512); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(linesIdnt);

			// AST REWRITE
			// elements: linesIdnt
			// token labels: linesIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_linesIdnt=new RewriteRuleTokenStream(adaptor,"token linesIdnt",linesIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2047:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2047:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES"), root_1);
				adaptor.addChild(root_1, stream_linesIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowFormatLinesIdentifier"


	public static class tableRowNullFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableRowNullFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2050:1: tableRowNullFormat : KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) ;
	public final HiveParser.tableRowNullFormat_return tableRowNullFormat() throws RecognitionException {
		HiveParser.tableRowNullFormat_return retval = new HiveParser.tableRowNullFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token nullIdnt=null;
		Token KW_NULL693=null;
		Token KW_DEFINED694=null;
		Token KW_AS695=null;

		ASTNode nullIdnt_tree=null;
		ASTNode KW_NULL693_tree=null;
		ASTNode KW_DEFINED694_tree=null;
		ASTNode KW_AS695_tree=null;
		RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_DEFINED=new RewriteRuleTokenStream(adaptor,"token KW_DEFINED");

		 pushMsg("table row format's null specifier", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2053:5: ( KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATNULL $nullIdnt) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2054:7: KW_NULL KW_DEFINED KW_AS nullIdnt= StringLiteral
			{
			KW_NULL693=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_tableRowNullFormat11558); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL693);

			KW_DEFINED694=(Token)match(input,KW_DEFINED,FOLLOW_KW_DEFINED_in_tableRowNullFormat11560); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DEFINED.add(KW_DEFINED694);

			KW_AS695=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableRowNullFormat11562); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS695);

			nullIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowNullFormat11566); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(nullIdnt);

			// AST REWRITE
			// elements: nullIdnt
			// token labels: nullIdnt
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_nullIdnt=new RewriteRuleTokenStream(adaptor,"token nullIdnt",nullIdnt);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2055:5: -> ^( TOK_TABLEROWFORMATNULL $nullIdnt)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2055:8: ^( TOK_TABLEROWFORMATNULL $nullIdnt)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEROWFORMATNULL, "TOK_TABLEROWFORMATNULL"), root_1);
				adaptor.addChild(root_1, stream_nullIdnt.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableRowNullFormat"


	public static class tableFileFormat_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableFileFormat"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2057:1: tableFileFormat : ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? ( KW_STORED KW_AS fileformat= identifier )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? ) | KW_STORED KW_BY genericSpec= identifier ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? ( KW_STORED KW_AS fileformat= identifier )? -> ^( TOK_STORAGEHANDLER $genericSpec ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
	public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
		HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token inFmt=null;
		Token outFmt=null;
		Token inDriver=null;
		Token outDriver=null;
		Token storageHandler=null;
		Token KW_STORED696=null;
		Token KW_AS697=null;
		Token KW_INPUTFORMAT698=null;
		Token KW_OUTPUTFORMAT699=null;
		Token KW_INPUTDRIVER700=null;
		Token KW_OUTPUTDRIVER701=null;
		Token KW_STORED702=null;
		Token KW_BY703=null;
		Token KW_WITH704=null;
		Token KW_SERDEPROPERTIES705=null;
		Token KW_STORED706=null;
		Token KW_AS707=null;
		Token KW_STORED708=null;
		Token KW_BY709=null;
		Token KW_WITH710=null;
		Token KW_SERDEPROPERTIES711=null;
		Token KW_STORED712=null;
		Token KW_AS713=null;
		Token KW_STORED714=null;
		Token KW_AS715=null;
		ParserRuleReturnScope serdeprops =null;
		ParserRuleReturnScope fileformat =null;
		ParserRuleReturnScope genericSpec =null;

		ASTNode inFmt_tree=null;
		ASTNode outFmt_tree=null;
		ASTNode inDriver_tree=null;
		ASTNode outDriver_tree=null;
		ASTNode storageHandler_tree=null;
		ASTNode KW_STORED696_tree=null;
		ASTNode KW_AS697_tree=null;
		ASTNode KW_INPUTFORMAT698_tree=null;
		ASTNode KW_OUTPUTFORMAT699_tree=null;
		ASTNode KW_INPUTDRIVER700_tree=null;
		ASTNode KW_OUTPUTDRIVER701_tree=null;
		ASTNode KW_STORED702_tree=null;
		ASTNode KW_BY703_tree=null;
		ASTNode KW_WITH704_tree=null;
		ASTNode KW_SERDEPROPERTIES705_tree=null;
		ASTNode KW_STORED706_tree=null;
		ASTNode KW_AS707_tree=null;
		ASTNode KW_STORED708_tree=null;
		ASTNode KW_BY709_tree=null;
		ASTNode KW_WITH710_tree=null;
		ASTNode KW_SERDEPROPERTIES711_tree=null;
		ASTNode KW_STORED712_tree=null;
		ASTNode KW_AS713_tree=null;
		ASTNode KW_STORED714_tree=null;
		ASTNode KW_AS715_tree=null;
		RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
		RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
		RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
		RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");
		RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");

		 pushMsg("table file format specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2060:5: ( ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? ( KW_STORED KW_AS fileformat= identifier )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? ) | KW_STORED KW_BY genericSpec= identifier ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? ( KW_STORED KW_AS fileformat= identifier )? -> ^( TOK_STORAGEHANDLER $genericSpec ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
			int alt215=4;
			int LA215_0 = input.LA(1);
			if ( (LA215_0==KW_STORED) ) {
				int LA215_1 = input.LA(2);
				if ( (LA215_1==KW_AS) ) {
					int LA215_2 = input.LA(3);
					if ( (LA215_2==KW_INPUTFORMAT) ) {
						int LA215_4 = input.LA(4);
						if ( (synpred20_HiveParser()) ) {
							alt215=1;
						}
						else if ( (true) ) {
							alt215=4;
						}

					}
					else if ( (LA215_2==Identifier||(LA215_2 >= KW_ABORT && LA215_2 <= KW_AFTER)||LA215_2==KW_ALLOC_FRACTION||LA215_2==KW_ANALYZE||LA215_2==KW_ARCHIVE||(LA215_2 >= KW_ASC && LA215_2 <= KW_AT)||(LA215_2 >= KW_AUTOCOMMIT && LA215_2 <= KW_BEFORE)||(LA215_2 >= KW_BUCKET && LA215_2 <= KW_BUCKETS)||(LA215_2 >= KW_CACHE && LA215_2 <= KW_CASCADE)||(LA215_2 >= KW_CBO && LA215_2 <= KW_CHANGE)||(LA215_2 >= KW_CHECK && LA215_2 <= KW_COLLECTION)||(LA215_2 >= KW_COLUMNS && LA215_2 <= KW_COMMENT)||(LA215_2 >= KW_COMPACT && LA215_2 <= KW_CONCATENATE)||(LA215_2 >= KW_CONTINUE && LA215_2 <= KW_COST)||LA215_2==KW_CRON||LA215_2==KW_DATA||LA215_2==KW_DATABASES||(LA215_2 >= KW_DATETIME && LA215_2 <= KW_DCPROPERTIES)||LA215_2==KW_DEBUG||(LA215_2 >= KW_DEFAULT && LA215_2 <= KW_DEFINED)||(LA215_2 >= KW_DELIMITED && LA215_2 <= KW_DESC)||(LA215_2 >= KW_DETAIL && LA215_2 <= KW_DISABLE)||(LA215_2 >= KW_DISTRIBUTE && LA215_2 <= KW_DO)||LA215_2==KW_DOW||(LA215_2 >= KW_DUMP && LA215_2 <= KW_ELEM_TYPE)||LA215_2==KW_ENABLE||(LA215_2 >= KW_ENFORCED && LA215_2 <= KW_EVERY)||(LA215_2 >= KW_EXCLUSIVE && LA215_2 <= KW_EXECUTED)||(LA215_2 >= KW_EXPIRE_SNAPSHOTS && LA215_2 <= KW_EXPRESSION)||(LA215_2 >= KW_FIELDS && LA215_2 <= KW_FIRST)||(LA215_2 >= KW_FORMAT && LA215_2 <= KW_FORMATTED)||LA215_2==KW_FUNCTIONS||(LA215_2 >= KW_HOUR && LA215_2 <= KW_IDXPROPERTIES)||LA215_2==KW_IGNORE||(LA215_2 >= KW_INDEX && LA215_2 <= KW_INDEXES)||(LA215_2 >= KW_INPATH && LA215_2 <= KW_INPUTDRIVER)||(LA215_2 >= KW_ISOLATION && LA215_2 <= KW_JAR)||(LA215_2 >= KW_JOINCOST && LA215_2 <= KW_LAST)||LA215_2==KW_LEVEL||(LA215_2 >= KW_LIMIT && LA215_2 <= KW_LOAD)||(LA215_2 >= KW_LOCATION && LA215_2 <= KW_LONG)||(LA215_2 >= KW_MANAGED && LA215_2 <= KW_MANAGEMENT)||(LA215_2 >= KW_MAPJOIN && LA215_2 <= KW_MATERIALIZED)||LA215_2==KW_METADATA||(LA215_2 >= KW_MINUTE && LA215_2 <= KW_MONTH)||(LA215_2 >= KW_MOVE && LA215_2 <= KW_MSCK)||(LA215_2 >= KW_NORELY && LA215_2 <= KW_NOSCAN)||LA215_2==KW_NOVALIDATE||LA215_2==KW_NULLS||LA215_2==KW_OFFSET||(LA215_2 >= KW_OPERATOR && LA215_2 <= KW_OPTION)||(LA215_2 >= KW_OUTPUTDRIVER && LA215_2 <= KW_OUTPUTFORMAT)||(LA215_2 >= KW_OVERWRITE && LA215_2 <= KW_OWNER)||(LA215_2 >= KW_PARTITIONED && LA215_2 <= KW_PATH)||(LA215_2 >= KW_PLAN && LA215_2 <= KW_POOL)||LA215_2==KW_PRINCIPALS||LA215_2==KW_PURGE||(LA215_2 >= KW_QUARTER && LA215_2 <= KW_QUERY_PARALLELISM)||LA215_2==KW_READ||(LA215_2 >= KW_REBUILD && LA215_2 <= KW_RECORDWRITER)||(LA215_2 >= KW_RELOAD && LA215_2 <= KW_RESTRICT)||LA215_2==KW_REWRITE||(LA215_2 >= KW_ROLE && LA215_2 <= KW_ROLES)||(LA215_2 >= KW_SCHEDULED && LA215_2 <= KW_SECOND)||(LA215_2 >= KW_SEMI && LA215_2 <= KW_SERVER)||(LA215_2 >= KW_SETS && LA215_2 <= KW_SKEWED)||LA215_2==KW_SNAPSHOT||(LA215_2 >= KW_SORT && LA215_2 <= KW_SSL)||(LA215_2 >= KW_STATISTICS && LA215_2 <= KW_SUMMARY)||(LA215_2 >= KW_SYSTEM_TIME && LA215_2 <= KW_SYSTEM_VERSION)||LA215_2==KW_TABLES||(LA215_2 >= KW_TBLPROPERTIES && LA215_2 <= KW_TERMINATED)||LA215_2==KW_TINYINT||LA215_2==KW_TOUCH||(LA215_2 >= KW_TRANSACTION && LA215_2 <= KW_TRANSACTIONS)||LA215_2==KW_TRIM||(LA215_2 >= KW_TYPE && LA215_2 <= KW_UNARCHIVE)||LA215_2==KW_UNDO||LA215_2==KW_UNIONTYPE||(LA215_2 >= KW_UNKNOWN && LA215_2 <= KW_UNSIGNED)||(LA215_2 >= KW_URI && LA215_2 <= KW_USE)||(LA215_2 >= KW_UTC && LA215_2 <= KW_VALIDATE)||LA215_2==KW_VALUE_TYPE||(LA215_2 >= KW_VECTORIZATION && LA215_2 <= KW_WEEK)||LA215_2==KW_WHILE||(LA215_2 >= KW_WITHIN && LA215_2 <= KW_ZONE)||LA215_2==KW_BATCH||LA215_2==KW_DAYOFWEEK||LA215_2==KW_HOLD_DDLTIME||LA215_2==KW_NO_DROP||LA215_2==KW_OFFLINE||LA215_2==KW_PROTECTION||LA215_2==KW_READONLY||LA215_2==KW_TIMESTAMPTZ) ) {
						alt215=4;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 215, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( (LA215_1==KW_BY) ) {
					int LA215_3 = input.LA(3);
					if ( (LA215_3==StringLiteral) ) {
						alt215=2;
					}
					else if ( (LA215_3==Identifier||(LA215_3 >= KW_ABORT && LA215_3 <= KW_AFTER)||LA215_3==KW_ALLOC_FRACTION||LA215_3==KW_ANALYZE||LA215_3==KW_ARCHIVE||(LA215_3 >= KW_ASC && LA215_3 <= KW_AT)||(LA215_3 >= KW_AUTOCOMMIT && LA215_3 <= KW_BEFORE)||(LA215_3 >= KW_BUCKET && LA215_3 <= KW_BUCKETS)||(LA215_3 >= KW_CACHE && LA215_3 <= KW_CASCADE)||(LA215_3 >= KW_CBO && LA215_3 <= KW_CHANGE)||(LA215_3 >= KW_CHECK && LA215_3 <= KW_COLLECTION)||(LA215_3 >= KW_COLUMNS && LA215_3 <= KW_COMMENT)||(LA215_3 >= KW_COMPACT && LA215_3 <= KW_CONCATENATE)||(LA215_3 >= KW_CONTINUE && LA215_3 <= KW_COST)||LA215_3==KW_CRON||LA215_3==KW_DATA||LA215_3==KW_DATABASES||(LA215_3 >= KW_DATETIME && LA215_3 <= KW_DCPROPERTIES)||LA215_3==KW_DEBUG||(LA215_3 >= KW_DEFAULT && LA215_3 <= KW_DEFINED)||(LA215_3 >= KW_DELIMITED && LA215_3 <= KW_DESC)||(LA215_3 >= KW_DETAIL && LA215_3 <= KW_DISABLE)||(LA215_3 >= KW_DISTRIBUTE && LA215_3 <= KW_DO)||LA215_3==KW_DOW||(LA215_3 >= KW_DUMP && LA215_3 <= KW_ELEM_TYPE)||LA215_3==KW_ENABLE||(LA215_3 >= KW_ENFORCED && LA215_3 <= KW_EVERY)||(LA215_3 >= KW_EXCLUSIVE && LA215_3 <= KW_EXECUTED)||(LA215_3 >= KW_EXPIRE_SNAPSHOTS && LA215_3 <= KW_EXPRESSION)||(LA215_3 >= KW_FIELDS && LA215_3 <= KW_FIRST)||(LA215_3 >= KW_FORMAT && LA215_3 <= KW_FORMATTED)||LA215_3==KW_FUNCTIONS||(LA215_3 >= KW_HOUR && LA215_3 <= KW_IDXPROPERTIES)||LA215_3==KW_IGNORE||(LA215_3 >= KW_INDEX && LA215_3 <= KW_INDEXES)||(LA215_3 >= KW_INPATH && LA215_3 <= KW_INPUTFORMAT)||(LA215_3 >= KW_ISOLATION && LA215_3 <= KW_JAR)||(LA215_3 >= KW_JOINCOST && LA215_3 <= KW_LAST)||LA215_3==KW_LEVEL||(LA215_3 >= KW_LIMIT && LA215_3 <= KW_LOAD)||(LA215_3 >= KW_LOCATION && LA215_3 <= KW_LONG)||(LA215_3 >= KW_MANAGED && LA215_3 <= KW_MANAGEMENT)||(LA215_3 >= KW_MAPJOIN && LA215_3 <= KW_MATERIALIZED)||LA215_3==KW_METADATA||(LA215_3 >= KW_MINUTE && LA215_3 <= KW_MONTH)||(LA215_3 >= KW_MOVE && LA215_3 <= KW_MSCK)||(LA215_3 >= KW_NORELY && LA215_3 <= KW_NOSCAN)||LA215_3==KW_NOVALIDATE||LA215_3==KW_NULLS||LA215_3==KW_OFFSET||(LA215_3 >= KW_OPERATOR && LA215_3 <= KW_OPTION)||(LA215_3 >= KW_OUTPUTDRIVER && LA215_3 <= KW_OUTPUTFORMAT)||(LA215_3 >= KW_OVERWRITE && LA215_3 <= KW_OWNER)||(LA215_3 >= KW_PARTITIONED && LA215_3 <= KW_PATH)||(LA215_3 >= KW_PLAN && LA215_3 <= KW_POOL)||LA215_3==KW_PRINCIPALS||LA215_3==KW_PURGE||(LA215_3 >= KW_QUARTER && LA215_3 <= KW_QUERY_PARALLELISM)||LA215_3==KW_READ||(LA215_3 >= KW_REBUILD && LA215_3 <= KW_RECORDWRITER)||(LA215_3 >= KW_RELOAD && LA215_3 <= KW_RESTRICT)||LA215_3==KW_REWRITE||(LA215_3 >= KW_ROLE && LA215_3 <= KW_ROLES)||(LA215_3 >= KW_SCHEDULED && LA215_3 <= KW_SECOND)||(LA215_3 >= KW_SEMI && LA215_3 <= KW_SERVER)||(LA215_3 >= KW_SETS && LA215_3 <= KW_SKEWED)||LA215_3==KW_SNAPSHOT||(LA215_3 >= KW_SORT && LA215_3 <= KW_SSL)||(LA215_3 >= KW_STATISTICS && LA215_3 <= KW_SUMMARY)||(LA215_3 >= KW_SYSTEM_TIME && LA215_3 <= KW_SYSTEM_VERSION)||LA215_3==KW_TABLES||(LA215_3 >= KW_TBLPROPERTIES && LA215_3 <= KW_TERMINATED)||LA215_3==KW_TINYINT||LA215_3==KW_TOUCH||(LA215_3 >= KW_TRANSACTION && LA215_3 <= KW_TRANSACTIONS)||LA215_3==KW_TRIM||(LA215_3 >= KW_TYPE && LA215_3 <= KW_UNARCHIVE)||LA215_3==KW_UNDO||LA215_3==KW_UNIONTYPE||(LA215_3 >= KW_UNKNOWN && LA215_3 <= KW_UNSIGNED)||(LA215_3 >= KW_URI && LA215_3 <= KW_USE)||(LA215_3 >= KW_UTC && LA215_3 <= KW_VALIDATE)||LA215_3==KW_VALUE_TYPE||(LA215_3 >= KW_VECTORIZATION && LA215_3 <= KW_WEEK)||LA215_3==KW_WHILE||(LA215_3 >= KW_WITHIN && LA215_3 <= KW_ZONE)||LA215_3==KW_BATCH||LA215_3==KW_DAYOFWEEK||LA215_3==KW_HOLD_DDLTIME||LA215_3==KW_NO_DROP||LA215_3==KW_OFFLINE||LA215_3==KW_PROTECTION||LA215_3==KW_READONLY||LA215_3==KW_TIMESTAMPTZ) ) {
						alt215=3;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 215, 3, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 215, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 215, 0, input);
				throw nvae;
			}

			switch (alt215) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:7: ( KW_STORED KW_AS KW_INPUTFORMAT )=> KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					{
					KW_STORED696=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11621); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED696);

					KW_AS697=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat11623); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS697);

					KW_INPUTFORMAT698=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11625); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT698);

					inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat11629); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(inFmt);

					KW_OUTPUTFORMAT699=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11631); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT699);

					outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat11635); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(outFmt);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:131: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
					int alt210=2;
					int LA210_0 = input.LA(1);
					if ( (LA210_0==KW_INPUTDRIVER) ) {
						alt210=1;
					}
					switch (alt210) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:132: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
							{
							KW_INPUTDRIVER700=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11638); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER700);

							inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat11642); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(inDriver);

							KW_OUTPUTDRIVER701=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11644); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER701);

							outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat11648); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_StringLiteral.add(outDriver);

							}
							break;

					}

					// AST REWRITE
					// elements: inFmt, outDriver, outFmt, inDriver
					// token labels: inFmt, inDriver, outDriver, outFmt
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
					RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
					RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
					RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2062:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2062:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT"), root_1);
						adaptor.addChild(root_1, stream_inFmt.nextNode());
						adaptor.addChild(root_1, stream_outFmt.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2062:48: ( $inDriver)?
						if ( stream_inDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_inDriver.nextNode());
						}
						stream_inDriver.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2062:59: ( $outDriver)?
						if ( stream_outDriver.hasNext() ) {
							adaptor.addChild(root_1, stream_outDriver.nextNode());
						}
						stream_outDriver.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2063:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? ( KW_STORED KW_AS fileformat= identifier )?
					{
					KW_STORED702=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11686); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED702);

					KW_BY703=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableFileFormat11688); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY703);

					storageHandler=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat11692); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(storageHandler);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
					int alt211=2;
					int LA211_0 = input.LA(1);
					if ( (LA211_0==KW_WITH) ) {
						alt211=1;
					}
					switch (alt211) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2064:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
							{
							KW_WITH704=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_tableFileFormat11704); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH704);

							KW_SERDEPROPERTIES705=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11706); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES705);

							pushFollow(FOLLOW_tableProperties_in_tableFileFormat11710);
							serdeprops=tableProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2065:10: ( KW_STORED KW_AS fileformat= identifier )?
					int alt212=2;
					int LA212_0 = input.LA(1);
					if ( (LA212_0==KW_STORED) ) {
						alt212=1;
					}
					switch (alt212) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2065:11: KW_STORED KW_AS fileformat= identifier
							{
							KW_STORED706=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11724); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED706);

							KW_AS707=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat11726); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS707);

							pushFollow(FOLLOW_identifier_in_tableFileFormat11730);
							fileformat=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(fileformat.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: storageHandler, fileformat, serdeprops
					// token labels: storageHandler
					// rule labels: serdeprops, fileformat, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_storageHandler=new RewriteRuleTokenStream(adaptor,"token storageHandler",storageHandler);
					RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
					RewriteRuleSubtreeStream stream_fileformat=new RewriteRuleSubtreeStream(adaptor,"rule fileformat",fileformat!=null?fileformat.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2066:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2066:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER"), root_1);
						adaptor.addChild(root_1, stream_storageHandler.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2066:48: ( $serdeprops)?
						if ( stream_serdeprops.hasNext() ) {
							adaptor.addChild(root_1, stream_serdeprops.nextTree());
						}
						stream_serdeprops.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2066:60: ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )?
						if ( stream_fileformat.hasNext() ) {
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2066:60: ^( TOK_FILEFORMAT_GENERIC $fileformat)
							{
							ASTNode root_2 = (ASTNode)adaptor.nil();
							root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_2);
							adaptor.addChild(root_2, stream_fileformat.nextTree());
							adaptor.addChild(root_1, root_2);
							}

						}
						stream_fileformat.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2067:9: KW_STORED KW_BY genericSpec= identifier ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? ( KW_STORED KW_AS fileformat= identifier )?
					{
					KW_STORED708=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11769); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED708);

					KW_BY709=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableFileFormat11771); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BY.add(KW_BY709);

					pushFollow(FOLLOW_identifier_in_tableFileFormat11775);
					genericSpec=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2068:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
					int alt213=2;
					int LA213_0 = input.LA(1);
					if ( (LA213_0==KW_WITH) ) {
						alt213=1;
					}
					switch (alt213) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2068:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
							{
							KW_WITH710=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_tableFileFormat11787); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH710);

							KW_SERDEPROPERTIES711=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11789); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES711);

							pushFollow(FOLLOW_tableProperties_in_tableFileFormat11793);
							serdeprops=tableProperties();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableProperties.add(serdeprops.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:10: ( KW_STORED KW_AS fileformat= identifier )?
					int alt214=2;
					int LA214_0 = input.LA(1);
					if ( (LA214_0==KW_STORED) ) {
						alt214=1;
					}
					switch (alt214) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2069:11: KW_STORED KW_AS fileformat= identifier
							{
							KW_STORED712=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11807); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED712);

							KW_AS713=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat11809); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS713);

							pushFollow(FOLLOW_identifier_in_tableFileFormat11813);
							fileformat=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_identifier.add(fileformat.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: fileformat, serdeprops, genericSpec
					// token labels: 
					// rule labels: serdeprops, fileformat, genericSpec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.getTree():null);
					RewriteRuleSubtreeStream stream_fileformat=new RewriteRuleSubtreeStream(adaptor,"rule fileformat",fileformat!=null?fileformat.getTree():null);
					RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2070:7: -> ^( TOK_STORAGEHANDLER $genericSpec ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:10: ^( TOK_STORAGEHANDLER $genericSpec ( $serdeprops)? ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER"), root_1);
						adaptor.addChild(root_1, stream_genericSpec.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:45: ( $serdeprops)?
						if ( stream_serdeprops.hasNext() ) {
							adaptor.addChild(root_1, stream_serdeprops.nextTree());
						}
						stream_serdeprops.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:57: ( ^( TOK_FILEFORMAT_GENERIC $fileformat) )?
						if ( stream_fileformat.hasNext() ) {
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2070:57: ^( TOK_FILEFORMAT_GENERIC $fileformat)
							{
							ASTNode root_2 = (ASTNode)adaptor.nil();
							root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_2);
							adaptor.addChild(root_2, stream_fileformat.nextTree());
							adaptor.addChild(root_1, root_2);
							}

						}
						stream_fileformat.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2071:9: KW_STORED KW_AS genericSpec= identifier
					{
					KW_STORED714=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat11852); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STORED.add(KW_STORED714);

					KW_AS715=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat11854); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS715);

					pushFollow(FOLLOW_identifier_in_tableFileFormat11858);
					genericSpec=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(genericSpec.getTree());
					// AST REWRITE
					// elements: genericSpec
					// token labels: 
					// rule labels: genericSpec, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2072:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2072:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC"), root_1);
						adaptor.addChild(root_1, stream_genericSpec.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableFileFormat"


	public static class tableLocation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableLocation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2075:1: tableLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) ;
	public final HiveParser.tableLocation_return tableLocation() throws RecognitionException {
		HiveParser.tableLocation_return retval = new HiveParser.tableLocation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token locn=null;
		Token KW_LOCATION716=null;

		ASTNode locn_tree=null;
		ASTNode KW_LOCATION716_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

		 pushMsg("table location specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2078:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:7: KW_LOCATION locn= StringLiteral
			{
			KW_LOCATION716=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_tableLocation11906); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LOCATION.add(KW_LOCATION716);

			locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableLocation11910); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(locn);

			// AST REWRITE
			// elements: locn
			// token labels: locn
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2079:38: -> ^( TOK_TABLELOCATION $locn)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2079:41: ^( TOK_TABLELOCATION $locn)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABLELOCATION, "TOK_TABLELOCATION"), root_1);
				adaptor.addChild(root_1, stream_locn.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableLocation"


	public static class columnNameTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2082:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
	public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
		HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA718=null;
		ParserRuleReturnScope columnNameType717 =null;
		ParserRuleReturnScope columnNameType719 =null;

		ASTNode COMMA718_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");

		 pushMsg("column name type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:7: columnNameType ( COMMA columnNameType )*
			{
			pushFollow(FOLLOW_columnNameType_in_columnNameTypeList11946);
			columnNameType717=columnNameType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType717.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:22: ( COMMA columnNameType )*
			loop216:
			while (true) {
				int alt216=2;
				int LA216_0 = input.LA(1);
				if ( (LA216_0==COMMA) ) {
					int LA216_21 = input.LA(2);
					if ( (LA216_21==Identifier||(LA216_21 >= KW_ABORT && LA216_21 <= KW_AFTER)||LA216_21==KW_ALLOC_FRACTION||LA216_21==KW_ANALYZE||LA216_21==KW_ARCHIVE||(LA216_21 >= KW_ASC && LA216_21 <= KW_AT)||(LA216_21 >= KW_AUTOCOMMIT && LA216_21 <= KW_BEFORE)||(LA216_21 >= KW_BUCKET && LA216_21 <= KW_BUCKETS)||(LA216_21 >= KW_CACHE && LA216_21 <= KW_CASCADE)||(LA216_21 >= KW_CBO && LA216_21 <= KW_CHANGE)||(LA216_21 >= KW_CHECK && LA216_21 <= KW_COLLECTION)||(LA216_21 >= KW_COLUMNS && LA216_21 <= KW_COMMENT)||(LA216_21 >= KW_COMPACT && LA216_21 <= KW_CONCATENATE)||(LA216_21 >= KW_CONTINUE && LA216_21 <= KW_COST)||LA216_21==KW_CRON||LA216_21==KW_DATA||LA216_21==KW_DATABASES||(LA216_21 >= KW_DATETIME && LA216_21 <= KW_DCPROPERTIES)||LA216_21==KW_DEBUG||(LA216_21 >= KW_DEFAULT && LA216_21 <= KW_DEFINED)||(LA216_21 >= KW_DELIMITED && LA216_21 <= KW_DESC)||(LA216_21 >= KW_DETAIL && LA216_21 <= KW_DISABLE)||(LA216_21 >= KW_DISTRIBUTE && LA216_21 <= KW_DO)||LA216_21==KW_DOW||(LA216_21 >= KW_DUMP && LA216_21 <= KW_ELEM_TYPE)||LA216_21==KW_ENABLE||(LA216_21 >= KW_ENFORCED && LA216_21 <= KW_EVERY)||(LA216_21 >= KW_EXCLUSIVE && LA216_21 <= KW_EXECUTED)||(LA216_21 >= KW_EXPIRE_SNAPSHOTS && LA216_21 <= KW_EXPRESSION)||(LA216_21 >= KW_FIELDS && LA216_21 <= KW_FIRST)||(LA216_21 >= KW_FORMAT && LA216_21 <= KW_FORMATTED)||LA216_21==KW_FUNCTIONS||(LA216_21 >= KW_HOUR && LA216_21 <= KW_IDXPROPERTIES)||LA216_21==KW_IGNORE||(LA216_21 >= KW_INDEX && LA216_21 <= KW_INDEXES)||(LA216_21 >= KW_INPATH && LA216_21 <= KW_INPUTFORMAT)||(LA216_21 >= KW_ISOLATION && LA216_21 <= KW_JAR)||(LA216_21 >= KW_JOINCOST && LA216_21 <= KW_LAST)||LA216_21==KW_LEVEL||(LA216_21 >= KW_LIMIT && LA216_21 <= KW_LOAD)||(LA216_21 >= KW_LOCATION && LA216_21 <= KW_LONG)||(LA216_21 >= KW_MANAGED && LA216_21 <= KW_MANAGEMENT)||(LA216_21 >= KW_MAPJOIN && LA216_21 <= KW_MATERIALIZED)||LA216_21==KW_METADATA||(LA216_21 >= KW_MINUTE && LA216_21 <= KW_MONTH)||(LA216_21 >= KW_MOVE && LA216_21 <= KW_MSCK)||(LA216_21 >= KW_NORELY && LA216_21 <= KW_NOSCAN)||LA216_21==KW_NOVALIDATE||LA216_21==KW_NULLS||LA216_21==KW_OFFSET||(LA216_21 >= KW_OPERATOR && LA216_21 <= KW_OPTION)||(LA216_21 >= KW_OUTPUTDRIVER && LA216_21 <= KW_OUTPUTFORMAT)||(LA216_21 >= KW_OVERWRITE && LA216_21 <= KW_OWNER)||(LA216_21 >= KW_PARTITIONED && LA216_21 <= KW_PATH)||(LA216_21 >= KW_PLAN && LA216_21 <= KW_POOL)||LA216_21==KW_PRINCIPALS||LA216_21==KW_PURGE||(LA216_21 >= KW_QUARTER && LA216_21 <= KW_QUERY_PARALLELISM)||LA216_21==KW_READ||(LA216_21 >= KW_REBUILD && LA216_21 <= KW_RECORDWRITER)||(LA216_21 >= KW_RELOAD && LA216_21 <= KW_RESTRICT)||LA216_21==KW_REWRITE||(LA216_21 >= KW_ROLE && LA216_21 <= KW_ROLES)||(LA216_21 >= KW_SCHEDULED && LA216_21 <= KW_SECOND)||(LA216_21 >= KW_SEMI && LA216_21 <= KW_SERVER)||(LA216_21 >= KW_SETS && LA216_21 <= KW_SKEWED)||LA216_21==KW_SNAPSHOT||(LA216_21 >= KW_SORT && LA216_21 <= KW_SSL)||(LA216_21 >= KW_STATISTICS && LA216_21 <= KW_SUMMARY)||(LA216_21 >= KW_SYSTEM_TIME && LA216_21 <= KW_SYSTEM_VERSION)||LA216_21==KW_TABLES||(LA216_21 >= KW_TBLPROPERTIES && LA216_21 <= KW_TERMINATED)||LA216_21==KW_TINYINT||LA216_21==KW_TOUCH||(LA216_21 >= KW_TRANSACTION && LA216_21 <= KW_TRANSACTIONS)||LA216_21==KW_TRIM||(LA216_21 >= KW_TYPE && LA216_21 <= KW_UNARCHIVE)||LA216_21==KW_UNDO||LA216_21==KW_UNIONTYPE||(LA216_21 >= KW_UNKNOWN && LA216_21 <= KW_UNSIGNED)||(LA216_21 >= KW_URI && LA216_21 <= KW_USE)||(LA216_21 >= KW_UTC && LA216_21 <= KW_VALIDATE)||LA216_21==KW_VALUE_TYPE||(LA216_21 >= KW_VECTORIZATION && LA216_21 <= KW_WEEK)||LA216_21==KW_WHILE||(LA216_21 >= KW_WITHIN && LA216_21 <= KW_ZONE)||LA216_21==KW_BATCH||LA216_21==KW_DAYOFWEEK||LA216_21==KW_HOLD_DDLTIME||LA216_21==KW_NO_DROP||LA216_21==KW_OFFLINE||LA216_21==KW_PROTECTION||LA216_21==KW_READONLY||LA216_21==KW_TIMESTAMPTZ) ) {
						alt216=1;
					}

				}

				switch (alt216) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:23: COMMA columnNameType
					{
					COMMA718=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeList11949); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA718);

					pushFollow(FOLLOW_columnNameType_in_columnNameTypeList11951);
					columnNameType719=columnNameType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameType.add(columnNameType719.getTree());
					}
					break;

				default :
					break loop216;
				}
			}

			// AST REWRITE
			// elements: columnNameType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2085:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2085:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameType.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameType.nextTree());
				}
				stream_columnNameType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeList"


	public static class columnNameTypeOrConstraintList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeOrConstraintList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2088:1: columnNameTypeOrConstraintList : columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ ) ;
	public final HiveParser.columnNameTypeOrConstraintList_return columnNameTypeOrConstraintList() throws RecognitionException {
		HiveParser.columnNameTypeOrConstraintList_return retval = new HiveParser.columnNameTypeOrConstraintList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA721=null;
		ParserRuleReturnScope columnNameTypeOrConstraint720 =null;
		ParserRuleReturnScope columnNameTypeOrConstraint722 =null;

		ASTNode COMMA721_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameTypeOrConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeOrConstraint");

		 pushMsg("column name type and constraints list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2091:5: ( columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )* -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2091:7: columnNameTypeOrConstraint ( COMMA columnNameTypeOrConstraint )*
			{
			pushFollow(FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList11989);
			columnNameTypeOrConstraint720=columnNameTypeOrConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameTypeOrConstraint.add(columnNameTypeOrConstraint720.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2091:34: ( COMMA columnNameTypeOrConstraint )*
			loop217:
			while (true) {
				int alt217=2;
				int LA217_0 = input.LA(1);
				if ( (LA217_0==COMMA) ) {
					alt217=1;
				}

				switch (alt217) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2091:35: COMMA columnNameTypeOrConstraint
					{
					COMMA721=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeOrConstraintList11992); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA721);

					pushFollow(FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList11994);
					columnNameTypeOrConstraint722=columnNameTypeOrConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameTypeOrConstraint.add(columnNameTypeOrConstraint722.getTree());
					}
					break;

				default :
					break loop217;
				}
			}

			// AST REWRITE
			// elements: columnNameTypeOrConstraint
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2091:70: -> ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2091:73: ^( TOK_TABCOLLIST ( columnNameTypeOrConstraint )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameTypeOrConstraint.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameTypeOrConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameTypeOrConstraint.nextTree());
				}
				stream_columnNameTypeOrConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeOrConstraintList"


	public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameColonTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2094:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
	public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
		HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA724=null;
		ParserRuleReturnScope columnNameColonType723 =null;
		ParserRuleReturnScope columnNameColonType725 =null;

		ASTNode COMMA724_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameColonType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonType");

		 pushMsg("column name type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2097:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2097:7: columnNameColonType ( COMMA columnNameColonType )*
			{
			pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList12032);
			columnNameColonType723=columnNameColonType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType723.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2097:27: ( COMMA columnNameColonType )*
			loop218:
			while (true) {
				int alt218=2;
				int LA218_0 = input.LA(1);
				if ( (LA218_0==COMMA) ) {
					alt218=1;
				}

				switch (alt218) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2097:28: COMMA columnNameColonType
					{
					COMMA724=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameColonTypeList12035); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA724);

					pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList12037);
					columnNameColonType725=columnNameColonType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameColonType.add(columnNameColonType725.getTree());
					}
					break;

				default :
					break loop218;
				}
			}

			// AST REWRITE
			// elements: columnNameColonType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2097:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2097:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST"), root_1);
				if ( !(stream_columnNameColonType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameColonType.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameColonType.nextTree());
				}
				stream_columnNameColonType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameColonTypeList"


	public static class columnNameList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2100:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
	public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
		HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA727=null;
		ParserRuleReturnScope columnName726 =null;
		ParserRuleReturnScope columnName728 =null;

		ASTNode COMMA727_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("column name list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2103:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2103:7: columnName ( COMMA columnName )*
			{
			pushFollow(FOLLOW_columnName_in_columnNameList12075);
			columnName726=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(columnName726.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2103:18: ( COMMA columnName )*
			loop219:
			while (true) {
				int alt219=2;
				int LA219_0 = input.LA(1);
				if ( (LA219_0==COMMA) ) {
					alt219=1;
				}

				switch (alt219) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2103:19: COMMA columnName
					{
					COMMA727=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameList12078); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA727);

					pushFollow(FOLLOW_columnName_in_columnNameList12080);
					columnName728=columnName();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnName.add(columnName728.getTree());
					}
					break;

				default :
					break loop219;
				}
			}

			// AST REWRITE
			// elements: columnName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2103:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2103:41: ^( TOK_TABCOLNAME ( columnName )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnName.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnName.hasNext() ) {
					adaptor.addChild(root_1, stream_columnName.nextTree());
				}
				stream_columnName.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameList"


	public static class columnName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2106:1: columnName : identifier ;
	public final HiveParser.columnName_return columnName() throws RecognitionException {
		HiveParser.columnName_return retval = new HiveParser.columnName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope identifier729 =null;


		 pushMsg("column name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2109:5: ( identifier )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2110:7: identifier
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_columnName12124);
			identifier729=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier729.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnName"


	public static class extColumnName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "extColumnName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2113:1: extColumnName : identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* ;
	public final HiveParser.extColumnName_return extColumnName() throws RecognitionException {
		HiveParser.extColumnName_return retval = new HiveParser.extColumnName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token DOT731=null;
		Token KW_ELEM_TYPE732=null;
		Token KW_KEY_TYPE733=null;
		Token KW_VALUE_TYPE734=null;
		ParserRuleReturnScope identifier730 =null;
		ParserRuleReturnScope identifier735 =null;

		ASTNode DOT731_tree=null;
		ASTNode KW_ELEM_TYPE732_tree=null;
		ASTNode KW_KEY_TYPE733_tree=null;
		ASTNode KW_VALUE_TYPE734_tree=null;

		 pushMsg("column name for complex types", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2116:5: ( identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )* )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:7: identifier ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_identifier_in_extColumnName12157);
			identifier730=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier730.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:18: ( DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier ) )*
			loop221:
			while (true) {
				int alt221=2;
				int LA221_0 = input.LA(1);
				if ( (LA221_0==DOT) ) {
					alt221=1;
				}

				switch (alt221) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:19: DOT ^ ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
					{
					DOT731=(Token)match(input,DOT,FOLLOW_DOT_in_extColumnName12160); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					DOT731_tree = (ASTNode)adaptor.create(DOT731);
					root_0 = (ASTNode)adaptor.becomeRoot(DOT731_tree, root_0);
					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:24: ( ( KW_ELEM_TYPE )=> KW_ELEM_TYPE | ( KW_KEY_TYPE )=> KW_KEY_TYPE | ( KW_VALUE_TYPE )=> KW_VALUE_TYPE | identifier )
					int alt220=4;
					switch ( input.LA(1) ) {
					case KW_ELEM_TYPE:
						{
						int LA220_1 = input.LA(2);
						if ( (synpred21_HiveParser()) ) {
							alt220=1;
						}
						else if ( (true) ) {
							alt220=4;
						}

						}
						break;
					case KW_KEY_TYPE:
						{
						int LA220_2 = input.LA(2);
						if ( (synpred22_HiveParser()) ) {
							alt220=2;
						}
						else if ( (true) ) {
							alt220=4;
						}

						}
						break;
					case KW_VALUE_TYPE:
						{
						int LA220_3 = input.LA(2);
						if ( (synpred23_HiveParser()) ) {
							alt220=3;
						}
						else if ( (true) ) {
							alt220=4;
						}

						}
						break;
					case Identifier:
					case KW_ABORT:
					case KW_ACTIVATE:
					case KW_ACTIVE:
					case KW_ADD:
					case KW_ADMIN:
					case KW_AFTER:
					case KW_ALLOC_FRACTION:
					case KW_ANALYZE:
					case KW_ARCHIVE:
					case KW_ASC:
					case KW_AST:
					case KW_AT:
					case KW_AUTOCOMMIT:
					case KW_BEFORE:
					case KW_BUCKET:
					case KW_BUCKETS:
					case KW_CACHE:
					case KW_CASCADE:
					case KW_CBO:
					case KW_CHANGE:
					case KW_CHECK:
					case KW_CLUSTER:
					case KW_CLUSTERED:
					case KW_CLUSTERSTATUS:
					case KW_COLLECTION:
					case KW_COLUMNS:
					case KW_COMMENT:
					case KW_COMPACT:
					case KW_COMPACTIONS:
					case KW_COMPUTE:
					case KW_CONCATENATE:
					case KW_CONTINUE:
					case KW_COST:
					case KW_CRON:
					case KW_DATA:
					case KW_DATABASES:
					case KW_DATETIME:
					case KW_DAY:
					case KW_DBPROPERTIES:
					case KW_DCPROPERTIES:
					case KW_DEBUG:
					case KW_DEFAULT:
					case KW_DEFERRED:
					case KW_DEFINED:
					case KW_DELIMITED:
					case KW_DEPENDENCY:
					case KW_DESC:
					case KW_DETAIL:
					case KW_DIRECTORIES:
					case KW_DIRECTORY:
					case KW_DISABLE:
					case KW_DISTRIBUTE:
					case KW_DISTRIBUTED:
					case KW_DO:
					case KW_DOW:
					case KW_DUMP:
					case KW_ENABLE:
					case KW_ENFORCED:
					case KW_ESCAPED:
					case KW_EVERY:
					case KW_EXCLUSIVE:
					case KW_EXECUTE:
					case KW_EXECUTED:
					case KW_EXPIRE_SNAPSHOTS:
					case KW_EXPLAIN:
					case KW_EXPORT:
					case KW_EXPRESSION:
					case KW_FIELDS:
					case KW_FILE:
					case KW_FILEFORMAT:
					case KW_FIRST:
					case KW_FORMAT:
					case KW_FORMATTED:
					case KW_FUNCTIONS:
					case KW_HOUR:
					case KW_ID:
					case KW_IDXPROPERTIES:
					case KW_IGNORE:
					case KW_INDEX:
					case KW_INDEXES:
					case KW_INPATH:
					case KW_INPUTDRIVER:
					case KW_INPUTFORMAT:
					case KW_ISOLATION:
					case KW_ITEMS:
					case KW_JAR:
					case KW_JOINCOST:
					case KW_KEY:
					case KW_KEYS:
					case KW_KILL:
					case KW_LAST:
					case KW_LEVEL:
					case KW_LIMIT:
					case KW_LINES:
					case KW_LOAD:
					case KW_LOCATION:
					case KW_LOCK:
					case KW_LOCKS:
					case KW_LOGICAL:
					case KW_LONG:
					case KW_MANAGED:
					case KW_MANAGEDLOCATION:
					case KW_MANAGEMENT:
					case KW_MAPJOIN:
					case KW_MAPPING:
					case KW_MATCHED:
					case KW_MATERIALIZED:
					case KW_METADATA:
					case KW_MINUTE:
					case KW_MONTH:
					case KW_MOVE:
					case KW_MSCK:
					case KW_NORELY:
					case KW_NOSCAN:
					case KW_NOVALIDATE:
					case KW_NULLS:
					case KW_OFFSET:
					case KW_OPERATOR:
					case KW_OPTION:
					case KW_OUTPUTDRIVER:
					case KW_OUTPUTFORMAT:
					case KW_OVERWRITE:
					case KW_OWNER:
					case KW_PARTITIONED:
					case KW_PARTITIONS:
					case KW_PATH:
					case KW_PLAN:
					case KW_PLANS:
					case KW_PLUS:
					case KW_POOL:
					case KW_PRINCIPALS:
					case KW_PURGE:
					case KW_QUARTER:
					case KW_QUERY:
					case KW_QUERY_PARALLELISM:
					case KW_READ:
					case KW_REBUILD:
					case KW_RECORDREADER:
					case KW_RECORDWRITER:
					case KW_RELOAD:
					case KW_RELY:
					case KW_REMOTE:
					case KW_RENAME:
					case KW_REOPTIMIZATION:
					case KW_REPAIR:
					case KW_REPL:
					case KW_REPLACE:
					case KW_REPLICATION:
					case KW_RESOURCE:
					case KW_RESPECT:
					case KW_RESTRICT:
					case KW_REWRITE:
					case KW_ROLE:
					case KW_ROLES:
					case KW_SCHEDULED:
					case KW_SCHEDULING_POLICY:
					case KW_SCHEMA:
					case KW_SCHEMAS:
					case KW_SECOND:
					case KW_SEMI:
					case KW_SERDE:
					case KW_SERDEPROPERTIES:
					case KW_SERVER:
					case KW_SETS:
					case KW_SHARED:
					case KW_SHOW:
					case KW_SHOW_DATABASE:
					case KW_SKEWED:
					case KW_SNAPSHOT:
					case KW_SORT:
					case KW_SORTED:
					case KW_SPEC:
					case KW_SSL:
					case KW_STATISTICS:
					case KW_STATUS:
					case KW_STORED:
					case KW_STREAMTABLE:
					case KW_STRING:
					case KW_STRUCT:
					case KW_SUMMARY:
					case KW_SYSTEM_TIME:
					case KW_SYSTEM_VERSION:
					case KW_TABLES:
					case KW_TBLPROPERTIES:
					case KW_TEMPORARY:
					case KW_TERMINATED:
					case KW_TINYINT:
					case KW_TOUCH:
					case KW_TRANSACTION:
					case KW_TRANSACTIONAL:
					case KW_TRANSACTIONS:
					case KW_TRIM:
					case KW_TYPE:
					case KW_UNARCHIVE:
					case KW_UNDO:
					case KW_UNIONTYPE:
					case KW_UNKNOWN:
					case KW_UNLOCK:
					case KW_UNMANAGED:
					case KW_UNSET:
					case KW_UNSIGNED:
					case KW_URI:
					case KW_URL:
					case KW_USE:
					case KW_UTC:
					case KW_UTCTIMESTAMP:
					case KW_VALIDATE:
					case KW_VECTORIZATION:
					case KW_VIEW:
					case KW_VIEWS:
					case KW_WAIT:
					case KW_WEEK:
					case KW_WHILE:
					case KW_WITHIN:
					case KW_WORK:
					case KW_WORKLOAD:
					case KW_WRITE:
					case KW_YEAR:
					case KW_ZONE:
					case KW_BATCH:
					case KW_DAYOFWEEK:
					case KW_HOLD_DDLTIME:
					case KW_NO_DROP:
					case KW_OFFLINE:
					case KW_PROTECTION:
					case KW_READONLY:
					case KW_TIMESTAMPTZ:
						{
						alt220=4;
						}
						break;
					default:
						if (state.backtracking>0) {state.failed=true; return retval;}
						NoViableAltException nvae =
							new NoViableAltException("", 220, 0, input);
						throw nvae;
					}
					switch (alt220) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:25: ( KW_ELEM_TYPE )=> KW_ELEM_TYPE
							{
							KW_ELEM_TYPE732=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_extColumnName12170); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_ELEM_TYPE732_tree = (ASTNode)adaptor.create(KW_ELEM_TYPE732);
							adaptor.addChild(root_0, KW_ELEM_TYPE732_tree);
							}

							}
							break;
						case 2 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:58: ( KW_KEY_TYPE )=> KW_KEY_TYPE
							{
							KW_KEY_TYPE733=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_extColumnName12180); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_KEY_TYPE733_tree = (ASTNode)adaptor.create(KW_KEY_TYPE733);
							adaptor.addChild(root_0, KW_KEY_TYPE733_tree);
							}

							}
							break;
						case 3 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:89: ( KW_VALUE_TYPE )=> KW_VALUE_TYPE
							{
							KW_VALUE_TYPE734=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_extColumnName12190); if (state.failed) return retval;
							if ( state.backtracking==0 ) {
							KW_VALUE_TYPE734_tree = (ASTNode)adaptor.create(KW_VALUE_TYPE734);
							adaptor.addChild(root_0, KW_VALUE_TYPE734_tree);
							}

							}
							break;
						case 4 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:124: identifier
							{
							pushFollow(FOLLOW_identifier_in_extColumnName12194);
							identifier735=identifier();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, identifier735.getTree());

							}
							break;

					}

					}
					break;

				default :
					break loop221;
				}
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "extColumnName"


	public static class columnNameOrderList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameOrderList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2120:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
	public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
		HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA737=null;
		ParserRuleReturnScope columnNameOrder736 =null;
		ParserRuleReturnScope columnNameOrder738 =null;

		ASTNode COMMA737_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameOrder=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrder");

		 pushMsg("column name order list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:7: columnNameOrder ( COMMA columnNameOrder )*
			{
			pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList12224);
			columnNameOrder736=columnNameOrder();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder736.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:23: ( COMMA columnNameOrder )*
			loop222:
			while (true) {
				int alt222=2;
				int LA222_0 = input.LA(1);
				if ( (LA222_0==COMMA) ) {
					alt222=1;
				}

				switch (alt222) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:24: COMMA columnNameOrder
					{
					COMMA737=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameOrderList12227); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA737);

					pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList12229);
					columnNameOrder738=columnNameOrder();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameOrder.add(columnNameOrder738.getTree());
					}
					break;

				default :
					break loop222;
				}
			}

			// AST REWRITE
			// elements: columnNameOrder
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2123:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2123:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnNameOrder.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameOrder.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameOrder.nextTree());
				}
				stream_columnNameOrder.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameOrderList"


	public static class columnParenthesesList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnParenthesesList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2126:1: columnParenthesesList : LPAREN ! columnNameList RPAREN !;
	public final HiveParser.columnParenthesesList_return columnParenthesesList() throws RecognitionException {
		HiveParser.columnParenthesesList_return retval = new HiveParser.columnParenthesesList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN739=null;
		Token RPAREN741=null;
		ParserRuleReturnScope columnNameList740 =null;

		ASTNode LPAREN739_tree=null;
		ASTNode RPAREN741_tree=null;

		 pushMsg("column parentheses list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2129:5: ( LPAREN ! columnNameList RPAREN !)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2129:7: LPAREN ! columnNameList RPAREN !
			{
			root_0 = (ASTNode)adaptor.nil();


			LPAREN739=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_columnParenthesesList12267); if (state.failed) return retval;
			pushFollow(FOLLOW_columnNameList_in_columnParenthesesList12270);
			columnNameList740=columnNameList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameList740.getTree());

			RPAREN741=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_columnParenthesesList12272); if (state.failed) return retval;
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnParenthesesList"


	public static class enableValidateSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enableValidateSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2132:1: enableValidateSpecification : ( enableSpecification ( validateSpecification )? | enforcedSpecification );
	public final HiveParser.enableValidateSpecification_return enableValidateSpecification() throws RecognitionException {
		HiveParser.enableValidateSpecification_return retval = new HiveParser.enableValidateSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableSpecification742 =null;
		ParserRuleReturnScope validateSpecification743 =null;
		ParserRuleReturnScope enforcedSpecification744 =null;


		 pushMsg("enable specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:5: ( enableSpecification ( validateSpecification )? | enforcedSpecification )
			int alt224=2;
			int LA224_0 = input.LA(1);
			if ( (LA224_0==KW_DISABLE||LA224_0==KW_ENABLE) ) {
				alt224=1;
			}
			else if ( (LA224_0==KW_ENFORCED||LA224_0==KW_NOT) ) {
				alt224=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 224, 0, input);
				throw nvae;
			}

			switch (alt224) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:7: enableSpecification ( validateSpecification )?
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enableSpecification_in_enableValidateSpecification12300);
					enableSpecification742=enableSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enableSpecification742.getTree());

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:27: ( validateSpecification )?
					int alt223=2;
					int LA223_0 = input.LA(1);
					if ( (LA223_0==KW_NOVALIDATE||LA223_0==KW_VALIDATE) ) {
						alt223=1;
					}
					switch (alt223) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2135:27: validateSpecification
							{
							pushFollow(FOLLOW_validateSpecification_in_enableValidateSpecification12302);
							validateSpecification743=validateSpecification();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) adaptor.addChild(root_0, validateSpecification743.getTree());

							}
							break;

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2136:7: enforcedSpecification
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_enforcedSpecification_in_enableValidateSpecification12311);
					enforcedSpecification744=enforcedSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, enforcedSpecification744.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enableValidateSpecification"


	public static class enableSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enableSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2139:1: enableSpecification : ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) );
	public final HiveParser.enableSpecification_return enableSpecification() throws RecognitionException {
		HiveParser.enableSpecification_return retval = new HiveParser.enableSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENABLE745=null;
		Token KW_DISABLE746=null;

		ASTNode KW_ENABLE745_tree=null;
		ASTNode KW_DISABLE746_tree=null;
		RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
		RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");

		 pushMsg("enable specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:5: ( KW_ENABLE -> ^( TOK_ENABLE ) | KW_DISABLE -> ^( TOK_DISABLE ) )
			int alt225=2;
			int LA225_0 = input.LA(1);
			if ( (LA225_0==KW_ENABLE) ) {
				alt225=1;
			}
			else if ( (LA225_0==KW_DISABLE) ) {
				alt225=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 225, 0, input);
				throw nvae;
			}

			switch (alt225) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:7: KW_ENABLE
					{
					KW_ENABLE745=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_enableSpecification12338); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENABLE.add(KW_ENABLE745);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2142:17: -> ^( TOK_ENABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2142:20: ^( TOK_ENABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:7: KW_DISABLE
					{
					KW_DISABLE746=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_enableSpecification12352); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DISABLE.add(KW_DISABLE746);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2143:18: -> ^( TOK_DISABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2143:21: ^( TOK_DISABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enableSpecification"


	public static class validateSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "validateSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2146:1: validateSpecification : ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) );
	public final HiveParser.validateSpecification_return validateSpecification() throws RecognitionException {
		HiveParser.validateSpecification_return retval = new HiveParser.validateSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_VALIDATE747=null;
		Token KW_NOVALIDATE748=null;

		ASTNode KW_VALIDATE747_tree=null;
		ASTNode KW_NOVALIDATE748_tree=null;
		RewriteRuleTokenStream stream_KW_VALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_VALIDATE");
		RewriteRuleTokenStream stream_KW_NOVALIDATE=new RewriteRuleTokenStream(adaptor,"token KW_NOVALIDATE");

		 pushMsg("validate specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:5: ( KW_VALIDATE -> ^( TOK_VALIDATE ) | KW_NOVALIDATE -> ^( TOK_NOVALIDATE ) )
			int alt226=2;
			int LA226_0 = input.LA(1);
			if ( (LA226_0==KW_VALIDATE) ) {
				alt226=1;
			}
			else if ( (LA226_0==KW_NOVALIDATE) ) {
				alt226=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 226, 0, input);
				throw nvae;
			}

			switch (alt226) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:7: KW_VALIDATE
					{
					KW_VALIDATE747=(Token)match(input,KW_VALIDATE,FOLLOW_KW_VALIDATE_in_validateSpecification12385); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VALIDATE.add(KW_VALIDATE747);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2149:19: -> ^( TOK_VALIDATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2149:22: ^( TOK_VALIDATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VALIDATE, "TOK_VALIDATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2150:7: KW_NOVALIDATE
					{
					KW_NOVALIDATE748=(Token)match(input,KW_NOVALIDATE,FOLLOW_KW_NOVALIDATE_in_validateSpecification12399); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOVALIDATE.add(KW_NOVALIDATE748);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2150:21: -> ^( TOK_NOVALIDATE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2150:24: ^( TOK_NOVALIDATE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NOVALIDATE, "TOK_NOVALIDATE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "validateSpecification"


	public static class enforcedSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "enforcedSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2153:1: enforcedSpecification : ( KW_ENFORCED -> ^( TOK_ENABLE ) | KW_NOT KW_ENFORCED -> ^( TOK_DISABLE ) );
	public final HiveParser.enforcedSpecification_return enforcedSpecification() throws RecognitionException {
		HiveParser.enforcedSpecification_return retval = new HiveParser.enforcedSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ENFORCED749=null;
		Token KW_NOT750=null;
		Token KW_ENFORCED751=null;

		ASTNode KW_ENFORCED749_tree=null;
		ASTNode KW_NOT750_tree=null;
		ASTNode KW_ENFORCED751_tree=null;
		RewriteRuleTokenStream stream_KW_ENFORCED=new RewriteRuleTokenStream(adaptor,"token KW_ENFORCED");
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");

		 pushMsg("enforced specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2156:5: ( KW_ENFORCED -> ^( TOK_ENABLE ) | KW_NOT KW_ENFORCED -> ^( TOK_DISABLE ) )
			int alt227=2;
			int LA227_0 = input.LA(1);
			if ( (LA227_0==KW_ENFORCED) ) {
				alt227=1;
			}
			else if ( (LA227_0==KW_NOT) ) {
				alt227=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 227, 0, input);
				throw nvae;
			}

			switch (alt227) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2156:7: KW_ENFORCED
					{
					KW_ENFORCED749=(Token)match(input,KW_ENFORCED,FOLLOW_KW_ENFORCED_in_enforcedSpecification12432); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENFORCED.add(KW_ENFORCED749);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2156:19: -> ^( TOK_ENABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2156:22: ^( TOK_ENABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ENABLE, "TOK_ENABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2157:7: KW_NOT KW_ENFORCED
					{
					KW_NOT750=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_enforcedSpecification12446); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT750);

					KW_ENFORCED751=(Token)match(input,KW_ENFORCED,FOLLOW_KW_ENFORCED_in_enforcedSpecification12448); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ENFORCED.add(KW_ENFORCED751);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2157:26: -> ^( TOK_DISABLE )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2157:29: ^( TOK_DISABLE )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DISABLE, "TOK_DISABLE"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "enforcedSpecification"


	public static class relySpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "relySpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2160:1: relySpecification : ( KW_RELY -> ^( TOK_RELY ) | KW_NORELY -> ^( TOK_NORELY ) );
	public final HiveParser.relySpecification_return relySpecification() throws RecognitionException {
		HiveParser.relySpecification_return retval = new HiveParser.relySpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_RELY752=null;
		Token KW_NORELY753=null;

		ASTNode KW_RELY752_tree=null;
		ASTNode KW_NORELY753_tree=null;
		RewriteRuleTokenStream stream_KW_NORELY=new RewriteRuleTokenStream(adaptor,"token KW_NORELY");
		RewriteRuleTokenStream stream_KW_RELY=new RewriteRuleTokenStream(adaptor,"token KW_RELY");

		 pushMsg("rely specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2163:5: ( KW_RELY -> ^( TOK_RELY ) | KW_NORELY -> ^( TOK_NORELY ) )
			int alt228=2;
			int LA228_0 = input.LA(1);
			if ( (LA228_0==KW_RELY) ) {
				alt228=1;
			}
			else if ( (LA228_0==KW_NORELY) ) {
				alt228=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 228, 0, input);
				throw nvae;
			}

			switch (alt228) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2163:8: KW_RELY
					{
					KW_RELY752=(Token)match(input,KW_RELY,FOLLOW_KW_RELY_in_relySpecification12482); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_RELY.add(KW_RELY752);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2163:16: -> ^( TOK_RELY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2163:19: ^( TOK_RELY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_RELY, "TOK_RELY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2164:8: KW_NORELY
					{
					KW_NORELY753=(Token)match(input,KW_NORELY,FOLLOW_KW_NORELY_in_relySpecification12497); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NORELY.add(KW_NORELY753);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2164:18: -> ^( TOK_NORELY )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2164:21: ^( TOK_NORELY )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NORELY, "TOK_NORELY"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "relySpecification"


	public static class createConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2167:1: createConstraint : ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) ;
	public final HiveParser.createConstraint_return createConstraint() throws RecognitionException {
		HiveParser.createConstraint_return retval = new HiveParser.createConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT754=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tableLevelConstraint755 =null;
		ParserRuleReturnScope constraintOptsCreate756 =null;

		ASTNode KW_CONSTRAINT754_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableLevelConstraint=new RewriteRuleSubtreeStream(adaptor,"rule tableLevelConstraint");

		 pushMsg("pk or uk or nn constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:5: ( ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:7: ( KW_CONSTRAINT constraintName= identifier )? tableLevelConstraint ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt229=2;
			int LA229_0 = input.LA(1);
			if ( (LA229_0==KW_CONSTRAINT) ) {
				alt229=1;
			}
			switch (alt229) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT754=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_createConstraint12531); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT754);

					pushFollow(FOLLOW_identifier_in_createConstraint12535);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_tableLevelConstraint_in_createConstraint12539);
			tableLevelConstraint755=tableLevelConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableLevelConstraint.add(tableLevelConstraint755.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:71: ( constraintOptsCreate )?
			int alt230=2;
			int LA230_0 = input.LA(1);
			if ( (LA230_0==KW_DISABLE||LA230_0==KW_ENABLE||LA230_0==KW_ENFORCED||LA230_0==KW_NOT) ) {
				alt230=1;
			}
			switch (alt230) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2170:71: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_createConstraint12541);
					constraintOptsCreate756=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate756.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintName, constraintOptsCreate
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2171:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint755!=null?((ASTNode)tableLevelConstraint755.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2172:83: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2173:5: -> ^( ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2173:8: ^( ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint755!=null?((ASTNode)tableLevelConstraint755.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2173:39: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createConstraint"


	public static class alterConstraintWithName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterConstraintWithName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2176:1: alterConstraintWithName : KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )? -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) ;
	public final HiveParser.alterConstraintWithName_return alterConstraintWithName() throws RecognitionException {
		HiveParser.alterConstraintWithName_return retval = new HiveParser.alterConstraintWithName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT757=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tableLevelConstraint758 =null;
		ParserRuleReturnScope constraintOptsAlter759 =null;

		ASTNode KW_CONSTRAINT757_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableLevelConstraint=new RewriteRuleSubtreeStream(adaptor,"rule tableLevelConstraint");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");

		 pushMsg("pk or uk or nn constraint with name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:5: ( KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )? -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:7: KW_CONSTRAINT constraintName= identifier tableLevelConstraint ( constraintOptsAlter )?
			{
			KW_CONSTRAINT757=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName12616); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT757);

			pushFollow(FOLLOW_identifier_in_alterConstraintWithName12620);
			constraintName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
			pushFollow(FOLLOW_tableLevelConstraint_in_alterConstraintWithName12622);
			tableLevelConstraint758=tableLevelConstraint();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableLevelConstraint.add(tableLevelConstraint758.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:68: ( constraintOptsAlter )?
			int alt231=2;
			int LA231_0 = input.LA(1);
			if ( (LA231_0==KW_DISABLE||LA231_0==KW_ENABLE||LA231_0==KW_ENFORCED||LA231_0==KW_NOT) ) {
				alt231=1;
			}
			switch (alt231) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2179:68: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterConstraintWithName12624);
					constraintOptsAlter759=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter759.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsAlter, constraintName
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2180:5: -> ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:7: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((tableLevelConstraint758!=null?((ASTNode)tableLevelConstraint758.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:38: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2180:77: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterConstraintWithName"


	public static class tableLevelConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableLevelConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2183:1: tableLevelConstraint : ( pkUkConstraint | checkConstraint );
	public final HiveParser.tableLevelConstraint_return tableLevelConstraint() throws RecognitionException {
		HiveParser.tableLevelConstraint_return retval = new HiveParser.tableLevelConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope pkUkConstraint760 =null;
		ParserRuleReturnScope checkConstraint761 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:5: ( pkUkConstraint | checkConstraint )
			int alt232=2;
			int LA232_0 = input.LA(1);
			if ( (LA232_0==KW_PRIMARY||LA232_0==KW_UNIQUE) ) {
				alt232=1;
			}
			else if ( (LA232_0==KW_CHECK) ) {
				alt232=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 232, 0, input);
				throw nvae;
			}

			switch (alt232) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2184:7: pkUkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_pkUkConstraint_in_tableLevelConstraint12661);
					pkUkConstraint760=pkUkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, pkUkConstraint760.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2185:7: checkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_checkConstraint_in_tableLevelConstraint12669);
					checkConstraint761=checkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, checkConstraint761.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableLevelConstraint"


	public static class pkUkConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "pkUkConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2188:1: pkUkConstraint : tableConstraintType pkCols= columnParenthesesList -> ^( tableConstraintType $pkCols) ;
	public final HiveParser.pkUkConstraint_return pkUkConstraint() throws RecognitionException {
		HiveParser.pkUkConstraint_return retval = new HiveParser.pkUkConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope pkCols =null;
		ParserRuleReturnScope tableConstraintType762 =null;

		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule tableConstraintType");

		 pushMsg("pk or uk table level constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:5: ( tableConstraintType pkCols= columnParenthesesList -> ^( tableConstraintType $pkCols) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2191:7: tableConstraintType pkCols= columnParenthesesList
			{
			pushFollow(FOLLOW_tableConstraintType_in_pkUkConstraint12696);
			tableConstraintType762=tableConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableConstraintType.add(tableConstraintType762.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_pkUkConstraint12700);
			pkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(pkCols.getTree());
			// AST REWRITE
			// elements: pkCols, tableConstraintType
			// token labels: 
			// rule labels: pkCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_pkCols=new RewriteRuleSubtreeStream(adaptor,"rule pkCols",pkCols!=null?pkCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2192:5: -> ^( tableConstraintType $pkCols)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2192:8: ^( tableConstraintType $pkCols)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_tableConstraintType.nextNode(), root_1);
				adaptor.addChild(root_1, stream_pkCols.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "pkUkConstraint"


	public static class checkConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "checkConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2195:1: checkConstraint : KW_CHECK LPAREN expression RPAREN -> ^( TOK_CHECK_CONSTRAINT expression ) ;
	public final HiveParser.checkConstraint_return checkConstraint() throws RecognitionException {
		HiveParser.checkConstraint_return retval = new HiveParser.checkConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CHECK763=null;
		Token LPAREN764=null;
		Token RPAREN766=null;
		ParserRuleReturnScope expression765 =null;

		ASTNode KW_CHECK763_tree=null;
		ASTNode LPAREN764_tree=null;
		ASTNode RPAREN766_tree=null;
		RewriteRuleTokenStream stream_KW_CHECK=new RewriteRuleTokenStream(adaptor,"token KW_CHECK");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");

		 pushMsg("CHECK constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2198:5: ( KW_CHECK LPAREN expression RPAREN -> ^( TOK_CHECK_CONSTRAINT expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2198:7: KW_CHECK LPAREN expression RPAREN
			{
			KW_CHECK763=(Token)match(input,KW_CHECK,FOLLOW_KW_CHECK_in_checkConstraint12740); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CHECK.add(KW_CHECK763);

			LPAREN764=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_checkConstraint12742); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN764);

			pushFollow(FOLLOW_expression_in_checkConstraint12744);
			expression765=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression765.getTree());
			RPAREN766=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_checkConstraint12746); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN766);

			// AST REWRITE
			// elements: expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2199:5: -> ^( TOK_CHECK_CONSTRAINT expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2199:8: ^( TOK_CHECK_CONSTRAINT expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CHECK_CONSTRAINT, "TOK_CHECK_CONSTRAINT"), root_1);
				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "checkConstraint"


	public static class createForeignKey_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "createForeignKey"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2202:1: createForeignKey : ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? ) ;
	public final HiveParser.createForeignKey_return createForeignKey() throws RecognitionException {
		HiveParser.createForeignKey_return retval = new HiveParser.createForeignKey_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT767=null;
		Token KW_FOREIGN768=null;
		Token KW_KEY769=null;
		Token KW_REFERENCES770=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope fkCols =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope parCols =null;
		ParserRuleReturnScope constraintOptsCreate771 =null;

		ASTNode KW_CONSTRAINT767_tree=null;
		ASTNode KW_FOREIGN768_tree=null;
		ASTNode KW_KEY769_tree=null;
		ASTNode KW_REFERENCES770_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("foreign key", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:7: ( KW_CONSTRAINT constraintName= identifier )? KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt233=2;
			int LA233_0 = input.LA(1);
			if ( (LA233_0==KW_CONSTRAINT) ) {
				alt233=1;
			}
			switch (alt233) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT767=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_createForeignKey12786); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT767);

					pushFollow(FOLLOW_identifier_in_createForeignKey12790);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_FOREIGN768=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_createForeignKey12794); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN768);

			KW_KEY769=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_createForeignKey12796); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY769);

			pushFollow(FOLLOW_columnParenthesesList_in_createForeignKey12800);
			fkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());
			KW_REFERENCES770=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_createForeignKey12803); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES770);

			pushFollow(FOLLOW_tableName_in_createForeignKey12807);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_createForeignKey12811);
			parCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:160: ( constraintOptsCreate )?
			int alt234=2;
			int LA234_0 = input.LA(1);
			if ( (LA234_0==KW_DISABLE||LA234_0==KW_ENABLE||LA234_0==KW_ENFORCED||LA234_0==KW_NOT) ) {
				alt234=1;
			}
			switch (alt234) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2205:160: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_createForeignKey12813);
					constraintOptsCreate771=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate771.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: parCols, parCols, constraintOptsCreate, constraintOptsCreate, fkCols, tabName, tabName, constraintName, fkCols
			// token labels: 
			// rule labels: parCols, tabName, fkCols, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.getTree():null);
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2206:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2207:96: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2208:5: -> ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:8: ^( TOK_FOREIGN_KEY $fkCols $tabName $parCols ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2208:52: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "createForeignKey"


	public static class alterForeignKeyWithName_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterForeignKeyWithName"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2211:1: alterForeignKeyWithName : KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )? -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? ) ;
	public final HiveParser.alterForeignKeyWithName_return alterForeignKeyWithName() throws RecognitionException {
		HiveParser.alterForeignKeyWithName_return retval = new HiveParser.alterForeignKeyWithName_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT772=null;
		Token KW_FOREIGN773=null;
		Token KW_KEY774=null;
		Token KW_REFERENCES775=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope fkCols =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope parCols =null;
		ParserRuleReturnScope constraintOptsAlter776 =null;

		ASTNode KW_CONSTRAINT772_tree=null;
		ASTNode KW_FOREIGN773_tree=null;
		ASTNode KW_KEY774_tree=null;
		ASTNode KW_REFERENCES775_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleTokenStream stream_KW_FOREIGN=new RewriteRuleTokenStream(adaptor,"token KW_FOREIGN");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("foreign key with key name", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:5: ( KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )? -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:7: KW_CONSTRAINT constraintName= identifier KW_FOREIGN KW_KEY fkCols= columnParenthesesList KW_REFERENCES tabName= tableName parCols= columnParenthesesList ( constraintOptsAlter )?
			{
			KW_CONSTRAINT772=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName12906); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT772);

			pushFollow(FOLLOW_identifier_in_alterForeignKeyWithName12910);
			constraintName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
			KW_FOREIGN773=(Token)match(input,KW_FOREIGN,FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName12912); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FOREIGN.add(KW_FOREIGN773);

			KW_KEY774=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_alterForeignKeyWithName12914); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY774);

			pushFollow(FOLLOW_columnParenthesesList_in_alterForeignKeyWithName12918);
			fkCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(fkCols.getTree());
			KW_REFERENCES775=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName12921); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES775);

			pushFollow(FOLLOW_tableName_in_alterForeignKeyWithName12925);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			pushFollow(FOLLOW_columnParenthesesList_in_alterForeignKeyWithName12929);
			parCols=columnParenthesesList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnParenthesesList.add(parCols.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:157: ( constraintOptsAlter )?
			int alt235=2;
			int LA235_0 = input.LA(1);
			if ( (LA235_0==KW_DISABLE||LA235_0==KW_ENABLE||LA235_0==KW_ENFORCED||LA235_0==KW_NOT) ) {
				alt235=1;
			}
			switch (alt235) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2214:157: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName12931);
					constraintOptsAlter776=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter776.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tabName, constraintName, fkCols, constraintOptsAlter, parCols
			// token labels: 
			// rule labels: tabName, parCols, fkCols, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_parCols=new RewriteRuleSubtreeStream(adaptor,"rule parCols",parCols!=null?parCols.getTree():null);
			RewriteRuleSubtreeStream stream_fkCols=new RewriteRuleSubtreeStream(adaptor,"rule fkCols",fkCols!=null?fkCols.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2215:5: -> ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:8: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) $fkCols $tabName $parCols ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:26: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_fkCols.nextTree());
				adaptor.addChild(root_1, stream_tabName.nextTree());
				adaptor.addChild(root_1, stream_parCols.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2215:91: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterForeignKeyWithName"


	public static class skewedValueElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedValueElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2218:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
	public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
		HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope skewedColumnValues777 =null;
		ParserRuleReturnScope skewedColumnValuePairList778 =null;


		 pushMsg("skewed value element", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2221:5: ( skewedColumnValues | skewedColumnValuePairList )
			int alt236=2;
			int LA236_0 = input.LA(1);
			if ( (LA236_0==CharSetName||LA236_0==IntegralLiteral||(LA236_0 >= KW_CURRENT_DATE && LA236_0 <= KW_CURRENT_TIMESTAMP)||LA236_0==KW_DATE||LA236_0==KW_FALSE||LA236_0==KW_NULL||(LA236_0 >= KW_TIMESTAMP && LA236_0 <= KW_TIMESTAMPLOCALTZ)||LA236_0==KW_TRUE||(LA236_0 >= Number && LA236_0 <= NumberLiteral)||LA236_0==QUESTION||LA236_0==StringLiteral) ) {
				alt236=1;
			}
			else if ( (LA236_0==LPAREN) ) {
				alt236=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 236, 0, input);
				throw nvae;
			}

			switch (alt236) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2222:7: skewedColumnValues
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement12994);
					skewedColumnValues777=skewedColumnValues();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValues777.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2223:8: skewedColumnValuePairList
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement13003);
					skewedColumnValuePairList778=skewedColumnValuePairList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePairList778.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedValueElement"


	public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValuePairList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2226:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
	public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
		HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA780=null;
		ParserRuleReturnScope skewedColumnValuePair779 =null;
		ParserRuleReturnScope skewedColumnValuePair781 =null;

		ASTNode COMMA780_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedColumnValuePair=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValuePair");

		 pushMsg("column value pair list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
			{
			pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13030);
			skewedColumnValuePair779=skewedColumnValuePair();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair779.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:29: ( COMMA skewedColumnValuePair )*
			loop237:
			while (true) {
				int alt237=2;
				int LA237_0 = input.LA(1);
				if ( (LA237_0==COMMA) ) {
					alt237=1;
				}

				switch (alt237) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:30: COMMA skewedColumnValuePair
					{
					COMMA780=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValuePairList13033); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA780);

					pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13035);
					skewedColumnValuePair781=skewedColumnValuePair();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedColumnValuePair.add(skewedColumnValuePair781.getTree());
					}
					break;

				default :
					break loop237;
				}
			}

			// AST REWRITE
			// elements: skewedColumnValuePair
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2229:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2229:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR"), root_1);
				if ( !(stream_skewedColumnValuePair.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedColumnValuePair.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());
				}
				stream_skewedColumnValuePair.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValuePairList"


	public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValuePair"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2232:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
	public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
		HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN782=null;
		Token RPAREN783=null;
		ParserRuleReturnScope colValues =null;

		ASTNode LPAREN782_tree=null;
		ASTNode RPAREN783_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleSubtreeStream stream_skewedColumnValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValues");

		 pushMsg("column value pair", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2235:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2236:7: LPAREN colValues= skewedColumnValues RPAREN
			{
			LPAREN782=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedColumnValuePair13079); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN782);

			pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair13083);
			colValues=skewedColumnValues();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValues.add(colValues.getTree());
			RPAREN783=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedColumnValuePair13085); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN783);

			// AST REWRITE
			// elements: colValues
			// token labels: 
			// rule labels: colValues, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colValues=new RewriteRuleSubtreeStream(adaptor,"rule colValues",colValues!=null?colValues.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2237:7: -> ^( TOK_TABCOLVALUES $colValues)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2237:10: ^( TOK_TABCOLVALUES $colValues)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES"), root_1);
				adaptor.addChild(root_1, stream_colValues.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValuePair"


	public static class skewedColumnValues_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValues"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2240:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
	public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
		HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA785=null;
		ParserRuleReturnScope skewedColumnValue784 =null;
		ParserRuleReturnScope skewedColumnValue786 =null;

		ASTNode COMMA785_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_skewedColumnValue=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValue");

		 pushMsg("column values", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:7: skewedColumnValue ( COMMA skewedColumnValue )*
			{
			pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues13127);
			skewedColumnValue784=skewedColumnValue();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue784.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:25: ( COMMA skewedColumnValue )*
			loop238:
			while (true) {
				int alt238=2;
				int LA238_0 = input.LA(1);
				if ( (LA238_0==COMMA) ) {
					alt238=1;
				}

				switch (alt238) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:26: COMMA skewedColumnValue
					{
					COMMA785=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValues13130); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA785);

					pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues13132);
					skewedColumnValue786=skewedColumnValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_skewedColumnValue.add(skewedColumnValue786.getTree());
					}
					break;

				default :
					break loop238;
				}
			}

			// AST REWRITE
			// elements: skewedColumnValue
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2243:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2243:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE"), root_1);
				if ( !(stream_skewedColumnValue.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_skewedColumnValue.hasNext() ) {
					adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());
				}
				stream_skewedColumnValue.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValues"


	public static class skewedColumnValue_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedColumnValue"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2246:1: skewedColumnValue : constant ;
	public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
		HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope constant787 =null;


		 pushMsg("column value", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2249:5: ( constant )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2250:7: constant
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_constant_in_skewedColumnValue13176);
			constant787=constant();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, constant787.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedColumnValue"


	public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "skewedValueLocationElement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2253:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
	public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
		HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope skewedColumnValue788 =null;
		ParserRuleReturnScope skewedColumnValuePair789 =null;


		 pushMsg("skewed value location element", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2256:5: ( skewedColumnValue | skewedColumnValuePair )
			int alt239=2;
			int LA239_0 = input.LA(1);
			if ( (LA239_0==CharSetName||LA239_0==IntegralLiteral||(LA239_0 >= KW_CURRENT_DATE && LA239_0 <= KW_CURRENT_TIMESTAMP)||LA239_0==KW_DATE||LA239_0==KW_FALSE||LA239_0==KW_NULL||(LA239_0 >= KW_TIMESTAMP && LA239_0 <= KW_TIMESTAMPLOCALTZ)||LA239_0==KW_TRUE||(LA239_0 >= Number && LA239_0 <= NumberLiteral)||LA239_0==QUESTION||LA239_0==StringLiteral) ) {
				alt239=1;
			}
			else if ( (LA239_0==LPAREN) ) {
				alt239=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 239, 0, input);
				throw nvae;
			}

			switch (alt239) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2257:7: skewedColumnValue
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement13209);
					skewedColumnValue788=skewedColumnValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValue788.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2258:8: skewedColumnValuePair
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement13218);
					skewedColumnValuePair789=skewedColumnValuePair();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, skewedColumnValuePair789.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "skewedValueLocationElement"


	public static class orderSpecification_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orderSpecification"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2261:1: orderSpecification : ( KW_ASC | KW_DESC );
	public final HiveParser.orderSpecification_return orderSpecification() throws RecognitionException {
		HiveParser.orderSpecification_return retval = new HiveParser.orderSpecification_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token set790=null;

		ASTNode set790_tree=null;

		 pushMsg("order specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2264:5: ( KW_ASC | KW_DESC )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:
			{
			root_0 = (ASTNode)adaptor.nil();


			set790=input.LT(1);
			if ( input.LA(1)==KW_ASC||input.LA(1)==KW_DESC ) {
				input.consume();
				if ( state.backtracking==0 ) adaptor.addChild(root_0, (ASTNode)adaptor.create(set790));
				state.errorRecovery=false;
				state.failed=false;
			}
			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				MismatchedSetException mse = new MismatchedSetException(null,input);
				throw mse;
			}
			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orderSpecification"


	public static class nullOrdering_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "nullOrdering"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2266:1: nullOrdering : ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) );
	public final HiveParser.nullOrdering_return nullOrdering() throws RecognitionException {
		HiveParser.nullOrdering_return retval = new HiveParser.nullOrdering_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NULLS791=null;
		Token KW_FIRST792=null;
		Token KW_NULLS793=null;
		Token KW_LAST794=null;

		ASTNode KW_NULLS791_tree=null;
		ASTNode KW_FIRST792_tree=null;
		ASTNode KW_NULLS793_tree=null;
		ASTNode KW_LAST794_tree=null;
		RewriteRuleTokenStream stream_KW_FIRST=new RewriteRuleTokenStream(adaptor,"token KW_FIRST");
		RewriteRuleTokenStream stream_KW_NULLS=new RewriteRuleTokenStream(adaptor,"token KW_NULLS");
		RewriteRuleTokenStream stream_KW_LAST=new RewriteRuleTokenStream(adaptor,"token KW_LAST");

		 pushMsg("nulls ordering", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:5: ( KW_NULLS KW_FIRST -> ^( TOK_NULLS_FIRST ) | KW_NULLS KW_LAST -> ^( TOK_NULLS_LAST ) )
			int alt240=2;
			int LA240_0 = input.LA(1);
			if ( (LA240_0==KW_NULLS) ) {
				int LA240_1 = input.LA(2);
				if ( (LA240_1==KW_FIRST) ) {
					alt240=1;
				}
				else if ( (LA240_1==KW_LAST) ) {
					alt240=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 240, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 240, 0, input);
				throw nvae;
			}

			switch (alt240) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:7: KW_NULLS KW_FIRST
					{
					KW_NULLS791=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering13272); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS791);

					KW_FIRST792=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_nullOrdering13274); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FIRST.add(KW_FIRST792);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2269:25: -> ^( TOK_NULLS_FIRST )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2269:28: ^( TOK_NULLS_FIRST )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2270:7: KW_NULLS KW_LAST
					{
					KW_NULLS793=(Token)match(input,KW_NULLS,FOLLOW_KW_NULLS_in_nullOrdering13288); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULLS.add(KW_NULLS793);

					KW_LAST794=(Token)match(input,KW_LAST,FOLLOW_KW_LAST_in_nullOrdering13290); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LAST.add(KW_LAST794);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2270:24: -> ^( TOK_NULLS_LAST )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2270:27: ^( TOK_NULLS_LAST )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "nullOrdering"


	public static class columnNameOrder_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameOrder"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2273:1: columnNameOrder : identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) ;
	public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
		HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope orderSpec =null;
		ParserRuleReturnScope nullSpec =null;
		ParserRuleReturnScope identifier795 =null;

		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");
		RewriteRuleSubtreeStream stream_orderSpecification=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecification");

		 pushMsg("column name order", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:5: ( identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) ) -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) ) -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:7: identifier (orderSpec= orderSpecification )? (nullSpec= nullOrdering )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameOrder13323);
			identifier795=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier795.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:27: (orderSpec= orderSpecification )?
			int alt241=2;
			int LA241_0 = input.LA(1);
			if ( (LA241_0==KW_ASC||LA241_0==KW_DESC) ) {
				alt241=1;
			}
			switch (alt241) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:27: orderSpec= orderSpecification
					{
					pushFollow(FOLLOW_orderSpecification_in_columnNameOrder13327);
					orderSpec=orderSpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderSpecification.add(orderSpec.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:56: (nullSpec= nullOrdering )?
			int alt242=2;
			int LA242_0 = input.LA(1);
			if ( (LA242_0==KW_NULLS) ) {
				alt242=1;
			}
			switch (alt242) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2276:56: nullSpec= nullOrdering
					{
					pushFollow(FOLLOW_nullOrdering_in_columnNameOrder13332);
					nullSpec=nullOrdering();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: nullSpec, identifier, identifier, nullSpec, identifier, identifier, identifier, identifier, nullSpec
			// token labels: 
			// rule labels: nullSpec, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2277:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2278:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2278:37: ^( TOK_NULLS_FIRST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2279:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2280:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2280:37: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2281:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_ASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2282:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2282:37: ^( TOK_NULLS_FIRST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2283:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType()==HiveParser.KW_DESC}? ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_DESC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2284:13: ^( TOK_TABSORTCOLNAMEDESC ^( TOK_NULLS_LAST identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2284:38: ^( TOK_NULLS_LAST identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2285:5: -> {$orderSpec.tree.getType()==HiveParser.KW_ASC}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType()==HiveParser.KW_ASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2286:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2286:37: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2287:5: -> ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2287:8: ^( TOK_TABSORTCOLNAMEDESC ^( $nullSpec identifier ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2287:33: ^( $nullSpec identifier )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_identifier.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameOrder"


	public static class columnNameCommentList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameCommentList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2290:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
	public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
		HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA797=null;
		ParserRuleReturnScope columnNameComment796 =null;
		ParserRuleReturnScope columnNameComment798 =null;

		ASTNode COMMA797_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_columnNameComment=new RewriteRuleSubtreeStream(adaptor,"rule columnNameComment");

		 pushMsg("column name comment list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:7: columnNameComment ( COMMA columnNameComment )*
			{
			pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList13529);
			columnNameComment796=columnNameComment();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment796.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:25: ( COMMA columnNameComment )*
			loop243:
			while (true) {
				int alt243=2;
				int LA243_0 = input.LA(1);
				if ( (LA243_0==COMMA) ) {
					alt243=1;
				}

				switch (alt243) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:26: COMMA columnNameComment
					{
					COMMA797=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameCommentList13532); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA797);

					pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList13534);
					columnNameComment798=columnNameComment();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameComment.add(columnNameComment798.getTree());
					}
					break;

				default :
					break loop243;
				}
			}

			// AST REWRITE
			// elements: columnNameComment
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2293:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2293:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_1);
				if ( !(stream_columnNameComment.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_columnNameComment.hasNext() ) {
					adaptor.addChild(root_1, stream_columnNameComment.nextTree());
				}
				stream_columnNameComment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameCommentList"


	public static class columnNameComment_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameComment"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2296:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
	public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
		HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT799=null;
		ParserRuleReturnScope colName =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT799_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");

		 pushMsg("column name comment", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2299:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2299:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameComment13574);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2299:26: ( KW_COMMENT comment= StringLiteral )?
			int alt244=2;
			int LA244_0 = input.LA(1);
			if ( (LA244_0==KW_COMMENT) ) {
				alt244=1;
			}
			switch (alt244) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2299:27: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT799=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameComment13577); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT799);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameComment13581); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colName, comment
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2300:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2300:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, (ASTNode)adaptor.create(TOK_NULL, "TOK_NULL"));
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2300:40: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameComment"


	public static class orderSpecificationRewrite_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "orderSpecificationRewrite"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2303:1: orderSpecificationRewrite : ( KW_ASC -> ^( TOK_TABSORTCOLNAMEASC ) | KW_DESC -> ^( TOK_TABSORTCOLNAMEDESC ) );
	public final HiveParser.orderSpecificationRewrite_return orderSpecificationRewrite() throws RecognitionException {
		HiveParser.orderSpecificationRewrite_return retval = new HiveParser.orderSpecificationRewrite_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ASC800=null;
		Token KW_DESC801=null;

		ASTNode KW_ASC800_tree=null;
		ASTNode KW_DESC801_tree=null;
		RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
		RewriteRuleTokenStream stream_KW_ASC=new RewriteRuleTokenStream(adaptor,"token KW_ASC");

		 pushMsg("order specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2306:5: ( KW_ASC -> ^( TOK_TABSORTCOLNAMEASC ) | KW_DESC -> ^( TOK_TABSORTCOLNAMEDESC ) )
			int alt245=2;
			int LA245_0 = input.LA(1);
			if ( (LA245_0==KW_ASC) ) {
				alt245=1;
			}
			else if ( (LA245_0==KW_DESC) ) {
				alt245=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 245, 0, input);
				throw nvae;
			}

			switch (alt245) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2306:7: KW_ASC
					{
					KW_ASC800=(Token)match(input,KW_ASC,FOLLOW_KW_ASC_in_orderSpecificationRewrite13629); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ASC.add(KW_ASC800);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2306:14: -> ^( TOK_TABSORTCOLNAMEASC )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2306:17: ^( TOK_TABSORTCOLNAMEASC )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2307:7: KW_DESC
					{
					KW_DESC801=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_orderSpecificationRewrite13643); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DESC.add(KW_DESC801);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2307:15: -> ^( TOK_TABSORTCOLNAMEDESC )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2307:18: ^( TOK_TABSORTCOLNAMEDESC )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "orderSpecificationRewrite"


	public static class columnRefOrder_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnRefOrder"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2310:1: columnRefOrder : expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEASC && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEDESC && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEASC}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEDESC}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> ^( $orderSpec ^( $nullSpec expression ) ) ;
	public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
		HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope orderSpec =null;
		ParserRuleReturnScope nullSpec =null;
		ParserRuleReturnScope expression802 =null;

		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_orderSpecificationRewrite=new RewriteRuleSubtreeStream(adaptor,"rule orderSpecificationRewrite");
		RewriteRuleSubtreeStream stream_nullOrdering=new RewriteRuleSubtreeStream(adaptor,"rule nullOrdering");

		 pushMsg("column order", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:5: ( expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )? -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) ) -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) ) -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEASC && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEDESC && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEASC}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) ) -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEDESC}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) ) -> ^( $orderSpec ^( $nullSpec expression ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:7: expression (orderSpec= orderSpecificationRewrite )? (nullSpec= nullOrdering )?
			{
			pushFollow(FOLLOW_expression_in_columnRefOrder13676);
			expression802=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression802.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:27: (orderSpec= orderSpecificationRewrite )?
			int alt246=2;
			int LA246_0 = input.LA(1);
			if ( (LA246_0==KW_ASC||LA246_0==KW_DESC) ) {
				alt246=1;
			}
			switch (alt246) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:27: orderSpec= orderSpecificationRewrite
					{
					pushFollow(FOLLOW_orderSpecificationRewrite_in_columnRefOrder13680);
					orderSpec=orderSpecificationRewrite();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderSpecificationRewrite.add(orderSpec.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:63: (nullSpec= nullOrdering )?
			int alt247=2;
			int LA247_0 = input.LA(1);
			if ( (LA247_0==KW_NULLS) ) {
				alt247=1;
			}
			switch (alt247) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2313:63: nullSpec= nullOrdering
					{
					pushFollow(FOLLOW_nullOrdering_in_columnRefOrder13685);
					nullSpec=nullOrdering();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_nullOrdering.add(nullSpec.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: orderSpec, nullSpec, expression, expression, orderSpec, expression, expression, expression, orderSpec, orderSpec, expression, expression, orderSpec, expression, nullSpec
			// token labels: 
			// rule labels: orderSpec, nullSpec, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_orderSpec=new RewriteRuleSubtreeStream(adaptor,"rule orderSpec",orderSpec!=null?orderSpec.getTree():null);
			RewriteRuleSubtreeStream stream_nullSpec=new RewriteRuleSubtreeStream(adaptor,"rule nullSpec",nullSpec!=null?nullSpec.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2315:5: -> {$orderSpec.tree == null && $nullSpec.tree == null && nullsLast()}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2316:37: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2318:5: -> {$orderSpec.tree == null && $nullSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null && (nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2319:13: ^( TOK_TABSORTCOLNAMEASC ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2319:37: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2321:5: -> {$orderSpec.tree == null}? ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
			if ((orderSpec!=null?((ASTNode)orderSpec.getTree()):null) == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2322:13: ^( TOK_TABSORTCOLNAMEASC ^( $nullSpec expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2322:37: ^( $nullSpec expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2324:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEASC && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType() == HiveParser.TOK_TABSORTCOLNAMEASC && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2325:13: ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2325:26: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2327:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEDESC && nullsLast()}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType() == HiveParser.TOK_TABSORTCOLNAMEDESC && nullsLast()) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2328:13: ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2328:26: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2330:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEASC}? ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType() == HiveParser.TOK_TABSORTCOLNAMEASC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:13: ^( $orderSpec ^( TOK_NULLS_FIRST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2331:26: ^( TOK_NULLS_FIRST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_FIRST, "TOK_NULLS_FIRST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2333:5: -> {$nullSpec.tree == null && $orderSpec.tree.getType() == HiveParser.TOK_TABSORTCOLNAMEDESC}? ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
			if ((nullSpec!=null?((ASTNode)nullSpec.getTree()):null) == null && (orderSpec!=null?((ASTNode)orderSpec.getTree()):null).getType() == HiveParser.TOK_TABSORTCOLNAMEDESC) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2334:13: ^( $orderSpec ^( TOK_NULLS_LAST expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2334:26: ^( TOK_NULLS_LAST expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NULLS_LAST, "TOK_NULLS_LAST"), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2336:5: -> ^( $orderSpec ^( $nullSpec expression ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:8: ^( $orderSpec ^( $nullSpec expression ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot(stream_orderSpec.nextNode(), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2336:21: ^( $nullSpec expression )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot(stream_nullSpec.nextNode(), root_2);
				adaptor.addChild(root_2, stream_expression.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnRefOrder"


	public static class columnNameType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2339:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
	public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
		HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT804=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType803 =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT804_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameType13988);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			pushFollow(FOLLOW_colType_in_columnNameType13990);
			colType803=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType803.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:34: ( KW_COMMENT comment= StringLiteral )?
			int alt248=2;
			int LA248_0 = input.LA(1);
			if ( (LA248_0==KW_COMMENT) ) {
				alt248=1;
			}
			switch (alt248) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2342:35: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT804=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameType13993); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT804);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameType13997); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colType, colName, colName, colType, comment
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2343:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
			if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
				adaptor.addChild(root_0, throwColumnNameException());
			}

			else // 2344:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
			if (comment == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2344:28: ^( TOK_TABCOL $colName colType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2345:5: -> ^( TOK_TABCOL $colName colType $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2345:28: ^( TOK_TABCOL $colName colType $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameType"


	public static class columnNameTypeOrConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeOrConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2348:1: columnNameTypeOrConstraint : ( ( tableConstraint ) | ( columnNameTypeConstraint ) );
	public final HiveParser.columnNameTypeOrConstraint_return columnNameTypeOrConstraint() throws RecognitionException {
		HiveParser.columnNameTypeOrConstraint_return retval = new HiveParser.columnNameTypeOrConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope tableConstraint805 =null;
		ParserRuleReturnScope columnNameTypeConstraint806 =null;


		 pushMsg("column name or constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:5: ( ( tableConstraint ) | ( columnNameTypeConstraint ) )
			int alt249=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
			case KW_FOREIGN:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt249=1;
				}
				break;
			case KW_CHECK:
				{
				int LA249_5 = input.LA(2);
				if ( (LA249_5==LPAREN) ) {
					alt249=1;
				}
				else if ( (LA249_5==KW_ARRAY||(LA249_5 >= KW_BIGINT && LA249_5 <= KW_BOOLEAN)||LA249_5==KW_CHAR||(LA249_5 >= KW_DATE && LA249_5 <= KW_DATETIME)||LA249_5==KW_DECIMAL||LA249_5==KW_DOUBLE||LA249_5==KW_FLOAT||LA249_5==KW_INT||LA249_5==KW_MAP||LA249_5==KW_REAL||LA249_5==KW_SMALLINT||(LA249_5 >= KW_STRING && LA249_5 <= KW_STRUCT)||(LA249_5 >= KW_TIMESTAMP && LA249_5 <= KW_TINYINT)||LA249_5==KW_UNIONTYPE||LA249_5==KW_VARCHAR) ) {
					alt249=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 249, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ASC:
			case KW_AST:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DCPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPIRE_SNAPSHOTS:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_HOUR:
			case KW_ID:
			case KW_IDXPROPERTIES:
			case KW_IGNORE:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGED:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_REMOTE:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESPECT:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SPEC:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_SYSTEM_TIME:
			case KW_SYSTEM_VERSION:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_TRIM:
			case KW_TYPE:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNKNOWN:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_URL:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WITHIN:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt249=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 249, 0, input);
				throw nvae;
			}
			switch (alt249) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:7: ( tableConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:7: ( tableConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2351:9: tableConstraint
					{
					pushFollow(FOLLOW_tableConstraint_in_columnNameTypeOrConstraint14093);
					tableConstraint805=tableConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableConstraint805.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2352:7: ( columnNameTypeConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2352:7: ( columnNameTypeConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2352:9: columnNameTypeConstraint
					{
					pushFollow(FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint14105);
					columnNameTypeConstraint806=columnNameTypeConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, columnNameTypeConstraint806.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeOrConstraint"


	public static class tableConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2355:1: tableConstraint : ( ( createForeignKey ) | ( createConstraint ) );
	public final HiveParser.tableConstraint_return tableConstraint() throws RecognitionException {
		HiveParser.tableConstraint_return retval = new HiveParser.tableConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope createForeignKey807 =null;
		ParserRuleReturnScope createConstraint808 =null;


		 pushMsg("table constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:5: ( ( createForeignKey ) | ( createConstraint ) )
			int alt250=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA250_1 = input.LA(2);
				if ( (LA250_1==Identifier) ) {
					int LA250_6 = input.LA(3);
					if ( (LA250_6==KW_FOREIGN) ) {
						alt250=1;
					}
					else if ( (LA250_6==KW_CHECK||LA250_6==KW_PRIMARY||LA250_6==KW_UNIQUE) ) {
						alt250=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 250, 6, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA250_1 >= KW_ABORT && LA250_1 <= KW_AFTER)||LA250_1==KW_ALLOC_FRACTION||LA250_1==KW_ANALYZE||LA250_1==KW_ARCHIVE||(LA250_1 >= KW_ASC && LA250_1 <= KW_AT)||(LA250_1 >= KW_AUTOCOMMIT && LA250_1 <= KW_BEFORE)||(LA250_1 >= KW_BUCKET && LA250_1 <= KW_BUCKETS)||(LA250_1 >= KW_CACHE && LA250_1 <= KW_CASCADE)||(LA250_1 >= KW_CBO && LA250_1 <= KW_CHANGE)||(LA250_1 >= KW_CHECK && LA250_1 <= KW_COLLECTION)||(LA250_1 >= KW_COLUMNS && LA250_1 <= KW_COMMENT)||(LA250_1 >= KW_COMPACT && LA250_1 <= KW_CONCATENATE)||(LA250_1 >= KW_CONTINUE && LA250_1 <= KW_COST)||LA250_1==KW_CRON||LA250_1==KW_DATA||LA250_1==KW_DATABASES||(LA250_1 >= KW_DATETIME && LA250_1 <= KW_DCPROPERTIES)||LA250_1==KW_DEBUG||(LA250_1 >= KW_DEFAULT && LA250_1 <= KW_DEFINED)||(LA250_1 >= KW_DELIMITED && LA250_1 <= KW_DESC)||(LA250_1 >= KW_DETAIL && LA250_1 <= KW_DISABLE)||(LA250_1 >= KW_DISTRIBUTE && LA250_1 <= KW_DO)||LA250_1==KW_DOW||(LA250_1 >= KW_DUMP && LA250_1 <= KW_ELEM_TYPE)||LA250_1==KW_ENABLE||(LA250_1 >= KW_ENFORCED && LA250_1 <= KW_EVERY)||(LA250_1 >= KW_EXCLUSIVE && LA250_1 <= KW_EXECUTED)||(LA250_1 >= KW_EXPIRE_SNAPSHOTS && LA250_1 <= KW_EXPRESSION)||(LA250_1 >= KW_FIELDS && LA250_1 <= KW_FIRST)||(LA250_1 >= KW_FORMAT && LA250_1 <= KW_FORMATTED)||LA250_1==KW_FUNCTIONS||(LA250_1 >= KW_HOUR && LA250_1 <= KW_IDXPROPERTIES)||LA250_1==KW_IGNORE||(LA250_1 >= KW_INDEX && LA250_1 <= KW_INDEXES)||(LA250_1 >= KW_INPATH && LA250_1 <= KW_INPUTFORMAT)||(LA250_1 >= KW_ISOLATION && LA250_1 <= KW_JAR)||(LA250_1 >= KW_JOINCOST && LA250_1 <= KW_LAST)||LA250_1==KW_LEVEL||(LA250_1 >= KW_LIMIT && LA250_1 <= KW_LOAD)||(LA250_1 >= KW_LOCATION && LA250_1 <= KW_LONG)||(LA250_1 >= KW_MANAGED && LA250_1 <= KW_MANAGEMENT)||(LA250_1 >= KW_MAPJOIN && LA250_1 <= KW_MATERIALIZED)||LA250_1==KW_METADATA||(LA250_1 >= KW_MINUTE && LA250_1 <= KW_MONTH)||(LA250_1 >= KW_MOVE && LA250_1 <= KW_MSCK)||(LA250_1 >= KW_NORELY && LA250_1 <= KW_NOSCAN)||LA250_1==KW_NOVALIDATE||LA250_1==KW_NULLS||LA250_1==KW_OFFSET||(LA250_1 >= KW_OPERATOR && LA250_1 <= KW_OPTION)||(LA250_1 >= KW_OUTPUTDRIVER && LA250_1 <= KW_OUTPUTFORMAT)||(LA250_1 >= KW_OVERWRITE && LA250_1 <= KW_OWNER)||(LA250_1 >= KW_PARTITIONED && LA250_1 <= KW_PATH)||(LA250_1 >= KW_PLAN && LA250_1 <= KW_POOL)||LA250_1==KW_PRINCIPALS||LA250_1==KW_PURGE||(LA250_1 >= KW_QUARTER && LA250_1 <= KW_QUERY_PARALLELISM)||LA250_1==KW_READ||(LA250_1 >= KW_REBUILD && LA250_1 <= KW_RECORDWRITER)||(LA250_1 >= KW_RELOAD && LA250_1 <= KW_RESTRICT)||LA250_1==KW_REWRITE||(LA250_1 >= KW_ROLE && LA250_1 <= KW_ROLES)||(LA250_1 >= KW_SCHEDULED && LA250_1 <= KW_SECOND)||(LA250_1 >= KW_SEMI && LA250_1 <= KW_SERVER)||(LA250_1 >= KW_SETS && LA250_1 <= KW_SKEWED)||LA250_1==KW_SNAPSHOT||(LA250_1 >= KW_SORT && LA250_1 <= KW_SSL)||(LA250_1 >= KW_STATISTICS && LA250_1 <= KW_SUMMARY)||(LA250_1 >= KW_SYSTEM_TIME && LA250_1 <= KW_SYSTEM_VERSION)||LA250_1==KW_TABLES||(LA250_1 >= KW_TBLPROPERTIES && LA250_1 <= KW_TERMINATED)||LA250_1==KW_TINYINT||LA250_1==KW_TOUCH||(LA250_1 >= KW_TRANSACTION && LA250_1 <= KW_TRANSACTIONS)||LA250_1==KW_TRIM||(LA250_1 >= KW_TYPE && LA250_1 <= KW_UNARCHIVE)||LA250_1==KW_UNDO||LA250_1==KW_UNIONTYPE||(LA250_1 >= KW_UNKNOWN && LA250_1 <= KW_UNSIGNED)||(LA250_1 >= KW_URI && LA250_1 <= KW_USE)||(LA250_1 >= KW_UTC && LA250_1 <= KW_VALIDATE)||LA250_1==KW_VALUE_TYPE||(LA250_1 >= KW_VECTORIZATION && LA250_1 <= KW_WEEK)||LA250_1==KW_WHILE||(LA250_1 >= KW_WITHIN && LA250_1 <= KW_ZONE)||LA250_1==KW_BATCH||LA250_1==KW_DAYOFWEEK||LA250_1==KW_HOLD_DDLTIME||LA250_1==KW_NO_DROP||LA250_1==KW_OFFLINE||LA250_1==KW_PROTECTION||LA250_1==KW_READONLY||LA250_1==KW_TIMESTAMPTZ) ) {
					int LA250_7 = input.LA(3);
					if ( (LA250_7==KW_FOREIGN) ) {
						alt250=1;
					}
					else if ( (LA250_7==KW_CHECK||LA250_7==KW_PRIMARY||LA250_7==KW_UNIQUE) ) {
						alt250=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 250, 7, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 250, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_FOREIGN:
				{
				alt250=1;
				}
				break;
			case KW_CHECK:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt250=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 250, 0, input);
				throw nvae;
			}
			switch (alt250) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:7: ( createForeignKey )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:7: ( createForeignKey )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2358:9: createForeignKey
					{
					pushFollow(FOLLOW_createForeignKey_in_tableConstraint14136);
					createForeignKey807=createForeignKey();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createForeignKey807.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:7: ( createConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:7: ( createConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2359:9: createConstraint
					{
					pushFollow(FOLLOW_createConstraint_in_tableConstraint14148);
					createConstraint808=createConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, createConstraint808.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableConstraint"


	public static class columnNameTypeConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameTypeConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2362:1: columnNameTypeConstraint : colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? ) ;
	public final HiveParser.columnNameTypeConstraint_return columnNameTypeConstraint() throws RecognitionException {
		HiveParser.columnNameTypeConstraint_return retval = new HiveParser.columnNameTypeConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token KW_COMMENT811=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType809 =null;
		ParserRuleReturnScope columnConstraint810 =null;

		ASTNode comment_tree=null;
		ASTNode KW_COMMENT811_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraint=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraint");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:5: (colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )? -> {containExcludedCharForCreateTableColumnName($colName.text)}? -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:7: colName= identifier colType ( columnConstraint[$colName.tree] )? ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameTypeConstraint14179);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			pushFollow(FOLLOW_colType_in_columnNameTypeConstraint14181);
			colType809=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType809.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:34: ( columnConstraint[$colName.tree] )?
			int alt251=2;
			int LA251_0 = input.LA(1);
			if ( (LA251_0==KW_CHECK||LA251_0==KW_CONSTRAINT||LA251_0==KW_DEFAULT||LA251_0==KW_NOT||LA251_0==KW_PRIMARY||LA251_0==KW_REFERENCES||LA251_0==KW_UNIQUE) ) {
				alt251=1;
			}
			switch (alt251) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:34: columnConstraint[$colName.tree]
					{
					pushFollow(FOLLOW_columnConstraint_in_columnNameTypeConstraint14183);
					columnConstraint810=columnConstraint((colName!=null?((ASTNode)colName.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnConstraint.add(columnConstraint810.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:67: ( KW_COMMENT comment= StringLiteral )?
			int alt252=2;
			int LA252_0 = input.LA(1);
			if ( (LA252_0==KW_COMMENT) ) {
				alt252=1;
			}
			switch (alt252) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2365:68: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT811=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameTypeConstraint14188); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT811);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameTypeConstraint14192); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colName, columnConstraint, comment, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2366:5: -> {containExcludedCharForCreateTableColumnName($colName.text)}?
			if (containExcludedCharForCreateTableColumnName((colName!=null?input.toString(colName.start,colName.stop):null))) {
				adaptor.addChild(root_0, throwColumnNameException());
			}

			else // 2367:5: -> ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2367:8: ^( TOK_TABCOL $colName colType ( $comment)? ( columnConstraint )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2367:39: ( $comment)?
				if ( stream_comment.hasNext() ) {
					adaptor.addChild(root_1, stream_comment.nextNode());
				}
				stream_comment.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2367:48: ( columnConstraint )?
				if ( stream_columnConstraint.hasNext() ) {
					adaptor.addChild(root_1, stream_columnConstraint.nextTree());
				}
				stream_columnConstraint.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameTypeConstraint"


	public static class columnConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2370:1: columnConstraint[CommonTree fkColName] : ( ( foreignKeyConstraint[$fkColName] ) | ( colConstraint ) );
	public final HiveParser.columnConstraint_return columnConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.columnConstraint_return retval = new HiveParser.columnConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope foreignKeyConstraint812 =null;
		ParserRuleReturnScope colConstraint813 =null;


		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:5: ( ( foreignKeyConstraint[$fkColName] ) | ( colConstraint ) )
			int alt253=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA253_1 = input.LA(2);
				if ( (LA253_1==Identifier) ) {
					int LA253_8 = input.LA(3);
					if ( (LA253_8==KW_REFERENCES) ) {
						alt253=1;
					}
					else if ( (LA253_8==KW_CHECK||LA253_8==KW_DEFAULT||LA253_8==KW_NOT||LA253_8==KW_PRIMARY||LA253_8==KW_UNIQUE) ) {
						alt253=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 253, 8, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA253_1 >= KW_ABORT && LA253_1 <= KW_AFTER)||LA253_1==KW_ALLOC_FRACTION||LA253_1==KW_ANALYZE||LA253_1==KW_ARCHIVE||(LA253_1 >= KW_ASC && LA253_1 <= KW_AT)||(LA253_1 >= KW_AUTOCOMMIT && LA253_1 <= KW_BEFORE)||(LA253_1 >= KW_BUCKET && LA253_1 <= KW_BUCKETS)||(LA253_1 >= KW_CACHE && LA253_1 <= KW_CASCADE)||(LA253_1 >= KW_CBO && LA253_1 <= KW_CHANGE)||(LA253_1 >= KW_CHECK && LA253_1 <= KW_COLLECTION)||(LA253_1 >= KW_COLUMNS && LA253_1 <= KW_COMMENT)||(LA253_1 >= KW_COMPACT && LA253_1 <= KW_CONCATENATE)||(LA253_1 >= KW_CONTINUE && LA253_1 <= KW_COST)||LA253_1==KW_CRON||LA253_1==KW_DATA||LA253_1==KW_DATABASES||(LA253_1 >= KW_DATETIME && LA253_1 <= KW_DCPROPERTIES)||LA253_1==KW_DEBUG||(LA253_1 >= KW_DEFAULT && LA253_1 <= KW_DEFINED)||(LA253_1 >= KW_DELIMITED && LA253_1 <= KW_DESC)||(LA253_1 >= KW_DETAIL && LA253_1 <= KW_DISABLE)||(LA253_1 >= KW_DISTRIBUTE && LA253_1 <= KW_DO)||LA253_1==KW_DOW||(LA253_1 >= KW_DUMP && LA253_1 <= KW_ELEM_TYPE)||LA253_1==KW_ENABLE||(LA253_1 >= KW_ENFORCED && LA253_1 <= KW_EVERY)||(LA253_1 >= KW_EXCLUSIVE && LA253_1 <= KW_EXECUTED)||(LA253_1 >= KW_EXPIRE_SNAPSHOTS && LA253_1 <= KW_EXPRESSION)||(LA253_1 >= KW_FIELDS && LA253_1 <= KW_FIRST)||(LA253_1 >= KW_FORMAT && LA253_1 <= KW_FORMATTED)||LA253_1==KW_FUNCTIONS||(LA253_1 >= KW_HOUR && LA253_1 <= KW_IDXPROPERTIES)||LA253_1==KW_IGNORE||(LA253_1 >= KW_INDEX && LA253_1 <= KW_INDEXES)||(LA253_1 >= KW_INPATH && LA253_1 <= KW_INPUTFORMAT)||(LA253_1 >= KW_ISOLATION && LA253_1 <= KW_JAR)||(LA253_1 >= KW_JOINCOST && LA253_1 <= KW_LAST)||LA253_1==KW_LEVEL||(LA253_1 >= KW_LIMIT && LA253_1 <= KW_LOAD)||(LA253_1 >= KW_LOCATION && LA253_1 <= KW_LONG)||(LA253_1 >= KW_MANAGED && LA253_1 <= KW_MANAGEMENT)||(LA253_1 >= KW_MAPJOIN && LA253_1 <= KW_MATERIALIZED)||LA253_1==KW_METADATA||(LA253_1 >= KW_MINUTE && LA253_1 <= KW_MONTH)||(LA253_1 >= KW_MOVE && LA253_1 <= KW_MSCK)||(LA253_1 >= KW_NORELY && LA253_1 <= KW_NOSCAN)||LA253_1==KW_NOVALIDATE||LA253_1==KW_NULLS||LA253_1==KW_OFFSET||(LA253_1 >= KW_OPERATOR && LA253_1 <= KW_OPTION)||(LA253_1 >= KW_OUTPUTDRIVER && LA253_1 <= KW_OUTPUTFORMAT)||(LA253_1 >= KW_OVERWRITE && LA253_1 <= KW_OWNER)||(LA253_1 >= KW_PARTITIONED && LA253_1 <= KW_PATH)||(LA253_1 >= KW_PLAN && LA253_1 <= KW_POOL)||LA253_1==KW_PRINCIPALS||LA253_1==KW_PURGE||(LA253_1 >= KW_QUARTER && LA253_1 <= KW_QUERY_PARALLELISM)||LA253_1==KW_READ||(LA253_1 >= KW_REBUILD && LA253_1 <= KW_RECORDWRITER)||(LA253_1 >= KW_RELOAD && LA253_1 <= KW_RESTRICT)||LA253_1==KW_REWRITE||(LA253_1 >= KW_ROLE && LA253_1 <= KW_ROLES)||(LA253_1 >= KW_SCHEDULED && LA253_1 <= KW_SECOND)||(LA253_1 >= KW_SEMI && LA253_1 <= KW_SERVER)||(LA253_1 >= KW_SETS && LA253_1 <= KW_SKEWED)||LA253_1==KW_SNAPSHOT||(LA253_1 >= KW_SORT && LA253_1 <= KW_SSL)||(LA253_1 >= KW_STATISTICS && LA253_1 <= KW_SUMMARY)||(LA253_1 >= KW_SYSTEM_TIME && LA253_1 <= KW_SYSTEM_VERSION)||LA253_1==KW_TABLES||(LA253_1 >= KW_TBLPROPERTIES && LA253_1 <= KW_TERMINATED)||LA253_1==KW_TINYINT||LA253_1==KW_TOUCH||(LA253_1 >= KW_TRANSACTION && LA253_1 <= KW_TRANSACTIONS)||LA253_1==KW_TRIM||(LA253_1 >= KW_TYPE && LA253_1 <= KW_UNARCHIVE)||LA253_1==KW_UNDO||LA253_1==KW_UNIONTYPE||(LA253_1 >= KW_UNKNOWN && LA253_1 <= KW_UNSIGNED)||(LA253_1 >= KW_URI && LA253_1 <= KW_USE)||(LA253_1 >= KW_UTC && LA253_1 <= KW_VALIDATE)||LA253_1==KW_VALUE_TYPE||(LA253_1 >= KW_VECTORIZATION && LA253_1 <= KW_WEEK)||LA253_1==KW_WHILE||(LA253_1 >= KW_WITHIN && LA253_1 <= KW_ZONE)||LA253_1==KW_BATCH||LA253_1==KW_DAYOFWEEK||LA253_1==KW_HOLD_DDLTIME||LA253_1==KW_NO_DROP||LA253_1==KW_OFFLINE||LA253_1==KW_PROTECTION||LA253_1==KW_READONLY||LA253_1==KW_TIMESTAMPTZ) ) {
					int LA253_9 = input.LA(3);
					if ( (LA253_9==KW_REFERENCES) ) {
						alt253=1;
					}
					else if ( (LA253_9==KW_CHECK||LA253_9==KW_DEFAULT||LA253_9==KW_NOT||LA253_9==KW_PRIMARY||LA253_9==KW_UNIQUE) ) {
						alt253=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 253, 9, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 253, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_REFERENCES:
				{
				alt253=1;
				}
				break;
			case KW_CHECK:
			case KW_DEFAULT:
			case KW_NOT:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt253=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 253, 0, input);
				throw nvae;
			}
			switch (alt253) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:7: ( foreignKeyConstraint[$fkColName] )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:7: ( foreignKeyConstraint[$fkColName] )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2373:9: foreignKeyConstraint[$fkColName]
					{
					pushFollow(FOLLOW_foreignKeyConstraint_in_columnConstraint14256);
					foreignKeyConstraint812=foreignKeyConstraint(fkColName);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, foreignKeyConstraint812.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:7: ( colConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:7: ( colConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2374:9: colConstraint
					{
					pushFollow(FOLLOW_colConstraint_in_columnConstraint14269);
					colConstraint813=colConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, colConstraint813.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnConstraint"


	public static class foreignKeyConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "foreignKeyConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2377:1: foreignKeyConstraint[CommonTree fkColName] : ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) ;
	public final HiveParser.foreignKeyConstraint_return foreignKeyConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.foreignKeyConstraint_return retval = new HiveParser.foreignKeyConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT814=null;
		Token KW_REFERENCES815=null;
		Token LPAREN816=null;
		Token RPAREN817=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope constraintOptsCreate818 =null;

		ASTNode KW_CONSTRAINT814_tree=null;
		ASTNode KW_REFERENCES815_tree=null;
		ASTNode LPAREN816_tree=null;
		ASTNode RPAREN817_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:7: ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt254=2;
			int LA254_0 = input.LA(1);
			if ( (LA254_0==KW_CONSTRAINT) ) {
				alt254=1;
			}
			switch (alt254) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT814=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint14300); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT814);

					pushFollow(FOLLOW_identifier_in_foreignKeyConstraint14304);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_REFERENCES815=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_foreignKeyConstraint14308); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES815);

			pushFollow(FOLLOW_tableName_in_foreignKeyConstraint14312);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			LPAREN816=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_foreignKeyConstraint14314); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN816);

			pushFollow(FOLLOW_columnName_in_foreignKeyConstraint14318);
			colName=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(colName.getTree());
			RPAREN817=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_foreignKeyConstraint14320); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN817);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:115: ( constraintOptsCreate )?
			int alt255=2;
			int LA255_0 = input.LA(1);
			if ( (LA255_0==KW_DISABLE||LA255_0==KW_ENABLE||LA255_0==KW_ENFORCED||LA255_0==KW_NOT) ) {
				alt255=1;
			}
			switch (alt255) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2380:115: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_foreignKeyConstraint14322);
					constraintOptsCreate818=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate818.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintName, tabName, colName, tabName, colName, constraintOptsCreate, constraintOptsCreate
			// token labels: 
			// rule labels: tabName, colName, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2381:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:70: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:110: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2382:137: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2383:5: -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2383:8: ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2383:26: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2383:66: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2383:93: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "foreignKeyConstraint"


	public static class colConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2386:1: colConstraint : ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) ;
	public final HiveParser.colConstraint_return colConstraint() throws RecognitionException {
		HiveParser.colConstraint_return retval = new HiveParser.colConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT819=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope columnConstraintType820 =null;
		ParserRuleReturnScope constraintOptsCreate821 =null;

		ASTNode KW_CONSTRAINT819_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_constraintOptsCreate=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsCreate");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraintType");

		 pushMsg("column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:5: ( ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? ) -> ^( ( constraintOptsCreate )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:7: ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsCreate )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt256=2;
			int LA256_0 = input.LA(1);
			if ( (LA256_0==KW_CONSTRAINT) ) {
				alt256=1;
			}
			switch (alt256) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT819=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_colConstraint14430); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT819);

					pushFollow(FOLLOW_identifier_in_colConstraint14434);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_columnConstraintType_in_colConstraint14438);
			columnConstraintType820=columnConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnConstraintType.add(columnConstraintType820.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:71: ( constraintOptsCreate )?
			int alt257=2;
			int LA257_0 = input.LA(1);
			if ( (LA257_0==KW_DISABLE||LA257_0==KW_ENABLE||LA257_0==KW_ENFORCED||LA257_0==KW_NOT) ) {
				alt257=1;
			}
			switch (alt257) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2389:71: constraintOptsCreate
					{
					pushFollow(FOLLOW_constraintOptsCreate_in_colConstraint14440);
					constraintOptsCreate821=constraintOptsCreate();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsCreate.add(constraintOptsCreate821.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintOptsCreate, constraintName, constraintOptsCreate
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2390:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2391:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType820!=null?((ASTNode)columnConstraintType820.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2391:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2391:83: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2392:5: -> ^( ( constraintOptsCreate )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:8: ^( ( constraintOptsCreate )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType820!=null?((ASTNode)columnConstraintType820.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2392:39: ( constraintOptsCreate )?
				if ( stream_constraintOptsCreate.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsCreate.nextTree());
				}
				stream_constraintOptsCreate.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colConstraint"


	public static class alterColumnConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterColumnConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2395:1: alterColumnConstraint[CommonTree fkColName] : ( ( alterForeignKeyConstraint[$fkColName] ) | ( alterColConstraint ) );
	public final HiveParser.alterColumnConstraint_return alterColumnConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.alterColumnConstraint_return retval = new HiveParser.alterColumnConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope alterForeignKeyConstraint822 =null;
		ParserRuleReturnScope alterColConstraint823 =null;


		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2398:5: ( ( alterForeignKeyConstraint[$fkColName] ) | ( alterColConstraint ) )
			int alt258=2;
			switch ( input.LA(1) ) {
			case KW_CONSTRAINT:
				{
				int LA258_1 = input.LA(2);
				if ( (LA258_1==Identifier) ) {
					int LA258_8 = input.LA(3);
					if ( (LA258_8==KW_REFERENCES) ) {
						alt258=1;
					}
					else if ( (LA258_8==KW_CHECK||LA258_8==KW_DEFAULT||LA258_8==KW_NOT||LA258_8==KW_PRIMARY||LA258_8==KW_UNIQUE) ) {
						alt258=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 258, 8, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}
				else if ( ((LA258_1 >= KW_ABORT && LA258_1 <= KW_AFTER)||LA258_1==KW_ALLOC_FRACTION||LA258_1==KW_ANALYZE||LA258_1==KW_ARCHIVE||(LA258_1 >= KW_ASC && LA258_1 <= KW_AT)||(LA258_1 >= KW_AUTOCOMMIT && LA258_1 <= KW_BEFORE)||(LA258_1 >= KW_BUCKET && LA258_1 <= KW_BUCKETS)||(LA258_1 >= KW_CACHE && LA258_1 <= KW_CASCADE)||(LA258_1 >= KW_CBO && LA258_1 <= KW_CHANGE)||(LA258_1 >= KW_CHECK && LA258_1 <= KW_COLLECTION)||(LA258_1 >= KW_COLUMNS && LA258_1 <= KW_COMMENT)||(LA258_1 >= KW_COMPACT && LA258_1 <= KW_CONCATENATE)||(LA258_1 >= KW_CONTINUE && LA258_1 <= KW_COST)||LA258_1==KW_CRON||LA258_1==KW_DATA||LA258_1==KW_DATABASES||(LA258_1 >= KW_DATETIME && LA258_1 <= KW_DCPROPERTIES)||LA258_1==KW_DEBUG||(LA258_1 >= KW_DEFAULT && LA258_1 <= KW_DEFINED)||(LA258_1 >= KW_DELIMITED && LA258_1 <= KW_DESC)||(LA258_1 >= KW_DETAIL && LA258_1 <= KW_DISABLE)||(LA258_1 >= KW_DISTRIBUTE && LA258_1 <= KW_DO)||LA258_1==KW_DOW||(LA258_1 >= KW_DUMP && LA258_1 <= KW_ELEM_TYPE)||LA258_1==KW_ENABLE||(LA258_1 >= KW_ENFORCED && LA258_1 <= KW_EVERY)||(LA258_1 >= KW_EXCLUSIVE && LA258_1 <= KW_EXECUTED)||(LA258_1 >= KW_EXPIRE_SNAPSHOTS && LA258_1 <= KW_EXPRESSION)||(LA258_1 >= KW_FIELDS && LA258_1 <= KW_FIRST)||(LA258_1 >= KW_FORMAT && LA258_1 <= KW_FORMATTED)||LA258_1==KW_FUNCTIONS||(LA258_1 >= KW_HOUR && LA258_1 <= KW_IDXPROPERTIES)||LA258_1==KW_IGNORE||(LA258_1 >= KW_INDEX && LA258_1 <= KW_INDEXES)||(LA258_1 >= KW_INPATH && LA258_1 <= KW_INPUTFORMAT)||(LA258_1 >= KW_ISOLATION && LA258_1 <= KW_JAR)||(LA258_1 >= KW_JOINCOST && LA258_1 <= KW_LAST)||LA258_1==KW_LEVEL||(LA258_1 >= KW_LIMIT && LA258_1 <= KW_LOAD)||(LA258_1 >= KW_LOCATION && LA258_1 <= KW_LONG)||(LA258_1 >= KW_MANAGED && LA258_1 <= KW_MANAGEMENT)||(LA258_1 >= KW_MAPJOIN && LA258_1 <= KW_MATERIALIZED)||LA258_1==KW_METADATA||(LA258_1 >= KW_MINUTE && LA258_1 <= KW_MONTH)||(LA258_1 >= KW_MOVE && LA258_1 <= KW_MSCK)||(LA258_1 >= KW_NORELY && LA258_1 <= KW_NOSCAN)||LA258_1==KW_NOVALIDATE||LA258_1==KW_NULLS||LA258_1==KW_OFFSET||(LA258_1 >= KW_OPERATOR && LA258_1 <= KW_OPTION)||(LA258_1 >= KW_OUTPUTDRIVER && LA258_1 <= KW_OUTPUTFORMAT)||(LA258_1 >= KW_OVERWRITE && LA258_1 <= KW_OWNER)||(LA258_1 >= KW_PARTITIONED && LA258_1 <= KW_PATH)||(LA258_1 >= KW_PLAN && LA258_1 <= KW_POOL)||LA258_1==KW_PRINCIPALS||LA258_1==KW_PURGE||(LA258_1 >= KW_QUARTER && LA258_1 <= KW_QUERY_PARALLELISM)||LA258_1==KW_READ||(LA258_1 >= KW_REBUILD && LA258_1 <= KW_RECORDWRITER)||(LA258_1 >= KW_RELOAD && LA258_1 <= KW_RESTRICT)||LA258_1==KW_REWRITE||(LA258_1 >= KW_ROLE && LA258_1 <= KW_ROLES)||(LA258_1 >= KW_SCHEDULED && LA258_1 <= KW_SECOND)||(LA258_1 >= KW_SEMI && LA258_1 <= KW_SERVER)||(LA258_1 >= KW_SETS && LA258_1 <= KW_SKEWED)||LA258_1==KW_SNAPSHOT||(LA258_1 >= KW_SORT && LA258_1 <= KW_SSL)||(LA258_1 >= KW_STATISTICS && LA258_1 <= KW_SUMMARY)||(LA258_1 >= KW_SYSTEM_TIME && LA258_1 <= KW_SYSTEM_VERSION)||LA258_1==KW_TABLES||(LA258_1 >= KW_TBLPROPERTIES && LA258_1 <= KW_TERMINATED)||LA258_1==KW_TINYINT||LA258_1==KW_TOUCH||(LA258_1 >= KW_TRANSACTION && LA258_1 <= KW_TRANSACTIONS)||LA258_1==KW_TRIM||(LA258_1 >= KW_TYPE && LA258_1 <= KW_UNARCHIVE)||LA258_1==KW_UNDO||LA258_1==KW_UNIONTYPE||(LA258_1 >= KW_UNKNOWN && LA258_1 <= KW_UNSIGNED)||(LA258_1 >= KW_URI && LA258_1 <= KW_USE)||(LA258_1 >= KW_UTC && LA258_1 <= KW_VALIDATE)||LA258_1==KW_VALUE_TYPE||(LA258_1 >= KW_VECTORIZATION && LA258_1 <= KW_WEEK)||LA258_1==KW_WHILE||(LA258_1 >= KW_WITHIN && LA258_1 <= KW_ZONE)||LA258_1==KW_BATCH||LA258_1==KW_DAYOFWEEK||LA258_1==KW_HOLD_DDLTIME||LA258_1==KW_NO_DROP||LA258_1==KW_OFFLINE||LA258_1==KW_PROTECTION||LA258_1==KW_READONLY||LA258_1==KW_TIMESTAMPTZ) ) {
					int LA258_9 = input.LA(3);
					if ( (LA258_9==KW_REFERENCES) ) {
						alt258=1;
					}
					else if ( (LA258_9==KW_CHECK||LA258_9==KW_DEFAULT||LA258_9==KW_NOT||LA258_9==KW_PRIMARY||LA258_9==KW_UNIQUE) ) {
						alt258=2;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 258, 9, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 258, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_REFERENCES:
				{
				alt258=1;
				}
				break;
			case KW_CHECK:
			case KW_DEFAULT:
			case KW_NOT:
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt258=2;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 258, 0, input);
				throw nvae;
			}
			switch (alt258) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2398:7: ( alterForeignKeyConstraint[$fkColName] )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2398:7: ( alterForeignKeyConstraint[$fkColName] )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2398:9: alterForeignKeyConstraint[$fkColName]
					{
					pushFollow(FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint14518);
					alterForeignKeyConstraint822=alterForeignKeyConstraint(fkColName);
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterForeignKeyConstraint822.getTree());

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2399:7: ( alterColConstraint )
					{
					root_0 = (ASTNode)adaptor.nil();


					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2399:7: ( alterColConstraint )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2399:9: alterColConstraint
					{
					pushFollow(FOLLOW_alterColConstraint_in_alterColumnConstraint14531);
					alterColConstraint823=alterColConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, alterColConstraint823.getTree());

					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterColumnConstraint"


	public static class alterForeignKeyConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterForeignKeyConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2402:1: alterForeignKeyConstraint[CommonTree fkColName] : ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) ;
	public final HiveParser.alterForeignKeyConstraint_return alterForeignKeyConstraint(CommonTree fkColName) throws RecognitionException {
		HiveParser.alterForeignKeyConstraint_return retval = new HiveParser.alterForeignKeyConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT824=null;
		Token KW_REFERENCES825=null;
		Token LPAREN826=null;
		Token RPAREN827=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope tabName =null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope constraintOptsAlter828 =null;

		ASTNode KW_CONSTRAINT824_tree=null;
		ASTNode KW_REFERENCES825_tree=null;
		ASTNode LPAREN826_tree=null;
		ASTNode RPAREN827_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_REFERENCES=new RewriteRuleTokenStream(adaptor,"token KW_REFERENCES");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");

		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:5: ( ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:7: ( KW_CONSTRAINT constraintName= identifier )? KW_REFERENCES tabName= tableName LPAREN colName= columnName RPAREN ( constraintOptsAlter )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt259=2;
			int LA259_0 = input.LA(1);
			if ( (LA259_0==KW_CONSTRAINT) ) {
				alt259=1;
			}
			switch (alt259) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT824=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint14562); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT824);

					pushFollow(FOLLOW_identifier_in_alterForeignKeyConstraint14566);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			KW_REFERENCES825=(Token)match(input,KW_REFERENCES,FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint14570); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_REFERENCES.add(KW_REFERENCES825);

			pushFollow(FOLLOW_tableName_in_alterForeignKeyConstraint14574);
			tabName=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tabName.getTree());
			LPAREN826=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterForeignKeyConstraint14576); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN826);

			pushFollow(FOLLOW_columnName_in_alterForeignKeyConstraint14580);
			colName=columnName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnName.add(colName.getTree());
			RPAREN827=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterForeignKeyConstraint14582); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN827);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:115: ( constraintOptsAlter )?
			int alt260=2;
			int LA260_0 = input.LA(1);
			if ( (LA260_0==KW_DISABLE||LA260_0==KW_ENABLE||LA260_0==KW_ENFORCED||LA260_0==KW_NOT) ) {
				alt260=1;
			}
			switch (alt260) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2405:115: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint14584);
					constraintOptsAlter828=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter828.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: tabName, constraintOptsAlter, constraintName, colName, tabName, constraintOptsAlter, colName
			// token labels: 
			// rule labels: tabName, colName, constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.getTree():null);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2406:5: -> {$constraintName.tree != null}? ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2407:13: ^( TOK_FOREIGN_KEY ^( TOK_CONSTRAINT_NAME $constraintName) ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2407:31: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2407:70: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2407:110: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2407:137: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2408:5: -> ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2408:8: ^( TOK_FOREIGN_KEY ^( TOK_TABCOLNAME ) $tabName ^( TOK_TABCOLNAME $colName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FOREIGN_KEY, "TOK_FOREIGN_KEY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2408:26: ^( TOK_TABCOLNAME )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, fkColName);
				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_tabName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2408:66: ^( TOK_TABCOLNAME $colName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME"), root_2);
				adaptor.addChild(root_2, stream_colName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2408:93: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterForeignKeyConstraint"


	public static class alterColConstraint_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "alterColConstraint"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2411:1: alterColConstraint : ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) -> ^( ( constraintOptsAlter )? ) ;
	public final HiveParser.alterColConstraint_return alterColConstraint() throws RecognitionException {
		HiveParser.alterColConstraint_return retval = new HiveParser.alterColConstraint_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_CONSTRAINT829=null;
		ParserRuleReturnScope constraintName =null;
		ParserRuleReturnScope columnConstraintType830 =null;
		ParserRuleReturnScope constraintOptsAlter831 =null;

		ASTNode KW_CONSTRAINT829_tree=null;
		RewriteRuleTokenStream stream_KW_CONSTRAINT=new RewriteRuleTokenStream(adaptor,"token KW_CONSTRAINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_columnConstraintType=new RewriteRuleSubtreeStream(adaptor,"rule columnConstraintType");
		RewriteRuleSubtreeStream stream_constraintOptsAlter=new RewriteRuleSubtreeStream(adaptor,"rule constraintOptsAlter");

		 pushMsg("alter column constraint", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:5: ( ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )? -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? ) -> ^( ( constraintOptsAlter )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:7: ( KW_CONSTRAINT constraintName= identifier )? columnConstraintType ( constraintOptsAlter )?
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:7: ( KW_CONSTRAINT constraintName= identifier )?
			int alt261=2;
			int LA261_0 = input.LA(1);
			if ( (LA261_0==KW_CONSTRAINT) ) {
				alt261=1;
			}
			switch (alt261) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:8: KW_CONSTRAINT constraintName= identifier
					{
					KW_CONSTRAINT829=(Token)match(input,KW_CONSTRAINT,FOLLOW_KW_CONSTRAINT_in_alterColConstraint14692); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CONSTRAINT.add(KW_CONSTRAINT829);

					pushFollow(FOLLOW_identifier_in_alterColConstraint14696);
					constraintName=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(constraintName.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_columnConstraintType_in_alterColConstraint14700);
			columnConstraintType830=columnConstraintType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnConstraintType.add(columnConstraintType830.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:71: ( constraintOptsAlter )?
			int alt262=2;
			int LA262_0 = input.LA(1);
			if ( (LA262_0==KW_DISABLE||LA262_0==KW_ENABLE||LA262_0==KW_ENFORCED||LA262_0==KW_NOT) ) {
				alt262=1;
			}
			switch (alt262) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2414:71: constraintOptsAlter
					{
					pushFollow(FOLLOW_constraintOptsAlter_in_alterColConstraint14702);
					constraintOptsAlter831=constraintOptsAlter();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_constraintOptsAlter.add(constraintOptsAlter831.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: constraintName, constraintOptsAlter, constraintOptsAlter
			// token labels: 
			// rule labels: constraintName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_constraintName=new RewriteRuleSubtreeStream(adaptor,"rule constraintName",constraintName!=null?constraintName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2415:5: -> {$constraintName.tree != null}? ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
			if ((constraintName!=null?((ASTNode)constraintName.getTree()):null) != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2416:13: ^( ^( TOK_CONSTRAINT_NAME $constraintName) ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType830!=null?((ASTNode)columnConstraintType830.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2416:44: ^( TOK_CONSTRAINT_NAME $constraintName)
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CONSTRAINT_NAME, "TOK_CONSTRAINT_NAME"), root_2);
				adaptor.addChild(root_2, stream_constraintName.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2416:83: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2417:5: -> ^( ( constraintOptsAlter )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2417:8: ^( ( constraintOptsAlter )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((columnConstraintType830!=null?((ASTNode)columnConstraintType830.getTree()):null), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2417:39: ( constraintOptsAlter )?
				if ( stream_constraintOptsAlter.hasNext() ) {
					adaptor.addChild(root_1, stream_constraintOptsAlter.nextTree());
				}
				stream_constraintOptsAlter.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "alterColConstraint"


	public static class columnConstraintType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnConstraintType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2420:1: columnConstraintType : ( KW_NOT KW_NULL -> TOK_NOT_NULL | KW_DEFAULT defaultVal -> ^( TOK_DEFAULT_VALUE defaultVal ) | checkConstraint | tableConstraintType );
	public final HiveParser.columnConstraintType_return columnConstraintType() throws RecognitionException {
		HiveParser.columnConstraintType_return retval = new HiveParser.columnConstraintType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_NOT832=null;
		Token KW_NULL833=null;
		Token KW_DEFAULT834=null;
		ParserRuleReturnScope defaultVal835 =null;
		ParserRuleReturnScope checkConstraint836 =null;
		ParserRuleReturnScope tableConstraintType837 =null;

		ASTNode KW_NOT832_tree=null;
		ASTNode KW_NULL833_tree=null;
		ASTNode KW_DEFAULT834_tree=null;
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_NULL=new RewriteRuleTokenStream(adaptor,"token KW_NULL");
		RewriteRuleTokenStream stream_KW_DEFAULT=new RewriteRuleTokenStream(adaptor,"token KW_DEFAULT");
		RewriteRuleSubtreeStream stream_defaultVal=new RewriteRuleSubtreeStream(adaptor,"rule defaultVal");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2421:5: ( KW_NOT KW_NULL -> TOK_NOT_NULL | KW_DEFAULT defaultVal -> ^( TOK_DEFAULT_VALUE defaultVal ) | checkConstraint | tableConstraintType )
			int alt263=4;
			switch ( input.LA(1) ) {
			case KW_NOT:
				{
				alt263=1;
				}
				break;
			case KW_DEFAULT:
				{
				alt263=2;
				}
				break;
			case KW_CHECK:
				{
				alt263=3;
				}
				break;
			case KW_PRIMARY:
			case KW_UNIQUE:
				{
				alt263=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 263, 0, input);
				throw nvae;
			}
			switch (alt263) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2421:7: KW_NOT KW_NULL
					{
					KW_NOT832=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_columnConstraintType14767); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT832);

					KW_NULL833=(Token)match(input,KW_NULL,FOLLOW_KW_NULL_in_columnConstraintType14769); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_NULL.add(KW_NULL833);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2421:28: -> TOK_NOT_NULL
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_NOT_NULL, "TOK_NOT_NULL"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2422:7: KW_DEFAULT defaultVal
					{
					KW_DEFAULT834=(Token)match(input,KW_DEFAULT,FOLLOW_KW_DEFAULT_in_columnConstraintType14790); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DEFAULT.add(KW_DEFAULT834);

					pushFollow(FOLLOW_defaultVal_in_columnConstraintType14792);
					defaultVal835=defaultVal();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_defaultVal.add(defaultVal835.getTree());
					// AST REWRITE
					// elements: defaultVal
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2422:28: -> ^( TOK_DEFAULT_VALUE defaultVal )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2422:34: ^( TOK_DEFAULT_VALUE defaultVal )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DEFAULT_VALUE, "TOK_DEFAULT_VALUE"), root_1);
						adaptor.addChild(root_1, stream_defaultVal.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2423:7: checkConstraint
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_checkConstraint_in_columnConstraintType14810);
					checkConstraint836=checkConstraint();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, checkConstraint836.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2424:7: tableConstraintType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_tableConstraintType_in_columnConstraintType14818);
					tableConstraintType837=tableConstraintType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableConstraintType837.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnConstraintType"


	public static class defaultVal_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "defaultVal"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2427:1: defaultVal : ( constant | function | castExpression );
	public final HiveParser.defaultVal_return defaultVal() throws RecognitionException {
		HiveParser.defaultVal_return retval = new HiveParser.defaultVal_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope constant838 =null;
		ParserRuleReturnScope function839 =null;
		ParserRuleReturnScope castExpression840 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2428:5: ( constant | function | castExpression )
			int alt264=3;
			switch ( input.LA(1) ) {
			case CharSetName:
			case IntegralLiteral:
			case KW_FALSE:
			case KW_NULL:
			case KW_TIMESTAMPLOCALTZ:
			case KW_TRUE:
			case Number:
			case NumberLiteral:
			case QUESTION:
			case StringLiteral:
				{
				alt264=1;
				}
				break;
			case KW_DATE:
				{
				int LA264_3 = input.LA(2);
				if ( (LA264_3==StringLiteral) ) {
					alt264=1;
				}
				else if ( (LA264_3==LPAREN) ) {
					alt264=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 264, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CURRENT_DATE:
				{
				int LA264_4 = input.LA(2);
				if ( (LA264_4==EOF||LA264_4==COMMA||LA264_4==KW_AFTER||LA264_4==KW_CASCADE||LA264_4==KW_COMMENT||LA264_4==KW_DISABLE||LA264_4==KW_ENABLE||LA264_4==KW_ENFORCED||LA264_4==KW_FIRST||LA264_4==KW_NOT||LA264_4==KW_RESTRICT||LA264_4==RPAREN) ) {
					alt264=1;
				}
				else if ( (LA264_4==LPAREN) ) {
					alt264=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 264, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TIMESTAMP:
				{
				int LA264_5 = input.LA(2);
				if ( (LA264_5==StringLiteral) ) {
					alt264=1;
				}
				else if ( (LA264_5==LPAREN) ) {
					alt264=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 264, 5, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_CURRENT_TIMESTAMP:
				{
				int LA264_6 = input.LA(2);
				if ( (LA264_6==EOF||LA264_6==COMMA||LA264_6==KW_AFTER||LA264_6==KW_CASCADE||LA264_6==KW_COMMENT||LA264_6==KW_DISABLE||LA264_6==KW_ENABLE||LA264_6==KW_ENFORCED||LA264_6==KW_FIRST||LA264_6==KW_NOT||LA264_6==KW_RESTRICT||LA264_6==RPAREN) ) {
					alt264=1;
				}
				else if ( (LA264_6==LPAREN) ) {
					alt264=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 264, 6, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case Identifier:
			case KW_ABORT:
			case KW_ACTIVATE:
			case KW_ACTIVE:
			case KW_ADD:
			case KW_ADMIN:
			case KW_AFTER:
			case KW_ALLOC_FRACTION:
			case KW_ANALYZE:
			case KW_ARCHIVE:
			case KW_ARRAY:
			case KW_ASC:
			case KW_AST:
			case KW_AT:
			case KW_AUTOCOMMIT:
			case KW_BEFORE:
			case KW_BIGINT:
			case KW_BINARY:
			case KW_BOOLEAN:
			case KW_BUCKET:
			case KW_BUCKETS:
			case KW_CACHE:
			case KW_CASCADE:
			case KW_CBO:
			case KW_CHANGE:
			case KW_CHECK:
			case KW_CLUSTER:
			case KW_CLUSTERED:
			case KW_CLUSTERSTATUS:
			case KW_COLLECTION:
			case KW_COLUMNS:
			case KW_COMMENT:
			case KW_COMPACT:
			case KW_COMPACTIONS:
			case KW_COMPUTE:
			case KW_CONCATENATE:
			case KW_CONTINUE:
			case KW_COST:
			case KW_CRON:
			case KW_DATA:
			case KW_DATABASES:
			case KW_DATETIME:
			case KW_DAY:
			case KW_DBPROPERTIES:
			case KW_DCPROPERTIES:
			case KW_DEBUG:
			case KW_DEFAULT:
			case KW_DEFERRED:
			case KW_DEFINED:
			case KW_DELIMITED:
			case KW_DEPENDENCY:
			case KW_DESC:
			case KW_DETAIL:
			case KW_DIRECTORIES:
			case KW_DIRECTORY:
			case KW_DISABLE:
			case KW_DISTRIBUTE:
			case KW_DISTRIBUTED:
			case KW_DO:
			case KW_DOUBLE:
			case KW_DOW:
			case KW_DUMP:
			case KW_ELEM_TYPE:
			case KW_ENABLE:
			case KW_ENFORCED:
			case KW_ESCAPED:
			case KW_EVERY:
			case KW_EXCLUSIVE:
			case KW_EXECUTE:
			case KW_EXECUTED:
			case KW_EXPIRE_SNAPSHOTS:
			case KW_EXPLAIN:
			case KW_EXPORT:
			case KW_EXPRESSION:
			case KW_FIELDS:
			case KW_FILE:
			case KW_FILEFORMAT:
			case KW_FIRST:
			case KW_FLOAT:
			case KW_FORMAT:
			case KW_FORMATTED:
			case KW_FUNCTIONS:
			case KW_GROUPING:
			case KW_HOUR:
			case KW_ID:
			case KW_IDXPROPERTIES:
			case KW_IF:
			case KW_IGNORE:
			case KW_INDEX:
			case KW_INDEXES:
			case KW_INPATH:
			case KW_INPUTDRIVER:
			case KW_INPUTFORMAT:
			case KW_INT:
			case KW_ISOLATION:
			case KW_ITEMS:
			case KW_JAR:
			case KW_JOINCOST:
			case KW_KEY:
			case KW_KEYS:
			case KW_KEY_TYPE:
			case KW_KILL:
			case KW_LAST:
			case KW_LEVEL:
			case KW_LIMIT:
			case KW_LINES:
			case KW_LOAD:
			case KW_LOCATION:
			case KW_LOCK:
			case KW_LOCKS:
			case KW_LOGICAL:
			case KW_LONG:
			case KW_MANAGED:
			case KW_MANAGEDLOCATION:
			case KW_MANAGEMENT:
			case KW_MAP:
			case KW_MAPJOIN:
			case KW_MAPPING:
			case KW_MATCHED:
			case KW_MATERIALIZED:
			case KW_METADATA:
			case KW_MINUTE:
			case KW_MONTH:
			case KW_MOVE:
			case KW_MSCK:
			case KW_NORELY:
			case KW_NOSCAN:
			case KW_NOVALIDATE:
			case KW_NULLS:
			case KW_OFFSET:
			case KW_OPERATOR:
			case KW_OPTION:
			case KW_OUTPUTDRIVER:
			case KW_OUTPUTFORMAT:
			case KW_OVERWRITE:
			case KW_OWNER:
			case KW_PARTITIONED:
			case KW_PARTITIONS:
			case KW_PATH:
			case KW_PLAN:
			case KW_PLANS:
			case KW_PLUS:
			case KW_POOL:
			case KW_PRINCIPALS:
			case KW_PURGE:
			case KW_QUARTER:
			case KW_QUERY:
			case KW_QUERY_PARALLELISM:
			case KW_READ:
			case KW_REAL:
			case KW_REBUILD:
			case KW_RECORDREADER:
			case KW_RECORDWRITER:
			case KW_RELOAD:
			case KW_RELY:
			case KW_REMOTE:
			case KW_RENAME:
			case KW_REOPTIMIZATION:
			case KW_REPAIR:
			case KW_REPL:
			case KW_REPLACE:
			case KW_REPLICATION:
			case KW_RESOURCE:
			case KW_RESPECT:
			case KW_RESTRICT:
			case KW_REWRITE:
			case KW_ROLE:
			case KW_ROLES:
			case KW_SCHEDULED:
			case KW_SCHEDULING_POLICY:
			case KW_SCHEMA:
			case KW_SCHEMAS:
			case KW_SECOND:
			case KW_SEMI:
			case KW_SERDE:
			case KW_SERDEPROPERTIES:
			case KW_SERVER:
			case KW_SETS:
			case KW_SHARED:
			case KW_SHOW:
			case KW_SHOW_DATABASE:
			case KW_SKEWED:
			case KW_SMALLINT:
			case KW_SNAPSHOT:
			case KW_SORT:
			case KW_SORTED:
			case KW_SPEC:
			case KW_SSL:
			case KW_STATISTICS:
			case KW_STATUS:
			case KW_STORED:
			case KW_STREAMTABLE:
			case KW_STRING:
			case KW_STRUCT:
			case KW_SUMMARY:
			case KW_SYSTEM_TIME:
			case KW_SYSTEM_VERSION:
			case KW_TABLES:
			case KW_TBLPROPERTIES:
			case KW_TEMPORARY:
			case KW_TERMINATED:
			case KW_TINYINT:
			case KW_TOUCH:
			case KW_TRANSACTION:
			case KW_TRANSACTIONAL:
			case KW_TRANSACTIONS:
			case KW_TRIM:
			case KW_TYPE:
			case KW_UNARCHIVE:
			case KW_UNDO:
			case KW_UNIONTYPE:
			case KW_UNKNOWN:
			case KW_UNLOCK:
			case KW_UNMANAGED:
			case KW_UNSET:
			case KW_UNSIGNED:
			case KW_URI:
			case KW_URL:
			case KW_USE:
			case KW_UTC:
			case KW_UTCTIMESTAMP:
			case KW_VALIDATE:
			case KW_VALUE_TYPE:
			case KW_VECTORIZATION:
			case KW_VIEW:
			case KW_VIEWS:
			case KW_WAIT:
			case KW_WEEK:
			case KW_WHILE:
			case KW_WITHIN:
			case KW_WORK:
			case KW_WORKLOAD:
			case KW_WRITE:
			case KW_YEAR:
			case KW_ZONE:
			case KW_BATCH:
			case KW_DAYOFWEEK:
			case KW_HOLD_DDLTIME:
			case KW_NO_DROP:
			case KW_OFFLINE:
			case KW_PROTECTION:
			case KW_READONLY:
			case KW_TIMESTAMPTZ:
				{
				alt264=2;
				}
				break;
			case KW_CAST:
				{
				alt264=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 264, 0, input);
				throw nvae;
			}
			switch (alt264) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2428:7: constant
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_constant_in_defaultVal14835);
					constant838=constant();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, constant838.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2429:7: function
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_function_in_defaultVal14843);
					function839=function();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, function839.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2430:7: castExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_castExpression_in_defaultVal14851);
					castExpression840=castExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, castExpression840.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "defaultVal"


	public static class tableConstraintType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "tableConstraintType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2433:1: tableConstraintType : ( KW_PRIMARY KW_KEY -> TOK_PRIMARY_KEY | KW_UNIQUE -> TOK_UNIQUE );
	public final HiveParser.tableConstraintType_return tableConstraintType() throws RecognitionException {
		HiveParser.tableConstraintType_return retval = new HiveParser.tableConstraintType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_PRIMARY841=null;
		Token KW_KEY842=null;
		Token KW_UNIQUE843=null;

		ASTNode KW_PRIMARY841_tree=null;
		ASTNode KW_KEY842_tree=null;
		ASTNode KW_UNIQUE843_tree=null;
		RewriteRuleTokenStream stream_KW_PRIMARY=new RewriteRuleTokenStream(adaptor,"token KW_PRIMARY");
		RewriteRuleTokenStream stream_KW_UNIQUE=new RewriteRuleTokenStream(adaptor,"token KW_UNIQUE");
		RewriteRuleTokenStream stream_KW_KEY=new RewriteRuleTokenStream(adaptor,"token KW_KEY");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2434:5: ( KW_PRIMARY KW_KEY -> TOK_PRIMARY_KEY | KW_UNIQUE -> TOK_UNIQUE )
			int alt265=2;
			int LA265_0 = input.LA(1);
			if ( (LA265_0==KW_PRIMARY) ) {
				alt265=1;
			}
			else if ( (LA265_0==KW_UNIQUE) ) {
				alt265=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 265, 0, input);
				throw nvae;
			}

			switch (alt265) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2434:7: KW_PRIMARY KW_KEY
					{
					KW_PRIMARY841=(Token)match(input,KW_PRIMARY,FOLLOW_KW_PRIMARY_in_tableConstraintType14868); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_PRIMARY.add(KW_PRIMARY841);

					KW_KEY842=(Token)match(input,KW_KEY,FOLLOW_KW_KEY_in_tableConstraintType14870); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_KEY.add(KW_KEY842);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2434:28: -> TOK_PRIMARY_KEY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_PRIMARY_KEY, "TOK_PRIMARY_KEY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2435:7: KW_UNIQUE
					{
					KW_UNIQUE843=(Token)match(input,KW_UNIQUE,FOLLOW_KW_UNIQUE_in_tableConstraintType14888); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNIQUE.add(KW_UNIQUE843);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2435:28: -> TOK_UNIQUE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_UNIQUE, "TOK_UNIQUE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "tableConstraintType"


	public static class constraintOptsCreate_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "constraintOptsCreate"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2438:1: constraintOptsCreate : enableValidateSpecification ( relySpecification )? ;
	public final HiveParser.constraintOptsCreate_return constraintOptsCreate() throws RecognitionException {
		HiveParser.constraintOptsCreate_return retval = new HiveParser.constraintOptsCreate_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableValidateSpecification844 =null;
		ParserRuleReturnScope relySpecification845 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:5: ( enableValidateSpecification ( relySpecification )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:7: enableValidateSpecification ( relySpecification )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_enableValidateSpecification_in_constraintOptsCreate14923);
			enableValidateSpecification844=enableValidateSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, enableValidateSpecification844.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:35: ( relySpecification )?
			int alt266=2;
			int LA266_0 = input.LA(1);
			if ( (LA266_0==KW_NORELY||LA266_0==KW_RELY) ) {
				alt266=1;
			}
			switch (alt266) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2439:35: relySpecification
					{
					pushFollow(FOLLOW_relySpecification_in_constraintOptsCreate14925);
					relySpecification845=relySpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, relySpecification845.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "constraintOptsCreate"


	public static class constraintOptsAlter_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "constraintOptsAlter"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2442:1: constraintOptsAlter : enableValidateSpecification ( relySpecification )? ;
	public final HiveParser.constraintOptsAlter_return constraintOptsAlter() throws RecognitionException {
		HiveParser.constraintOptsAlter_return retval = new HiveParser.constraintOptsAlter_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope enableValidateSpecification846 =null;
		ParserRuleReturnScope relySpecification847 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2443:5: ( enableValidateSpecification ( relySpecification )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2443:7: enableValidateSpecification ( relySpecification )?
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_enableValidateSpecification_in_constraintOptsAlter14943);
			enableValidateSpecification846=enableValidateSpecification();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, enableValidateSpecification846.getTree());

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2443:35: ( relySpecification )?
			int alt267=2;
			int LA267_0 = input.LA(1);
			if ( (LA267_0==KW_NORELY||LA267_0==KW_RELY) ) {
				alt267=1;
			}
			switch (alt267) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2443:35: relySpecification
					{
					pushFollow(FOLLOW_relySpecification_in_constraintOptsAlter14945);
					relySpecification847=relySpecification();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, relySpecification847.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "constraintOptsAlter"


	public static class columnNameColonType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnNameColonType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2446:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
	public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
		HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token comment=null;
		Token COLON848=null;
		Token KW_COMMENT850=null;
		ParserRuleReturnScope colName =null;
		ParserRuleReturnScope colType849 =null;

		ASTNode comment_tree=null;
		ASTNode COLON848_tree=null;
		ASTNode KW_COMMENT850_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
		RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2449:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2449:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
			{
			pushFollow(FOLLOW_identifier_in_columnNameColonType14975);
			colName=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(colName.getTree());
			COLON848=(Token)match(input,COLON,FOLLOW_COLON_in_columnNameColonType14977); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_COLON.add(COLON848);

			pushFollow(FOLLOW_colType_in_columnNameColonType14979);
			colType849=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType849.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2449:40: ( KW_COMMENT comment= StringLiteral )?
			int alt268=2;
			int LA268_0 = input.LA(1);
			if ( (LA268_0==KW_COMMENT) ) {
				alt268=1;
			}
			switch (alt268) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2449:41: KW_COMMENT comment= StringLiteral
					{
					KW_COMMENT850=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameColonType14982); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_COMMENT.add(KW_COMMENT850);

					comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameColonType14986); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(comment);

					}
					break;

			}

			// AST REWRITE
			// elements: colType, comment, colName, colName, colType
			// token labels: comment
			// rule labels: colName, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
			RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2450:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
			if (comment == null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2450:28: ^( TOK_TABCOL $colName colType )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2451:5: -> ^( TOK_TABCOL $colName colType $comment)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2451:28: ^( TOK_TABCOL $colName colType $comment)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABCOL, "TOK_TABCOL"), root_1);
				adaptor.addChild(root_1, stream_colName.nextTree());
				adaptor.addChild(root_1, stream_colType.nextTree());
				adaptor.addChild(root_1, stream_comment.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnNameColonType"


	public static class colType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2454:1: colType : type ;
	public final HiveParser.colType_return colType() throws RecognitionException {
		HiveParser.colType_return retval = new HiveParser.colType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope type851 =null;


		 pushMsg("column type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2457:5: ( type )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2457:7: type
			{
			root_0 = (ASTNode)adaptor.nil();


			pushFollow(FOLLOW_type_in_colType15070);
			type851=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) adaptor.addChild(root_0, type851.getTree());

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colType"


	public static class colTypeList_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "colTypeList"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2460:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
	public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
		HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token COMMA853=null;
		ParserRuleReturnScope colType852 =null;
		ParserRuleReturnScope colType854 =null;

		ASTNode COMMA853_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");

		 pushMsg("column type list", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2463:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2463:7: colType ( COMMA colType )*
			{
			pushFollow(FOLLOW_colType_in_colTypeList15097);
			colType852=colType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colType.add(colType852.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2463:15: ( COMMA colType )*
			loop269:
			while (true) {
				int alt269=2;
				int LA269_0 = input.LA(1);
				if ( (LA269_0==COMMA) ) {
					alt269=1;
				}

				switch (alt269) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2463:16: COMMA colType
					{
					COMMA853=(Token)match(input,COMMA,FOLLOW_COMMA_in_colTypeList15100); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA853);

					pushFollow(FOLLOW_colType_in_colTypeList15102);
					colType854=colType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_colType.add(colType854.getTree());
					}
					break;

				default :
					break loop269;
				}
			}

			// AST REWRITE
			// elements: colType
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2463:32: -> ^( TOK_COLTYPELIST ( colType )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2463:35: ^( TOK_COLTYPELIST ( colType )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST"), root_1);
				if ( !(stream_colType.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_colType.hasNext() ) {
					adaptor.addChild(root_1, stream_colType.nextTree());
				}
				stream_colType.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "colTypeList"


	public static class type_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "type"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2466:1: type : ( primitiveType | listType | structType | mapType | unionType );
	public final HiveParser.type_return type() throws RecognitionException {
		HiveParser.type_return retval = new HiveParser.type_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope primitiveType855 =null;
		ParserRuleReturnScope listType856 =null;
		ParserRuleReturnScope structType857 =null;
		ParserRuleReturnScope mapType858 =null;
		ParserRuleReturnScope unionType859 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:5: ( primitiveType | listType | structType | mapType | unionType )
			int alt270=5;
			switch ( input.LA(1) ) {
			case KW_BIGINT:
			case KW_BINARY:
			case KW_BOOLEAN:
			case KW_CHAR:
			case KW_DATE:
			case KW_DATETIME:
			case KW_DECIMAL:
			case KW_DOUBLE:
			case KW_FLOAT:
			case KW_INT:
			case KW_REAL:
			case KW_SMALLINT:
			case KW_STRING:
			case KW_TIMESTAMP:
			case KW_TIMESTAMPLOCALTZ:
			case KW_TINYINT:
			case KW_VARCHAR:
				{
				alt270=1;
				}
				break;
			case KW_ARRAY:
				{
				alt270=2;
				}
				break;
			case KW_STRUCT:
				{
				alt270=3;
				}
				break;
			case KW_MAP:
				{
				alt270=4;
				}
				break;
			case KW_UNIONTYPE:
				{
				alt270=5;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 270, 0, input);
				throw nvae;
			}
			switch (alt270) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2467:7: primitiveType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_primitiveType_in_type15130);
					primitiveType855=primitiveType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, primitiveType855.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2468:7: listType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_listType_in_type15138);
					listType856=listType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, listType856.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2469:7: structType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_structType_in_type15146);
					structType857=structType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, structType857.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2470:7: mapType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_mapType_in_type15154);
					mapType858=mapType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, mapType858.getTree());

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2471:7: unionType
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_unionType_in_type15162);
					unionType859=unionType();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, unionType859.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "type"


	public static class primitiveType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "primitiveType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2473:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_REAL -> TOK_FLOAT | KW_DOUBLE ( KW_PRECISION )? -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_TIMESTAMPLOCALTZ -> TOK_TIMESTAMPLOCALTZ | KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE -> TOK_TIMESTAMPLOCALTZ | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) );
	public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
		HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token prec=null;
		Token scale=null;
		Token length=null;
		Token KW_TINYINT860=null;
		Token KW_SMALLINT861=null;
		Token KW_INT862=null;
		Token KW_BIGINT863=null;
		Token KW_BOOLEAN864=null;
		Token KW_FLOAT865=null;
		Token KW_REAL866=null;
		Token KW_DOUBLE867=null;
		Token KW_PRECISION868=null;
		Token KW_DATE869=null;
		Token KW_DATETIME870=null;
		Token KW_TIMESTAMP871=null;
		Token KW_TIMESTAMPLOCALTZ872=null;
		Token KW_TIMESTAMP873=null;
		Token KW_WITH874=null;
		Token KW_LOCAL875=null;
		Token KW_TIME876=null;
		Token KW_ZONE877=null;
		Token KW_STRING878=null;
		Token KW_BINARY879=null;
		Token KW_DECIMAL880=null;
		Token LPAREN881=null;
		Token COMMA882=null;
		Token RPAREN883=null;
		Token KW_VARCHAR884=null;
		Token LPAREN885=null;
		Token RPAREN886=null;
		Token KW_CHAR887=null;
		Token LPAREN888=null;
		Token RPAREN889=null;

		ASTNode prec_tree=null;
		ASTNode scale_tree=null;
		ASTNode length_tree=null;
		ASTNode KW_TINYINT860_tree=null;
		ASTNode KW_SMALLINT861_tree=null;
		ASTNode KW_INT862_tree=null;
		ASTNode KW_BIGINT863_tree=null;
		ASTNode KW_BOOLEAN864_tree=null;
		ASTNode KW_FLOAT865_tree=null;
		ASTNode KW_REAL866_tree=null;
		ASTNode KW_DOUBLE867_tree=null;
		ASTNode KW_PRECISION868_tree=null;
		ASTNode KW_DATE869_tree=null;
		ASTNode KW_DATETIME870_tree=null;
		ASTNode KW_TIMESTAMP871_tree=null;
		ASTNode KW_TIMESTAMPLOCALTZ872_tree=null;
		ASTNode KW_TIMESTAMP873_tree=null;
		ASTNode KW_WITH874_tree=null;
		ASTNode KW_LOCAL875_tree=null;
		ASTNode KW_TIME876_tree=null;
		ASTNode KW_ZONE877_tree=null;
		ASTNode KW_STRING878_tree=null;
		ASTNode KW_BINARY879_tree=null;
		ASTNode KW_DECIMAL880_tree=null;
		ASTNode LPAREN881_tree=null;
		ASTNode COMMA882_tree=null;
		ASTNode RPAREN883_tree=null;
		ASTNode KW_VARCHAR884_tree=null;
		ASTNode LPAREN885_tree=null;
		ASTNode RPAREN886_tree=null;
		ASTNode KW_CHAR887_tree=null;
		ASTNode LPAREN888_tree=null;
		ASTNode RPAREN889_tree=null;
		RewriteRuleTokenStream stream_KW_DATETIME=new RewriteRuleTokenStream(adaptor,"token KW_DATETIME");
		RewriteRuleTokenStream stream_KW_TIMESTAMP=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMP");
		RewriteRuleTokenStream stream_KW_BOOLEAN=new RewriteRuleTokenStream(adaptor,"token KW_BOOLEAN");
		RewriteRuleTokenStream stream_KW_DOUBLE=new RewriteRuleTokenStream(adaptor,"token KW_DOUBLE");
		RewriteRuleTokenStream stream_KW_TIME=new RewriteRuleTokenStream(adaptor,"token KW_TIME");
		RewriteRuleTokenStream stream_KW_CHAR=new RewriteRuleTokenStream(adaptor,"token KW_CHAR");
		RewriteRuleTokenStream stream_KW_INT=new RewriteRuleTokenStream(adaptor,"token KW_INT");
		RewriteRuleTokenStream stream_KW_DECIMAL=new RewriteRuleTokenStream(adaptor,"token KW_DECIMAL");
		RewriteRuleTokenStream stream_KW_ZONE=new RewriteRuleTokenStream(adaptor,"token KW_ZONE");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_TINYINT=new RewriteRuleTokenStream(adaptor,"token KW_TINYINT");
		RewriteRuleTokenStream stream_KW_REAL=new RewriteRuleTokenStream(adaptor,"token KW_REAL");
		RewriteRuleTokenStream stream_KW_PRECISION=new RewriteRuleTokenStream(adaptor,"token KW_PRECISION");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_SMALLINT=new RewriteRuleTokenStream(adaptor,"token KW_SMALLINT");
		RewriteRuleTokenStream stream_KW_DATE=new RewriteRuleTokenStream(adaptor,"token KW_DATE");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_BIGINT=new RewriteRuleTokenStream(adaptor,"token KW_BIGINT");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_STRING=new RewriteRuleTokenStream(adaptor,"token KW_STRING");
		RewriteRuleTokenStream stream_KW_VARCHAR=new RewriteRuleTokenStream(adaptor,"token KW_VARCHAR");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleTokenStream stream_KW_FLOAT=new RewriteRuleTokenStream(adaptor,"token KW_FLOAT");
		RewriteRuleTokenStream stream_KW_TIMESTAMPLOCALTZ=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMPLOCALTZ");
		RewriteRuleTokenStream stream_KW_BINARY=new RewriteRuleTokenStream(adaptor,"token KW_BINARY");

		 pushMsg("primitive type specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2476:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_REAL -> TOK_FLOAT | KW_DOUBLE ( KW_PRECISION )? -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_TIMESTAMPLOCALTZ -> TOK_TIMESTAMPLOCALTZ | KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE -> TOK_TIMESTAMPLOCALTZ | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )? -> ^( TOK_DECIMAL ( $prec)? ( $scale)? ) | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) | KW_CHAR LPAREN length= Number RPAREN -> ^( TOK_CHAR $length) )
			int alt274=18;
			switch ( input.LA(1) ) {
			case KW_TINYINT:
				{
				alt274=1;
				}
				break;
			case KW_SMALLINT:
				{
				alt274=2;
				}
				break;
			case KW_INT:
				{
				alt274=3;
				}
				break;
			case KW_BIGINT:
				{
				alt274=4;
				}
				break;
			case KW_BOOLEAN:
				{
				alt274=5;
				}
				break;
			case KW_FLOAT:
				{
				alt274=6;
				}
				break;
			case KW_REAL:
				{
				alt274=7;
				}
				break;
			case KW_DOUBLE:
				{
				alt274=8;
				}
				break;
			case KW_DATE:
				{
				alt274=9;
				}
				break;
			case KW_DATETIME:
				{
				alt274=10;
				}
				break;
			case KW_TIMESTAMP:
				{
				int LA274_11 = input.LA(2);
				if ( (LA274_11==KW_WITH) ) {
					alt274=13;
				}
				else if ( (LA274_11==EOF||LA274_11==COMMA||LA274_11==GREATERTHAN||LA274_11==KW_AFTER||LA274_11==KW_CASCADE||(LA274_11 >= KW_CHECK && LA274_11 <= KW_CLUSTER)||LA274_11==KW_COMMENT||LA274_11==KW_CONSTRAINT||LA274_11==KW_DEFAULT||LA274_11==KW_DISTRIBUTE||LA274_11==KW_EXCEPT||LA274_11==KW_FIRST||LA274_11==KW_FORMAT||LA274_11==KW_FROM||LA274_11==KW_GROUP||LA274_11==KW_HAVING||LA274_11==KW_INSERT||LA274_11==KW_INTERSECT||LA274_11==KW_LATERAL||LA274_11==KW_LIMIT||LA274_11==KW_MAP||LA274_11==KW_MINUS||LA274_11==KW_NOT||LA274_11==KW_ORDER||LA274_11==KW_PRIMARY||LA274_11==KW_QUALIFY||LA274_11==KW_RECORDREADER||(LA274_11 >= KW_REDUCE && LA274_11 <= KW_REFERENCES)||LA274_11==KW_RESTRICT||LA274_11==KW_ROW||LA274_11==KW_SELECT||LA274_11==KW_SORT||LA274_11==KW_UNION||LA274_11==KW_UNIQUE||LA274_11==KW_WHERE||LA274_11==KW_WINDOW||LA274_11==RPAREN) ) {
					alt274=11;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 274, 11, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_TIMESTAMPLOCALTZ:
				{
				alt274=12;
				}
				break;
			case KW_STRING:
				{
				alt274=14;
				}
				break;
			case KW_BINARY:
				{
				alt274=15;
				}
				break;
			case KW_DECIMAL:
				{
				alt274=16;
				}
				break;
			case KW_VARCHAR:
				{
				alt274=17;
				}
				break;
			case KW_CHAR:
				{
				alt274=18;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 274, 0, input);
				throw nvae;
			}
			switch (alt274) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2476:7: KW_TINYINT
					{
					KW_TINYINT860=(Token)match(input,KW_TINYINT,FOLLOW_KW_TINYINT_in_primitiveType15184); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TINYINT.add(KW_TINYINT860);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2476:24: -> TOK_TINYINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TINYINT, "TOK_TINYINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2477:7: KW_SMALLINT
					{
					KW_SMALLINT861=(Token)match(input,KW_SMALLINT,FOLLOW_KW_SMALLINT_in_primitiveType15205); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_SMALLINT.add(KW_SMALLINT861);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2477:24: -> TOK_SMALLINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_SMALLINT, "TOK_SMALLINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2478:7: KW_INT
					{
					KW_INT862=(Token)match(input,KW_INT,FOLLOW_KW_INT_in_primitiveType15225); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INT.add(KW_INT862);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2478:24: -> TOK_INT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_INT, "TOK_INT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2479:7: KW_BIGINT
					{
					KW_BIGINT863=(Token)match(input,KW_BIGINT,FOLLOW_KW_BIGINT_in_primitiveType15250); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BIGINT.add(KW_BIGINT863);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2479:24: -> TOK_BIGINT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BIGINT, "TOK_BIGINT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2480:7: KW_BOOLEAN
					{
					KW_BOOLEAN864=(Token)match(input,KW_BOOLEAN,FOLLOW_KW_BOOLEAN_in_primitiveType15272); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BOOLEAN.add(KW_BOOLEAN864);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2480:24: -> TOK_BOOLEAN
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2481:7: KW_FLOAT
					{
					KW_FLOAT865=(Token)match(input,KW_FLOAT,FOLLOW_KW_FLOAT_in_primitiveType15293); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_FLOAT.add(KW_FLOAT865);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2481:24: -> TOK_FLOAT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_FLOAT, "TOK_FLOAT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2482:7: KW_REAL
					{
					KW_REAL866=(Token)match(input,KW_REAL,FOLLOW_KW_REAL_in_primitiveType15316); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_REAL.add(KW_REAL866);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2482:23: -> TOK_FLOAT
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_FLOAT, "TOK_FLOAT"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2483:7: KW_DOUBLE ( KW_PRECISION )?
					{
					KW_DOUBLE867=(Token)match(input,KW_DOUBLE,FOLLOW_KW_DOUBLE_in_primitiveType15340); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DOUBLE.add(KW_DOUBLE867);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2483:17: ( KW_PRECISION )?
					int alt271=2;
					int LA271_0 = input.LA(1);
					if ( (LA271_0==KW_PRECISION) ) {
						alt271=1;
					}
					switch (alt271) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2483:17: KW_PRECISION
							{
							KW_PRECISION868=(Token)match(input,KW_PRECISION,FOLLOW_KW_PRECISION_in_primitiveType15342); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_PRECISION.add(KW_PRECISION868);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2483:37: -> TOK_DOUBLE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DOUBLE, "TOK_DOUBLE"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 9 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2484:7: KW_DATE
					{
					KW_DATE869=(Token)match(input,KW_DATE,FOLLOW_KW_DATE_in_primitiveType15364); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATE.add(KW_DATE869);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2484:24: -> TOK_DATE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DATE, "TOK_DATE"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 10 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2485:7: KW_DATETIME
					{
					KW_DATETIME870=(Token)match(input,KW_DATETIME,FOLLOW_KW_DATETIME_in_primitiveType15388); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DATETIME.add(KW_DATETIME870);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2485:24: -> TOK_DATETIME
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DATETIME, "TOK_DATETIME"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 11 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2486:7: KW_TIMESTAMP
					{
					KW_TIMESTAMP871=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType15408); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP871);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2486:24: -> TOK_TIMESTAMP
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 12 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2487:7: KW_TIMESTAMPLOCALTZ
					{
					KW_TIMESTAMPLOCALTZ872=(Token)match(input,KW_TIMESTAMPLOCALTZ,FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType15427); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMPLOCALTZ.add(KW_TIMESTAMPLOCALTZ872);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2487:29: -> TOK_TIMESTAMPLOCALTZ
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMPLOCALTZ, "TOK_TIMESTAMPLOCALTZ"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 13 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2489:7: KW_TIMESTAMP KW_WITH KW_LOCAL KW_TIME KW_ZONE
					{
					KW_TIMESTAMP873=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType15449); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIMESTAMP.add(KW_TIMESTAMP873);

					KW_WITH874=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_primitiveType15451); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH874);

					KW_LOCAL875=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_primitiveType15453); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LOCAL.add(KW_LOCAL875);

					KW_TIME876=(Token)match(input,KW_TIME,FOLLOW_KW_TIME_in_primitiveType15455); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TIME.add(KW_TIME876);

					KW_ZONE877=(Token)match(input,KW_ZONE,FOLLOW_KW_ZONE_in_primitiveType15457); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ZONE.add(KW_ZONE877);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2489:53: -> TOK_TIMESTAMPLOCALTZ
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TIMESTAMPLOCALTZ, "TOK_TIMESTAMPLOCALTZ"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 14 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2494:7: KW_STRING
					{
					KW_STRING878=(Token)match(input,KW_STRING,FOLLOW_KW_STRING_in_primitiveType15489); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_STRING.add(KW_STRING878);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2494:24: -> TOK_STRING
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_STRING, "TOK_STRING"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 15 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2495:7: KW_BINARY
					{
					KW_BINARY879=(Token)match(input,KW_BINARY,FOLLOW_KW_BINARY_in_primitiveType15511); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_BINARY.add(KW_BINARY879);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2495:24: -> TOK_BINARY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_BINARY, "TOK_BINARY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 16 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:7: KW_DECIMAL ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
					{
					KW_DECIMAL880=(Token)match(input,KW_DECIMAL,FOLLOW_KW_DECIMAL_in_primitiveType15533); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DECIMAL.add(KW_DECIMAL880);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:18: ( LPAREN prec= Number ( COMMA scale= Number )? RPAREN )?
					int alt273=2;
					int LA273_0 = input.LA(1);
					if ( (LA273_0==LPAREN) ) {
						alt273=1;
					}
					switch (alt273) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:19: LPAREN prec= Number ( COMMA scale= Number )? RPAREN
							{
							LPAREN881=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType15536); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN881);

							prec=(Token)match(input,Number,FOLLOW_Number_in_primitiveType15540); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(prec);

							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:38: ( COMMA scale= Number )?
							int alt272=2;
							int LA272_0 = input.LA(1);
							if ( (LA272_0==COMMA) ) {
								alt272=1;
							}
							switch (alt272) {
								case 1 :
									// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:39: COMMA scale= Number
									{
									COMMA882=(Token)match(input,COMMA,FOLLOW_COMMA_in_primitiveType15543); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_COMMA.add(COMMA882);

									scale=(Token)match(input,Number,FOLLOW_Number_in_primitiveType15547); if (state.failed) return retval; 
									if ( state.backtracking==0 ) stream_Number.add(scale);

									}
									break;

							}

							RPAREN883=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType15551); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN883);

							}
							break;

					}

					// AST REWRITE
					// elements: prec, scale
					// token labels: prec, scale
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_prec=new RewriteRuleTokenStream(adaptor,"token prec",prec);
					RewriteRuleTokenStream stream_scale=new RewriteRuleTokenStream(adaptor,"token scale",scale);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2496:69: -> ^( TOK_DECIMAL ( $prec)? ( $scale)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:72: ^( TOK_DECIMAL ( $prec)? ( $scale)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DECIMAL, "TOK_DECIMAL"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:87: ( $prec)?
						if ( stream_prec.hasNext() ) {
							adaptor.addChild(root_1, stream_prec.nextNode());
						}
						stream_prec.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2496:94: ( $scale)?
						if ( stream_scale.hasNext() ) {
							adaptor.addChild(root_1, stream_scale.nextNode());
						}
						stream_scale.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 17 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2497:7: KW_VARCHAR LPAREN length= Number RPAREN
					{
					KW_VARCHAR884=(Token)match(input,KW_VARCHAR,FOLLOW_KW_VARCHAR_in_primitiveType15575); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_VARCHAR.add(KW_VARCHAR884);

					LPAREN885=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType15577); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN885);

					length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType15581); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(length);

					RPAREN886=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType15583); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN886);

					// AST REWRITE
					// elements: length
					// token labels: length
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2497:51: -> ^( TOK_VARCHAR $length)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2497:57: ^( TOK_VARCHAR $length)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_VARCHAR, "TOK_VARCHAR"), root_1);
						adaptor.addChild(root_1, stream_length.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 18 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2498:7: KW_CHAR LPAREN length= Number RPAREN
					{
					KW_CHAR887=(Token)match(input,KW_CHAR,FOLLOW_KW_CHAR_in_primitiveType15608); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_CHAR.add(KW_CHAR887);

					LPAREN888=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType15610); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN888);

					length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType15614); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(length);

					RPAREN889=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType15616); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN889);

					// AST REWRITE
					// elements: length
					// token labels: length
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2498:48: -> ^( TOK_CHAR $length)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2498:54: ^( TOK_CHAR $length)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CHAR, "TOK_CHAR"), root_1);
						adaptor.addChild(root_1, stream_length.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "primitiveType"


	public static class listType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "listType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2501:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
	public final HiveParser.listType_return listType() throws RecognitionException {
		HiveParser.listType_return retval = new HiveParser.listType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ARRAY890=null;
		Token LESSTHAN891=null;
		Token GREATERTHAN893=null;
		ParserRuleReturnScope type892 =null;

		ASTNode KW_ARRAY890_tree=null;
		ASTNode LESSTHAN891_tree=null;
		ASTNode GREATERTHAN893_tree=null;
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_KW_ARRAY=new RewriteRuleTokenStream(adaptor,"token KW_ARRAY");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");

		 pushMsg("list type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:7: KW_ARRAY LESSTHAN type GREATERTHAN
			{
			KW_ARRAY890=(Token)match(input,KW_ARRAY,FOLLOW_KW_ARRAY_in_listType15660); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ARRAY.add(KW_ARRAY890);

			LESSTHAN891=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_listType15662); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN891);

			pushFollow(FOLLOW_type_in_listType15664);
			type892=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_type.add(type892.getTree());
			GREATERTHAN893=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_listType15666); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN893);

			// AST REWRITE
			// elements: type
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2504:44: -> ^( TOK_LIST type )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2504:47: ^( TOK_LIST type )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIST, "TOK_LIST"), root_1);
				adaptor.addChild(root_1, stream_type.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "listType"


	public static class structType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "structType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2507:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
	public final HiveParser.structType_return structType() throws RecognitionException {
		HiveParser.structType_return retval = new HiveParser.structType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_STRUCT894=null;
		Token LESSTHAN895=null;
		Token GREATERTHAN897=null;
		ParserRuleReturnScope columnNameColonTypeList896 =null;

		ASTNode KW_STRUCT894_tree=null;
		ASTNode LESSTHAN895_tree=null;
		ASTNode GREATERTHAN897_tree=null;
		RewriteRuleTokenStream stream_KW_STRUCT=new RewriteRuleTokenStream(adaptor,"token KW_STRUCT");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_columnNameColonTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonTypeList");

		 pushMsg("struct type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2510:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2510:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
			{
			KW_STRUCT894=(Token)match(input,KW_STRUCT,FOLLOW_KW_STRUCT_in_structType15703); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STRUCT.add(KW_STRUCT894);

			LESSTHAN895=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_structType15705); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN895);

			pushFollow(FOLLOW_columnNameColonTypeList_in_structType15707);
			columnNameColonTypeList896=columnNameColonTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnNameColonTypeList.add(columnNameColonTypeList896.getTree());
			GREATERTHAN897=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_structType15709); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN897);

			// AST REWRITE
			// elements: columnNameColonTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2510:62: -> ^( TOK_STRUCT columnNameColonTypeList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2510:65: ^( TOK_STRUCT columnNameColonTypeList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_STRUCT, "TOK_STRUCT"), root_1);
				adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "structType"


	public static class mapType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "mapType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2513:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
	public final HiveParser.mapType_return mapType() throws RecognitionException {
		HiveParser.mapType_return retval = new HiveParser.mapType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_MAP898=null;
		Token LESSTHAN899=null;
		Token COMMA900=null;
		Token GREATERTHAN901=null;
		ParserRuleReturnScope left =null;
		ParserRuleReturnScope right =null;

		ASTNode KW_MAP898_tree=null;
		ASTNode LESSTHAN899_tree=null;
		ASTNode COMMA900_tree=null;
		ASTNode GREATERTHAN901_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
		RewriteRuleSubtreeStream stream_primitiveType=new RewriteRuleSubtreeStream(adaptor,"rule primitiveType");

		 pushMsg("map type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2516:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2516:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
			{
			KW_MAP898=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_mapType15744); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MAP.add(KW_MAP898);

			LESSTHAN899=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_mapType15746); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN899);

			pushFollow(FOLLOW_primitiveType_in_mapType15750);
			left=primitiveType();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_primitiveType.add(left.getTree());
			COMMA900=(Token)match(input,COMMA,FOLLOW_COMMA_in_mapType15752); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_COMMA.add(COMMA900);

			pushFollow(FOLLOW_type_in_mapType15756);
			right=type();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_type.add(right.getTree());
			GREATERTHAN901=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_mapType15758); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN901);

			// AST REWRITE
			// elements: right, left
			// token labels: 
			// rule labels: left, right, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_left=new RewriteRuleSubtreeStream(adaptor,"rule left",left!=null?left.getTree():null);
			RewriteRuleSubtreeStream stream_right=new RewriteRuleSubtreeStream(adaptor,"rule right",right!=null?right.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2517:5: -> ^( TOK_MAP $left $right)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2517:8: ^( TOK_MAP $left $right)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MAP, "TOK_MAP"), root_1);
				adaptor.addChild(root_1, stream_left.nextTree());
				adaptor.addChild(root_1, stream_right.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "mapType"


	public static class unionType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "unionType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2520:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
	public final HiveParser.unionType_return unionType() throws RecognitionException {
		HiveParser.unionType_return retval = new HiveParser.unionType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNIONTYPE902=null;
		Token LESSTHAN903=null;
		Token GREATERTHAN905=null;
		ParserRuleReturnScope colTypeList904 =null;

		ASTNode KW_UNIONTYPE902_tree=null;
		ASTNode LESSTHAN903_tree=null;
		ASTNode GREATERTHAN905_tree=null;
		RewriteRuleTokenStream stream_KW_UNIONTYPE=new RewriteRuleTokenStream(adaptor,"token KW_UNIONTYPE");
		RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
		RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
		RewriteRuleSubtreeStream stream_colTypeList=new RewriteRuleSubtreeStream(adaptor,"rule colTypeList");

		 pushMsg("uniontype type", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2523:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2523:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
			{
			KW_UNIONTYPE902=(Token)match(input,KW_UNIONTYPE,FOLLOW_KW_UNIONTYPE_in_unionType15801); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UNIONTYPE.add(KW_UNIONTYPE902);

			LESSTHAN903=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_unionType15803); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LESSTHAN.add(LESSTHAN903);

			pushFollow(FOLLOW_colTypeList_in_unionType15805);
			colTypeList904=colTypeList();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_colTypeList.add(colTypeList904.getTree());
			GREATERTHAN905=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_unionType15807); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_GREATERTHAN.add(GREATERTHAN905);

			// AST REWRITE
			// elements: colTypeList
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2523:53: -> ^( TOK_UNIONTYPE colTypeList )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2523:56: ^( TOK_UNIONTYPE colTypeList )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE"), root_1);
				adaptor.addChild(root_1, stream_colTypeList.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "unionType"


	public static class setOperator_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setOperator"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2526:1: setOperator : ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) );
	public final HiveParser.setOperator_return setOperator() throws RecognitionException {
		HiveParser.setOperator_return retval = new HiveParser.setOperator_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UNION906=null;
		Token KW_ALL907=null;
		Token KW_UNION908=null;
		Token KW_DISTINCT909=null;
		Token KW_INTERSECT910=null;
		Token KW_ALL911=null;
		Token KW_INTERSECT912=null;
		Token KW_DISTINCT913=null;
		Token KW_EXCEPT914=null;
		Token KW_ALL915=null;
		Token KW_EXCEPT916=null;
		Token KW_DISTINCT917=null;
		Token KW_MINUS918=null;
		Token KW_ALL919=null;
		Token KW_MINUS920=null;
		Token KW_DISTINCT921=null;

		ASTNode KW_UNION906_tree=null;
		ASTNode KW_ALL907_tree=null;
		ASTNode KW_UNION908_tree=null;
		ASTNode KW_DISTINCT909_tree=null;
		ASTNode KW_INTERSECT910_tree=null;
		ASTNode KW_ALL911_tree=null;
		ASTNode KW_INTERSECT912_tree=null;
		ASTNode KW_DISTINCT913_tree=null;
		ASTNode KW_EXCEPT914_tree=null;
		ASTNode KW_ALL915_tree=null;
		ASTNode KW_EXCEPT916_tree=null;
		ASTNode KW_DISTINCT917_tree=null;
		ASTNode KW_MINUS918_tree=null;
		ASTNode KW_ALL919_tree=null;
		ASTNode KW_MINUS920_tree=null;
		ASTNode KW_DISTINCT921_tree=null;
		RewriteRuleTokenStream stream_KW_INTERSECT=new RewriteRuleTokenStream(adaptor,"token KW_INTERSECT");
		RewriteRuleTokenStream stream_KW_EXCEPT=new RewriteRuleTokenStream(adaptor,"token KW_EXCEPT");
		RewriteRuleTokenStream stream_KW_UNION=new RewriteRuleTokenStream(adaptor,"token KW_UNION");
		RewriteRuleTokenStream stream_KW_DISTINCT=new RewriteRuleTokenStream(adaptor,"token KW_DISTINCT");
		RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
		RewriteRuleTokenStream stream_KW_MINUS=new RewriteRuleTokenStream(adaptor,"token KW_MINUS");

		 pushMsg("set operator", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2529:5: ( KW_UNION KW_ALL -> ^( TOK_UNIONALL ) | KW_UNION ( KW_DISTINCT )? -> ^( TOK_UNIONDISTINCT ) | KW_INTERSECT KW_ALL -> ^( TOK_INTERSECTALL ) | KW_INTERSECT ( KW_DISTINCT )? -> ^( TOK_INTERSECTDISTINCT ) | KW_EXCEPT KW_ALL -> ^( TOK_EXCEPTALL ) | KW_EXCEPT ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) | KW_MINUS KW_ALL -> ^( TOK_EXCEPTALL ) | KW_MINUS ( KW_DISTINCT )? -> ^( TOK_EXCEPTDISTINCT ) )
			int alt279=8;
			switch ( input.LA(1) ) {
			case KW_UNION:
				{
				int LA279_1 = input.LA(2);
				if ( (LA279_1==KW_ALL) ) {
					alt279=1;
				}
				else if ( (LA279_1==EOF||LA279_1==KW_DISTINCT||LA279_1==KW_FROM||LA279_1==KW_MAP||LA279_1==KW_REDUCE||LA279_1==KW_SELECT||LA279_1==KW_VALUES||LA279_1==LPAREN) ) {
					alt279=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 279, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_INTERSECT:
				{
				int LA279_2 = input.LA(2);
				if ( (LA279_2==KW_ALL) ) {
					alt279=3;
				}
				else if ( (LA279_2==EOF||LA279_2==KW_DISTINCT||LA279_2==KW_FROM||LA279_2==KW_MAP||LA279_2==KW_REDUCE||LA279_2==KW_SELECT||LA279_2==KW_VALUES||LA279_2==LPAREN) ) {
					alt279=4;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 279, 2, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_EXCEPT:
				{
				int LA279_3 = input.LA(2);
				if ( (LA279_3==KW_ALL) ) {
					alt279=5;
				}
				else if ( (LA279_3==EOF||LA279_3==KW_DISTINCT||LA279_3==KW_FROM||LA279_3==KW_MAP||LA279_3==KW_REDUCE||LA279_3==KW_SELECT||LA279_3==KW_VALUES||LA279_3==LPAREN) ) {
					alt279=6;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 279, 3, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			case KW_MINUS:
				{
				int LA279_4 = input.LA(2);
				if ( (LA279_4==KW_ALL) ) {
					alt279=7;
				}
				else if ( (LA279_4==EOF||LA279_4==KW_DISTINCT||LA279_4==KW_FROM||LA279_4==KW_MAP||LA279_4==KW_REDUCE||LA279_4==KW_SELECT||LA279_4==KW_VALUES||LA279_4==LPAREN) ) {
					alt279=8;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 279, 4, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 279, 0, input);
				throw nvae;
			}
			switch (alt279) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2529:7: KW_UNION KW_ALL
					{
					KW_UNION906=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator15842); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION906);

					KW_ALL907=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator15844); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL907);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2529:23: -> ^( TOK_UNIONALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2529:26: ^( TOK_UNIONALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2530:7: KW_UNION ( KW_DISTINCT )?
					{
					KW_UNION908=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_setOperator15858); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UNION.add(KW_UNION908);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2530:16: ( KW_DISTINCT )?
					int alt275=2;
					int LA275_0 = input.LA(1);
					if ( (LA275_0==KW_DISTINCT) ) {
						alt275=1;
					}
					switch (alt275) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2530:16: KW_DISTINCT
							{
							KW_DISTINCT909=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator15860); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT909);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2530:29: -> ^( TOK_UNIONDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2530:32: ^( TOK_UNIONDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONDISTINCT, "TOK_UNIONDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2531:7: KW_INTERSECT KW_ALL
					{
					KW_INTERSECT910=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator15875); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT910);

					KW_ALL911=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator15877); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL911);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2531:27: -> ^( TOK_INTERSECTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2531:30: ^( TOK_INTERSECTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INTERSECTALL, "TOK_INTERSECTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:7: KW_INTERSECT ( KW_DISTINCT )?
					{
					KW_INTERSECT912=(Token)match(input,KW_INTERSECT,FOLLOW_KW_INTERSECT_in_setOperator15891); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTERSECT.add(KW_INTERSECT912);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:20: ( KW_DISTINCT )?
					int alt276=2;
					int LA276_0 = input.LA(1);
					if ( (LA276_0==KW_DISTINCT) ) {
						alt276=1;
					}
					switch (alt276) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:20: KW_DISTINCT
							{
							KW_DISTINCT913=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator15893); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT913);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2532:33: -> ^( TOK_INTERSECTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2532:36: ^( TOK_INTERSECTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INTERSECTDISTINCT, "TOK_INTERSECTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 5 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2533:7: KW_EXCEPT KW_ALL
					{
					KW_EXCEPT914=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator15908); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT914);

					KW_ALL915=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator15910); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL915);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2533:24: -> ^( TOK_EXCEPTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2533:27: ^( TOK_EXCEPTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 6 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:7: KW_EXCEPT ( KW_DISTINCT )?
					{
					KW_EXCEPT916=(Token)match(input,KW_EXCEPT,FOLLOW_KW_EXCEPT_in_setOperator15924); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_EXCEPT.add(KW_EXCEPT916);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:17: ( KW_DISTINCT )?
					int alt277=2;
					int LA277_0 = input.LA(1);
					if ( (LA277_0==KW_DISTINCT) ) {
						alt277=1;
					}
					switch (alt277) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:17: KW_DISTINCT
							{
							KW_DISTINCT917=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator15926); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT917);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2534:30: -> ^( TOK_EXCEPTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2534:33: ^( TOK_EXCEPTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 7 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2535:7: KW_MINUS KW_ALL
					{
					KW_MINUS918=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator15941); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS918);

					KW_ALL919=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_setOperator15943); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ALL.add(KW_ALL919);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2535:23: -> ^( TOK_EXCEPTALL )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2535:26: ^( TOK_EXCEPTALL )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTALL, "TOK_EXCEPTALL"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 8 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2536:7: KW_MINUS ( KW_DISTINCT )?
					{
					KW_MINUS920=(Token)match(input,KW_MINUS,FOLLOW_KW_MINUS_in_setOperator15957); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_MINUS.add(KW_MINUS920);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2536:16: ( KW_DISTINCT )?
					int alt278=2;
					int LA278_0 = input.LA(1);
					if ( (LA278_0==KW_DISTINCT) ) {
						alt278=1;
					}
					switch (alt278) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2536:16: KW_DISTINCT
							{
							KW_DISTINCT921=(Token)match(input,KW_DISTINCT,FOLLOW_KW_DISTINCT_in_setOperator15959); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_DISTINCT.add(KW_DISTINCT921);

							}
							break;

					}

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2536:29: -> ^( TOK_EXCEPTDISTINCT )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2536:32: ^( TOK_EXCEPTDISTINCT )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_EXCEPTDISTINCT, "TOK_EXCEPTDISTINCT"), root_1);
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setOperator"


	public static class queryStatementExpression_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "queryStatementExpression"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2539:1: queryStatementExpression : (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody ;
	public final HiveParser.queryStatementExpression_return queryStatementExpression() throws RecognitionException {
		HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope w =null;
		ParserRuleReturnScope queryStatementExpressionBody922 =null;

		RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
		RewriteRuleSubtreeStream stream_queryStatementExpressionBody=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpressionBody");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2540:5: ( (w= withClause )? queryStatementExpressionBody -> queryStatementExpressionBody )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2545:5: (w= withClause )? queryStatementExpressionBody
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2545:5: (w= withClause )?
			int alt280=2;
			int LA280_0 = input.LA(1);
			if ( (LA280_0==KW_WITH) ) {
				alt280=1;
			}
			switch (alt280) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2545:6: w= withClause
					{
					pushFollow(FOLLOW_withClause_in_queryStatementExpression15996);
					w=withClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withClause.add(w.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_queryStatementExpressionBody_in_queryStatementExpression16004);
			queryStatementExpressionBody922=queryStatementExpressionBody();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_queryStatementExpressionBody.add(queryStatementExpressionBody922.getTree());
			if ( state.backtracking==0 ) {
			      if ((w!=null?((ASTNode)w.getTree()):null) != null) {
			      (queryStatementExpressionBody922!=null?((ASTNode)queryStatementExpressionBody922.getTree()):null).insertChild(0, (w!=null?((ASTNode)w.getTree()):null));
			      }
			    }
			// AST REWRITE
			// elements: queryStatementExpressionBody
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2551:5: -> queryStatementExpressionBody
			{
				adaptor.addChild(root_0, stream_queryStatementExpressionBody.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "queryStatementExpression"


	public static class queryStatementExpressionBody_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "queryStatementExpressionBody"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2554:1: queryStatementExpressionBody : ( fromStatement | regularBody );
	public final HiveParser.queryStatementExpressionBody_return queryStatementExpressionBody() throws RecognitionException {
		HiveParser.queryStatementExpressionBody_return retval = new HiveParser.queryStatementExpressionBody_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope fromStatement923 =null;
		ParserRuleReturnScope regularBody924 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2555:5: ( fromStatement | regularBody )
			int alt281=2;
			int LA281_0 = input.LA(1);
			if ( (LA281_0==KW_FROM) ) {
				alt281=1;
			}
			else if ( (LA281_0==KW_INSERT||LA281_0==KW_MAP||LA281_0==KW_REDUCE||LA281_0==KW_SELECT||LA281_0==KW_VALUES||LA281_0==LPAREN) ) {
				alt281=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 281, 0, input);
				throw nvae;
			}

			switch (alt281) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2556:5: fromStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_fromStatement_in_queryStatementExpressionBody16036);
					fromStatement923=fromStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, fromStatement923.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2557:7: regularBody
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_regularBody_in_queryStatementExpressionBody16044);
					regularBody924=regularBody();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, regularBody924.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "queryStatementExpressionBody"


	public static class withClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "withClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2560:1: withClause : KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) ;
	public final HiveParser.withClause_return withClause() throws RecognitionException {
		HiveParser.withClause_return retval = new HiveParser.withClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WITH925=null;
		Token COMMA927=null;
		ParserRuleReturnScope cteStatement926 =null;
		ParserRuleReturnScope cteStatement928 =null;

		ASTNode KW_WITH925_tree=null;
		ASTNode COMMA927_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
		RewriteRuleSubtreeStream stream_cteStatement=new RewriteRuleSubtreeStream(adaptor,"rule cteStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2561:3: ( KW_WITH cteStatement ( COMMA cteStatement )* -> ^( TOK_CTE ( cteStatement )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:3: KW_WITH cteStatement ( COMMA cteStatement )*
			{
			KW_WITH925=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_withClause16061); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WITH.add(KW_WITH925);

			pushFollow(FOLLOW_cteStatement_in_withClause16063);
			cteStatement926=cteStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement926.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:24: ( COMMA cteStatement )*
			loop282:
			while (true) {
				int alt282=2;
				int LA282_0 = input.LA(1);
				if ( (LA282_0==COMMA) ) {
					alt282=1;
				}

				switch (alt282) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:25: COMMA cteStatement
					{
					COMMA927=(Token)match(input,COMMA,FOLLOW_COMMA_in_withClause16066); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA927);

					pushFollow(FOLLOW_cteStatement_in_withClause16068);
					cteStatement928=cteStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_cteStatement.add(cteStatement928.getTree());
					}
					break;

				default :
					break loop282;
				}
			}

			// AST REWRITE
			// elements: cteStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2562:46: -> ^( TOK_CTE ( cteStatement )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2562:49: ^( TOK_CTE ( cteStatement )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_CTE, "TOK_CTE"), root_1);
				if ( !(stream_cteStatement.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_cteStatement.hasNext() ) {
					adaptor.addChild(root_1, stream_cteStatement.nextTree());
				}
				stream_cteStatement.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "withClause"


	public static class cteStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "cteStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2565:1: cteStatement : identifier ( LPAREN colAliases= columnNameList RPAREN )? KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ( $colAliases)? ) ;
	public final HiveParser.cteStatement_return cteStatement() throws RecognitionException {
		HiveParser.cteStatement_return retval = new HiveParser.cteStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN930=null;
		Token RPAREN931=null;
		Token KW_AS932=null;
		Token LPAREN933=null;
		Token RPAREN935=null;
		ParserRuleReturnScope colAliases =null;
		ParserRuleReturnScope identifier929 =null;
		ParserRuleReturnScope queryStatementExpression934 =null;

		ASTNode LPAREN930_tree=null;
		ASTNode RPAREN931_tree=null;
		ASTNode KW_AS932_tree=null;
		ASTNode LPAREN933_tree=null;
		ASTNode RPAREN935_tree=null;
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_queryStatementExpression=new RewriteRuleSubtreeStream(adaptor,"rule queryStatementExpression");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2566:4: ( identifier ( LPAREN colAliases= columnNameList RPAREN )? KW_AS LPAREN queryStatementExpression RPAREN -> ^( TOK_SUBQUERY queryStatementExpression identifier ( $colAliases)? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:4: identifier ( LPAREN colAliases= columnNameList RPAREN )? KW_AS LPAREN queryStatementExpression RPAREN
			{
			pushFollow(FOLLOW_identifier_in_cteStatement16094);
			identifier929=identifier();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_identifier.add(identifier929.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:15: ( LPAREN colAliases= columnNameList RPAREN )?
			int alt283=2;
			int LA283_0 = input.LA(1);
			if ( (LA283_0==LPAREN) ) {
				alt283=1;
			}
			switch (alt283) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2567:16: LPAREN colAliases= columnNameList RPAREN
					{
					LPAREN930=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_cteStatement16097); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN930);

					pushFollow(FOLLOW_columnNameList_in_cteStatement16101);
					colAliases=columnNameList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnNameList.add(colAliases.getTree());
					RPAREN931=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_cteStatement16103); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN931);

					}
					break;

			}

			KW_AS932=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_cteStatement16107); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS932);

			LPAREN933=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_cteStatement16109); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN933);

			pushFollow(FOLLOW_queryStatementExpression_in_cteStatement16111);
			queryStatementExpression934=queryStatementExpression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_queryStatementExpression.add(queryStatementExpression934.getTree());
			RPAREN935=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_cteStatement16113); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN935);

			// AST REWRITE
			// elements: identifier, colAliases, queryStatementExpression
			// token labels: 
			// rule labels: colAliases, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_colAliases=new RewriteRuleSubtreeStream(adaptor,"rule colAliases",colAliases!=null?colAliases.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2568:4: -> ^( TOK_SUBQUERY queryStatementExpression identifier ( $colAliases)? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:7: ^( TOK_SUBQUERY queryStatementExpression identifier ( $colAliases)? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_1);
				adaptor.addChild(root_1, stream_queryStatementExpression.nextTree());
				adaptor.addChild(root_1, stream_identifier.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2568:59: ( $colAliases)?
				if ( stream_colAliases.hasNext() ) {
					adaptor.addChild(root_1, stream_colAliases.nextTree());
				}
				stream_colAliases.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "cteStatement"


	public static class fromStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "fromStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2571:1: fromStatement : ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
	public final HiveParser.fromStatement_return fromStatement() throws RecognitionException {
		HiveParser.fromStatement_return retval = new HiveParser.fromStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope u =null;
		ParserRuleReturnScope r =null;
		ParserRuleReturnScope singleFromStatement936 =null;

		RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
		RewriteRuleSubtreeStream stream_singleFromStatement=new RewriteRuleSubtreeStream(adaptor,"rule singleFromStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:3: ( ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )* -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:3: ( singleFromStatement -> singleFromStatement ) (u= setOperator r= singleFromStatement -> ^( $u $r) )*
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:3: ( singleFromStatement -> singleFromStatement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2572:4: singleFromStatement
			{
			pushFollow(FOLLOW_singleFromStatement_in_fromStatement16140);
			singleFromStatement936=singleFromStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_singleFromStatement.add(singleFromStatement936.getTree());
			// AST REWRITE
			// elements: singleFromStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2572:25: -> singleFromStatement
			{
				adaptor.addChild(root_0, stream_singleFromStatement.nextTree());
			}


			retval.tree = root_0;
			}

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:2: (u= setOperator r= singleFromStatement -> ^( $u $r) )*
			loop284:
			while (true) {
				int alt284=2;
				int LA284_0 = input.LA(1);
				if ( (LA284_0==KW_EXCEPT||LA284_0==KW_INTERSECT||LA284_0==KW_MINUS||LA284_0==KW_UNION) ) {
					alt284=1;
				}

				switch (alt284) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2573:3: u= setOperator r= singleFromStatement
					{
					pushFollow(FOLLOW_setOperator_in_fromStatement16152);
					u=setOperator();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());
					pushFollow(FOLLOW_singleFromStatement_in_fromStatement16156);
					r=singleFromStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_singleFromStatement.add(r.getTree());
					// AST REWRITE
					// elements: u, r
					// token labels: 
					// rule labels: r, u, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_r=new RewriteRuleSubtreeStream(adaptor,"rule r",r!=null?r.getTree():null);
					RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2574:4: -> ^( $u $r)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2574:7: ^( $u $r)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, retval.tree);
						adaptor.addChild(root_1, stream_r.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

				default :
					break loop284;
				}
			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2576:3: -> {u != null}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
			if (u != null) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2576:19: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2577:9: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2578:11: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, retval.tree);
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2583:13: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2584:12: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2584:30: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2585:12: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2585:25: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2588:5: ->
			{
				adaptor.addChild(root_0, retval.tree);
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "fromStatement"


	public static class singleFromStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "singleFromStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2592:1: singleFromStatement : fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) ;
	public final HiveParser.singleFromStatement_return singleFromStatement() throws RecognitionException {
		HiveParser.singleFromStatement_return retval = new HiveParser.singleFromStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		List<Object> list_b=null;
		ParserRuleReturnScope fromClause937 =null;
		RuleReturnScope b = null;
		RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
		RewriteRuleSubtreeStream stream_body=new RewriteRuleSubtreeStream(adaptor,"rule body");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2593:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2594:5: fromClause (b+= body )+
			{
			pushFollow(FOLLOW_fromClause_in_singleFromStatement16366);
			fromClause937=fromClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_fromClause.add(fromClause937.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:5: (b+= body )+
			int cnt285=0;
			loop285:
			while (true) {
				int alt285=2;
				int LA285_0 = input.LA(1);
				if ( (LA285_0==KW_INSERT||LA285_0==KW_MAP||LA285_0==KW_REDUCE||LA285_0==KW_SELECT) ) {
					alt285=1;
				}

				switch (alt285) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:7: b+= body
					{
					pushFollow(FOLLOW_body_in_singleFromStatement16376);
					b=body();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_body.add(b.getTree());
					if (list_b==null) list_b=new ArrayList<Object>();
					list_b.add(b.getTree());
					}
					break;

				default :
					if ( cnt285 >= 1 ) break loop285;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(285, input);
					throw eee;
				}
				cnt285++;
			}

			// AST REWRITE
			// elements: fromClause, body
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2595:18: -> ^( TOK_QUERY fromClause ( body )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2595:21: ^( TOK_QUERY fromClause ( body )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				adaptor.addChild(root_1, stream_fromClause.nextTree());
				if ( !(stream_body.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_body.hasNext() ) {
					adaptor.addChild(root_1, stream_body.nextTree());
				}
				stream_body.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "singleFromStatement"


	public static class regularBody_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "regularBody"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2604:1: regularBody : (i= insertClause (s= selectStatement ->) | selectStatement );
	public final HiveParser.regularBody_return regularBody() throws RecognitionException {
		HiveParser.regularBody_return retval = new HiveParser.regularBody_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope i =null;
		ParserRuleReturnScope s =null;
		ParserRuleReturnScope selectStatement938 =null;

		RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
		RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2605:4: (i= insertClause (s= selectStatement ->) | selectStatement )
			int alt286=2;
			int LA286_0 = input.LA(1);
			if ( (LA286_0==KW_INSERT) ) {
				alt286=1;
			}
			else if ( (LA286_0==KW_MAP||LA286_0==KW_REDUCE||LA286_0==KW_SELECT||LA286_0==KW_VALUES||LA286_0==LPAREN) ) {
				alt286=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 286, 0, input);
				throw nvae;
			}

			switch (alt286) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2606:4: i= insertClause (s= selectStatement ->)
					{
					pushFollow(FOLLOW_insertClause_in_regularBody16413);
					i=insertClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_insertClause.add(i.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2607:4: (s= selectStatement ->)
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2608:4: s= selectStatement
					{
					pushFollow(FOLLOW_selectStatement_in_regularBody16425);
					s=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectStatement.add(s.getTree());
					if ( state.backtracking==0 ) {(s!=null?((ASTNode)s.getTree()):null).getFirstChildWithType(TOK_INSERT).replaceChildren(0, 0, (i!=null?((ASTNode)i.getTree()):null));}
					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2609:4: ->
					{
						adaptor.addChild(root_0, (s!=null?((ASTNode)s.getTree()):null));
					}


					retval.tree = root_0;
					}

					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2612:4: selectStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_selectStatement_in_regularBody16449);
					selectStatement938=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement938.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "regularBody"


	public static class atomSelectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "atomSelectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2615:1: atomSelectStatement : (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? (q= qualifyClause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ( $q)? ) ) | LPAREN ! selectStatement RPAREN !| valuesSource );
	public final HiveParser.atomSelectStatement_return atomSelectStatement() throws RecognitionException {
		HiveParser.atomSelectStatement_return retval = new HiveParser.atomSelectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token LPAREN939=null;
		Token RPAREN941=null;
		ParserRuleReturnScope s =null;
		ParserRuleReturnScope f =null;
		ParserRuleReturnScope w =null;
		ParserRuleReturnScope g =null;
		ParserRuleReturnScope h =null;
		ParserRuleReturnScope win =null;
		ParserRuleReturnScope q =null;
		ParserRuleReturnScope selectStatement940 =null;
		ParserRuleReturnScope valuesSource942 =null;

		ASTNode LPAREN939_tree=null;
		ASTNode RPAREN941_tree=null;
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
		RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
		RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
		RewriteRuleSubtreeStream stream_qualifyClause=new RewriteRuleSubtreeStream(adaptor,"rule qualifyClause");
		RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
		RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2616:4: (s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? (q= qualifyClause )? -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ( $q)? ) ) | LPAREN ! selectStatement RPAREN !| valuesSource )
			int alt293=3;
			switch ( input.LA(1) ) {
			case KW_MAP:
			case KW_REDUCE:
			case KW_SELECT:
				{
				alt293=1;
				}
				break;
			case LPAREN:
				{
				alt293=2;
				}
				break;
			case KW_VALUES:
				{
				alt293=3;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 293, 0, input);
				throw nvae;
			}
			switch (alt293) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2617:4: s= selectClause (f= fromClause )? (w= whereClause )? (g= groupByClause )? (h= havingClause )? (win= window_clause )? (q= qualifyClause )?
					{
					pushFollow(FOLLOW_selectClause_in_atomSelectStatement16469);
					s=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(s.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2618:5: (f= fromClause )?
					int alt287=2;
					int LA287_0 = input.LA(1);
					if ( (LA287_0==KW_FROM) ) {
						alt287=1;
					}
					switch (alt287) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2618:5: f= fromClause
							{
							pushFollow(FOLLOW_fromClause_in_atomSelectStatement16476);
							f=fromClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_fromClause.add(f.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2619:5: (w= whereClause )?
					int alt288=2;
					int LA288_0 = input.LA(1);
					if ( (LA288_0==KW_WHERE) ) {
						alt288=1;
					}
					switch (alt288) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2619:5: w= whereClause
							{
							pushFollow(FOLLOW_whereClause_in_atomSelectStatement16484);
							w=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(w.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2620:5: (g= groupByClause )?
					int alt289=2;
					int LA289_0 = input.LA(1);
					if ( (LA289_0==KW_GROUP) ) {
						alt289=1;
					}
					switch (alt289) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2620:5: g= groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_atomSelectStatement16492);
							g=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(g.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2621:5: (h= havingClause )?
					int alt290=2;
					int LA290_0 = input.LA(1);
					if ( (LA290_0==KW_HAVING) ) {
						alt290=1;
					}
					switch (alt290) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2621:5: h= havingClause
							{
							pushFollow(FOLLOW_havingClause_in_atomSelectStatement16500);
							h=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(h.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:7: (win= window_clause )?
					int alt291=2;
					int LA291_0 = input.LA(1);
					if ( (LA291_0==KW_WINDOW) ) {
						alt291=1;
					}
					switch (alt291) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2622:7: win= window_clause
							{
							pushFollow(FOLLOW_window_clause_in_atomSelectStatement16508);
							win=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(win.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:5: (q= qualifyClause )?
					int alt292=2;
					int LA292_0 = input.LA(1);
					if ( (LA292_0==KW_QUALIFY) ) {
						alt292=1;
					}
					switch (alt292) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2623:5: q= qualifyClause
							{
							pushFollow(FOLLOW_qualifyClause_in_atomSelectStatement16516);
							q=qualifyClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_qualifyClause.add(q.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: h, win, g, s, q, w, f
					// token labels: 
					// rule labels: q, s, f, g, w, h, win, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_q=new RewriteRuleSubtreeStream(adaptor,"rule q",q!=null?q.getTree():null);
					RewriteRuleSubtreeStream stream_s=new RewriteRuleSubtreeStream(adaptor,"rule s",s!=null?s.getTree():null);
					RewriteRuleSubtreeStream stream_f=new RewriteRuleSubtreeStream(adaptor,"rule f",f!=null?f.getTree():null);
					RewriteRuleSubtreeStream stream_g=new RewriteRuleSubtreeStream(adaptor,"rule g",g!=null?g.getTree():null);
					RewriteRuleSubtreeStream stream_w=new RewriteRuleSubtreeStream(adaptor,"rule w",w!=null?w.getTree():null);
					RewriteRuleSubtreeStream stream_h=new RewriteRuleSubtreeStream(adaptor,"rule h",h!=null?h.getTree():null);
					RewriteRuleSubtreeStream stream_win=new RewriteRuleSubtreeStream(adaptor,"rule win",win!=null?win.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2624:4: -> ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ( $q)? ) )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2624:7: ^( TOK_QUERY ( $f)? ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ( $q)? ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2624:20: ( $f)?
						if ( stream_f.hasNext() ) {
							adaptor.addChild(root_1, stream_f.nextTree());
						}
						stream_f.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2624:23: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) $s ( $w)? ( $g)? ( $h)? ( $win)? ( $q)? )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2624:36: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2624:54: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_2, stream_s.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:26: ( $w)?
						if ( stream_w.hasNext() ) {
							adaptor.addChild(root_2, stream_w.nextTree());
						}
						stream_w.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:30: ( $g)?
						if ( stream_g.hasNext() ) {
							adaptor.addChild(root_2, stream_g.nextTree());
						}
						stream_g.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:34: ( $h)?
						if ( stream_h.hasNext() ) {
							adaptor.addChild(root_2, stream_h.nextTree());
						}
						stream_h.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:38: ( $win)?
						if ( stream_win.hasNext() ) {
							adaptor.addChild(root_2, stream_win.nextTree());
						}
						stream_win.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2625:44: ( $q)?
						if ( stream_q.hasNext() ) {
							adaptor.addChild(root_2, stream_q.nextTree());
						}
						stream_q.reset();

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2627:4: LPAREN ! selectStatement RPAREN !
					{
					root_0 = (ASTNode)adaptor.nil();


					LPAREN939=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_atomSelectStatement16598); if (state.failed) return retval;
					pushFollow(FOLLOW_selectStatement_in_atomSelectStatement16601);
					selectStatement940=selectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, selectStatement940.getTree());

					RPAREN941=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_atomSelectStatement16603); if (state.failed) return retval;
					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2629:4: valuesSource
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_valuesSource_in_atomSelectStatement16614);
					valuesSource942=valuesSource();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, valuesSource942.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "atomSelectStatement"


	public static class selectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "selectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2632:1: selectStatement : a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) ;
	public final HiveParser.selectStatement_return selectStatement() throws RecognitionException {
		HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope a =null;
		ParserRuleReturnScope set =null;
		ParserRuleReturnScope o =null;
		ParserRuleReturnScope c =null;
		ParserRuleReturnScope d =null;
		ParserRuleReturnScope sort =null;
		ParserRuleReturnScope l =null;

		RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
		RewriteRuleSubtreeStream stream_setOpSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule setOpSelectStatement");
		RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
		RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2633:4: (a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )? -> {set == null}? -> {o==null && c==null && d==null && sort==null && l==null}? -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2634:4: a= atomSelectStatement (set= setOpSelectStatement[$atomSelectStatement.tree] )? (o= orderByClause )? (c= clusterByClause )? (d= distributeByClause )? (sort= sortByClause )? (l= limitClause )?
			{
			pushFollow(FOLLOW_atomSelectStatement_in_selectStatement16634);
			a=atomSelectStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_atomSelectStatement.add(a.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2635:7: (set= setOpSelectStatement[$atomSelectStatement.tree] )?
			int alt294=2;
			int LA294_0 = input.LA(1);
			if ( (LA294_0==KW_EXCEPT||LA294_0==KW_INTERSECT||LA294_0==KW_MINUS||LA294_0==KW_UNION) ) {
				alt294=1;
			}
			switch (alt294) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2635:7: set= setOpSelectStatement[$atomSelectStatement.tree]
					{
					pushFollow(FOLLOW_setOpSelectStatement_in_selectStatement16641);
					set=setOpSelectStatement((a!=null?((ASTNode)a.getTree()):null));
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOpSelectStatement.add(set.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2636:5: (o= orderByClause )?
			int alt295=2;
			int LA295_0 = input.LA(1);
			if ( (LA295_0==KW_ORDER) ) {
				alt295=1;
			}
			switch (alt295) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2636:5: o= orderByClause
					{
					pushFollow(FOLLOW_orderByClause_in_selectStatement16650);
					o=orderByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_orderByClause.add(o.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2637:5: (c= clusterByClause )?
			int alt296=2;
			int LA296_0 = input.LA(1);
			if ( (LA296_0==KW_CLUSTER) ) {
				alt296=1;
			}
			switch (alt296) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2637:5: c= clusterByClause
					{
					pushFollow(FOLLOW_clusterByClause_in_selectStatement16658);
					c=clusterByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_clusterByClause.add(c.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2638:5: (d= distributeByClause )?
			int alt297=2;
			int LA297_0 = input.LA(1);
			if ( (LA297_0==KW_DISTRIBUTE) ) {
				alt297=1;
			}
			switch (alt297) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2638:5: d= distributeByClause
					{
					pushFollow(FOLLOW_distributeByClause_in_selectStatement16666);
					d=distributeByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_distributeByClause.add(d.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2639:8: (sort= sortByClause )?
			int alt298=2;
			int LA298_0 = input.LA(1);
			if ( (LA298_0==KW_SORT) ) {
				alt298=1;
			}
			switch (alt298) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2639:8: sort= sortByClause
					{
					pushFollow(FOLLOW_sortByClause_in_selectStatement16674);
					sort=sortByClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_sortByClause.add(sort.getTree());
					}
					break;

			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2640:5: (l= limitClause )?
			int alt299=2;
			int LA299_0 = input.LA(1);
			if ( (LA299_0==KW_LIMIT) ) {
				alt299=1;
			}
			switch (alt299) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2640:5: l= limitClause
					{
					pushFollow(FOLLOW_limitClause_in_selectStatement16682);
					l=limitClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_limitClause.add(l.getTree());
					}
					break;

			}

			if ( state.backtracking==0 ) {
			   if(set == null){
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((o!=null?((ASTNode)o.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((c!=null?((ASTNode)c.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((d!=null?((ASTNode)d.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((sort!=null?((ASTNode)sort.getTree()):null));
			   (a!=null?((ASTNode)a.getTree()):null).getFirstChildWithType(TOK_INSERT).addChild((l!=null?((ASTNode)l.getTree()):null));
			   }
			   }
			// AST REWRITE
			// elements: l, o, d, sort, c
			// token labels: 
			// rule labels: c, d, sort, l, retval, o
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_c=new RewriteRuleSubtreeStream(adaptor,"rule c",c!=null?c.getTree():null);
			RewriteRuleSubtreeStream stream_d=new RewriteRuleSubtreeStream(adaptor,"rule d",d!=null?d.getTree():null);
			RewriteRuleSubtreeStream stream_sort=new RewriteRuleSubtreeStream(adaptor,"rule sort",sort!=null?sort.getTree():null);
			RewriteRuleSubtreeStream stream_l=new RewriteRuleSubtreeStream(adaptor,"rule l",l!=null?l.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);
			RewriteRuleSubtreeStream stream_o=new RewriteRuleSubtreeStream(adaptor,"rule o",o!=null?o.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2650:4: -> {set == null}?
			if (set == null) {
				adaptor.addChild(root_0, (a!=null?((ASTNode)a.getTree()):null));
			}

			else // 2652:4: -> {o==null && c==null && d==null && sort==null && l==null}?
			if (o==null && c==null && d==null && sort==null && l==null) {
				adaptor.addChild(root_0, (set!=null?((ASTNode)set.getTree()):null));
			}

			else // 2654:4: -> ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2654:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2655:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2656:13: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, (set!=null?((ASTNode)set.getTree()):null));
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2661:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ( $o)? ( $c)? ( $d)? ( $sort)? ( $l)? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2662:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2662:32: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2663:27: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2664:15: ( $o)?
				if ( stream_o.hasNext() ) {
					adaptor.addChild(root_2, stream_o.nextTree());
				}
				stream_o.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2664:19: ( $c)?
				if ( stream_c.hasNext() ) {
					adaptor.addChild(root_2, stream_c.nextTree());
				}
				stream_c.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2664:23: ( $d)?
				if ( stream_d.hasNext() ) {
					adaptor.addChild(root_2, stream_d.nextTree());
				}
				stream_d.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2664:27: ( $sort)?
				if ( stream_sort.hasNext() ) {
					adaptor.addChild(root_2, stream_sort.nextTree());
				}
				stream_sort.reset();

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2664:34: ( $l)?
				if ( stream_l.hasNext() ) {
					adaptor.addChild(root_2, stream_l.nextTree());
				}
				stream_l.reset();

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "selectStatement"


	public static class setOpSelectStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setOpSelectStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2669:1: setOpSelectStatement[CommonTree t] : (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->;
	public final HiveParser.setOpSelectStatement_return setOpSelectStatement(CommonTree t) throws RecognitionException {
		HiveParser.setOpSelectStatement_return retval = new HiveParser.setOpSelectStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope u =null;
		ParserRuleReturnScope b =null;

		RewriteRuleSubtreeStream stream_setOperator=new RewriteRuleSubtreeStream(adaptor,"rule setOperator");
		RewriteRuleSubtreeStream stream_atomSelectStatement=new RewriteRuleSubtreeStream(adaptor,"rule atomSelectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2670:4: ( (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+ -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) ->)
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2671:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2671:4: (u= setOperator b= atomSelectStatement -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b) -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) ) -> ^( $u $b) )+
			int cnt300=0;
			loop300:
			while (true) {
				int alt300=2;
				int LA300_0 = input.LA(1);
				if ( (LA300_0==KW_EXCEPT||LA300_0==KW_INTERSECT||LA300_0==KW_MINUS||LA300_0==KW_UNION) ) {
					alt300=1;
				}

				switch (alt300) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2671:5: u= setOperator b= atomSelectStatement
					{
					pushFollow(FOLLOW_setOperator_in_setOpSelectStatement16947);
					u=setOperator();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setOperator.add(u.getTree());
					pushFollow(FOLLOW_atomSelectStatement_in_setOpSelectStatement16951);
					b=atomSelectStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_atomSelectStatement.add(b.getTree());
					// AST REWRITE
					// elements: b, b, u, u, b, b
					// token labels: 
					// rule labels: b, u, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_b=new RewriteRuleSubtreeStream(adaptor,"rule b",b!=null?b.getTree():null);
					RewriteRuleSubtreeStream stream_u=new RewriteRuleSubtreeStream(adaptor,"rule u",u!=null?u.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2672:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
					if (retval.tree != null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2673:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2674:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2675:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2676:15: ^( TOK_UNIONALL $b)
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_4);
						adaptor.addChild(root_4, retval.tree);
						adaptor.addChild(root_4, stream_b.nextTree());
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2680:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2681:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2681:32: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:14: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2682:29: ^( TOK_SELEXPR TOK_SETCOLREF )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2685:4: -> {$setOpSelectStatement.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT}? ^( $u $b)
					if (retval.tree != null && ((CommonTree)u.getTree()).getType()!=HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2686:7: ^( $u $b)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, retval.tree);
						adaptor.addChild(root_1, stream_b.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2687:4: -> {$setOpSelectStatement.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
					if (retval.tree == null && ((CommonTree)u.getTree()).getType()==HiveParser.TOK_UNIONDISTINCT) {
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2688:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2689:11: ^( TOK_FROM ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2690:13: ^( TOK_SUBQUERY ^( TOK_UNIONALL $b) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2691:15: ^( TOK_UNIONALL $b)
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UNIONALL, "TOK_UNIONALL"), root_4);
						adaptor.addChild(root_4, t);
						adaptor.addChild(root_4, stream_b.nextTree());
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2695:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2696:13: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2696:31: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:13: ^( TOK_SELECTDI ^( TOK_SELEXPR TOK_SETCOLREF ) )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECTDI, "TOK_SELECTDI"), root_3);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2697:28: ^( TOK_SELEXPR TOK_SETCOLREF )
						{
						ASTNode root_4 = (ASTNode)adaptor.nil();
						root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
						adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
						adaptor.addChild(root_3, root_4);
						}

						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_0, root_1);
						}

					}

					else // 2700:4: -> ^( $u $b)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2700:7: ^( $u $b)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot(stream_u.nextNode(), root_1);
						adaptor.addChild(root_1, t);
						adaptor.addChild(root_1, stream_b.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

				default :
					if ( cnt300 >= 1 ) break loop300;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(300, input);
					throw eee;
				}
				cnt300++;
			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2702:4: -> {$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT\n ||$setOpSelectStatement.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL}? ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
			if (retval.tree.getChild(0).getType()==HiveParser.TOK_UNIONALL
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTDISTINCT
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_INTERSECTALL
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTDISTINCT
			   ||retval.tree.getChild(0).getType()==HiveParser.TOK_EXCEPTALL) {
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2707:7: ^( TOK_QUERY ^( TOK_FROM ^( TOK_SUBQUERY ) ) ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) ) )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_QUERY, "TOK_QUERY"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2708:11: ^( TOK_FROM ^( TOK_SUBQUERY ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_FROM, "TOK_FROM"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2709:13: ^( TOK_SUBQUERY )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SUBQUERY, "TOK_SUBQUERY"), root_3);
				adaptor.addChild(root_3, retval.tree);
				adaptor.addChild(root_3, adaptor.create(Identifier, generateUnionAlias()));
				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2714:11: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) ) )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2715:14: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2715:32: ^( TOK_DIR TOK_TMP_FILE )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:14: ^( TOK_SELECT ^( TOK_SELEXPR TOK_SETCOLREF ) )
				{
				ASTNode root_3 = (ASTNode)adaptor.nil();
				root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELECT, "TOK_SELECT"), root_3);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2716:27: ^( TOK_SELEXPR TOK_SETCOLREF )
				{
				ASTNode root_4 = (ASTNode)adaptor.nil();
				root_4 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SELEXPR, "TOK_SELEXPR"), root_4);
				adaptor.addChild(root_4, (ASTNode)adaptor.create(TOK_SETCOLREF, "TOK_SETCOLREF"));
				adaptor.addChild(root_3, root_4);
				}

				adaptor.addChild(root_2, root_3);
				}

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_0, root_1);
				}

			}

			else // 2719:4: ->
			{
				adaptor.addChild(root_0, retval.tree);
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setOpSelectStatement"


	public static class selectStatementWithCTE_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "selectStatementWithCTE"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2722:1: selectStatementWithCTE : (w= withClause )? selectStatement -> selectStatement ;
	public final HiveParser.selectStatementWithCTE_return selectStatementWithCTE() throws RecognitionException {
		HiveParser.selectStatementWithCTE_return retval = new HiveParser.selectStatementWithCTE_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope w =null;
		ParserRuleReturnScope selectStatement943 =null;

		RewriteRuleSubtreeStream stream_withClause=new RewriteRuleSubtreeStream(adaptor,"rule withClause");
		RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2723:5: ( (w= withClause )? selectStatement -> selectStatement )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2724:5: (w= withClause )? selectStatement
			{
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2724:5: (w= withClause )?
			int alt301=2;
			int LA301_0 = input.LA(1);
			if ( (LA301_0==KW_WITH) ) {
				alt301=1;
			}
			switch (alt301) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2724:6: w= withClause
					{
					pushFollow(FOLLOW_withClause_in_selectStatementWithCTE17586);
					w=withClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_withClause.add(w.getTree());
					}
					break;

			}

			pushFollow(FOLLOW_selectStatement_in_selectStatementWithCTE17594);
			selectStatement943=selectStatement();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_selectStatement.add(selectStatement943.getTree());
			if ( state.backtracking==0 ) {
			      if ((w!=null?((ASTNode)w.getTree()):null) != null) {
			      (selectStatement943!=null?((ASTNode)selectStatement943.getTree()):null).insertChild(0, (w!=null?((ASTNode)w.getTree()):null));
			      }
			    }
			// AST REWRITE
			// elements: selectStatement
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2730:5: -> selectStatement
			{
				adaptor.addChild(root_0, stream_selectStatement.nextTree());
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "selectStatementWithCTE"


	public static class body_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "body"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2733:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( qualifyClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( qualifyClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? ) );
	public final HiveParser.body_return body() throws RecognitionException {
		HiveParser.body_return retval = new HiveParser.body_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope insertClause944 =null;
		ParserRuleReturnScope selectClause945 =null;
		ParserRuleReturnScope lateralView946 =null;
		ParserRuleReturnScope whereClause947 =null;
		ParserRuleReturnScope groupByClause948 =null;
		ParserRuleReturnScope havingClause949 =null;
		ParserRuleReturnScope window_clause950 =null;
		ParserRuleReturnScope qualifyClause951 =null;
		ParserRuleReturnScope orderByClause952 =null;
		ParserRuleReturnScope clusterByClause953 =null;
		ParserRuleReturnScope distributeByClause954 =null;
		ParserRuleReturnScope sortByClause955 =null;
		ParserRuleReturnScope limitClause956 =null;
		ParserRuleReturnScope selectClause957 =null;
		ParserRuleReturnScope lateralView958 =null;
		ParserRuleReturnScope whereClause959 =null;
		ParserRuleReturnScope groupByClause960 =null;
		ParserRuleReturnScope havingClause961 =null;
		ParserRuleReturnScope window_clause962 =null;
		ParserRuleReturnScope qualifyClause963 =null;
		ParserRuleReturnScope orderByClause964 =null;
		ParserRuleReturnScope clusterByClause965 =null;
		ParserRuleReturnScope distributeByClause966 =null;
		ParserRuleReturnScope sortByClause967 =null;
		ParserRuleReturnScope limitClause968 =null;

		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
		RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
		RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
		RewriteRuleSubtreeStream stream_qualifyClause=new RewriteRuleSubtreeStream(adaptor,"rule qualifyClause");
		RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
		RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
		RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");
		RewriteRuleSubtreeStream stream_lateralView=new RewriteRuleSubtreeStream(adaptor,"rule lateralView");
		RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
		RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
		RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
		RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2734:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( qualifyClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( qualifyClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? ) )
			int alt324=2;
			int LA324_0 = input.LA(1);
			if ( (LA324_0==KW_INSERT) ) {
				alt324=1;
			}
			else if ( (LA324_0==KW_MAP||LA324_0==KW_REDUCE||LA324_0==KW_SELECT) ) {
				alt324=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 324, 0, input);
				throw nvae;
			}

			switch (alt324) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2735:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( qualifyClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
					{
					pushFollow(FOLLOW_insertClause_in_body17624);
					insertClause944=insertClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_insertClause.add(insertClause944.getTree());
					pushFollow(FOLLOW_selectClause_in_body17629);
					selectClause945=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(selectClause945.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2737:4: ( lateralView )?
					int alt302=2;
					int LA302_0 = input.LA(1);
					if ( (LA302_0==COMMA||LA302_0==KW_LATERAL) ) {
						alt302=1;
					}
					switch (alt302) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2737:4: lateralView
							{
							pushFollow(FOLLOW_lateralView_in_body17634);
							lateralView946=lateralView();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_lateralView.add(lateralView946.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2738:4: ( whereClause )?
					int alt303=2;
					int LA303_0 = input.LA(1);
					if ( (LA303_0==KW_WHERE) ) {
						alt303=1;
					}
					switch (alt303) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2738:4: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_body17640);
							whereClause947=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause947.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2739:4: ( groupByClause )?
					int alt304=2;
					int LA304_0 = input.LA(1);
					if ( (LA304_0==KW_GROUP) ) {
						alt304=1;
					}
					switch (alt304) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2739:4: groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_body17646);
							groupByClause948=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause948.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2740:4: ( havingClause )?
					int alt305=2;
					int LA305_0 = input.LA(1);
					if ( (LA305_0==KW_HAVING) ) {
						alt305=1;
					}
					switch (alt305) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2740:4: havingClause
							{
							pushFollow(FOLLOW_havingClause_in_body17652);
							havingClause949=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(havingClause949.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2741:4: ( window_clause )?
					int alt306=2;
					int LA306_0 = input.LA(1);
					if ( (LA306_0==KW_WINDOW) ) {
						alt306=1;
					}
					switch (alt306) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2741:4: window_clause
							{
							pushFollow(FOLLOW_window_clause_in_body17658);
							window_clause950=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(window_clause950.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2742:4: ( qualifyClause )?
					int alt307=2;
					int LA307_0 = input.LA(1);
					if ( (LA307_0==KW_QUALIFY) ) {
						alt307=1;
					}
					switch (alt307) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2742:4: qualifyClause
							{
							pushFollow(FOLLOW_qualifyClause_in_body17664);
							qualifyClause951=qualifyClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_qualifyClause.add(qualifyClause951.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2743:4: ( orderByClause )?
					int alt308=2;
					int LA308_0 = input.LA(1);
					if ( (LA308_0==KW_ORDER) ) {
						alt308=1;
					}
					switch (alt308) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2743:4: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_body17670);
							orderByClause952=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause952.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2744:4: ( clusterByClause )?
					int alt309=2;
					int LA309_0 = input.LA(1);
					if ( (LA309_0==KW_CLUSTER) ) {
						alt309=1;
					}
					switch (alt309) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2744:4: clusterByClause
							{
							pushFollow(FOLLOW_clusterByClause_in_body17676);
							clusterByClause953=clusterByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause953.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2745:4: ( distributeByClause )?
					int alt310=2;
					int LA310_0 = input.LA(1);
					if ( (LA310_0==KW_DISTRIBUTE) ) {
						alt310=1;
					}
					switch (alt310) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2745:4: distributeByClause
							{
							pushFollow(FOLLOW_distributeByClause_in_body17682);
							distributeByClause954=distributeByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause954.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:4: ( sortByClause )?
					int alt311=2;
					int LA311_0 = input.LA(1);
					if ( (LA311_0==KW_SORT) ) {
						alt311=1;
					}
					switch (alt311) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2746:4: sortByClause
							{
							pushFollow(FOLLOW_sortByClause_in_body17688);
							sortByClause955=sortByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause955.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2747:4: ( limitClause )?
					int alt312=2;
					int LA312_0 = input.LA(1);
					if ( (LA312_0==KW_LIMIT) ) {
						alt312=1;
					}
					switch (alt312) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2747:4: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_body17694);
							limitClause956=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause956.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: selectClause, groupByClause, limitClause, insertClause, window_clause, orderByClause, havingClause, whereClause, lateralView, clusterByClause, distributeByClause, sortByClause, qualifyClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2747:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2747:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);
						adaptor.addChild(root_1, stream_insertClause.nextTree());
						adaptor.addChild(root_1, stream_selectClause.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2748:35: ( lateralView )?
						if ( stream_lateralView.hasNext() ) {
							adaptor.addChild(root_1, stream_lateralView.nextTree());
						}
						stream_lateralView.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2748:48: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2748:61: ( groupByClause )?
						if ( stream_groupByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_groupByClause.nextTree());
						}
						stream_groupByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2748:76: ( havingClause )?
						if ( stream_havingClause.hasNext() ) {
							adaptor.addChild(root_1, stream_havingClause.nextTree());
						}
						stream_havingClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2748:90: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2748:105: ( clusterByClause )?
						if ( stream_clusterByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_clusterByClause.nextTree());
						}
						stream_clusterByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2749:22: ( distributeByClause )?
						if ( stream_distributeByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_distributeByClause.nextTree());
						}
						stream_distributeByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2749:42: ( sortByClause )?
						if ( stream_sortByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_sortByClause.nextTree());
						}
						stream_sortByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2749:56: ( window_clause )?
						if ( stream_window_clause.hasNext() ) {
							adaptor.addChild(root_1, stream_window_clause.nextTree());
						}
						stream_window_clause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2749:71: ( qualifyClause )?
						if ( stream_qualifyClause.hasNext() ) {
							adaptor.addChild(root_1, stream_qualifyClause.nextTree());
						}
						stream_qualifyClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2749:86: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2751:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( window_clause )? ( qualifyClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( limitClause )?
					{
					pushFollow(FOLLOW_selectClause_in_body17790);
					selectClause957=selectClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_selectClause.add(selectClause957.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2752:4: ( lateralView )?
					int alt313=2;
					int LA313_0 = input.LA(1);
					if ( (LA313_0==COMMA||LA313_0==KW_LATERAL) ) {
						alt313=1;
					}
					switch (alt313) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2752:4: lateralView
							{
							pushFollow(FOLLOW_lateralView_in_body17795);
							lateralView958=lateralView();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_lateralView.add(lateralView958.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2753:4: ( whereClause )?
					int alt314=2;
					int LA314_0 = input.LA(1);
					if ( (LA314_0==KW_WHERE) ) {
						alt314=1;
					}
					switch (alt314) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2753:4: whereClause
							{
							pushFollow(FOLLOW_whereClause_in_body17801);
							whereClause959=whereClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_whereClause.add(whereClause959.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2754:4: ( groupByClause )?
					int alt315=2;
					int LA315_0 = input.LA(1);
					if ( (LA315_0==KW_GROUP) ) {
						alt315=1;
					}
					switch (alt315) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2754:4: groupByClause
							{
							pushFollow(FOLLOW_groupByClause_in_body17807);
							groupByClause960=groupByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_groupByClause.add(groupByClause960.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2755:4: ( havingClause )?
					int alt316=2;
					int LA316_0 = input.LA(1);
					if ( (LA316_0==KW_HAVING) ) {
						alt316=1;
					}
					switch (alt316) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2755:4: havingClause
							{
							pushFollow(FOLLOW_havingClause_in_body17813);
							havingClause961=havingClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_havingClause.add(havingClause961.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2756:4: ( window_clause )?
					int alt317=2;
					int LA317_0 = input.LA(1);
					if ( (LA317_0==KW_WINDOW) ) {
						alt317=1;
					}
					switch (alt317) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2756:4: window_clause
							{
							pushFollow(FOLLOW_window_clause_in_body17819);
							window_clause962=window_clause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_window_clause.add(window_clause962.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2757:4: ( qualifyClause )?
					int alt318=2;
					int LA318_0 = input.LA(1);
					if ( (LA318_0==KW_QUALIFY) ) {
						alt318=1;
					}
					switch (alt318) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2757:4: qualifyClause
							{
							pushFollow(FOLLOW_qualifyClause_in_body17825);
							qualifyClause963=qualifyClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_qualifyClause.add(qualifyClause963.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2758:4: ( orderByClause )?
					int alt319=2;
					int LA319_0 = input.LA(1);
					if ( (LA319_0==KW_ORDER) ) {
						alt319=1;
					}
					switch (alt319) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2758:4: orderByClause
							{
							pushFollow(FOLLOW_orderByClause_in_body17831);
							orderByClause964=orderByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_orderByClause.add(orderByClause964.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2759:4: ( clusterByClause )?
					int alt320=2;
					int LA320_0 = input.LA(1);
					if ( (LA320_0==KW_CLUSTER) ) {
						alt320=1;
					}
					switch (alt320) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2759:4: clusterByClause
							{
							pushFollow(FOLLOW_clusterByClause_in_body17837);
							clusterByClause965=clusterByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_clusterByClause.add(clusterByClause965.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2760:4: ( distributeByClause )?
					int alt321=2;
					int LA321_0 = input.LA(1);
					if ( (LA321_0==KW_DISTRIBUTE) ) {
						alt321=1;
					}
					switch (alt321) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2760:4: distributeByClause
							{
							pushFollow(FOLLOW_distributeByClause_in_body17843);
							distributeByClause966=distributeByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_distributeByClause.add(distributeByClause966.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2761:4: ( sortByClause )?
					int alt322=2;
					int LA322_0 = input.LA(1);
					if ( (LA322_0==KW_SORT) ) {
						alt322=1;
					}
					switch (alt322) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2761:4: sortByClause
							{
							pushFollow(FOLLOW_sortByClause_in_body17849);
							sortByClause967=sortByClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_sortByClause.add(sortByClause967.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2762:4: ( limitClause )?
					int alt323=2;
					int LA323_0 = input.LA(1);
					if ( (LA323_0==KW_LIMIT) ) {
						alt323=1;
					}
					switch (alt323) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2762:4: limitClause
							{
							pushFollow(FOLLOW_limitClause_in_body17855);
							limitClause968=limitClause();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_limitClause.add(limitClause968.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: whereClause, limitClause, orderByClause, qualifyClause, lateralView, havingClause, selectClause, clusterByClause, distributeByClause, sortByClause, window_clause, groupByClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2762:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2762:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( qualifyClause )? ( limitClause )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2762:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
						{
						ASTNode root_2 = (ASTNode)adaptor.nil();
						root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_2);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2762:51: ^( TOK_DIR TOK_TMP_FILE )
						{
						ASTNode root_3 = (ASTNode)adaptor.nil();
						root_3 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_3);
						adaptor.addChild(root_3, (ASTNode)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE"));
						adaptor.addChild(root_2, root_3);
						}

						adaptor.addChild(root_1, root_2);
						}

						adaptor.addChild(root_1, stream_selectClause.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:35: ( lateralView )?
						if ( stream_lateralView.hasNext() ) {
							adaptor.addChild(root_1, stream_lateralView.nextTree());
						}
						stream_lateralView.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:48: ( whereClause )?
						if ( stream_whereClause.hasNext() ) {
							adaptor.addChild(root_1, stream_whereClause.nextTree());
						}
						stream_whereClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:61: ( groupByClause )?
						if ( stream_groupByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_groupByClause.nextTree());
						}
						stream_groupByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:76: ( havingClause )?
						if ( stream_havingClause.hasNext() ) {
							adaptor.addChild(root_1, stream_havingClause.nextTree());
						}
						stream_havingClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:90: ( orderByClause )?
						if ( stream_orderByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_orderByClause.nextTree());
						}
						stream_orderByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2763:105: ( clusterByClause )?
						if ( stream_clusterByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_clusterByClause.nextTree());
						}
						stream_clusterByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:22: ( distributeByClause )?
						if ( stream_distributeByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_distributeByClause.nextTree());
						}
						stream_distributeByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:42: ( sortByClause )?
						if ( stream_sortByClause.hasNext() ) {
							adaptor.addChild(root_1, stream_sortByClause.nextTree());
						}
						stream_sortByClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:56: ( window_clause )?
						if ( stream_window_clause.hasNext() ) {
							adaptor.addChild(root_1, stream_window_clause.nextTree());
						}
						stream_window_clause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:71: ( qualifyClause )?
						if ( stream_qualifyClause.hasNext() ) {
							adaptor.addChild(root_1, stream_qualifyClause.nextTree());
						}
						stream_qualifyClause.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2764:86: ( limitClause )?
						if ( stream_limitClause.hasNext() ) {
							adaptor.addChild(root_1, stream_limitClause.nextTree());
						}
						stream_limitClause.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "body"


	public static class insertClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "insertClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2767:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) );
	public final HiveParser.insertClause_return insertClause() throws RecognitionException {
		HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_INSERT969=null;
		Token KW_OVERWRITE970=null;
		Token KW_INSERT973=null;
		Token KW_INTO974=null;
		Token KW_TABLE975=null;
		Token LPAREN977=null;
		Token RPAREN978=null;
		ParserRuleReturnScope targetCols =null;
		ParserRuleReturnScope destination971 =null;
		ParserRuleReturnScope ifNotExists972 =null;
		ParserRuleReturnScope tableOrPartition976 =null;

		ASTNode KW_INSERT969_tree=null;
		ASTNode KW_OVERWRITE970_tree=null;
		ASTNode KW_INSERT973_tree=null;
		ASTNode KW_INTO974_tree=null;
		ASTNode KW_TABLE975_tree=null;
		ASTNode LPAREN977_tree=null;
		ASTNode RPAREN978_tree=null;
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
		RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
		RewriteRuleSubtreeStream stream_destination=new RewriteRuleSubtreeStream(adaptor,"rule destination");
		RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
		RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");

		 pushMsg("insert clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2770:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )? -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? ) )
			int alt328=2;
			int LA328_0 = input.LA(1);
			if ( (LA328_0==KW_INSERT) ) {
				int LA328_1 = input.LA(2);
				if ( (LA328_1==KW_OVERWRITE) ) {
					alt328=1;
				}
				else if ( (LA328_1==KW_INTO) ) {
					alt328=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 328, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 328, 0, input);
				throw nvae;
			}

			switch (alt328) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
					{
					KW_INSERT969=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause17979); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT969);

					KW_OVERWRITE970=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_insertClause17981); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OVERWRITE.add(KW_OVERWRITE970);

					pushFollow(FOLLOW_destination_in_insertClause17983);
					destination971=destination();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_destination.add(destination971.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:41: ( ifNotExists )?
					int alt325=2;
					int LA325_0 = input.LA(1);
					if ( (LA325_0==KW_IF) ) {
						alt325=1;
					}
					switch (alt325) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:41: ifNotExists
							{
							pushFollow(FOLLOW_ifNotExists_in_insertClause17985);
							ifNotExists972=ifNotExists();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_ifNotExists.add(ifNotExists972.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: destination, ifNotExists
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2771:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION"), root_1);
						adaptor.addChild(root_1, stream_destination.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2771:87: ( ifNotExists )?
						if ( stream_ifNotExists.hasNext() ) {
							adaptor.addChild(root_1, stream_ifNotExists.nextTree());
						}
						stream_ifNotExists.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:6: KW_INSERT KW_INTO ( KW_TABLE )? tableOrPartition ( LPAREN targetCols= columnNameList RPAREN )?
					{
					KW_INSERT973=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause18004); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT973);

					KW_INTO974=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_insertClause18006); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO974);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:24: ( KW_TABLE )?
					int alt326=2;
					int LA326_0 = input.LA(1);
					if ( (LA326_0==KW_TABLE) ) {
						alt326=1;
					}
					switch (alt326) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:24: KW_TABLE
							{
							KW_TABLE975=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_insertClause18008); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE975);

							}
							break;

					}

					pushFollow(FOLLOW_tableOrPartition_in_insertClause18011);
					tableOrPartition976=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition976.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:51: ( LPAREN targetCols= columnNameList RPAREN )?
					int alt327=2;
					int LA327_0 = input.LA(1);
					if ( (LA327_0==LPAREN) ) {
						int LA327_1 = input.LA(2);
						if ( (LA327_1==Identifier||(LA327_1 >= KW_ABORT && LA327_1 <= KW_AFTER)||LA327_1==KW_ALLOC_FRACTION||LA327_1==KW_ANALYZE||LA327_1==KW_ARCHIVE||(LA327_1 >= KW_ASC && LA327_1 <= KW_AT)||(LA327_1 >= KW_AUTOCOMMIT && LA327_1 <= KW_BEFORE)||(LA327_1 >= KW_BUCKET && LA327_1 <= KW_BUCKETS)||(LA327_1 >= KW_CACHE && LA327_1 <= KW_CASCADE)||(LA327_1 >= KW_CBO && LA327_1 <= KW_CHANGE)||(LA327_1 >= KW_CHECK && LA327_1 <= KW_COLLECTION)||(LA327_1 >= KW_COLUMNS && LA327_1 <= KW_COMMENT)||(LA327_1 >= KW_COMPACT && LA327_1 <= KW_CONCATENATE)||(LA327_1 >= KW_CONTINUE && LA327_1 <= KW_COST)||LA327_1==KW_CRON||LA327_1==KW_DATA||LA327_1==KW_DATABASES||(LA327_1 >= KW_DATETIME && LA327_1 <= KW_DCPROPERTIES)||LA327_1==KW_DEBUG||(LA327_1 >= KW_DEFAULT && LA327_1 <= KW_DEFINED)||(LA327_1 >= KW_DELIMITED && LA327_1 <= KW_DESC)||(LA327_1 >= KW_DETAIL && LA327_1 <= KW_DISABLE)||(LA327_1 >= KW_DISTRIBUTE && LA327_1 <= KW_DO)||LA327_1==KW_DOW||(LA327_1 >= KW_DUMP && LA327_1 <= KW_ELEM_TYPE)||LA327_1==KW_ENABLE||(LA327_1 >= KW_ENFORCED && LA327_1 <= KW_EVERY)||(LA327_1 >= KW_EXCLUSIVE && LA327_1 <= KW_EXECUTED)||(LA327_1 >= KW_EXPIRE_SNAPSHOTS && LA327_1 <= KW_EXPRESSION)||(LA327_1 >= KW_FIELDS && LA327_1 <= KW_FIRST)||(LA327_1 >= KW_FORMAT && LA327_1 <= KW_FORMATTED)||LA327_1==KW_FUNCTIONS||(LA327_1 >= KW_HOUR && LA327_1 <= KW_IDXPROPERTIES)||LA327_1==KW_IGNORE||(LA327_1 >= KW_INDEX && LA327_1 <= KW_INDEXES)||(LA327_1 >= KW_INPATH && LA327_1 <= KW_INPUTFORMAT)||(LA327_1 >= KW_ISOLATION && LA327_1 <= KW_JAR)||(LA327_1 >= KW_JOINCOST && LA327_1 <= KW_LAST)||LA327_1==KW_LEVEL||(LA327_1 >= KW_LIMIT && LA327_1 <= KW_LOAD)||(LA327_1 >= KW_LOCATION && LA327_1 <= KW_LONG)||(LA327_1 >= KW_MANAGED && LA327_1 <= KW_MANAGEMENT)||(LA327_1 >= KW_MAPJOIN && LA327_1 <= KW_MATERIALIZED)||LA327_1==KW_METADATA||(LA327_1 >= KW_MINUTE && LA327_1 <= KW_MONTH)||(LA327_1 >= KW_MOVE && LA327_1 <= KW_MSCK)||(LA327_1 >= KW_NORELY && LA327_1 <= KW_NOSCAN)||LA327_1==KW_NOVALIDATE||LA327_1==KW_NULLS||LA327_1==KW_OFFSET||(LA327_1 >= KW_OPERATOR && LA327_1 <= KW_OPTION)||(LA327_1 >= KW_OUTPUTDRIVER && LA327_1 <= KW_OUTPUTFORMAT)||(LA327_1 >= KW_OVERWRITE && LA327_1 <= KW_OWNER)||(LA327_1 >= KW_PARTITIONED && LA327_1 <= KW_PATH)||(LA327_1 >= KW_PLAN && LA327_1 <= KW_POOL)||LA327_1==KW_PRINCIPALS||LA327_1==KW_PURGE||(LA327_1 >= KW_QUARTER && LA327_1 <= KW_QUERY_PARALLELISM)||LA327_1==KW_READ||(LA327_1 >= KW_REBUILD && LA327_1 <= KW_RECORDWRITER)||(LA327_1 >= KW_RELOAD && LA327_1 <= KW_RESTRICT)||LA327_1==KW_REWRITE||(LA327_1 >= KW_ROLE && LA327_1 <= KW_ROLES)||(LA327_1 >= KW_SCHEDULED && LA327_1 <= KW_SECOND)||(LA327_1 >= KW_SEMI && LA327_1 <= KW_SERVER)||(LA327_1 >= KW_SETS && LA327_1 <= KW_SKEWED)||LA327_1==KW_SNAPSHOT||(LA327_1 >= KW_SORT && LA327_1 <= KW_SSL)||(LA327_1 >= KW_STATISTICS && LA327_1 <= KW_SUMMARY)||(LA327_1 >= KW_SYSTEM_TIME && LA327_1 <= KW_SYSTEM_VERSION)||LA327_1==KW_TABLES||(LA327_1 >= KW_TBLPROPERTIES && LA327_1 <= KW_TERMINATED)||LA327_1==KW_TINYINT||LA327_1==KW_TOUCH||(LA327_1 >= KW_TRANSACTION && LA327_1 <= KW_TRANSACTIONS)||LA327_1==KW_TRIM||(LA327_1 >= KW_TYPE && LA327_1 <= KW_UNARCHIVE)||LA327_1==KW_UNDO||LA327_1==KW_UNIONTYPE||(LA327_1 >= KW_UNKNOWN && LA327_1 <= KW_UNSIGNED)||(LA327_1 >= KW_URI && LA327_1 <= KW_USE)||(LA327_1 >= KW_UTC && LA327_1 <= KW_VALIDATE)||LA327_1==KW_VALUE_TYPE||(LA327_1 >= KW_VECTORIZATION && LA327_1 <= KW_WEEK)||LA327_1==KW_WHILE||(LA327_1 >= KW_WITHIN && LA327_1 <= KW_ZONE)||LA327_1==KW_BATCH||LA327_1==KW_DAYOFWEEK||LA327_1==KW_HOLD_DDLTIME||LA327_1==KW_NO_DROP||LA327_1==KW_OFFLINE||LA327_1==KW_PROTECTION||LA327_1==KW_READONLY||LA327_1==KW_TIMESTAMPTZ) ) {
							alt327=1;
						}
					}
					switch (alt327) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2772:52: LPAREN targetCols= columnNameList RPAREN
							{
							LPAREN977=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_insertClause18014); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_LPAREN.add(LPAREN977);

							pushFollow(FOLLOW_columnNameList_in_insertClause18018);
							targetCols=columnNameList();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_columnNameList.add(targetCols.getTree());
							RPAREN978=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_insertClause18020); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_RPAREN.add(RPAREN978);

							}
							break;

					}

					// AST REWRITE
					// elements: targetCols, tableOrPartition
					// token labels: 
					// rule labels: targetCols, retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.getTree():null);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2773:8: -> ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2773:11: ^( TOK_INSERT_INTO tableOrPartition ( $targetCols)? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO"), root_1);
						adaptor.addChild(root_1, stream_tableOrPartition.nextTree());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2773:47: ( $targetCols)?
						if ( stream_targetCols.hasNext() ) {
							adaptor.addChild(root_1, stream_targetCols.nextTree());
						}
						stream_targetCols.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "insertClause"


	public static class destination_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "destination"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2776:1: destination : ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition );
	public final HiveParser.destination_return destination() throws RecognitionException {
		HiveParser.destination_return retval = new HiveParser.destination_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token local=null;
		Token KW_DIRECTORY979=null;
		Token StringLiteral980=null;
		Token KW_TABLE983=null;
		ParserRuleReturnScope tableRowFormat981 =null;
		ParserRuleReturnScope tableFileFormat982 =null;
		ParserRuleReturnScope tableOrPartition984 =null;

		ASTNode local_tree=null;
		ASTNode KW_DIRECTORY979_tree=null;
		ASTNode StringLiteral980_tree=null;
		ASTNode KW_TABLE983_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_DIRECTORY=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORY");
		RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
		RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
		RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
		RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
		RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");

		 pushMsg("destination specification", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2779:4: ( (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? ) | KW_TABLE tableOrPartition -> tableOrPartition )
			int alt332=2;
			int LA332_0 = input.LA(1);
			if ( (LA332_0==KW_DIRECTORY||LA332_0==KW_LOCAL) ) {
				alt332=1;
			}
			else if ( (LA332_0==KW_TABLE) ) {
				alt332=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 332, 0, input);
				throw nvae;
			}

			switch (alt332) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:6: (local= KW_LOCAL )? KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:6: (local= KW_LOCAL )?
					int alt329=2;
					int LA329_0 = input.LA(1);
					if ( (LA329_0==KW_LOCAL) ) {
						alt329=1;
					}
					switch (alt329) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:7: local= KW_LOCAL
							{
							local=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_destination18076); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_LOCAL.add(local);

							}
							break;

					}

					KW_DIRECTORY979=(Token)match(input,KW_DIRECTORY,FOLLOW_KW_DIRECTORY_in_destination18080); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DIRECTORY.add(KW_DIRECTORY979);

					StringLiteral980=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_destination18082); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral980);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:53: ( tableRowFormat )?
					int alt330=2;
					int LA330_0 = input.LA(1);
					if ( (LA330_0==KW_ROW) ) {
						alt330=1;
					}
					switch (alt330) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:53: tableRowFormat
							{
							pushFollow(FOLLOW_tableRowFormat_in_destination18084);
							tableRowFormat981=tableRowFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableRowFormat.add(tableRowFormat981.getTree());
							}
							break;

					}

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:69: ( tableFileFormat )?
					int alt331=2;
					int LA331_0 = input.LA(1);
					if ( (LA331_0==KW_STORED) ) {
						alt331=1;
					}
					switch (alt331) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2780:69: tableFileFormat
							{
							pushFollow(FOLLOW_tableFileFormat_in_destination18087);
							tableFileFormat982=tableFileFormat();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_tableFileFormat.add(tableFileFormat982.getTree());
							}
							break;

					}

					// AST REWRITE
					// elements: StringLiteral, tableRowFormat, tableFileFormat, local
					// token labels: local
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_local=new RewriteRuleTokenStream(adaptor,"token local",local);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2781:8: -> ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2781:11: ^( TOK_DIR StringLiteral ( $local)? ( tableRowFormat )? ( tableFileFormat )? )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DIR, "TOK_DIR"), root_1);
						adaptor.addChild(root_1, stream_StringLiteral.nextNode());
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2781:36: ( $local)?
						if ( stream_local.hasNext() ) {
							adaptor.addChild(root_1, stream_local.nextNode());
						}
						stream_local.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2781:43: ( tableRowFormat )?
						if ( stream_tableRowFormat.hasNext() ) {
							adaptor.addChild(root_1, stream_tableRowFormat.nextTree());
						}
						stream_tableRowFormat.reset();

						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2781:59: ( tableFileFormat )?
						if ( stream_tableFileFormat.hasNext() ) {
							adaptor.addChild(root_1, stream_tableFileFormat.nextTree());
						}
						stream_tableFileFormat.reset();

						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2782:6: KW_TABLE tableOrPartition
					{
					KW_TABLE983=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_destination18120); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_TABLE.add(KW_TABLE983);

					pushFollow(FOLLOW_tableOrPartition_in_destination18122);
					tableOrPartition984=tableOrPartition();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_tableOrPartition.add(tableOrPartition984.getTree());
					// AST REWRITE
					// elements: tableOrPartition
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2782:32: -> tableOrPartition
					{
						adaptor.addChild(root_0, stream_tableOrPartition.nextTree());
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "destination"


	public static class limitClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "limitClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2785:1: limitClause : ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) );
	public final HiveParser.limitClause_return limitClause() throws RecognitionException {
		HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token offset=null;
		Token num=null;
		Token KW_LIMIT985=null;
		Token COMMA986=null;
		Token KW_LIMIT987=null;
		Token KW_OFFSET988=null;

		ASTNode offset_tree=null;
		ASTNode num_tree=null;
		ASTNode KW_LIMIT985_tree=null;
		ASTNode COMMA986_tree=null;
		ASTNode KW_LIMIT987_tree=null;
		ASTNode KW_OFFSET988_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");
		RewriteRuleTokenStream stream_KW_OFFSET=new RewriteRuleTokenStream(adaptor,"token KW_OFFSET");

		 pushMsg("limit clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2788:4: ( KW_LIMIT ( (offset= Number COMMA )? num= Number ) -> ^( TOK_LIMIT ( $offset)? $num) | KW_LIMIT num= Number KW_OFFSET offset= Number -> ^( TOK_LIMIT ( $offset)? $num) )
			int alt334=2;
			int LA334_0 = input.LA(1);
			if ( (LA334_0==KW_LIMIT) ) {
				int LA334_1 = input.LA(2);
				if ( (LA334_1==Number) ) {
					int LA334_2 = input.LA(3);
					if ( (LA334_2==KW_OFFSET) ) {
						alt334=2;
					}
					else if ( (LA334_2==EOF||LA334_2==COMMA||LA334_2==KW_EXCEPT||LA334_2==KW_INSERT||LA334_2==KW_INTERSECT||LA334_2==KW_MAP||LA334_2==KW_MINUS||LA334_2==KW_REDUCE||LA334_2==KW_SELECT||LA334_2==KW_UNION||LA334_2==RPAREN) ) {
						alt334=1;
					}

					else {
						if (state.backtracking>0) {state.failed=true; return retval;}
						int nvaeMark = input.mark();
						try {
							for (int nvaeConsume = 0; nvaeConsume < 3 - 1; nvaeConsume++) {
								input.consume();
							}
							NoViableAltException nvae =
								new NoViableAltException("", 334, 2, input);
							throw nvae;
						} finally {
							input.rewind(nvaeMark);
						}
					}

				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 334, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 334, 0, input);
				throw nvae;
			}

			switch (alt334) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:4: KW_LIMIT ( (offset= Number COMMA )? num= Number )
					{
					KW_LIMIT985=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause18154); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT985);

					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:13: ( (offset= Number COMMA )? num= Number )
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:14: (offset= Number COMMA )? num= Number
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:14: (offset= Number COMMA )?
					int alt333=2;
					int LA333_0 = input.LA(1);
					if ( (LA333_0==Number) ) {
						int LA333_1 = input.LA(2);
						if ( (LA333_1==COMMA) ) {
							alt333=1;
						}
					}
					switch (alt333) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:15: offset= Number COMMA
							{
							offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause18160); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_Number.add(offset);

							COMMA986=(Token)match(input,COMMA,FOLLOW_COMMA_in_limitClause18162); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA986);

							}
							break;

					}

					num=(Token)match(input,Number,FOLLOW_Number_in_limitClause18168); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(num);

					}

					// AST REWRITE
					// elements: offset, num
					// token labels: offset, num
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
					RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2789:49: -> ^( TOK_LIMIT ( $offset)? $num)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:52: ^( TOK_LIMIT ( $offset)? $num)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2789:64: ( $offset)?
						if ( stream_offset.hasNext() ) {
							adaptor.addChild(root_1, stream_offset.nextNode());
						}
						stream_offset.reset();

						adaptor.addChild(root_1, stream_num.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2790:6: KW_LIMIT num= Number KW_OFFSET offset= Number
					{
					KW_LIMIT987=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause18191); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_LIMIT.add(KW_LIMIT987);

					num=(Token)match(input,Number,FOLLOW_Number_in_limitClause18195); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(num);

					KW_OFFSET988=(Token)match(input,KW_OFFSET,FOLLOW_KW_OFFSET_in_limitClause18197); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_OFFSET.add(KW_OFFSET988);

					offset=(Token)match(input,Number,FOLLOW_Number_in_limitClause18201); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(offset);

					// AST REWRITE
					// elements: num, offset
					// token labels: offset, num
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleTokenStream stream_offset=new RewriteRuleTokenStream(adaptor,"token offset",offset);
					RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2790:50: -> ^( TOK_LIMIT ( $offset)? $num)
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2790:53: ^( TOK_LIMIT ( $offset)? $num)
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_LIMIT, "TOK_LIMIT"), root_1);
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2790:65: ( $offset)?
						if ( stream_offset.hasNext() ) {
							adaptor.addChild(root_1, stream_offset.nextNode());
						}
						stream_offset.reset();

						adaptor.addChild(root_1, stream_num.nextNode());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "limitClause"


	public static class deleteStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "deleteStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2794:1: deleteStatement : KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) ;
	public final HiveParser.deleteStatement_return deleteStatement() throws RecognitionException {
		HiveParser.deleteStatement_return retval = new HiveParser.deleteStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_DELETE989=null;
		Token KW_FROM990=null;
		ParserRuleReturnScope tableName991 =null;
		ParserRuleReturnScope whereClause992 =null;

		ASTNode KW_DELETE989_tree=null;
		ASTNode KW_FROM990_tree=null;
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("delete statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2797:4: ( KW_DELETE KW_FROM tableName ( whereClause )? -> ^( TOK_DELETE_FROM tableName ( whereClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:4: KW_DELETE KW_FROM tableName ( whereClause )?
			{
			KW_DELETE989=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_deleteStatement18245); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE989);

			KW_FROM990=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_deleteStatement18247); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_FROM.add(KW_FROM990);

			pushFollow(FOLLOW_tableName_in_deleteStatement18249);
			tableName991=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName991.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:32: ( whereClause )?
			int alt335=2;
			int LA335_0 = input.LA(1);
			if ( (LA335_0==KW_WHERE) ) {
				alt335=1;
			}
			switch (alt335) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:33: whereClause
					{
					pushFollow(FOLLOW_whereClause_in_deleteStatement18252);
					whereClause992=whereClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_whereClause.add(whereClause992.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: whereClause, tableName
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2798:47: -> ^( TOK_DELETE_FROM tableName ( whereClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:50: ^( TOK_DELETE_FROM tableName ( whereClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_DELETE_FROM, "TOK_DELETE_FROM"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2798:78: ( whereClause )?
				if ( stream_whereClause.hasNext() ) {
					adaptor.addChild(root_1, stream_whereClause.nextTree());
				}
				stream_whereClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "deleteStatement"


	public static class columnAssignmentClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "columnAssignmentClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2802:1: columnAssignmentClause : (| tableOrColumn EQUAL ^ precedencePlusExpressionOrDefault );
	public final HiveParser.columnAssignmentClause_return columnAssignmentClause() throws RecognitionException {
		HiveParser.columnAssignmentClause_return retval = new HiveParser.columnAssignmentClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token EQUAL994=null;
		ParserRuleReturnScope tableOrColumn993 =null;
		ParserRuleReturnScope precedencePlusExpressionOrDefault995 =null;

		ASTNode EQUAL994_tree=null;

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2803:4: (| tableOrColumn EQUAL ^ precedencePlusExpressionOrDefault )
			int alt336=2;
			int LA336_0 = input.LA(1);
			if ( (LA336_0==EOF||LA336_0==COMMA||(LA336_0 >= KW_WHEN && LA336_0 <= KW_WHERE)) ) {
				alt336=1;
			}
			else if ( (LA336_0==Identifier||(LA336_0 >= KW_ABORT && LA336_0 <= KW_AFTER)||LA336_0==KW_ALLOC_FRACTION||LA336_0==KW_ANALYZE||LA336_0==KW_ARCHIVE||(LA336_0 >= KW_ASC && LA336_0 <= KW_AT)||(LA336_0 >= KW_AUTOCOMMIT && LA336_0 <= KW_BEFORE)||(LA336_0 >= KW_BUCKET && LA336_0 <= KW_BUCKETS)||(LA336_0 >= KW_CACHE && LA336_0 <= KW_CASCADE)||(LA336_0 >= KW_CBO && LA336_0 <= KW_CHANGE)||(LA336_0 >= KW_CHECK && LA336_0 <= KW_COLLECTION)||(LA336_0 >= KW_COLUMNS && LA336_0 <= KW_COMMENT)||(LA336_0 >= KW_COMPACT && LA336_0 <= KW_CONCATENATE)||(LA336_0 >= KW_CONTINUE && LA336_0 <= KW_COST)||LA336_0==KW_CRON||LA336_0==KW_DATA||LA336_0==KW_DATABASES||(LA336_0 >= KW_DATETIME && LA336_0 <= KW_DCPROPERTIES)||LA336_0==KW_DEBUG||(LA336_0 >= KW_DEFAULT && LA336_0 <= KW_DEFINED)||(LA336_0 >= KW_DELIMITED && LA336_0 <= KW_DESC)||(LA336_0 >= KW_DETAIL && LA336_0 <= KW_DISABLE)||(LA336_0 >= KW_DISTRIBUTE && LA336_0 <= KW_DO)||LA336_0==KW_DOW||(LA336_0 >= KW_DUMP && LA336_0 <= KW_ELEM_TYPE)||LA336_0==KW_ENABLE||(LA336_0 >= KW_ENFORCED && LA336_0 <= KW_EVERY)||(LA336_0 >= KW_EXCLUSIVE && LA336_0 <= KW_EXECUTED)||(LA336_0 >= KW_EXPIRE_SNAPSHOTS && LA336_0 <= KW_EXPRESSION)||(LA336_0 >= KW_FIELDS && LA336_0 <= KW_FIRST)||(LA336_0 >= KW_FORMAT && LA336_0 <= KW_FORMATTED)||LA336_0==KW_FUNCTIONS||(LA336_0 >= KW_HOUR && LA336_0 <= KW_IDXPROPERTIES)||LA336_0==KW_IGNORE||(LA336_0 >= KW_INDEX && LA336_0 <= KW_INDEXES)||(LA336_0 >= KW_INPATH && LA336_0 <= KW_INPUTFORMAT)||(LA336_0 >= KW_ISOLATION && LA336_0 <= KW_JAR)||(LA336_0 >= KW_JOINCOST && LA336_0 <= KW_LAST)||LA336_0==KW_LEVEL||(LA336_0 >= KW_LIMIT && LA336_0 <= KW_LOAD)||(LA336_0 >= KW_LOCATION && LA336_0 <= KW_LONG)||(LA336_0 >= KW_MANAGED && LA336_0 <= KW_MANAGEMENT)||(LA336_0 >= KW_MAPJOIN && LA336_0 <= KW_MATERIALIZED)||LA336_0==KW_METADATA||(LA336_0 >= KW_MINUTE && LA336_0 <= KW_MONTH)||(LA336_0 >= KW_MOVE && LA336_0 <= KW_MSCK)||(LA336_0 >= KW_NORELY && LA336_0 <= KW_NOSCAN)||LA336_0==KW_NOVALIDATE||LA336_0==KW_NULLS||LA336_0==KW_OFFSET||(LA336_0 >= KW_OPERATOR && LA336_0 <= KW_OPTION)||(LA336_0 >= KW_OUTPUTDRIVER && LA336_0 <= KW_OUTPUTFORMAT)||(LA336_0 >= KW_OVERWRITE && LA336_0 <= KW_OWNER)||(LA336_0 >= KW_PARTITIONED && LA336_0 <= KW_PATH)||(LA336_0 >= KW_PLAN && LA336_0 <= KW_POOL)||LA336_0==KW_PRINCIPALS||LA336_0==KW_PURGE||(LA336_0 >= KW_QUARTER && LA336_0 <= KW_QUERY_PARALLELISM)||LA336_0==KW_READ||(LA336_0 >= KW_REBUILD && LA336_0 <= KW_RECORDWRITER)||(LA336_0 >= KW_RELOAD && LA336_0 <= KW_RESTRICT)||LA336_0==KW_REWRITE||(LA336_0 >= KW_ROLE && LA336_0 <= KW_ROLES)||(LA336_0 >= KW_SCHEDULED && LA336_0 <= KW_SECOND)||(LA336_0 >= KW_SEMI && LA336_0 <= KW_SERVER)||(LA336_0 >= KW_SETS && LA336_0 <= KW_SKEWED)||LA336_0==KW_SNAPSHOT||(LA336_0 >= KW_SORT && LA336_0 <= KW_SSL)||(LA336_0 >= KW_STATISTICS && LA336_0 <= KW_SUMMARY)||(LA336_0 >= KW_SYSTEM_TIME && LA336_0 <= KW_SYSTEM_VERSION)||LA336_0==KW_TABLES||(LA336_0 >= KW_TBLPROPERTIES && LA336_0 <= KW_TERMINATED)||LA336_0==KW_TINYINT||LA336_0==KW_TOUCH||(LA336_0 >= KW_TRANSACTION && LA336_0 <= KW_TRANSACTIONS)||LA336_0==KW_TRIM||(LA336_0 >= KW_TYPE && LA336_0 <= KW_UNARCHIVE)||LA336_0==KW_UNDO||LA336_0==KW_UNIONTYPE||(LA336_0 >= KW_UNKNOWN && LA336_0 <= KW_UNSIGNED)||(LA336_0 >= KW_URI && LA336_0 <= KW_USE)||(LA336_0 >= KW_UTC && LA336_0 <= KW_VALIDATE)||LA336_0==KW_VALUE_TYPE||(LA336_0 >= KW_VECTORIZATION && LA336_0 <= KW_WEEK)||LA336_0==KW_WHILE||(LA336_0 >= KW_WITHIN && LA336_0 <= KW_ZONE)||LA336_0==KW_BATCH||LA336_0==KW_DAYOFWEEK||LA336_0==KW_HOLD_DDLTIME||LA336_0==KW_NO_DROP||LA336_0==KW_OFFLINE||LA336_0==KW_PROTECTION||LA336_0==KW_READONLY||LA336_0==KW_TIMESTAMPTZ) ) {
				alt336=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 336, 0, input);
				throw nvae;
			}

			switch (alt336) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2804:4: 
					{
					root_0 = (ASTNode)adaptor.nil();


					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2804:6: tableOrColumn EQUAL ^ precedencePlusExpressionOrDefault
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_tableOrColumn_in_columnAssignmentClause18287);
					tableOrColumn993=tableOrColumn();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, tableOrColumn993.getTree());

					EQUAL994=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_columnAssignmentClause18289); if (state.failed) return retval;
					if ( state.backtracking==0 ) {
					EQUAL994_tree = (ASTNode)adaptor.create(EQUAL994);
					root_0 = (ASTNode)adaptor.becomeRoot(EQUAL994_tree, root_0);
					}

					pushFollow(FOLLOW_precedencePlusExpressionOrDefault_in_columnAssignmentClause18292);
					precedencePlusExpressionOrDefault995=precedencePlusExpressionOrDefault();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, precedencePlusExpressionOrDefault995.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "columnAssignmentClause"


	public static class precedencePlusExpressionOrDefault_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "precedencePlusExpressionOrDefault"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2807:1: precedencePlusExpressionOrDefault : ( ( KW_DEFAULT (~ DOT | EOF ) )=> defaultValue | precedencePlusExpression );
	public final HiveParser.precedencePlusExpressionOrDefault_return precedencePlusExpressionOrDefault() throws RecognitionException {
		HiveParser.precedencePlusExpressionOrDefault_return retval = new HiveParser.precedencePlusExpressionOrDefault_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope defaultValue996 =null;
		ParserRuleReturnScope precedencePlusExpression997 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2808:5: ( ( KW_DEFAULT (~ DOT | EOF ) )=> defaultValue | precedencePlusExpression )
			int alt337=2;
			int LA337_0 = input.LA(1);
			if ( (LA337_0==KW_DEFAULT) ) {
				int LA337_1 = input.LA(2);
				if ( (synpred24_HiveParser()) ) {
					alt337=1;
				}
				else if ( (true) ) {
					alt337=2;
				}

			}
			else if ( (LA337_0==CharSetName||(LA337_0 >= Identifier && LA337_0 <= KW_AFTER)||LA337_0==KW_ALLOC_FRACTION||LA337_0==KW_ANALYZE||(LA337_0 >= KW_ARCHIVE && LA337_0 <= KW_ARRAY)||(LA337_0 >= KW_ASC && LA337_0 <= KW_AT)||(LA337_0 >= KW_AUTOCOMMIT && LA337_0 <= KW_BEFORE)||(LA337_0 >= KW_BIGINT && LA337_0 <= KW_BOOLEAN)||(LA337_0 >= KW_BUCKET && LA337_0 <= KW_BUCKETS)||(LA337_0 >= KW_CACHE && LA337_0 <= KW_CHANGE)||(LA337_0 >= KW_CHECK && LA337_0 <= KW_COLLECTION)||(LA337_0 >= KW_COLUMNS && LA337_0 <= KW_COMMENT)||(LA337_0 >= KW_COMPACT && LA337_0 <= KW_CONCATENATE)||(LA337_0 >= KW_CONTINUE && LA337_0 <= KW_COST)||LA337_0==KW_CRON||(LA337_0 >= KW_CURRENT_DATE && LA337_0 <= KW_CURRENT_TIMESTAMP)||LA337_0==KW_DATA||LA337_0==KW_DATABASES||(LA337_0 >= KW_DATE && LA337_0 <= KW_DCPROPERTIES)||LA337_0==KW_DEBUG||(LA337_0 >= KW_DEFERRED && LA337_0 <= KW_DEFINED)||(LA337_0 >= KW_DELIMITED && LA337_0 <= KW_DESC)||(LA337_0 >= KW_DETAIL && LA337_0 <= KW_DISABLE)||(LA337_0 >= KW_DISTRIBUTE && LA337_0 <= KW_DOW)||(LA337_0 >= KW_DUMP && LA337_0 <= KW_ELEM_TYPE)||LA337_0==KW_ENABLE||(LA337_0 >= KW_ENFORCED && LA337_0 <= KW_EVERY)||(LA337_0 >= KW_EXCLUSIVE && LA337_0 <= KW_EXECUTED)||(LA337_0 >= KW_EXPIRE_SNAPSHOTS && LA337_0 <= KW_EXPRESSION)||(LA337_0 >= KW_EXTRACT && LA337_0 <= KW_FALSE)||(LA337_0 >= KW_FIELDS && LA337_0 <= KW_FLOOR)||(LA337_0 >= KW_FORMAT && LA337_0 <= KW_FORMATTED)||LA337_0==KW_FUNCTIONS||LA337_0==KW_GROUPING||(LA337_0 >= KW_HOUR && LA337_0 <= KW_IGNORE)||(LA337_0 >= KW_INDEX && LA337_0 <= KW_INDEXES)||(LA337_0 >= KW_INPATH && LA337_0 <= KW_INPUTFORMAT)||LA337_0==KW_INT||LA337_0==KW_INTERVAL||(LA337_0 >= KW_ISOLATION && LA337_0 <= KW_JAR)||(LA337_0 >= KW_JOINCOST && LA337_0 <= KW_LAST)||LA337_0==KW_LEVEL||(LA337_0 >= KW_LIMIT && LA337_0 <= KW_LOAD)||(LA337_0 >= KW_LOCATION && LA337_0 <= KW_LONG)||(LA337_0 >= KW_MANAGED && LA337_0 <= KW_MATERIALIZED)||LA337_0==KW_METADATA||(LA337_0 >= KW_MINUTE && LA337_0 <= KW_MONTH)||(LA337_0 >= KW_MOVE && LA337_0 <= KW_MSCK)||(LA337_0 >= KW_NORELY && LA337_0 <= KW_NOSCAN)||(LA337_0 >= KW_NOVALIDATE && LA337_0 <= KW_NULLS)||LA337_0==KW_OFFSET||(LA337_0 >= KW_OPERATOR && LA337_0 <= KW_OPTION)||(LA337_0 >= KW_OUTPUTDRIVER && LA337_0 <= KW_OUTPUTFORMAT)||(LA337_0 >= KW_OVERWRITE && LA337_0 <= KW_OWNER)||(LA337_0 >= KW_PARTITIONED && LA337_0 <= KW_PATH)||(LA337_0 >= KW_PLAN && LA337_0 <= KW_POOL)||LA337_0==KW_PRINCIPALS||LA337_0==KW_PURGE||(LA337_0 >= KW_QUARTER && LA337_0 <= KW_QUERY_PARALLELISM)||LA337_0==KW_READ||(LA337_0 >= KW_REAL && LA337_0 <= KW_RECORDWRITER)||(LA337_0 >= KW_RELOAD && LA337_0 <= KW_RESTRICT)||LA337_0==KW_REWRITE||(LA337_0 >= KW_ROLE && LA337_0 <= KW_ROLES)||(LA337_0 >= KW_SCHEDULED && LA337_0 <= KW_SECOND)||(LA337_0 >= KW_SEMI && LA337_0 <= KW_SERVER)||(LA337_0 >= KW_SETS && LA337_0 <= KW_SNAPSHOT)||(LA337_0 >= KW_SORT && LA337_0 <= KW_SSL)||(LA337_0 >= KW_STATISTICS && LA337_0 <= KW_SUMMARY)||(LA337_0 >= KW_SYSTEM_TIME && LA337_0 <= KW_SYSTEM_VERSION)||LA337_0==KW_TABLES||(LA337_0 >= KW_TBLPROPERTIES && LA337_0 <= KW_TERMINATED)||(LA337_0 >= KW_TIMESTAMP && LA337_0 <= KW_TINYINT)||LA337_0==KW_TOUCH||(LA337_0 >= KW_TRANSACTION && LA337_0 <= KW_TRANSACTIONS)||(LA337_0 >= KW_TRIM && LA337_0 <= KW_TRUE)||(LA337_0 >= KW_TYPE && LA337_0 <= KW_UNARCHIVE)||LA337_0==KW_UNDO||LA337_0==KW_UNIONTYPE||(LA337_0 >= KW_UNKNOWN && LA337_0 <= KW_UNSIGNED)||(LA337_0 >= KW_URI && LA337_0 <= KW_USE)||(LA337_0 >= KW_UTC && LA337_0 <= KW_VALIDATE)||LA337_0==KW_VALUE_TYPE||(LA337_0 >= KW_VECTORIZATION && LA337_0 <= KW_WEEK)||LA337_0==KW_WHILE||(LA337_0 >= KW_WITHIN && LA337_0 <= KW_ZONE)||LA337_0==LPAREN||LA337_0==MINUS||(LA337_0 >= Number && LA337_0 <= PLUS)||LA337_0==QUESTION||(LA337_0 >= StringLiteral && LA337_0 <= TILDE)||LA337_0==KW_BATCH||LA337_0==KW_DAYOFWEEK||LA337_0==KW_HOLD_DDLTIME||LA337_0==KW_NO_DROP||LA337_0==KW_OFFLINE||LA337_0==KW_PROTECTION||LA337_0==KW_READONLY||LA337_0==KW_TIMESTAMPTZ) ) {
				alt337=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 337, 0, input);
				throw nvae;
			}

			switch (alt337) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2809:5: ( KW_DEFAULT (~ DOT | EOF ) )=> defaultValue
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_defaultValue_in_precedencePlusExpressionOrDefault18325);
					defaultValue996=defaultValue();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, defaultValue996.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2810:7: precedencePlusExpression
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_precedencePlusExpression_in_precedencePlusExpressionOrDefault18333);
					precedencePlusExpression997=precedencePlusExpression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, precedencePlusExpression997.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "precedencePlusExpressionOrDefault"


	public static class setColumnsClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setColumnsClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2815:1: setColumnsClause : KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) ;
	public final HiveParser.setColumnsClause_return setColumnsClause() throws RecognitionException {
		HiveParser.setColumnsClause_return retval = new HiveParser.setColumnsClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET998=null;
		Token COMMA1000=null;
		ParserRuleReturnScope columnAssignmentClause999 =null;
		ParserRuleReturnScope columnAssignmentClause1001 =null;

		ASTNode KW_SET998_tree=null;
		ASTNode COMMA1000_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_columnAssignmentClause=new RewriteRuleSubtreeStream(adaptor,"rule columnAssignmentClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2816:4: ( KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )* -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:4: KW_SET columnAssignmentClause ( COMMA columnAssignmentClause )*
			{
			KW_SET998=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setColumnsClause18355); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET998);

			pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause18357);
			columnAssignmentClause999=columnAssignmentClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause999.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:34: ( COMMA columnAssignmentClause )*
			loop338:
			while (true) {
				int alt338=2;
				int LA338_0 = input.LA(1);
				if ( (LA338_0==COMMA) ) {
					alt338=1;
				}

				switch (alt338) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:35: COMMA columnAssignmentClause
					{
					COMMA1000=(Token)match(input,COMMA,FOLLOW_COMMA_in_setColumnsClause18360); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_COMMA.add(COMMA1000);

					pushFollow(FOLLOW_columnAssignmentClause_in_setColumnsClause18362);
					columnAssignmentClause1001=columnAssignmentClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnAssignmentClause.add(columnAssignmentClause1001.getTree());
					}
					break;

				default :
					break loop338;
				}
			}

			// AST REWRITE
			// elements: columnAssignmentClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2817:66: -> ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:69: ^( TOK_SET_COLUMNS_CLAUSE ( columnAssignmentClause )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_COLUMNS_CLAUSE, "TOK_SET_COLUMNS_CLAUSE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2817:94: ( columnAssignmentClause )*
				while ( stream_columnAssignmentClause.hasNext() ) {
					adaptor.addChild(root_1, stream_columnAssignmentClause.nextTree());
				}
				stream_columnAssignmentClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setColumnsClause"


	public static class updateStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "updateStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2824:1: updateStatement : KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) ;
	public final HiveParser.updateStatement_return updateStatement() throws RecognitionException {
		HiveParser.updateStatement_return retval = new HiveParser.updateStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE1002=null;
		ParserRuleReturnScope tableName1003 =null;
		ParserRuleReturnScope setColumnsClause1004 =null;
		ParserRuleReturnScope whereClause1005 =null;

		ASTNode KW_UPDATE1002_tree=null;
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");
		RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");

		 pushMsg("update statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2827:4: ( KW_UPDATE tableName setColumnsClause ( whereClause )? -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2828:4: KW_UPDATE tableName setColumnsClause ( whereClause )?
			{
			KW_UPDATE1002=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateStatement18404); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1002);

			pushFollow(FOLLOW_tableName_in_updateStatement18406);
			tableName1003=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1003.getTree());
			pushFollow(FOLLOW_setColumnsClause_in_updateStatement18408);
			setColumnsClause1004=setColumnsClause();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1004.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2828:41: ( whereClause )?
			int alt339=2;
			int LA339_0 = input.LA(1);
			if ( (LA339_0==KW_WHERE) ) {
				alt339=1;
			}
			switch (alt339) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2828:41: whereClause
					{
					pushFollow(FOLLOW_whereClause_in_updateStatement18410);
					whereClause1005=whereClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_whereClause.add(whereClause1005.getTree());
					}
					break;

			}

			// AST REWRITE
			// elements: setColumnsClause, tableName, whereClause
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2828:54: -> ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2828:57: ^( TOK_UPDATE_TABLE tableName setColumnsClause ( whereClause )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UPDATE_TABLE, "TOK_UPDATE_TABLE"), root_1);
				adaptor.addChild(root_1, stream_tableName.nextTree());
				adaptor.addChild(root_1, stream_setColumnsClause.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2828:103: ( whereClause )?
				if ( stream_whereClause.hasNext() ) {
					adaptor.addChild(root_1, stream_whereClause.nextTree());
				}
				stream_whereClause.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "updateStatement"


	public static class sqlTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "sqlTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2835:1: sqlTransactionStatement : ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement );
	public final HiveParser.sqlTransactionStatement_return sqlTransactionStatement() throws RecognitionException {
		HiveParser.sqlTransactionStatement_return retval = new HiveParser.sqlTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope startTransactionStatement1006 =null;
		ParserRuleReturnScope commitStatement1007 =null;
		ParserRuleReturnScope rollbackStatement1008 =null;
		ParserRuleReturnScope setAutoCommitStatement1009 =null;


		 pushMsg("transaction statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2838:3: ( startTransactionStatement | commitStatement | rollbackStatement | setAutoCommitStatement )
			int alt340=4;
			switch ( input.LA(1) ) {
			case KW_START:
				{
				alt340=1;
				}
				break;
			case KW_COMMIT:
				{
				alt340=2;
				}
				break;
			case KW_ROLLBACK:
				{
				alt340=3;
				}
				break;
			case KW_SET:
				{
				alt340=4;
				}
				break;
			default:
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 340, 0, input);
				throw nvae;
			}
			switch (alt340) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2839:3: startTransactionStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_startTransactionStatement_in_sqlTransactionStatement18452);
					startTransactionStatement1006=startTransactionStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, startTransactionStatement1006.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2840:4: commitStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_commitStatement_in_sqlTransactionStatement18457);
					commitStatement1007=commitStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, commitStatement1007.getTree());

					}
					break;
				case 3 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2841:4: rollbackStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_rollbackStatement_in_sqlTransactionStatement18462);
					rollbackStatement1008=rollbackStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, rollbackStatement1008.getTree());

					}
					break;
				case 4 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2842:4: setAutoCommitStatement
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement18467);
					setAutoCommitStatement1009=setAutoCommitStatement();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, setAutoCommitStatement1009.getTree());

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "sqlTransactionStatement"


	public static class startTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "startTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2845:1: startTransactionStatement : KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) ;
	public final HiveParser.startTransactionStatement_return startTransactionStatement() throws RecognitionException {
		HiveParser.startTransactionStatement_return retval = new HiveParser.startTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_START1010=null;
		Token KW_TRANSACTION1011=null;
		Token COMMA1013=null;
		ParserRuleReturnScope transactionMode1012 =null;
		ParserRuleReturnScope transactionMode1014 =null;

		ASTNode KW_START1010_tree=null;
		ASTNode KW_TRANSACTION1011_tree=null;
		ASTNode COMMA1013_tree=null;
		RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
		RewriteRuleTokenStream stream_KW_START=new RewriteRuleTokenStream(adaptor,"token KW_START");
		RewriteRuleTokenStream stream_KW_TRANSACTION=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTION");
		RewriteRuleSubtreeStream stream_transactionMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionMode");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2846:3: ( KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )? -> ^( TOK_START_TRANSACTION ( transactionMode )* ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:3: KW_START KW_TRANSACTION ( transactionMode ( COMMA transactionMode )* )?
			{
			KW_START1010=(Token)match(input,KW_START,FOLLOW_KW_START_in_startTransactionStatement18481); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_START.add(KW_START1010);

			KW_TRANSACTION1011=(Token)match(input,KW_TRANSACTION,FOLLOW_KW_TRANSACTION_in_startTransactionStatement18483); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRANSACTION.add(KW_TRANSACTION1011);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:27: ( transactionMode ( COMMA transactionMode )* )?
			int alt342=2;
			int LA342_0 = input.LA(1);
			if ( (LA342_0==KW_ISOLATION||LA342_0==KW_READ) ) {
				alt342=1;
			}
			switch (alt342) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:29: transactionMode ( COMMA transactionMode )*
					{
					pushFollow(FOLLOW_transactionMode_in_startTransactionStatement18487);
					transactionMode1012=transactionMode();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode1012.getTree());
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:46: ( COMMA transactionMode )*
					loop341:
					while (true) {
						int alt341=2;
						int LA341_0 = input.LA(1);
						if ( (LA341_0==COMMA) ) {
							alt341=1;
						}

						switch (alt341) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:48: COMMA transactionMode
							{
							COMMA1013=(Token)match(input,COMMA,FOLLOW_COMMA_in_startTransactionStatement18492); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_COMMA.add(COMMA1013);

							pushFollow(FOLLOW_transactionMode_in_startTransactionStatement18494);
							transactionMode1014=transactionMode();
							state._fsp--;
							if (state.failed) return retval;
							if ( state.backtracking==0 ) stream_transactionMode.add(transactionMode1014.getTree());
							}
							break;

						default :
							break loop341;
						}
					}

					}
					break;

			}

			// AST REWRITE
			// elements: transactionMode
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2847:77: -> ^( TOK_START_TRANSACTION ( transactionMode )* )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:80: ^( TOK_START_TRANSACTION ( transactionMode )* )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_START_TRANSACTION, "TOK_START_TRANSACTION"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2847:104: ( transactionMode )*
				while ( stream_transactionMode.hasNext() ) {
					adaptor.addChild(root_1, stream_transactionMode.nextTree());
				}
				stream_transactionMode.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "startTransactionStatement"


	public static class transactionMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "transactionMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2850:1: transactionMode : ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) );
	public final HiveParser.transactionMode_return transactionMode() throws RecognitionException {
		HiveParser.transactionMode_return retval = new HiveParser.transactionMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope isolationLevel1015 =null;
		ParserRuleReturnScope transactionAccessMode1016 =null;

		RewriteRuleSubtreeStream stream_transactionAccessMode=new RewriteRuleSubtreeStream(adaptor,"rule transactionAccessMode");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2851:3: ( isolationLevel | transactionAccessMode -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode ) )
			int alt343=2;
			int LA343_0 = input.LA(1);
			if ( (LA343_0==KW_ISOLATION) ) {
				alt343=1;
			}
			else if ( (LA343_0==KW_READ) ) {
				alt343=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 343, 0, input);
				throw nvae;
			}

			switch (alt343) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2852:3: isolationLevel
					{
					root_0 = (ASTNode)adaptor.nil();


					pushFollow(FOLLOW_isolationLevel_in_transactionMode18525);
					isolationLevel1015=isolationLevel();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, isolationLevel1015.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2853:5: transactionAccessMode
					{
					pushFollow(FOLLOW_transactionAccessMode_in_transactionMode18531);
					transactionAccessMode1016=transactionAccessMode();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_transactionAccessMode.add(transactionAccessMode1016.getTree());
					// AST REWRITE
					// elements: transactionAccessMode
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2853:27: -> ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2853:30: ^( TOK_TXN_ACCESS_MODE transactionAccessMode )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TXN_ACCESS_MODE, "TOK_TXN_ACCESS_MODE"), root_1);
						adaptor.addChild(root_1, stream_transactionAccessMode.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "transactionMode"


	public static class transactionAccessMode_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "transactionAccessMode"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2856:1: transactionAccessMode : ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE );
	public final HiveParser.transactionAccessMode_return transactionAccessMode() throws RecognitionException {
		HiveParser.transactionAccessMode_return retval = new HiveParser.transactionAccessMode_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_READ1017=null;
		Token KW_ONLY1018=null;
		Token KW_READ1019=null;
		Token KW_WRITE1020=null;

		ASTNode KW_READ1017_tree=null;
		ASTNode KW_ONLY1018_tree=null;
		ASTNode KW_READ1019_tree=null;
		ASTNode KW_WRITE1020_tree=null;
		RewriteRuleTokenStream stream_KW_READ=new RewriteRuleTokenStream(adaptor,"token KW_READ");
		RewriteRuleTokenStream stream_KW_ONLY=new RewriteRuleTokenStream(adaptor,"token KW_ONLY");
		RewriteRuleTokenStream stream_KW_WRITE=new RewriteRuleTokenStream(adaptor,"token KW_WRITE");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2857:3: ( KW_READ KW_ONLY -> TOK_TXN_READ_ONLY | KW_READ KW_WRITE -> TOK_TXN_READ_WRITE )
			int alt344=2;
			int LA344_0 = input.LA(1);
			if ( (LA344_0==KW_READ) ) {
				int LA344_1 = input.LA(2);
				if ( (LA344_1==KW_ONLY) ) {
					alt344=1;
				}
				else if ( (LA344_1==KW_WRITE) ) {
					alt344=2;
				}

				else {
					if (state.backtracking>0) {state.failed=true; return retval;}
					int nvaeMark = input.mark();
					try {
						input.consume();
						NoViableAltException nvae =
							new NoViableAltException("", 344, 1, input);
						throw nvae;
					} finally {
						input.rewind(nvaeMark);
					}
				}

			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 344, 0, input);
				throw nvae;
			}

			switch (alt344) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2858:3: KW_READ KW_ONLY
					{
					KW_READ1017=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode18554); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ1017);

					KW_ONLY1018=(Token)match(input,KW_ONLY,FOLLOW_KW_ONLY_in_transactionAccessMode18556); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_ONLY.add(KW_ONLY1018);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2858:19: -> TOK_TXN_READ_ONLY
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TXN_READ_ONLY, "TOK_TXN_READ_ONLY"));
					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2859:5: KW_READ KW_WRITE
					{
					KW_READ1019=(Token)match(input,KW_READ,FOLLOW_KW_READ_in_transactionAccessMode18566); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_READ.add(KW_READ1019);

					KW_WRITE1020=(Token)match(input,KW_WRITE,FOLLOW_KW_WRITE_in_transactionAccessMode18568); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WRITE.add(KW_WRITE1020);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2859:22: -> TOK_TXN_READ_WRITE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_TXN_READ_WRITE, "TOK_TXN_READ_WRITE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "transactionAccessMode"


	public static class isolationLevel_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "isolationLevel"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2862:1: isolationLevel : KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) ;
	public final HiveParser.isolationLevel_return isolationLevel() throws RecognitionException {
		HiveParser.isolationLevel_return retval = new HiveParser.isolationLevel_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ISOLATION1021=null;
		Token KW_LEVEL1022=null;
		ParserRuleReturnScope levelOfIsolation1023 =null;

		ASTNode KW_ISOLATION1021_tree=null;
		ASTNode KW_LEVEL1022_tree=null;
		RewriteRuleTokenStream stream_KW_LEVEL=new RewriteRuleTokenStream(adaptor,"token KW_LEVEL");
		RewriteRuleTokenStream stream_KW_ISOLATION=new RewriteRuleTokenStream(adaptor,"token KW_ISOLATION");
		RewriteRuleSubtreeStream stream_levelOfIsolation=new RewriteRuleSubtreeStream(adaptor,"rule levelOfIsolation");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2863:3: ( KW_ISOLATION KW_LEVEL levelOfIsolation -> ^( TOK_ISOLATION_LEVEL levelOfIsolation ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2864:3: KW_ISOLATION KW_LEVEL levelOfIsolation
			{
			KW_ISOLATION1021=(Token)match(input,KW_ISOLATION,FOLLOW_KW_ISOLATION_in_isolationLevel18587); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ISOLATION.add(KW_ISOLATION1021);

			KW_LEVEL1022=(Token)match(input,KW_LEVEL,FOLLOW_KW_LEVEL_in_isolationLevel18589); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_LEVEL.add(KW_LEVEL1022);

			pushFollow(FOLLOW_levelOfIsolation_in_isolationLevel18591);
			levelOfIsolation1023=levelOfIsolation();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_levelOfIsolation.add(levelOfIsolation1023.getTree());
			// AST REWRITE
			// elements: levelOfIsolation
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2864:42: -> ^( TOK_ISOLATION_LEVEL levelOfIsolation )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2864:45: ^( TOK_ISOLATION_LEVEL levelOfIsolation )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ISOLATION_LEVEL, "TOK_ISOLATION_LEVEL"), root_1);
				adaptor.addChild(root_1, stream_levelOfIsolation.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "isolationLevel"


	public static class levelOfIsolation_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "levelOfIsolation"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2868:1: levelOfIsolation : KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT ;
	public final HiveParser.levelOfIsolation_return levelOfIsolation() throws RecognitionException {
		HiveParser.levelOfIsolation_return retval = new HiveParser.levelOfIsolation_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SNAPSHOT1024=null;

		ASTNode KW_SNAPSHOT1024_tree=null;
		RewriteRuleTokenStream stream_KW_SNAPSHOT=new RewriteRuleTokenStream(adaptor,"token KW_SNAPSHOT");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2869:3: ( KW_SNAPSHOT -> TOK_ISOLATION_SNAPSHOT )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2870:3: KW_SNAPSHOT
			{
			KW_SNAPSHOT1024=(Token)match(input,KW_SNAPSHOT,FOLLOW_KW_SNAPSHOT_in_levelOfIsolation18616); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SNAPSHOT.add(KW_SNAPSHOT1024);

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2870:15: -> TOK_ISOLATION_SNAPSHOT
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_ISOLATION_SNAPSHOT, "TOK_ISOLATION_SNAPSHOT"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "levelOfIsolation"


	public static class commitStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "commitStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2873:1: commitStatement : KW_COMMIT ( KW_WORK )? -> TOK_COMMIT ;
	public final HiveParser.commitStatement_return commitStatement() throws RecognitionException {
		HiveParser.commitStatement_return retval = new HiveParser.commitStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_COMMIT1025=null;
		Token KW_WORK1026=null;

		ASTNode KW_COMMIT1025_tree=null;
		ASTNode KW_WORK1026_tree=null;
		RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");
		RewriteRuleTokenStream stream_KW_COMMIT=new RewriteRuleTokenStream(adaptor,"token KW_COMMIT");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2874:3: ( KW_COMMIT ( KW_WORK )? -> TOK_COMMIT )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2875:3: KW_COMMIT ( KW_WORK )?
			{
			KW_COMMIT1025=(Token)match(input,KW_COMMIT,FOLLOW_KW_COMMIT_in_commitStatement18635); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_COMMIT.add(KW_COMMIT1025);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2875:13: ( KW_WORK )?
			int alt345=2;
			int LA345_0 = input.LA(1);
			if ( (LA345_0==KW_WORK) ) {
				alt345=1;
			}
			switch (alt345) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2875:15: KW_WORK
					{
					KW_WORK1026=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_commitStatement18639); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK1026);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2875:26: -> TOK_COMMIT
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_COMMIT, "TOK_COMMIT"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "commitStatement"


	public static class rollbackStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "rollbackStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2878:1: rollbackStatement : KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK ;
	public final HiveParser.rollbackStatement_return rollbackStatement() throws RecognitionException {
		HiveParser.rollbackStatement_return retval = new HiveParser.rollbackStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ROLLBACK1027=null;
		Token KW_WORK1028=null;

		ASTNode KW_ROLLBACK1027_tree=null;
		ASTNode KW_WORK1028_tree=null;
		RewriteRuleTokenStream stream_KW_ROLLBACK=new RewriteRuleTokenStream(adaptor,"token KW_ROLLBACK");
		RewriteRuleTokenStream stream_KW_WORK=new RewriteRuleTokenStream(adaptor,"token KW_WORK");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2879:3: ( KW_ROLLBACK ( KW_WORK )? -> TOK_ROLLBACK )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2880:3: KW_ROLLBACK ( KW_WORK )?
			{
			KW_ROLLBACK1027=(Token)match(input,KW_ROLLBACK,FOLLOW_KW_ROLLBACK_in_rollbackStatement18661); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ROLLBACK.add(KW_ROLLBACK1027);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2880:15: ( KW_WORK )?
			int alt346=2;
			int LA346_0 = input.LA(1);
			if ( (LA346_0==KW_WORK) ) {
				alt346=1;
			}
			switch (alt346) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2880:17: KW_WORK
					{
					KW_WORK1028=(Token)match(input,KW_WORK,FOLLOW_KW_WORK_in_rollbackStatement18665); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_WORK.add(KW_WORK1028);

					}
					break;

			}

			// AST REWRITE
			// elements: 
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2880:28: -> TOK_ROLLBACK
			{
				adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_ROLLBACK, "TOK_ROLLBACK"));
			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "rollbackStatement"


	public static class setAutoCommitStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "setAutoCommitStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2882:1: setAutoCommitStatement : KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) ;
	public final HiveParser.setAutoCommitStatement_return setAutoCommitStatement() throws RecognitionException {
		HiveParser.setAutoCommitStatement_return retval = new HiveParser.setAutoCommitStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_SET1029=null;
		Token KW_AUTOCOMMIT1030=null;
		ParserRuleReturnScope booleanValueTok1031 =null;

		ASTNode KW_SET1029_tree=null;
		ASTNode KW_AUTOCOMMIT1030_tree=null;
		RewriteRuleTokenStream stream_KW_AUTOCOMMIT=new RewriteRuleTokenStream(adaptor,"token KW_AUTOCOMMIT");
		RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
		RewriteRuleSubtreeStream stream_booleanValueTok=new RewriteRuleSubtreeStream(adaptor,"rule booleanValueTok");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2883:3: ( KW_SET KW_AUTOCOMMIT booleanValueTok -> ^( TOK_SET_AUTOCOMMIT booleanValueTok ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2884:3: KW_SET KW_AUTOCOMMIT booleanValueTok
			{
			KW_SET1029=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_setAutoCommitStatement18686); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_SET.add(KW_SET1029);

			KW_AUTOCOMMIT1030=(Token)match(input,KW_AUTOCOMMIT,FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement18688); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AUTOCOMMIT.add(KW_AUTOCOMMIT1030);

			pushFollow(FOLLOW_booleanValueTok_in_setAutoCommitStatement18690);
			booleanValueTok1031=booleanValueTok();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_booleanValueTok.add(booleanValueTok1031.getTree());
			// AST REWRITE
			// elements: booleanValueTok
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2884:40: -> ^( TOK_SET_AUTOCOMMIT booleanValueTok )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2884:43: ^( TOK_SET_AUTOCOMMIT booleanValueTok )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_SET_AUTOCOMMIT, "TOK_SET_AUTOCOMMIT"), root_1);
				adaptor.addChild(root_1, stream_booleanValueTok.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "setAutoCommitStatement"


	public static class abortTransactionStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "abortTransactionStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2890:1: abortTransactionStatement : KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) ;
	public final HiveParser.abortTransactionStatement_return abortTransactionStatement() throws RecognitionException {
		HiveParser.abortTransactionStatement_return retval = new HiveParser.abortTransactionStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_ABORT1032=null;
		Token KW_TRANSACTIONS1033=null;
		Token Number1034=null;

		ASTNode KW_ABORT1032_tree=null;
		ASTNode KW_TRANSACTIONS1033_tree=null;
		ASTNode Number1034_tree=null;
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_KW_TRANSACTIONS=new RewriteRuleTokenStream(adaptor,"token KW_TRANSACTIONS");
		RewriteRuleTokenStream stream_KW_ABORT=new RewriteRuleTokenStream(adaptor,"token KW_ABORT");

		 pushMsg("abort transactions statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2893:3: ( KW_ABORT KW_TRANSACTIONS ( Number )+ -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2894:3: KW_ABORT KW_TRANSACTIONS ( Number )+
			{
			KW_ABORT1032=(Token)match(input,KW_ABORT,FOLLOW_KW_ABORT_in_abortTransactionStatement18725); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ABORT.add(KW_ABORT1032);

			KW_TRANSACTIONS1033=(Token)match(input,KW_TRANSACTIONS,FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement18727); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TRANSACTIONS.add(KW_TRANSACTIONS1033);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2894:28: ( Number )+
			int cnt347=0;
			loop347:
			while (true) {
				int alt347=2;
				int LA347_0 = input.LA(1);
				if ( (LA347_0==Number) ) {
					alt347=1;
				}

				switch (alt347) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2894:30: Number
					{
					Number1034=(Token)match(input,Number,FOLLOW_Number_in_abortTransactionStatement18731); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_Number.add(Number1034);

					}
					break;

				default :
					if ( cnt347 >= 1 ) break loop347;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(347, input);
					throw eee;
				}
				cnt347++;
			}

			// AST REWRITE
			// elements: Number
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2894:40: -> ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2894:43: ^( TOK_ABORT_TRANSACTIONS ( Number )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_ABORT_TRANSACTIONS, "TOK_ABORT_TRANSACTIONS"), root_1);
				if ( !(stream_Number.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_Number.hasNext() ) {
					adaptor.addChild(root_1, stream_Number.nextNode());
				}
				stream_Number.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "abortTransactionStatement"


	public static class mergeStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "mergeStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2901:1: mergeStatement : KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses ) ;
	public final HiveParser.mergeStatement_return mergeStatement() throws RecognitionException {
		HiveParser.mergeStatement_return retval = new HiveParser.mergeStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_MERGE1035=null;
		Token QUERY_HINT1036=null;
		Token KW_INTO1037=null;
		Token KW_AS1039=null;
		Token KW_USING1041=null;
		Token KW_ON1043=null;
		ParserRuleReturnScope tableName1038 =null;
		ParserRuleReturnScope identifier1040 =null;
		ParserRuleReturnScope joinSourcePart1042 =null;
		ParserRuleReturnScope expression1044 =null;
		ParserRuleReturnScope whenClauses1045 =null;

		ASTNode KW_MERGE1035_tree=null;
		ASTNode QUERY_HINT1036_tree=null;
		ASTNode KW_INTO1037_tree=null;
		ASTNode KW_AS1039_tree=null;
		ASTNode KW_USING1041_tree=null;
		ASTNode KW_ON1043_tree=null;
		RewriteRuleTokenStream stream_KW_MERGE=new RewriteRuleTokenStream(adaptor,"token KW_MERGE");
		RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
		RewriteRuleTokenStream stream_KW_USING=new RewriteRuleTokenStream(adaptor,"token KW_USING");
		RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
		RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
		RewriteRuleTokenStream stream_QUERY_HINT=new RewriteRuleTokenStream(adaptor,"token QUERY_HINT");
		RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_whenClauses=new RewriteRuleSubtreeStream(adaptor,"rule whenClauses");
		RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
		RewriteRuleSubtreeStream stream_joinSourcePart=new RewriteRuleSubtreeStream(adaptor,"rule joinSourcePart");

		 pushMsg("MERGE statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2904:4: ( KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:4: KW_MERGE ( QUERY_HINT )? KW_INTO tableName ( ( KW_AS )? identifier )? KW_USING joinSourcePart KW_ON expression whenClauses
			{
			KW_MERGE1035=(Token)match(input,KW_MERGE,FOLLOW_KW_MERGE_in_mergeStatement18777); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MERGE.add(KW_MERGE1035);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:13: ( QUERY_HINT )?
			int alt348=2;
			int LA348_0 = input.LA(1);
			if ( (LA348_0==QUERY_HINT) ) {
				alt348=1;
			}
			switch (alt348) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:13: QUERY_HINT
					{
					QUERY_HINT1036=(Token)match(input,QUERY_HINT,FOLLOW_QUERY_HINT_in_mergeStatement18779); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_QUERY_HINT.add(QUERY_HINT1036);

					}
					break;

			}

			KW_INTO1037=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_mergeStatement18782); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INTO.add(KW_INTO1037);

			pushFollow(FOLLOW_tableName_in_mergeStatement18784);
			tableName1038=tableName();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_tableName.add(tableName1038.getTree());
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:43: ( ( KW_AS )? identifier )?
			int alt350=2;
			int LA350_0 = input.LA(1);
			if ( (LA350_0==Identifier||(LA350_0 >= KW_ABORT && LA350_0 <= KW_AFTER)||LA350_0==KW_ALLOC_FRACTION||LA350_0==KW_ANALYZE||LA350_0==KW_ARCHIVE||(LA350_0 >= KW_AS && LA350_0 <= KW_AT)||(LA350_0 >= KW_AUTOCOMMIT && LA350_0 <= KW_BEFORE)||(LA350_0 >= KW_BUCKET && LA350_0 <= KW_BUCKETS)||(LA350_0 >= KW_CACHE && LA350_0 <= KW_CASCADE)||(LA350_0 >= KW_CBO && LA350_0 <= KW_CHANGE)||(LA350_0 >= KW_CHECK && LA350_0 <= KW_COLLECTION)||(LA350_0 >= KW_COLUMNS && LA350_0 <= KW_COMMENT)||(LA350_0 >= KW_COMPACT && LA350_0 <= KW_CONCATENATE)||(LA350_0 >= KW_CONTINUE && LA350_0 <= KW_COST)||LA350_0==KW_CRON||LA350_0==KW_DATA||LA350_0==KW_DATABASES||(LA350_0 >= KW_DATETIME && LA350_0 <= KW_DCPROPERTIES)||LA350_0==KW_DEBUG||(LA350_0 >= KW_DEFAULT && LA350_0 <= KW_DEFINED)||(LA350_0 >= KW_DELIMITED && LA350_0 <= KW_DESC)||(LA350_0 >= KW_DETAIL && LA350_0 <= KW_DISABLE)||(LA350_0 >= KW_DISTRIBUTE && LA350_0 <= KW_DO)||LA350_0==KW_DOW||(LA350_0 >= KW_DUMP && LA350_0 <= KW_ELEM_TYPE)||LA350_0==KW_ENABLE||(LA350_0 >= KW_ENFORCED && LA350_0 <= KW_EVERY)||(LA350_0 >= KW_EXCLUSIVE && LA350_0 <= KW_EXECUTED)||(LA350_0 >= KW_EXPIRE_SNAPSHOTS && LA350_0 <= KW_EXPRESSION)||(LA350_0 >= KW_FIELDS && LA350_0 <= KW_FIRST)||(LA350_0 >= KW_FORMAT && LA350_0 <= KW_FORMATTED)||LA350_0==KW_FUNCTIONS||(LA350_0 >= KW_HOUR && LA350_0 <= KW_IDXPROPERTIES)||LA350_0==KW_IGNORE||(LA350_0 >= KW_INDEX && LA350_0 <= KW_INDEXES)||(LA350_0 >= KW_INPATH && LA350_0 <= KW_INPUTFORMAT)||(LA350_0 >= KW_ISOLATION && LA350_0 <= KW_JAR)||(LA350_0 >= KW_JOINCOST && LA350_0 <= KW_LAST)||LA350_0==KW_LEVEL||(LA350_0 >= KW_LIMIT && LA350_0 <= KW_LOAD)||(LA350_0 >= KW_LOCATION && LA350_0 <= KW_LONG)||(LA350_0 >= KW_MANAGED && LA350_0 <= KW_MANAGEMENT)||(LA350_0 >= KW_MAPJOIN && LA350_0 <= KW_MATERIALIZED)||LA350_0==KW_METADATA||(LA350_0 >= KW_MINUTE && LA350_0 <= KW_MONTH)||(LA350_0 >= KW_MOVE && LA350_0 <= KW_MSCK)||(LA350_0 >= KW_NORELY && LA350_0 <= KW_NOSCAN)||LA350_0==KW_NOVALIDATE||LA350_0==KW_NULLS||LA350_0==KW_OFFSET||(LA350_0 >= KW_OPERATOR && LA350_0 <= KW_OPTION)||(LA350_0 >= KW_OUTPUTDRIVER && LA350_0 <= KW_OUTPUTFORMAT)||(LA350_0 >= KW_OVERWRITE && LA350_0 <= KW_OWNER)||(LA350_0 >= KW_PARTITIONED && LA350_0 <= KW_PATH)||(LA350_0 >= KW_PLAN && LA350_0 <= KW_POOL)||LA350_0==KW_PRINCIPALS||LA350_0==KW_PURGE||(LA350_0 >= KW_QUARTER && LA350_0 <= KW_QUERY_PARALLELISM)||LA350_0==KW_READ||(LA350_0 >= KW_REBUILD && LA350_0 <= KW_RECORDWRITER)||(LA350_0 >= KW_RELOAD && LA350_0 <= KW_RESTRICT)||LA350_0==KW_REWRITE||(LA350_0 >= KW_ROLE && LA350_0 <= KW_ROLES)||(LA350_0 >= KW_SCHEDULED && LA350_0 <= KW_SECOND)||(LA350_0 >= KW_SEMI && LA350_0 <= KW_SERVER)||(LA350_0 >= KW_SETS && LA350_0 <= KW_SKEWED)||LA350_0==KW_SNAPSHOT||(LA350_0 >= KW_SORT && LA350_0 <= KW_SSL)||(LA350_0 >= KW_STATISTICS && LA350_0 <= KW_SUMMARY)||(LA350_0 >= KW_SYSTEM_TIME && LA350_0 <= KW_SYSTEM_VERSION)||LA350_0==KW_TABLES||(LA350_0 >= KW_TBLPROPERTIES && LA350_0 <= KW_TERMINATED)||LA350_0==KW_TINYINT||LA350_0==KW_TOUCH||(LA350_0 >= KW_TRANSACTION && LA350_0 <= KW_TRANSACTIONS)||LA350_0==KW_TRIM||(LA350_0 >= KW_TYPE && LA350_0 <= KW_UNARCHIVE)||LA350_0==KW_UNDO||LA350_0==KW_UNIONTYPE||(LA350_0 >= KW_UNKNOWN && LA350_0 <= KW_UNSIGNED)||(LA350_0 >= KW_URI && LA350_0 <= KW_USE)||(LA350_0 >= KW_UTC && LA350_0 <= KW_VALIDATE)||LA350_0==KW_VALUE_TYPE||(LA350_0 >= KW_VECTORIZATION && LA350_0 <= KW_WEEK)||LA350_0==KW_WHILE||(LA350_0 >= KW_WITHIN && LA350_0 <= KW_ZONE)||LA350_0==KW_BATCH||LA350_0==KW_DAYOFWEEK||LA350_0==KW_HOLD_DDLTIME||LA350_0==KW_NO_DROP||LA350_0==KW_OFFLINE||LA350_0==KW_PROTECTION||LA350_0==KW_READONLY||LA350_0==KW_TIMESTAMPTZ) ) {
				alt350=1;
			}
			switch (alt350) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:44: ( KW_AS )? identifier
					{
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:44: ( KW_AS )?
					int alt349=2;
					int LA349_0 = input.LA(1);
					if ( (LA349_0==KW_AS) ) {
						alt349=1;
					}
					switch (alt349) {
						case 1 :
							// org/apache/hadoop/hive/ql/parse/HiveParser.g:2905:44: KW_AS
							{
							KW_AS1039=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_mergeStatement18787); if (state.failed) return retval; 
							if ( state.backtracking==0 ) stream_KW_AS.add(KW_AS1039);

							}
							break;

					}

					pushFollow(FOLLOW_identifier_in_mergeStatement18790);
					identifier1040=identifier();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_identifier.add(identifier1040.getTree());
					}
					break;

			}

			KW_USING1041=(Token)match(input,KW_USING,FOLLOW_KW_USING_in_mergeStatement18794); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_USING.add(KW_USING1041);

			pushFollow(FOLLOW_joinSourcePart_in_mergeStatement18796);
			joinSourcePart1042=joinSourcePart();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_joinSourcePart.add(joinSourcePart1042.getTree());
			KW_ON1043=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_mergeStatement18798); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ON.add(KW_ON1043);

			pushFollow(FOLLOW_expression_in_mergeStatement18800);
			expression1044=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression1044.getTree());
			pushFollow(FOLLOW_whenClauses_in_mergeStatement18802);
			whenClauses1045=whenClauses();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_whenClauses.add(whenClauses1045.getTree());
			// AST REWRITE
			// elements: tableName, QUERY_HINT, identifier, joinSourcePart, whenClauses, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2906:6: -> ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:9: ^( TOK_MERGE ^( TOK_TABREF tableName ( identifier )? ) joinSourcePart expression ( QUERY_HINT )? whenClauses )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MERGE, "TOK_MERGE"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:21: ^( TOK_TABREF tableName ( identifier )? )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_TABREF, "TOK_TABREF"), root_2);
				adaptor.addChild(root_2, stream_tableName.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:44: ( identifier )?
				if ( stream_identifier.hasNext() ) {
					adaptor.addChild(root_2, stream_identifier.nextTree());
				}
				stream_identifier.reset();

				adaptor.addChild(root_1, root_2);
				}

				adaptor.addChild(root_1, stream_joinSourcePart.nextTree());
				adaptor.addChild(root_1, stream_expression.nextTree());
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2906:83: ( QUERY_HINT )?
				if ( stream_QUERY_HINT.hasNext() ) {
					adaptor.addChild(root_1, stream_QUERY_HINT.nextNode());
				}
				stream_QUERY_HINT.reset();

				adaptor.addChild(root_1, stream_whenClauses.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "mergeStatement"


	public static class whenClauses_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenClauses"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2914:1: whenClauses : ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? ;
	public final HiveParser.whenClauses_return whenClauses() throws RecognitionException {
		HiveParser.whenClauses_return retval = new HiveParser.whenClauses_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		ParserRuleReturnScope whenMatchedAndClause1046 =null;
		ParserRuleReturnScope whenMatchedThenClause1047 =null;
		ParserRuleReturnScope whenNotMatchedClause1048 =null;


		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2915:4: ( ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )? )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:4: ( whenMatchedAndClause | whenMatchedThenClause )* ( whenNotMatchedClause )?
			{
			root_0 = (ASTNode)adaptor.nil();


			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:4: ( whenMatchedAndClause | whenMatchedThenClause )*
			loop351:
			while (true) {
				int alt351=3;
				int LA351_0 = input.LA(1);
				if ( (LA351_0==KW_WHEN) ) {
					int LA351_1 = input.LA(2);
					if ( (LA351_1==KW_MATCHED) ) {
						int LA351_4 = input.LA(3);
						if ( (LA351_4==KW_AND) ) {
							alt351=1;
						}
						else if ( (LA351_4==KW_THEN) ) {
							alt351=2;
						}

					}

				}

				switch (alt351) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:5: whenMatchedAndClause
					{
					pushFollow(FOLLOW_whenMatchedAndClause_in_whenClauses18851);
					whenMatchedAndClause1046=whenMatchedAndClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedAndClause1046.getTree());

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:26: whenMatchedThenClause
					{
					pushFollow(FOLLOW_whenMatchedThenClause_in_whenClauses18853);
					whenMatchedThenClause1047=whenMatchedThenClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenMatchedThenClause1047.getTree());

					}
					break;

				default :
					break loop351;
				}
			}

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:50: ( whenNotMatchedClause )?
			int alt352=2;
			int LA352_0 = input.LA(1);
			if ( (LA352_0==KW_WHEN) ) {
				alt352=1;
			}
			switch (alt352) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2916:50: whenNotMatchedClause
					{
					pushFollow(FOLLOW_whenNotMatchedClause_in_whenClauses18857);
					whenNotMatchedClause1048=whenNotMatchedClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) adaptor.addChild(root_0, whenNotMatchedClause1048.getTree());

					}
					break;

			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenClauses"


	public static class whenNotMatchedClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenNotMatchedClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2918:1: whenNotMatchedClause : KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? ) ;
	public final HiveParser.whenNotMatchedClause_return whenNotMatchedClause() throws RecognitionException {
		HiveParser.whenNotMatchedClause_return retval = new HiveParser.whenNotMatchedClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1049=null;
		Token KW_NOT1050=null;
		Token KW_MATCHED1051=null;
		Token KW_AND1052=null;
		Token KW_THEN1054=null;
		Token KW_INSERT1055=null;
		Token KW_VALUES1056=null;
		ParserRuleReturnScope targetCols =null;
		ParserRuleReturnScope expression1053 =null;
		ParserRuleReturnScope valueRowConstructor1057 =null;

		ASTNode KW_WHEN1049_tree=null;
		ASTNode KW_NOT1050_tree=null;
		ASTNode KW_MATCHED1051_tree=null;
		ASTNode KW_AND1052_tree=null;
		ASTNode KW_THEN1054_tree=null;
		ASTNode KW_INSERT1055_tree=null;
		ASTNode KW_VALUES1056_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleTokenStream stream_KW_VALUES=new RewriteRuleTokenStream(adaptor,"token KW_VALUES");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_columnParenthesesList=new RewriteRuleSubtreeStream(adaptor,"rule columnParenthesesList");
		RewriteRuleSubtreeStream stream_valueRowConstructor=new RewriteRuleSubtreeStream(adaptor,"rule valueRowConstructor");

		 pushMsg("WHEN NOT MATCHED clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2921:4: ( KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:3: KW_WHEN KW_NOT KW_MATCHED ( KW_AND expression )? KW_THEN KW_INSERT (targetCols= columnParenthesesList )? KW_VALUES valueRowConstructor
			{
			KW_WHEN1049=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenNotMatchedClause18884); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1049);

			KW_NOT1050=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_whenNotMatchedClause18886); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_NOT.add(KW_NOT1050);

			KW_MATCHED1051=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenNotMatchedClause18888); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1051);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:29: ( KW_AND expression )?
			int alt353=2;
			int LA353_0 = input.LA(1);
			if ( (LA353_0==KW_AND) ) {
				alt353=1;
			}
			switch (alt353) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:30: KW_AND expression
					{
					KW_AND1052=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenNotMatchedClause18891); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1052);

					pushFollow(FOLLOW_expression_in_whenNotMatchedClause18893);
					expression1053=expression();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_expression.add(expression1053.getTree());
					}
					break;

			}

			KW_THEN1054=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenNotMatchedClause18897); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1054);

			KW_INSERT1055=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_whenNotMatchedClause18899); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_INSERT.add(KW_INSERT1055);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:68: (targetCols= columnParenthesesList )?
			int alt354=2;
			int LA354_0 = input.LA(1);
			if ( (LA354_0==LPAREN) ) {
				alt354=1;
			}
			switch (alt354) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2922:69: targetCols= columnParenthesesList
					{
					pushFollow(FOLLOW_columnParenthesesList_in_whenNotMatchedClause18904);
					targetCols=columnParenthesesList();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_columnParenthesesList.add(targetCols.getTree());
					}
					break;

			}

			KW_VALUES1056=(Token)match(input,KW_VALUES,FOLLOW_KW_VALUES_in_whenNotMatchedClause18908); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_VALUES.add(KW_VALUES1056);

			pushFollow(FOLLOW_valueRowConstructor_in_whenNotMatchedClause18910);
			valueRowConstructor1057=valueRowConstructor();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_valueRowConstructor.add(valueRowConstructor1057.getTree());
			// AST REWRITE
			// elements: valueRowConstructor, expression, targetCols
			// token labels: 
			// rule labels: targetCols, retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_targetCols=new RewriteRuleSubtreeStream(adaptor,"rule targetCols",targetCols!=null?targetCols.getTree():null);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2922:134: -> ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:5: ^( TOK_NOT_MATCHED ^( TOK_INSERT ( $targetCols)? valueRowConstructor ) ( expression )? )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_NOT_MATCHED, "TOK_NOT_MATCHED"), root_1);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:23: ^( TOK_INSERT ( $targetCols)? valueRowConstructor )
				{
				ASTNode root_2 = (ASTNode)adaptor.nil();
				root_2 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_INSERT, "TOK_INSERT"), root_2);
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:37: ( $targetCols)?
				if ( stream_targetCols.hasNext() ) {
					adaptor.addChild(root_2, stream_targetCols.nextTree());
				}
				stream_targetCols.reset();

				adaptor.addChild(root_2, stream_valueRowConstructor.nextTree());
				adaptor.addChild(root_1, root_2);
				}

				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2923:70: ( expression )?
				if ( stream_expression.hasNext() ) {
					adaptor.addChild(root_1, stream_expression.nextTree());
				}
				stream_expression.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenNotMatchedClause"


	public static class whenMatchedAndClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenMatchedAndClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2925:1: whenMatchedAndClause : KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) ;
	public final HiveParser.whenMatchedAndClause_return whenMatchedAndClause() throws RecognitionException {
		HiveParser.whenMatchedAndClause_return retval = new HiveParser.whenMatchedAndClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1058=null;
		Token KW_MATCHED1059=null;
		Token KW_AND1060=null;
		Token KW_THEN1062=null;
		ParserRuleReturnScope expression1061 =null;
		ParserRuleReturnScope updateOrDelete1063 =null;

		ASTNode KW_WHEN1058_tree=null;
		ASTNode KW_MATCHED1059_tree=null;
		ASTNode KW_AND1060_tree=null;
		ASTNode KW_THEN1062_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_AND=new RewriteRuleTokenStream(adaptor,"token KW_AND");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
		RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");

		 pushMsg("WHEN MATCHED AND clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2928:3: ( KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete expression ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2929:3: KW_WHEN KW_MATCHED KW_AND expression KW_THEN updateOrDelete
			{
			KW_WHEN1058=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedAndClause18957); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1058);

			KW_MATCHED1059=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedAndClause18959); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1059);

			KW_AND1060=(Token)match(input,KW_AND,FOLLOW_KW_AND_in_whenMatchedAndClause18961); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_AND.add(KW_AND1060);

			pushFollow(FOLLOW_expression_in_whenMatchedAndClause18963);
			expression1061=expression();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_expression.add(expression1061.getTree());
			KW_THEN1062=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedAndClause18965); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1062);

			pushFollow(FOLLOW_updateOrDelete_in_whenMatchedAndClause18967);
			updateOrDelete1063=updateOrDelete();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1063.getTree());
			// AST REWRITE
			// elements: updateOrDelete, expression
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2929:63: -> ^( TOK_MATCHED updateOrDelete expression )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2930:5: ^( TOK_MATCHED updateOrDelete expression )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED"), root_1);
				adaptor.addChild(root_1, stream_updateOrDelete.nextTree());
				adaptor.addChild(root_1, stream_expression.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenMatchedAndClause"


	public static class whenMatchedThenClause_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "whenMatchedThenClause"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2932:1: whenMatchedThenClause : KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) ;
	public final HiveParser.whenMatchedThenClause_return whenMatchedThenClause() throws RecognitionException {
		HiveParser.whenMatchedThenClause_return retval = new HiveParser.whenMatchedThenClause_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_WHEN1064=null;
		Token KW_MATCHED1065=null;
		Token KW_THEN1066=null;
		ParserRuleReturnScope updateOrDelete1067 =null;

		ASTNode KW_WHEN1064_tree=null;
		ASTNode KW_MATCHED1065_tree=null;
		ASTNode KW_THEN1066_tree=null;
		RewriteRuleTokenStream stream_KW_WHEN=new RewriteRuleTokenStream(adaptor,"token KW_WHEN");
		RewriteRuleTokenStream stream_KW_THEN=new RewriteRuleTokenStream(adaptor,"token KW_THEN");
		RewriteRuleTokenStream stream_KW_MATCHED=new RewriteRuleTokenStream(adaptor,"token KW_MATCHED");
		RewriteRuleSubtreeStream stream_updateOrDelete=new RewriteRuleSubtreeStream(adaptor,"rule updateOrDelete");

		 pushMsg("WHEN MATCHED THEN clause", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2935:3: ( KW_WHEN KW_MATCHED KW_THEN updateOrDelete -> ^( TOK_MATCHED updateOrDelete ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2936:3: KW_WHEN KW_MATCHED KW_THEN updateOrDelete
			{
			KW_WHEN1064=(Token)match(input,KW_WHEN,FOLLOW_KW_WHEN_in_whenMatchedThenClause19005); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_WHEN.add(KW_WHEN1064);

			KW_MATCHED1065=(Token)match(input,KW_MATCHED,FOLLOW_KW_MATCHED_in_whenMatchedThenClause19007); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_MATCHED.add(KW_MATCHED1065);

			KW_THEN1066=(Token)match(input,KW_THEN,FOLLOW_KW_THEN_in_whenMatchedThenClause19009); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_THEN.add(KW_THEN1066);

			pushFollow(FOLLOW_updateOrDelete_in_whenMatchedThenClause19011);
			updateOrDelete1067=updateOrDelete();
			state._fsp--;
			if (state.failed) return retval;
			if ( state.backtracking==0 ) stream_updateOrDelete.add(updateOrDelete1067.getTree());
			// AST REWRITE
			// elements: updateOrDelete
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2936:45: -> ^( TOK_MATCHED updateOrDelete )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2937:6: ^( TOK_MATCHED updateOrDelete )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_MATCHED, "TOK_MATCHED"), root_1);
				adaptor.addChild(root_1, stream_updateOrDelete.nextTree());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "whenMatchedThenClause"


	public static class updateOrDelete_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "updateOrDelete"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2939:1: updateOrDelete : ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE );
	public final HiveParser.updateOrDelete_return updateOrDelete() throws RecognitionException {
		HiveParser.updateOrDelete_return retval = new HiveParser.updateOrDelete_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_UPDATE1068=null;
		Token KW_DELETE1070=null;
		ParserRuleReturnScope setColumnsClause1069 =null;

		ASTNode KW_UPDATE1068_tree=null;
		ASTNode KW_DELETE1070_tree=null;
		RewriteRuleTokenStream stream_KW_DELETE=new RewriteRuleTokenStream(adaptor,"token KW_DELETE");
		RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
		RewriteRuleSubtreeStream stream_setColumnsClause=new RewriteRuleSubtreeStream(adaptor,"rule setColumnsClause");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2940:4: ( KW_UPDATE setColumnsClause -> ^( TOK_UPDATE setColumnsClause ) | KW_DELETE -> TOK_DELETE )
			int alt355=2;
			int LA355_0 = input.LA(1);
			if ( (LA355_0==KW_UPDATE) ) {
				alt355=1;
			}
			else if ( (LA355_0==KW_DELETE) ) {
				alt355=2;
			}

			else {
				if (state.backtracking>0) {state.failed=true; return retval;}
				NoViableAltException nvae =
					new NoViableAltException("", 355, 0, input);
				throw nvae;
			}

			switch (alt355) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2941:4: KW_UPDATE setColumnsClause
					{
					KW_UPDATE1068=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_updateOrDelete19040); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_UPDATE.add(KW_UPDATE1068);

					pushFollow(FOLLOW_setColumnsClause_in_updateOrDelete19042);
					setColumnsClause1069=setColumnsClause();
					state._fsp--;
					if (state.failed) return retval;
					if ( state.backtracking==0 ) stream_setColumnsClause.add(setColumnsClause1069.getTree());
					// AST REWRITE
					// elements: setColumnsClause
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2941:31: -> ^( TOK_UPDATE setColumnsClause )
					{
						// org/apache/hadoop/hive/ql/parse/HiveParser.g:2941:34: ^( TOK_UPDATE setColumnsClause )
						{
						ASTNode root_1 = (ASTNode)adaptor.nil();
						root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_UPDATE, "TOK_UPDATE"), root_1);
						adaptor.addChild(root_1, stream_setColumnsClause.nextTree());
						adaptor.addChild(root_0, root_1);
						}

					}


					retval.tree = root_0;
					}

					}
					break;
				case 2 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2943:4: KW_DELETE
					{
					KW_DELETE1070=(Token)match(input,KW_DELETE,FOLLOW_KW_DELETE_in_updateOrDelete19060); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_KW_DELETE.add(KW_DELETE1070);

					// AST REWRITE
					// elements: 
					// token labels: 
					// rule labels: retval
					// token list labels: 
					// rule list labels: 
					// wildcard labels: 
					if ( state.backtracking==0 ) {
					retval.tree = root_0;
					RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

					root_0 = (ASTNode)adaptor.nil();
					// 2943:14: -> TOK_DELETE
					{
						adaptor.addChild(root_0, (ASTNode)adaptor.create(TOK_DELETE, "TOK_DELETE"));
					}


					retval.tree = root_0;
					}

					}
					break;

			}
			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "updateOrDelete"


	public static class killQueryStatement_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "killQueryStatement"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2949:1: killQueryStatement : KW_KILL KW_QUERY ( StringLiteral )+ -> ^( TOK_KILL_QUERY ( StringLiteral )+ ) ;
	public final HiveParser.killQueryStatement_return killQueryStatement() throws RecognitionException {
		HiveParser.killQueryStatement_return retval = new HiveParser.killQueryStatement_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token KW_KILL1071=null;
		Token KW_QUERY1072=null;
		Token StringLiteral1073=null;

		ASTNode KW_KILL1071_tree=null;
		ASTNode KW_QUERY1072_tree=null;
		ASTNode StringLiteral1073_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_KILL=new RewriteRuleTokenStream(adaptor,"token KW_KILL");
		RewriteRuleTokenStream stream_KW_QUERY=new RewriteRuleTokenStream(adaptor,"token KW_QUERY");

		 pushMsg("kill query statement", state); 
		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2952:3: ( KW_KILL KW_QUERY ( StringLiteral )+ -> ^( TOK_KILL_QUERY ( StringLiteral )+ ) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2953:3: KW_KILL KW_QUERY ( StringLiteral )+
			{
			KW_KILL1071=(Token)match(input,KW_KILL,FOLLOW_KW_KILL_in_killQueryStatement19092); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_KILL.add(KW_KILL1071);

			KW_QUERY1072=(Token)match(input,KW_QUERY,FOLLOW_KW_QUERY_in_killQueryStatement19094); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_QUERY.add(KW_QUERY1072);

			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2953:20: ( StringLiteral )+
			int cnt356=0;
			loop356:
			while (true) {
				int alt356=2;
				int LA356_0 = input.LA(1);
				if ( (LA356_0==StringLiteral) ) {
					alt356=1;
				}

				switch (alt356) {
				case 1 :
					// org/apache/hadoop/hive/ql/parse/HiveParser.g:2953:22: StringLiteral
					{
					StringLiteral1073=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_killQueryStatement19098); if (state.failed) return retval; 
					if ( state.backtracking==0 ) stream_StringLiteral.add(StringLiteral1073);

					}
					break;

				default :
					if ( cnt356 >= 1 ) break loop356;
					if (state.backtracking>0) {state.failed=true; return retval;}
					EarlyExitException eee = new EarlyExitException(356, input);
					throw eee;
				}
				cnt356++;
			}

			// AST REWRITE
			// elements: StringLiteral
			// token labels: 
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2953:39: -> ^( TOK_KILL_QUERY ( StringLiteral )+ )
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2953:42: ^( TOK_KILL_QUERY ( StringLiteral )+ )
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_KILL_QUERY, "TOK_KILL_QUERY"), root_1);
				if ( !(stream_StringLiteral.hasNext()) ) {
					throw new RewriteEarlyExitException();
				}
				while ( stream_StringLiteral.hasNext() ) {
					adaptor.addChild(root_1, stream_StringLiteral.nextNode());
				}
				stream_StringLiteral.reset();

				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
			if ( state.backtracking==0 ) { popMsg(state); }
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "killQueryStatement"


	public static class compactionId_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "compactionId"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2959:1: compactionId : KW_ID EQUAL compactId= Number -> ^( TOK_COMPACT_ID $compactId) ;
	public final HiveParser.compactionId_return compactionId() throws RecognitionException {
		HiveParser.compactionId_return retval = new HiveParser.compactionId_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token compactId=null;
		Token KW_ID1074=null;
		Token EQUAL1075=null;

		ASTNode compactId_tree=null;
		ASTNode KW_ID1074_tree=null;
		ASTNode EQUAL1075_tree=null;
		RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
		RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
		RewriteRuleTokenStream stream_KW_ID=new RewriteRuleTokenStream(adaptor,"token KW_ID");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2960:3: ( KW_ID EQUAL compactId= Number -> ^( TOK_COMPACT_ID $compactId) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2960:5: KW_ID EQUAL compactId= Number
			{
			KW_ID1074=(Token)match(input,KW_ID,FOLLOW_KW_ID_in_compactionId19129); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_ID.add(KW_ID1074);

			EQUAL1075=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_compactionId19131); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_EQUAL.add(EQUAL1075);

			compactId=(Token)match(input,Number,FOLLOW_Number_in_compactionId19135); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_Number.add(compactId);

			// AST REWRITE
			// elements: compactId
			// token labels: compactId
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_compactId=new RewriteRuleTokenStream(adaptor,"token compactId",compactId);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2960:34: -> ^( TOK_COMPACT_ID $compactId)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2960:37: ^( TOK_COMPACT_ID $compactId)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COMPACT_ID, "TOK_COMPACT_ID"), root_1);
				adaptor.addChild(root_1, stream_compactId.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "compactionId"


	public static class compactionPool_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "compactionPool"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2962:1: compactionPool : KW_POOL poolName= StringLiteral -> ^( TOK_COMPACT_POOL $poolName) ;
	public final HiveParser.compactionPool_return compactionPool() throws RecognitionException {
		HiveParser.compactionPool_return retval = new HiveParser.compactionPool_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token poolName=null;
		Token KW_POOL1076=null;

		ASTNode poolName_tree=null;
		ASTNode KW_POOL1076_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_POOL=new RewriteRuleTokenStream(adaptor,"token KW_POOL");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2963:3: ( KW_POOL poolName= StringLiteral -> ^( TOK_COMPACT_POOL $poolName) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2963:5: KW_POOL poolName= StringLiteral
			{
			KW_POOL1076=(Token)match(input,KW_POOL,FOLLOW_KW_POOL_in_compactionPool19156); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_POOL.add(KW_POOL1076);

			poolName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_compactionPool19160); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(poolName);

			// AST REWRITE
			// elements: poolName
			// token labels: poolName
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_poolName=new RewriteRuleTokenStream(adaptor,"token poolName",poolName);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2963:36: -> ^( TOK_COMPACT_POOL $poolName)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2963:39: ^( TOK_COMPACT_POOL $poolName)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COMPACT_POOL, "TOK_COMPACT_POOL"), root_1);
				adaptor.addChild(root_1, stream_poolName.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "compactionPool"


	public static class compactionType_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "compactionType"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2965:1: compactionType : KW_TYPE compactType= StringLiteral -> ^( TOK_COMPACTION_TYPE $compactType) ;
	public final HiveParser.compactionType_return compactionType() throws RecognitionException {
		HiveParser.compactionType_return retval = new HiveParser.compactionType_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token compactType=null;
		Token KW_TYPE1077=null;

		ASTNode compactType_tree=null;
		ASTNode KW_TYPE1077_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_TYPE=new RewriteRuleTokenStream(adaptor,"token KW_TYPE");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2966:3: ( KW_TYPE compactType= StringLiteral -> ^( TOK_COMPACTION_TYPE $compactType) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2966:5: KW_TYPE compactType= StringLiteral
			{
			KW_TYPE1077=(Token)match(input,KW_TYPE,FOLLOW_KW_TYPE_in_compactionType19181); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_TYPE.add(KW_TYPE1077);

			compactType=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_compactionType19185); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(compactType);

			// AST REWRITE
			// elements: compactType
			// token labels: compactType
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_compactType=new RewriteRuleTokenStream(adaptor,"token compactType",compactType);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2966:39: -> ^( TOK_COMPACTION_TYPE $compactType)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2966:42: ^( TOK_COMPACTION_TYPE $compactType)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COMPACTION_TYPE, "TOK_COMPACTION_TYPE"), root_1);
				adaptor.addChild(root_1, stream_compactType.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "compactionType"


	public static class compactionStatus_return extends ParserRuleReturnScope {
		ASTNode tree;
		@Override
		public ASTNode getTree() { return tree; }
	};


	// $ANTLR start "compactionStatus"
	// org/apache/hadoop/hive/ql/parse/HiveParser.g:2968:1: compactionStatus : KW_STATUS status= StringLiteral -> ^( TOK_COMPACTION_STATUS $status) ;
	public final HiveParser.compactionStatus_return compactionStatus() throws RecognitionException {
		HiveParser.compactionStatus_return retval = new HiveParser.compactionStatus_return();
		retval.start = input.LT(1);

		ASTNode root_0 = null;

		Token status=null;
		Token KW_STATUS1078=null;

		ASTNode status_tree=null;
		ASTNode KW_STATUS1078_tree=null;
		RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
		RewriteRuleTokenStream stream_KW_STATUS=new RewriteRuleTokenStream(adaptor,"token KW_STATUS");

		try {
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:3: ( KW_STATUS status= StringLiteral -> ^( TOK_COMPACTION_STATUS $status) )
			// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:5: KW_STATUS status= StringLiteral
			{
			KW_STATUS1078=(Token)match(input,KW_STATUS,FOLLOW_KW_STATUS_in_compactionStatus19206); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_KW_STATUS.add(KW_STATUS1078);

			status=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_compactionStatus19210); if (state.failed) return retval; 
			if ( state.backtracking==0 ) stream_StringLiteral.add(status);

			// AST REWRITE
			// elements: status
			// token labels: status
			// rule labels: retval
			// token list labels: 
			// rule list labels: 
			// wildcard labels: 
			if ( state.backtracking==0 ) {
			retval.tree = root_0;
			RewriteRuleTokenStream stream_status=new RewriteRuleTokenStream(adaptor,"token status",status);
			RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.getTree():null);

			root_0 = (ASTNode)adaptor.nil();
			// 2969:36: -> ^( TOK_COMPACTION_STATUS $status)
			{
				// org/apache/hadoop/hive/ql/parse/HiveParser.g:2969:39: ^( TOK_COMPACTION_STATUS $status)
				{
				ASTNode root_1 = (ASTNode)adaptor.nil();
				root_1 = (ASTNode)adaptor.becomeRoot((ASTNode)adaptor.create(TOK_COMPACTION_STATUS, "TOK_COMPACTION_STATUS"), root_1);
				adaptor.addChild(root_1, stream_status.nextNode());
				adaptor.addChild(root_0, root_1);
				}

			}


			retval.tree = root_0;
			}

			}

			retval.stop = input.LT(-1);

			if ( state.backtracking==0 ) {
			retval.tree = (ASTNode)adaptor.rulePostProcessing(root_0);
			adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);
			}
		}

		catch (RecognitionException e) {
		 reportError(e);
		  throw e;
		}

		finally {
			// do for sure before leaving
		}
		return retval;
	}
	// $ANTLR end "compactionStatus"

	// $ANTLR start synpred1_HiveParser
	public final void synpred1_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1090:7: ( grantPrivileges )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1090:8: grantPrivileges
		{
		pushFollow(FOLLOW_grantPrivileges_in_synpred1_HiveParser3126);
		grantPrivileges();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred1_HiveParser

	// $ANTLR start synpred2_HiveParser
	public final void synpred2_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:7: ( revokePrivileges )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:8: revokePrivileges
		{
		pushFollow(FOLLOW_revokePrivileges_in_synpred2_HiveParser3140);
		revokePrivileges();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred2_HiveParser

	// $ANTLR start synpred3_HiveParser
	public final void synpred3_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:4: ( KW_ELEM_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:5: KW_ELEM_TYPE
		{
		match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred3_HiveParser4427); if (state.failed) return;

		}

	}
	// $ANTLR end synpred3_HiveParser

	// $ANTLR start synpred4_HiveParser
	public final void synpred4_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:4: ( KW_KEY_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1270:5: KW_KEY_TYPE
		{
		match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred4_HiveParser4443); if (state.failed) return;

		}

	}
	// $ANTLR end synpred4_HiveParser

	// $ANTLR start synpred5_HiveParser
	public final void synpred5_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1272:4: ( KW_VALUE_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1272:5: KW_VALUE_TYPE
		{
		match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred5_HiveParser4459); if (state.failed) return;

		}

	}
	// $ANTLR end synpred5_HiveParser

	// $ANTLR start synpred6_HiveParser
	public final void synpred6_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1296:5: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred6_HiveParser

	// $ANTLR start synpred7_HiveParser
	public final void synpred7_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:5: ( KW_DATACONNECTOR )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:6: KW_DATACONNECTOR
		{
		match(input,KW_DATACONNECTOR,FOLLOW_KW_DATACONNECTOR_in_synpred7_HiveParser4666); if (state.failed) return;

		}

	}
	// $ANTLR end synpred7_HiveParser

	// $ANTLR start synpred8_HiveParser
	public final void synpred8_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:5: ( KW_FUNCTION )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1300:6: KW_FUNCTION
		{
		match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_synpred8_HiveParser4707); if (state.failed) return;

		}

	}
	// $ANTLR end synpred8_HiveParser

	// $ANTLR start synpred9_HiveParser
	public final void synpred9_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:5: ( KW_FORMATTED | KW_EXTENDED )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_EXTENDED||input.LA(1)==KW_FORMATTED ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred9_HiveParser

	// $ANTLR start synpred10_HiveParser
	public final void synpred10_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:7: ( KW_COMPUTE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:8: KW_COMPUTE
		{
		match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_synpred10_HiveParser4860); if (state.failed) return;

		}

	}
	// $ANTLR end synpred10_HiveParser

	// $ANTLR start synpred11_HiveParser
	public final void synpred11_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1317:7: ( KW_CACHE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1317:8: KW_CACHE
		{
		match(input,KW_CACHE,FOLLOW_KW_CACHE_in_synpred11_HiveParser4988); if (state.failed) return;

		}

	}
	// $ANTLR end synpred11_HiveParser

	// $ANTLR start synpred12_HiveParser
	public final void synpred12_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:9: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred12_HiveParser

	// $ANTLR start synpred13_HiveParser
	public final void synpred13_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1343:7: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred13_HiveParser

	// $ANTLR start synpred14_HiveParser
	public final void synpred14_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:7: ( KW_ID )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:8: KW_ID
		{
		match(input,KW_ID,FOLLOW_KW_ID_in_synpred14_HiveParser5687); if (state.failed) return;

		}

	}
	// $ANTLR end synpred14_HiveParser

	// $ANTLR start synpred15_HiveParser
	public final void synpred15_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:7: ( KW_DATABASE | KW_SCHEMA )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:
		{
		if ( input.LA(1)==KW_DATABASE||input.LA(1)==KW_SCHEMA ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred15_HiveParser

	// $ANTLR start synpred16_HiveParser
	public final void synpred16_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:5: ( KW_ALL )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1476:6: KW_ALL
		{
		match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred16_HiveParser6787); if (state.failed) return;

		}

	}
	// $ANTLR end synpred16_HiveParser

	// $ANTLR start synpred17_HiveParser
	public final void synpred17_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:5: ( KW_NONE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1478:6: KW_NONE
		{
		match(input,KW_NONE,FOLLOW_KW_NONE_in_synpred17_HiveParser6818); if (state.failed) return;

		}

	}
	// $ANTLR end synpred17_HiveParser

	// $ANTLR start synpred18_HiveParser
	public final void synpred18_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1502:7: ( KW_ALL )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1502:8: KW_ALL
		{
		match(input,KW_ALL,FOLLOW_KW_ALL_in_synpred18_HiveParser6992); if (state.failed) return;

		}

	}
	// $ANTLR end synpred18_HiveParser

	// $ANTLR start synpred19_HiveParser
	public final void synpred19_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:117: ( storedAsDirs )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:1930:118: storedAsDirs
		{
		pushFollow(FOLLOW_storedAsDirs_in_synpred19_HiveParser10631);
		storedAsDirs();
		state._fsp--;
		if (state.failed) return;

		}

	}
	// $ANTLR end synpred19_HiveParser

	// $ANTLR start synpred20_HiveParser
	public final void synpred20_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:7: ( KW_STORED KW_AS KW_INPUTFORMAT )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2061:8: KW_STORED KW_AS KW_INPUTFORMAT
		{
		match(input,KW_STORED,FOLLOW_KW_STORED_in_synpred20_HiveParser11612); if (state.failed) return;

		match(input,KW_AS,FOLLOW_KW_AS_in_synpred20_HiveParser11614); if (state.failed) return;

		match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_synpred20_HiveParser11616); if (state.failed) return;

		}

	}
	// $ANTLR end synpred20_HiveParser

	// $ANTLR start synpred21_HiveParser
	public final void synpred21_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:25: ( KW_ELEM_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:26: KW_ELEM_TYPE
		{
		match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_synpred21_HiveParser12165); if (state.failed) return;

		}

	}
	// $ANTLR end synpred21_HiveParser

	// $ANTLR start synpred22_HiveParser
	public final void synpred22_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:58: ( KW_KEY_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:59: KW_KEY_TYPE
		{
		match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_synpred22_HiveParser12175); if (state.failed) return;

		}

	}
	// $ANTLR end synpred22_HiveParser

	// $ANTLR start synpred23_HiveParser
	public final void synpred23_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:89: ( KW_VALUE_TYPE )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2117:90: KW_VALUE_TYPE
		{
		match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_synpred23_HiveParser12185); if (state.failed) return;

		}

	}
	// $ANTLR end synpred23_HiveParser

	// $ANTLR start synpred24_HiveParser
	public final void synpred24_HiveParser_fragment() throws RecognitionException {
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2809:5: ( KW_DEFAULT (~ DOT | EOF ) )
		// org/apache/hadoop/hive/ql/parse/HiveParser.g:2809:6: KW_DEFAULT (~ DOT | EOF )
		{
		match(input,KW_DEFAULT,FOLLOW_KW_DEFAULT_in_synpred24_HiveParser18313); if (state.failed) return;

		if ( input.LA(1)==EOF||(input.LA(1) >= AMPERSAND && input.LA(1) <= DOLLAR)||(input.LA(1) >= Digit && input.LA(1) <= TOK_YEAR) ) {
			input.consume();
			state.errorRecovery=false;
			state.failed=false;
		}
		else {
			if (state.backtracking>0) {state.failed=true; return;}
			MismatchedSetException mse = new MismatchedSetException(null,input);
			throw mse;
		}
		}

	}
	// $ANTLR end synpred24_HiveParser

	// Delegated rules
	public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator() throws RecognitionException { return gIdentifiersParser.precedenceUnaryOperator(); }

	public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnarySuffixExpression(); }

	public HiveParser_IdentifiersParser.floorDateQualifiers_return floorDateQualifiers() throws RecognitionException { return gIdentifiersParser.floorDateQualifiers(); }

	public HiveParser_IdentifiersParser.subQuerySelectorOperator_return subQuerySelectorOperator() throws RecognitionException { return gIdentifiersParser.subQuerySelectorOperator(); }

	public HiveParser_ResourcePlanParser.alterTriggerStatement_return alterTriggerStatement() throws RecognitionException { return gResourcePlanParser.alterTriggerStatement(); }

	public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException { return gIdentifiersParser.caseExpression(); }

	public HiveParser_ResourcePlanParser.createPoolStatement_return createPoolStatement() throws RecognitionException { return gResourcePlanParser.createPoolStatement(); }

	public HiveParser_ResourcePlanParser.poolPath_return poolPath() throws RecognitionException { return gResourcePlanParser.poolPath(); }

	public HiveParser_ResourcePlanParser.poolAssign_return poolAssign() throws RecognitionException { return gResourcePlanParser.poolAssign(); }

	public HiveParser_AlterClauseParser.alterMaterializedViewSuffixRebuild_return alterMaterializedViewSuffixRebuild(CommonTree tableNameTree) throws RecognitionException { return gAlterClauseParser.alterMaterializedViewSuffixRebuild(tableNameTree); }

	public HiveParser_AlterClauseParser.skewedLocations_return skewedLocations() throws RecognitionException { return gAlterClauseParser.skewedLocations(); }

	public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException { return gIdentifiersParser.partitionVal(); }

	public HiveParser_ResourcePlanParser.withReplace_return withReplace() throws RecognitionException { return gResourcePlanParser.withReplace(); }

	public HiveParser_IdentifiersParser.expressionsInParenthesis_return expressionsInParenthesis(boolean isStruct, boolean forceStruct) throws RecognitionException { return gIdentifiersParser.expressionsInParenthesis(isStruct, forceStruct); }

	public HiveParser_ResourcePlanParser.dropResourcePlanStatement_return dropResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.dropResourcePlanStatement(); }

	public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator() throws RecognitionException { return gIdentifiersParser.precedenceStarOperator(); }

	public HiveParser_AlterClauseParser.alterDatabaseSuffixSetManagedLocation_return alterDatabaseSuffixSetManagedLocation() throws RecognitionException { return gAlterClauseParser.alterDatabaseSuffixSetManagedLocation(); }

	public HiveParser_ResourcePlanParser.rpAssign_return rpAssign() throws RecognitionException { return gResourcePlanParser.rpAssign(); }

	public HiveParser_PrepareStatementParser.executeStatement_return executeStatement() throws RecognitionException { return gPrepareStatementParser.executeStatement(); }

	public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_start_boundary(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixExchangePartition(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixBucketNum(partition); }

	public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException { return gIdentifiersParser.havingClause(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions(boolean table) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixAddPartitions(table); }

	public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException { return gIdentifiersParser.nonReserved(); }

	public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException { return gFromClauseParser.fromSource(); }

	public HiveParser_IdentifiersParser.extractExpression_return extractExpression() throws RecognitionException { return gIdentifiersParser.extractExpression(); }

	public HiveParser_AlterClauseParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException { return gAlterClauseParser.tablePartitionPrefix(); }

	public HiveParser_ResourcePlanParser.poolAssignList_return poolAssignList() throws RecognitionException { return gResourcePlanParser.poolAssignList(); }

	public HiveParser_IdentifiersParser.subQueryExpression_return subQueryExpression() throws RecognitionException { return gIdentifiersParser.subQueryExpression(); }

	public HiveParser_IdentifiersParser.floorExpression_return floorExpression() throws RecognitionException { return gIdentifiersParser.floorExpression(); }

	public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException { return gFromClauseParser.splitSample(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixUpdateColumns_return alterStatementSuffixUpdateColumns() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixUpdateColumns(); }

	public HiveParser_AlterClauseParser.partitionLocation_return partitionLocation() throws RecognitionException { return gAlterClauseParser.partitionLocation(); }

	public HiveParser_ResourcePlanParser.rpUnassign_return rpUnassign() throws RecognitionException { return gResourcePlanParser.rpUnassign(); }

	public HiveParser_IdentifiersParser.null_treatment_return null_treatment() throws RecognitionException { return gIdentifiersParser.null_treatment(); }

	public HiveParser_AlterClauseParser.fileFormat_return fileFormat() throws RecognitionException { return gAlterClauseParser.fileFormat(); }

	public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression() throws RecognitionException { return gIdentifiersParser.precedenceNotExpression(); }

	public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException { return gFromClauseParser.tableAlias(); }

	public HiveParser_IdentifiersParser.precedenceDistinctOperator_return precedenceDistinctOperator() throws RecognitionException { return gIdentifiersParser.precedenceDistinctOperator(); }

	public HiveParser_IdentifiersParser.precedenceConcatenateOperator_return precedenceConcatenateOperator() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateOperator(); }

	public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException { return gIdentifiersParser.tableOrPartition(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixClusterbySortby(); }

	public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression() throws RecognitionException { return gIdentifiersParser.precedencePlusExpression(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionPart_return precedenceSimilarExpressionPart(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPart(t); }

	public HiveParser_AlterClauseParser.alterDataConnectorSuffixSetOwner_return alterDataConnectorSuffixSetOwner() throws RecognitionException { return gAlterClauseParser.alterDataConnectorSuffixSetOwner(); }

	public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException { return gFromClauseParser.uniqueJoinSource(); }

	public HiveParser_IdentifiersParser.columnRefOrderInParenthesis_return columnRefOrderInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderInParenthesis(); }

	public HiveParser_ResourcePlanParser.createMappingStatement_return createMappingStatement() throws RecognitionException { return gResourcePlanParser.createMappingStatement(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixLocation_return alterStatementSuffixLocation(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixLocation(partition); }

	public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException { return gIdentifiersParser.precedenceAndOperator(); }

	public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException { return gIdentifiersParser.stringLiteralSequence(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixDropConstraint_return alterStatementSuffixDropConstraint() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixDropConstraint(); }

	public HiveParser_ResourcePlanParser.createResourcePlanStatement_return createResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.createResourcePlanStatement(); }

	public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException { return gFromClauseParser.aliasList(); }

	public HiveParser_IdentifiersParser.timestampLiteral_return timestampLiteral() throws RecognitionException { return gIdentifiersParser.timestampLiteral(); }

	public HiveParser_AlterClauseParser.alterStatementChangeColPosition_return alterStatementChangeColPosition() throws RecognitionException { return gAlterClauseParser.alterStatementChangeColPosition(); }

	public HiveParser_IdentifiersParser.sql11ReservedKeywordsUsedAsFunctionName_return sql11ReservedKeywordsUsedAsFunctionName() throws RecognitionException { return gIdentifiersParser.sql11ReservedKeywordsUsedAsFunctionName(); }

	public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException { return gFromClauseParser.tableSample(); }

	public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException { return gSelectClauseParser.trfmClause(); }

	public HiveParser_AlterClauseParser.alterStatementPartitionKeyType_return alterStatementPartitionKeyType() throws RecognitionException { return gAlterClauseParser.alterStatementPartitionKeyType(); }

	public HiveParser_IdentifiersParser.groupByEmpty_return groupByEmpty() throws RecognitionException { return gIdentifiersParser.groupByEmpty(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions(boolean table) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixDropPartitions(table); }

	public HiveParser_ResourcePlanParser.enable_return enable() throws RecognitionException { return gResourcePlanParser.enable(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixSetOwner_return alterStatementSuffixSetOwner() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixSetOwner(); }

	public HiveParser_AlterClauseParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation() throws RecognitionException { return gAlterClauseParser.alterTblPartitionStatementSuffixSkewedLocation(); }

	public HiveParser_FromClauseParser.asOfClause_return asOfClause() throws RecognitionException { return gFromClauseParser.asOfClause(); }

	public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException { return gIdentifiersParser.functionName(); }

	public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException { return gFromClauseParser.lateralView(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixExecute_return alterStatementSuffixExecute() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixExecute(); }

	public HiveParser_ResourcePlanParser.dropTriggerStatement_return dropTriggerStatement() throws RecognitionException { return gResourcePlanParser.dropTriggerStatement(); }

	public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException { return gFromClauseParser.tableBucketSample(); }

	public HiveParser_AlterClauseParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException { return gAlterClauseParser.alterTableStatementSuffix(); }

	public HiveParser_AlterClauseParser.blocking_return blocking() throws RecognitionException { return gAlterClauseParser.blocking(); }

	public HiveParser_IdentifiersParser.intervalValue_return intervalValue() throws RecognitionException { return gIdentifiersParser.intervalValue(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionIn_return precedenceSimilarExpressionIn(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionIn(t); }

	public HiveParser_IdentifiersParser.firstExpressionsWithAlias_return firstExpressionsWithAlias() throws RecognitionException { return gIdentifiersParser.firstExpressionsWithAlias(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionAtom_return precedenceSimilarExpressionAtom(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionAtom(t); }

	public HiveParser_AlterClauseParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixAddPartitionsElement(); }

	public HiveParser_CreateDDLParser.dataConnectorUrl_return dataConnectorUrl() throws RecognitionException { return gCreateDDLParser.dataConnectorUrl(); }

	public HiveParser_IdentifiersParser.prepareStmtParam_return prepareStmtParam() throws RecognitionException { return gIdentifiersParser.prepareStmtParam(); }

	public HiveParser_CreateDDLParser.dataConnectorComment_return dataConnectorComment() throws RecognitionException { return gCreateDDLParser.dataConnectorComment(); }

	public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException { return gIdentifiersParser.groupingSetExpression(); }

	public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction() throws RecognitionException { return gFromClauseParser.partitionedTableFunction(); }

	public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression() throws RecognitionException { return gIdentifiersParser.precedenceAndExpression(); }

	public HiveParser_IdentifiersParser.precedenceSimilarOperator_return precedenceSimilarOperator() throws RecognitionException { return gIdentifiersParser.precedenceSimilarOperator(); }

	public HiveParser_FromClauseParser.joinSourcePart_return joinSourcePart() throws RecognitionException { return gFromClauseParser.joinSourcePart(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixRenamePart(); }

	public HiveParser_IdentifiersParser.timeQualifiers_return timeQualifiers() throws RecognitionException { return gIdentifiersParser.timeQualifiers(); }

	public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException { return gFromClauseParser.fromClause(); }

	public HiveParser_AlterClauseParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException { return gAlterClauseParser.skewedLocationsList(); }

	public HiveParser_CreateDDLParser.createDataConnectorStatement_return createDataConnectorStatement() throws RecognitionException { return gCreateDDLParser.createDataConnectorStatement(); }

	public HiveParser_PrepareStatementParser.executeParamList_return executeParamList() throws RecognitionException { return gPrepareStatementParser.executeParamList(); }

	public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator() throws RecognitionException { return gIdentifiersParser.precedencePlusOperator(); }

	public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException { return gIdentifiersParser.atomExpression(); }

	public HiveParser_ResourcePlanParser.triggerActionExpression_return triggerActionExpression() throws RecognitionException { return gResourcePlanParser.triggerActionExpression(); }

	public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException { return gIdentifiersParser.castExpression(); }

	public HiveParser_AlterClauseParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties() throws RecognitionException { return gAlterClauseParser.alterDatabaseSuffixProperties(); }

	public HiveParser_IdentifiersParser.principalIdentifier_return principalIdentifier() throws RecognitionException { return gIdentifiersParser.principalIdentifier(); }

	public HiveParser_IdentifiersParser.isCondition_return isCondition() throws RecognitionException { return gIdentifiersParser.isCondition(); }

	public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource() throws RecognitionException { return gFromClauseParser.partitionTableFunctionSource(); }

	public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException { return gIdentifiersParser.groupByClause(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixUpdateStatsCol_return alterStatementSuffixUpdateStatsCol(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixUpdateStatsCol(partition); }

	public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException { return gFromClauseParser.tableSource(); }

	public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException { return gSelectClauseParser.window_frame(); }

	public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException { return gFromClauseParser.uniqueJoinToken(); }

	public HiveParser_AlterClauseParser.alterDatabaseSuffixSetLocation_return alterDatabaseSuffixSetLocation() throws RecognitionException { return gAlterClauseParser.alterDatabaseSuffixSetLocation(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionQuantifierPredicate_return precedenceSimilarExpressionQuantifierPredicate(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionQuantifierPredicate(t); }

	public HiveParser_IdentifiersParser.rollupStandard_return rollupStandard() throws RecognitionException { return gIdentifiersParser.rollupStandard(); }

	public HiveParser_IdentifiersParser.precedenceConcatenateExpression_return precedenceConcatenateExpression() throws RecognitionException { return gIdentifiersParser.precedenceConcatenateExpression(); }

	public HiveParser_ResourcePlanParser.activate_return activate() throws RecognitionException { return gResourcePlanParser.activate(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixAddConstraint_return alterStatementSuffixAddConstraint() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixAddConstraint(); }

	public HiveParser_AlterClauseParser.alterDataConnectorSuffixSetUrl_return alterDataConnectorSuffixSetUrl() throws RecognitionException { return gAlterClauseParser.alterDataConnectorSuffixSetUrl(); }

	public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException { return gIdentifiersParser.constant(); }

	public HiveParser_AlterClauseParser.alterMaterializedViewStatementSuffix_return alterMaterializedViewStatementSuffix(CommonTree tableNameTree) throws RecognitionException { return gAlterClauseParser.alterMaterializedViewStatementSuffix(tableNameTree); }

	public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException { return gFromClauseParser.searchCondition(); }

	public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException { return gFromClauseParser.viewName(); }

	public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException { return gFromClauseParser.tableAllColumns(); }

	public HiveParser_IdentifiersParser.trimFunction_return trimFunction() throws RecognitionException { return gIdentifiersParser.trimFunction(); }

	public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException { return gIdentifiersParser.charSetStringLiteral(); }

	public HiveParser_ResourcePlanParser.alterMappingStatement_return alterMappingStatement() throws RecognitionException { return gResourcePlanParser.alterMappingStatement(); }

	public HiveParser_AlterClauseParser.compactPool_return compactPool() throws RecognitionException { return gAlterClauseParser.compactPool(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixStatsPart_return alterStatementSuffixStatsPart() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixStatsPart(); }

	public HiveParser_IdentifiersParser.qualifyClause_return qualifyClause() throws RecognitionException { return gIdentifiersParser.qualifyClause(); }

	public HiveParser_FromClauseParser.uniqueJoinTableSource_return uniqueJoinTableSource() throws RecognitionException { return gFromClauseParser.uniqueJoinTableSource(); }

	public HiveParser_CreateDDLParser.dataConnectorType_return dataConnectorType() throws RecognitionException { return gCreateDDLParser.dataConnectorType(); }

	public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandExpression(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixTouch(); }

	public HiveParser_ResourcePlanParser.replaceResourcePlanStatement_return replaceResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.replaceResourcePlanStatement(); }

	public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException { return gFromClauseParser.tableOrColumn(); }

	public HiveParser_AlterClauseParser.alterDataConnectorStatementSuffix_return alterDataConnectorStatementSuffix() throws RecognitionException { return gAlterClauseParser.alterDataConnectorStatementSuffix(); }

	public HiveParser_IdentifiersParser.groupby_expression_return groupby_expression() throws RecognitionException { return gIdentifiersParser.groupby_expression(); }

	public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException { return gFromClauseParser.uniqueJoinExpr(); }

	public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException { return gIdentifiersParser.clusterByClause(); }

	public HiveParser_PrepareStatementParser.prepareStatement_return prepareStatement() throws RecognitionException { return gPrepareStatementParser.prepareStatement(); }

	public HiveParser_ResourcePlanParser.dropPoolStatement_return dropPoolStatement() throws RecognitionException { return gResourcePlanParser.dropPoolStatement(); }

	public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator() throws RecognitionException { return gIdentifiersParser.precedenceEqualOperator(); }

	public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException { return gIdentifiersParser.descFuncNames(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionMain_return precedenceSimilarExpressionMain() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionMain(); }

	public HiveParser_AlterClauseParser.alterDataConnectorSuffixProperties_return alterDataConnectorSuffixProperties() throws RecognitionException { return gAlterClauseParser.alterDataConnectorSuffixProperties(); }

	public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException { return gFromClauseParser.joinSource(); }

	public HiveParser_AlterClauseParser.alterDatabaseSuffixSetOwner_return alterDatabaseSuffixSetOwner() throws RecognitionException { return gAlterClauseParser.alterDatabaseSuffixSetOwner(); }

	public HiveParser_IdentifiersParser.parameterIdx_return parameterIdx() throws RecognitionException { return gIdentifiersParser.parameterIdx(); }

	public HiveParser_FromClauseParser.defaultValue_return defaultValue() throws RecognitionException { return gFromClauseParser.defaultValue(); }

	public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException { return gSelectClauseParser.selectTrfmClause(); }

	public HiveParser_ResourcePlanParser.alterPoolStatement_return alterPoolStatement() throws RecognitionException { return gResourcePlanParser.alterPoolStatement(); }

	public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException { return gIdentifiersParser.whenExpression(); }

	public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException { return gSelectClauseParser.window_defn(); }

	public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression() throws RecognitionException { return gSelectClauseParser.window_range_expression(); }

	public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException { return gIdentifiersParser.havingCondition(); }

	public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException { return gFromClauseParser.joinToken(); }

	public HiveParser_ResourcePlanParser.resourcePlanDdlStatements_return resourcePlanDdlStatements() throws RecognitionException { return gResourcePlanParser.resourcePlanDdlStatements(); }

	public HiveParser_ResourcePlanParser.triggerLiteral_return triggerLiteral() throws RecognitionException { return gResourcePlanParser.triggerLiteral(); }

	public HiveParser_IdentifiersParser.groupingExpressionSingle_return groupingExpressionSingle() throws RecognitionException { return gIdentifiersParser.groupingExpressionSingle(); }

	public HiveParser_IdentifiersParser.rollupOldSyntax_return rollupOldSyntax() throws RecognitionException { return gIdentifiersParser.rollupOldSyntax(); }

	public HiveParser_ResourcePlanParser.unmanaged_return unmanaged() throws RecognitionException { return gResourcePlanParser.unmanaged(); }

	public HiveParser_ResourcePlanParser.globalWmStatement_return globalWmStatement() throws RecognitionException { return gResourcePlanParser.globalWmStatement(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrExpression(); }

	public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException { return gIdentifiersParser.expressions(); }

	public HiveParser_FromClauseParser.valuesSource_return valuesSource() throws RecognitionException { return gFromClauseParser.valuesSource(); }

	public HiveParser_FromClauseParser.atomjoinSource_return atomjoinSource() throws RecognitionException { return gFromClauseParser.atomjoinSource(); }

	public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException { return gIdentifiersParser.partitionSpec(); }

	public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceOrOperator(); }

	public HiveParser_ResourcePlanParser.rpAssignList_return rpAssignList() throws RecognitionException { return gResourcePlanParser.rpAssignList(); }

	public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandOperator(); }

	public HiveParser_ResourcePlanParser.createTriggerStatement_return createTriggerStatement() throws RecognitionException { return gResourcePlanParser.createTriggerStatement(); }

	public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException { return gIdentifiersParser.booleanValue(); }

	public HiveParser_IdentifiersParser.intervalQualifiers_return intervalQualifiers() throws RecognitionException { return gIdentifiersParser.intervalQualifiers(); }

	public HiveParser_IdentifiersParser.expressionPart_return expressionPart(CommonTree firstExprTree, boolean isStruct) throws RecognitionException { return gIdentifiersParser.expressionPart(firstExprTree, isStruct); }

	public HiveParser_IdentifiersParser.quantifierType_return quantifierType() throws RecognitionException { return gIdentifiersParser.quantifierType(); }

	public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException { return gSelectClauseParser.selectExpression(); }

	public HiveParser_IdentifiersParser.precedenceRegexpOperator_return precedenceRegexpOperator() throws RecognitionException { return gIdentifiersParser.precedenceRegexpOperator(); }

	public HiveParser_ResourcePlanParser.dropMappingStatement_return dropMappingStatement() throws RecognitionException { return gResourcePlanParser.dropMappingStatement(); }

	public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException { return gIdentifiersParser.identifier(); }

	public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException { return gIdentifiersParser.sysFuncNames(); }

	public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException { return gIdentifiersParser.precedenceNotOperator(); }

	public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException { return gSelectClauseParser.window_clause(); }

	public HiveParser_IdentifiersParser.function_return function() throws RecognitionException { return gIdentifiersParser.function(); }

	public HiveParser_IdentifiersParser.intervalLiteral_return intervalLiteral() throws RecognitionException { return gIdentifiersParser.intervalLiteral(); }

	public HiveParser_FromClauseParser.valuesClause_return valuesClause() throws RecognitionException { return gFromClauseParser.valuesClause(); }

	public HiveParser_IdentifiersParser.partitionSelectorOperator_return partitionSelectorOperator() throws RecognitionException { return gIdentifiersParser.partitionSelectorOperator(); }

	public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException { return gSelectClauseParser.selectItem(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixRenameCol(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorOperator(); }

	public HiveParser_IdentifiersParser.groupingSetExpressionMultiple_return groupingSetExpressionMultiple() throws RecognitionException { return gIdentifiersParser.groupingSetExpressionMultiple(); }

	public HiveParser_ResourcePlanParser.triggerExpressionStandalone_return triggerExpressionStandalone() throws RecognitionException { return gResourcePlanParser.triggerExpressionStandalone(); }

	public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression() throws RecognitionException { return gSelectClauseParser.window_value_expression(); }

	public HiveParser_ResourcePlanParser.triggerAtomExpression_return triggerAtomExpression() throws RecognitionException { return gResourcePlanParser.triggerAtomExpression(); }

	public HiveParser_FromClauseParser.firstValueRowConstructor_return firstValueRowConstructor() throws RecognitionException { return gFromClauseParser.firstValueRowConstructor(); }

	public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceOrExpression(); }

	public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException { return gFromClauseParser.expressionList(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixArchive(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorExpression(); }

	public HiveParser_IdentifiersParser.timestampLocalTZLiteral_return timestampLocalTZLiteral() throws RecognitionException { return gIdentifiersParser.timestampLocalTZLiteral(); }

	public HiveParser_ResourcePlanParser.triggerExpression_return triggerExpression() throws RecognitionException { return gResourcePlanParser.triggerExpression(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixSkewedby(); }

	public HiveParser_SelectClauseParser.window_specification_return window_specification(CommonTree nullTreatment) throws RecognitionException { return gSelectClauseParser.window_specification(nullTreatment); }

	public HiveParser_AlterClauseParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException { return gAlterClauseParser.skewedLocationMap(); }

	public HiveParser_ResourcePlanParser.triggerAndExpression_return triggerAndExpression() throws RecognitionException { return gResourcePlanParser.triggerAndExpression(); }

	public HiveParser_ResourcePlanParser.rpUnassignList_return rpUnassignList() throws RecognitionException { return gResourcePlanParser.rpUnassignList(); }

	public HiveParser_AlterClauseParser.alterStatement_return alterStatement() throws RecognitionException { return gAlterClauseParser.alterStatement(); }

	public HiveParser_ResourcePlanParser.disable_return disable() throws RecognitionException { return gResourcePlanParser.disable(); }

	public HiveParser_CreateDDLParser.createTableStatement_return createTableStatement() throws RecognitionException { return gCreateDDLParser.createTableStatement(); }

	public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_boundary(); }

	public HiveParser_ResourcePlanParser.alterResourcePlanStatement_return alterResourcePlanStatement() throws RecognitionException { return gResourcePlanParser.alterResourcePlanStatement(); }

	public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException { return gFromClauseParser.partitioningSpec(); }

	public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException { return gIdentifiersParser.partitionByClause(); }

	public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException { return gFromClauseParser.whereClause(); }

	public HiveParser_ResourcePlanParser.comparisionOperator_return comparisionOperator() throws RecognitionException { return gResourcePlanParser.comparisionOperator(); }

	public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException { return gIdentifiersParser.sortByClause(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixProperties_return alterStatementSuffixProperties() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixProperties(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixSerdeProperties(partition); }

	public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression() throws RecognitionException { return gIdentifiersParser.precedenceStarExpression(); }

	public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException { return gIdentifiersParser.expression(); }

	public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnaryPrefixExpression(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixAddCol(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixMergeFiles(partition); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpression_return precedenceSimilarExpression() throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpression(); }

	public HiveParser_IdentifiersParser.partitionSelectorVal_return partitionSelectorVal() throws RecognitionException { return gIdentifiersParser.partitionSelectorVal(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixFileFormat(partition); }

	public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException { return gSelectClauseParser.selectList(); }

	public HiveParser_FromClauseParser.valueRowConstructor_return valueRowConstructor() throws RecognitionException { return gFromClauseParser.valueRowConstructor(); }

	public HiveParser_AlterClauseParser.alterMaterializedViewSuffixRewrite_return alterMaterializedViewSuffixRewrite(CommonTree tableNameTree) throws RecognitionException { return gAlterClauseParser.alterMaterializedViewSuffixRewrite(tableNameTree); }

	public HiveParser_IdentifiersParser.booleanValueTok_return booleanValueTok() throws RecognitionException { return gIdentifiersParser.booleanValueTok(); }

	public HiveParser_IdentifiersParser.functionIdentifier_return functionIdentifier() throws RecognitionException { return gIdentifiersParser.functionIdentifier(); }

	public HiveParser_CreateDDLParser.dcProperties_return dcProperties() throws RecognitionException { return gCreateDDLParser.dcProperties(); }

	public HiveParser_CreateDDLParser.dropDataConnectorStatement_return dropDataConnectorStatement() throws RecognitionException { return gCreateDDLParser.dropDataConnectorStatement(); }

	public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException { return gIdentifiersParser.distributeByClause(); }

	public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression() throws RecognitionException { return gIdentifiersParser.precedenceEqualExpression(); }

	public HiveParser_AlterClauseParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException { return gAlterClauseParser.alterViewStatementSuffix(); }

	public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException { return gIdentifiersParser.orderByClause(); }

	public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression() throws RecognitionException { return gIdentifiersParser.precedenceFieldExpression(); }

	public HiveParser_ResourcePlanParser.triggerOrExpression_return triggerOrExpression() throws RecognitionException { return gResourcePlanParser.triggerOrExpression(); }

	public HiveParser_IdentifiersParser.expressionsNotInParenthesis_return expressionsNotInParenthesis(boolean isStruct, boolean forceStruct) throws RecognitionException { return gIdentifiersParser.expressionsNotInParenthesis(isStruct, forceStruct); }

	public HiveParser_AlterClauseParser.alterStatementSuffixRename_return alterStatementSuffixRename(boolean table) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixRename(table); }

	public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException { return gFromClauseParser.tableName(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixUnArchive(); }

	public HiveParser_IdentifiersParser.expressionWithAlias_return expressionWithAlias() throws RecognitionException { return gIdentifiersParser.expressionWithAlias(); }

	public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException { return gSelectClauseParser.selectExpressionList(); }

	public HiveParser_IdentifiersParser.intervalExpression_return intervalExpression() throws RecognitionException { return gIdentifiersParser.intervalExpression(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixUpdateStats_return alterStatementSuffixUpdateStats(boolean partition) throws RecognitionException { return gAlterClauseParser.alterStatementSuffixUpdateStats(partition); }

	public HiveParser_AlterClauseParser.alterStatementSuffixSetPartSpec_return alterStatementSuffixSetPartSpec() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixSetPartSpec(); }

	public HiveParser_AlterClauseParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix(boolean partition) throws RecognitionException { return gAlterClauseParser.alterTblPartitionStatementSuffix(partition); }

	public HiveParser_AlterClauseParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException { return gAlterClauseParser.alterViewSuffixProperties(); }

	public HiveParser_IdentifiersParser.precedenceSimilarExpressionPartNot_return precedenceSimilarExpressionPartNot(CommonTree t) throws RecognitionException { return gIdentifiersParser.precedenceSimilarExpressionPartNot(t); }

	public HiveParser_AlterClauseParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix() throws RecognitionException { return gAlterClauseParser.alterDatabaseStatementSuffix(); }

	public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException { return gFromClauseParser.subQuerySource(); }

	public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException { return gIdentifiersParser.dateLiteral(); }

	public HiveParser_IdentifiersParser.partitionSelectorSpec_return partitionSelectorSpec() throws RecognitionException { return gIdentifiersParser.partitionSelectorSpec(); }

	public HiveParser_IdentifiersParser.columnRefOrderNotInParenthesis_return columnRefOrderNotInParenthesis() throws RecognitionException { return gIdentifiersParser.columnRefOrderNotInParenthesis(); }

	public HiveParser_IdentifiersParser.expressionOrDefault_return expressionOrDefault() throws RecognitionException { return gIdentifiersParser.expressionOrDefault(); }

	public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException { return gSelectClauseParser.selectClause(); }

	public HiveParser_CreateDDLParser.likeTableOrFile_return likeTableOrFile() throws RecognitionException { return gCreateDDLParser.likeTableOrFile(); }

	public HiveParser_ResourcePlanParser.triggerActionExpressionStandalone_return triggerActionExpressionStandalone() throws RecognitionException { return gResourcePlanParser.triggerActionExpressionStandalone(); }

	public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrOperator(); }

	public HiveParser_AlterClauseParser.alterStatementSuffixCompact_return alterStatementSuffixCompact() throws RecognitionException { return gAlterClauseParser.alterStatementSuffixCompact(); }

	public HiveParser_FromClauseParser.virtualTableSource_return virtualTableSource() throws RecognitionException { return gFromClauseParser.virtualTableSource(); }

	public HiveParser_FromClauseParser.valuesTableConstructor_return valuesTableConstructor() throws RecognitionException { return gFromClauseParser.valuesTableConstructor(); }

	public final boolean synpred18_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred18_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred21_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred21_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred7_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred7_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred23_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred23_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred11_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred11_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred15_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred15_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred13_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred13_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred10_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred10_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred8_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred8_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred4_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred4_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred2_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred2_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred6_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred6_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred22_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred22_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred19_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred19_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred14_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred14_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred17_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred17_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred20_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred20_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred12_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred12_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred3_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred3_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred9_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred9_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred16_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred16_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred24_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred24_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred5_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred5_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}
	public final boolean synpred1_HiveParser() {
		state.backtracking++;
		int start = input.mark();
		try {
			synpred1_HiveParser_fragment(); // can never throw exception
		} catch (RecognitionException re) {
			System.err.println("impossible: "+re);
		}
		boolean success = !state.failed;
		input.rewind(start);
		state.backtracking--;
		state.failed=false;
		return success;
	}


	protected DFA2 dfa2 = new DFA2(this);
	protected DFA26 dfa26 = new DFA26(this);
	protected DFA111 dfa111 = new DFA111(this);
	protected DFA202 dfa202 = new DFA202(this);
	static final String DFA2_eotS =
		"\154\uffff";
	static final String DFA2_eofS =
		"\154\uffff";
	static final String DFA2_minS =
		"\1\32\26\uffff\1\32\124\uffff";
	static final String DFA2_maxS =
		"\1\u0191\26\uffff\1\u0191\124\uffff";
	static final String DFA2_acceptS =
		"\1\uffff\1\2\50\uffff\1\1\101\uffff";
	static final String DFA2_specialS =
		"\154\uffff}>";
	static final String[] DFA2_transitionS = {
			"\1\1\7\uffff\1\1\1\27\7\uffff\1\52\1\uffff\1\52\16\uffff\1\52\12\uffff"+
			"\1\1\10\uffff\1\1\21\uffff\2\52\4\uffff\1\1\1\uffff\1\52\2\1\3\uffff"+
			"\1\1\6\uffff\1\1\3\uffff\1\1\7\uffff\1\1\4\uffff\1\1\1\uffff\1\52\17"+
			"\uffff\1\52\1\1\3\uffff\1\1\10\uffff\1\1\7\uffff\1\1\15\uffff\1\1\11"+
			"\uffff\1\1\2\uffff\1\1\2\52\5\uffff\1\1\4\uffff\1\1\6\uffff\1\1\42\uffff"+
			"\1\1\20\uffff\1\1\2\uffff\1\1\3\uffff\1\52\1\uffff\2\1\4\uffff\1\1\5"+
			"\uffff\1\1\10\uffff\1\1\4\uffff\1\1\2\uffff\1\1\11\uffff\1\1\37\uffff"+
			"\1\1\11\uffff\1\1\3\uffff\1\1\2\uffff\1\1\5\uffff\1\1\2\uffff\1\52\10"+
			"\uffff\1\1\12\uffff\1\1",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\52\7\uffff\2\52\7\uffff\1\52\1\uffff\1\52\16\uffff\1\52\12\uffff"+
			"\1\52\10\uffff\1\52\21\uffff\2\52\4\uffff\1\52\1\uffff\3\52\3\uffff\1"+
			"\52\6\uffff\1\52\3\uffff\1\52\7\uffff\1\52\4\uffff\1\52\1\uffff\1\52"+
			"\17\uffff\2\52\3\uffff\1\52\10\uffff\1\52\7\uffff\1\52\15\uffff\1\52"+
			"\11\uffff\1\52\2\uffff\3\52\5\uffff\1\52\4\uffff\1\52\6\uffff\1\52\42"+
			"\uffff\1\52\20\uffff\1\52\2\uffff\1\52\3\uffff\1\52\1\uffff\2\52\4\uffff"+
			"\1\52\5\uffff\1\52\10\uffff\1\52\4\uffff\1\52\2\uffff\1\52\11\uffff\1"+
			"\52\12\uffff\1\1\24\uffff\1\52\11\uffff\1\52\3\uffff\1\52\2\uffff\1\52"+
			"\5\uffff\1\52\2\uffff\1\52\10\uffff\1\52\12\uffff\1\52",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA2_eot = DFA.unpackEncodedString(DFA2_eotS);
	static final short[] DFA2_eof = DFA.unpackEncodedString(DFA2_eofS);
	static final char[] DFA2_min = DFA.unpackEncodedStringToUnsignedChars(DFA2_minS);
	static final char[] DFA2_max = DFA.unpackEncodedStringToUnsignedChars(DFA2_maxS);
	static final short[] DFA2_accept = DFA.unpackEncodedString(DFA2_acceptS);
	static final short[] DFA2_special = DFA.unpackEncodedString(DFA2_specialS);
	static final short[][] DFA2_transition;

	static {
		int numStates = DFA2_transitionS.length;
		DFA2_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA2_transition[i] = DFA.unpackEncodedString(DFA2_transitionS[i]);
		}
	}

	protected class DFA2 extends DFA {

		public DFA2(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 2;
			this.eot = DFA2_eot;
			this.eof = DFA2_eof;
			this.min = DFA2_min;
			this.max = DFA2_max;
			this.accept = DFA2_accept;
			this.special = DFA2_special;
			this.transition = DFA2_transition;
		}
		@Override
		public String getDescription() {
			return "()* loopback of 903:6: ( explainOption )*";
		}
	}

	static final String DFA26_eotS =
		"\u0099\uffff";
	static final String DFA26_eofS =
		"\u0099\uffff";
	static final String DFA26_minS =
		"\1\32\1\46\1\uffff\1\46\1\uffff\1\46\2\uffff\1\105\3\uffff\2\131\2\30"+
		"\12\uffff\1\u008b\24\uffff\1\u009d\73\uffff\1\11\1\uffff\1\11\13\uffff"+
		"\1\11\1\uffff\1\11\16\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1"+
		"\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0";
	static final String DFA26_maxS =
		"\1\u0174\1\u017e\1\uffff\1\u017e\1\uffff\1\u017e\2\uffff\1\u017f\3\uffff"+
		"\2\u014e\2\u02d8\12\uffff\1\u015d\24\uffff\1\u00cf\73\uffff\1\u0191\1"+
		"\uffff\1\u0191\13\uffff\1\u0191\1\uffff\1\u0191\16\uffff\1\0\1\uffff\1"+
		"\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff\1\0\1\uffff"+
		"\1\0";
	static final String DFA26_acceptS =
		"\2\uffff\1\2\1\uffff\1\6\1\uffff\1\10\2\uffff\1\12\1\25\1\27\4\uffff\1"+
		"\46\1\50\1\51\1\52\2\uffff\1\1\1\4\1\14\1\15\1\uffff\1\34\3\uffff\1\53"+
		"\5\uffff\1\13\1\uffff\1\22\3\uffff\1\5\1\17\1\20\1\21\1\uffff\1\35\3\uffff"+
		"\1\3\1\uffff\1\24\3\uffff\1\54\1\7\3\uffff\1\16\10\uffff\1\11\13\uffff"+
		"\1\40\1\41\1\42\1\43\1\47\7\uffff\1\30\1\32\1\uffff\1\31\1\33\1\uffff"+
		"\5\36\1\uffff\1\36\1\uffff\2\36\1\44\2\uffff\6\37\1\uffff\1\37\1\uffff"+
		"\2\37\1\45\3\uffff\1\23\4\uffff\1\26\1\uffff\1\36\1\uffff\1\36\1\uffff"+
		"\1\36\1\uffff\1\36\1\uffff\1\37\1\uffff\1\37\1\uffff\1\37\1\uffff\1\37"+
		"\1\uffff";
	static final String DFA26_specialS =
		"\16\uffff\1\0\1\1\133\uffff\1\2\1\uffff\1\3\13\uffff\1\4\1\uffff\1\5\16"+
		"\uffff\1\6\1\uffff\1\7\1\uffff\1\10\1\uffff\1\11\1\uffff\1\12\1\uffff"+
		"\1\13\1\uffff\1\14\1\uffff\1\15}>";
	static final String[] DFA26_transitionS = {
			"\1\21\7\uffff\1\5\1\13\54\uffff\1\1\32\uffff\2\6\3\uffff\1\23\6\uffff"+
			"\1\3\3\uffff\1\23\43\uffff\1\16\36\uffff\1\22\14\uffff\1\14\23\uffff"+
			"\1\11\66\uffff\1\12\6\uffff\1\23\4\uffff\1\17\23\uffff\1\20\2\uffff\1"+
			"\10\51\uffff\1\4\11\uffff\1\15\6\uffff\1\2",
			"\1\23\62\uffff\1\26\1\uffff\1\37\57\uffff\1\27\21\uffff\1\47\2\uffff"+
			"\1\23\57\uffff\1\27\6\uffff\1\30\25\uffff\1\45\21\uffff\1\23\30\uffff"+
			"\1\26\6\uffff\1\23\6\uffff\1\33\5\uffff\1\31\1\uffff\1\26\37\uffff\1"+
			"\27\3\uffff\1\32\12\uffff\1\27\2\uffff\1\23\24\uffff\1\23\10\uffff\1"+
			"\45",
			"",
			"\1\23\62\uffff\1\64\1\uffff\1\72\101\uffff\1\66\2\uffff\1\23\66\uffff"+
			"\1\56\47\uffff\1\23\37\uffff\1\23\6\uffff\1\60\5\uffff\1\54\1\uffff\1"+
			"\64\37\uffff\1\53\3\uffff\1\57\15\uffff\1\23\24\uffff\1\23\10\uffff\1"+
			"\55",
			"",
			"\1\23\62\uffff\1\73\1\uffff\1\73\104\uffff\1\23\66\uffff\1\73\47\uffff"+
			"\1\23\37\uffff\1\23\14\uffff\1\77\1\uffff\1\73\37\uffff\1\73\21\uffff"+
			"\1\23\24\uffff\1\23\10\uffff\1\73",
			"",
			"",
			"\1\110\3\uffff\1\110\2\uffff\1\110\3\uffff\1\110\3\uffff\1\130\5\uffff"+
			"\1\110\1\uffff\1\110\55\uffff\1\110\23\uffff\1\110\1\124\54\uffff\1\110"+
			"\12\uffff\1\110\40\uffff\1\110\14\uffff\1\126\31\uffff\1\110\6\uffff"+
			"\1\125\1\127\7\uffff\1\110\20\uffff\1\110\15\uffff\2\110\1\uffff\1\110"+
			"\14\uffff\1\110\40\uffff\1\110",
			"",
			"",
			"",
			"\1\141\u00d4\uffff\1\141\37\uffff\1\140",
			"\1\144\u00d4\uffff\1\144\37\uffff\1\143",
			"\1\160\1\uffff\6\160\1\146\1\160\1\147\1\160\3\uffff\1\160\2\uffff\3"+
			"\160\1\uffff\2\160\5\uffff\2\160\1\uffff\2\160\2\uffff\2\160\1\uffff"+
			"\5\160\1\uffff\2\160\1\uffff\4\160\2\uffff\2\160\1\151\1\160\6\uffff"+
			"\1\160\1\uffff\1\160\3\uffff\4\160\1\uffff\1\160\1\uffff\3\160\1\157"+
			"\3\160\1\uffff\4\160\1\uffff\3\160\1\uffff\1\160\1\152\2\160\1\uffff"+
			"\1\160\1\uffff\3\160\2\uffff\3\160\1\uffff\4\160\5\uffff\4\160\6\uffff"+
			"\2\160\3\uffff\1\160\4\uffff\3\160\1\uffff\1\160\2\uffff\2\160\1\uffff"+
			"\3\160\1\156\5\uffff\3\160\1\uffff\6\160\4\uffff\1\160\1\uffff\3\160"+
			"\1\uffff\1\160\1\153\3\160\1\uffff\3\160\1\uffff\4\160\1\uffff\1\160"+
			"\1\uffff\2\160\1\uffff\2\160\1\uffff\2\160\1\uffff\1\160\1\uffff\1\160"+
			"\1\uffff\1\160\2\uffff\2\160\4\uffff\2\160\1\uffff\2\160\1\uffff\3\160"+
			"\2\uffff\4\160\5\uffff\1\160\1\uffff\1\160\1\uffff\3\160\1\uffff\1\160"+
			"\2\uffff\3\160\3\uffff\14\160\1\uffff\1\160\2\uffff\2\160\4\uffff\5\160"+
			"\1\154\4\160\1\uffff\3\160\1\155\1\160\1\uffff\1\160\1\uffff\4\160\1"+
			"\uffff\7\160\1\uffff\2\160\1\uffff\1\160\1\uffff\3\160\4\uffff\1\160"+
			"\1\uffff\1\160\1\uffff\3\160\2\uffff\1\160\2\uffff\2\160\1\uffff\1\160"+
			"\1\uffff\1\160\2\uffff\5\160\1\150\3\160\2\uffff\3\160\1\uffff\1\160"+
			"\1\uffff\5\160\2\uffff\1\160\2\uffff\6\160\100\uffff\1\160\54\uffff\1"+
			"\160\70\uffff\1\160\70\uffff\1\160\3\uffff\1\160\32\uffff\1\160\7\uffff"+
			"\1\160\104\uffff\1\160",
			"\1\176\1\uffff\6\176\1\164\1\176\1\165\1\176\3\uffff\1\176\2\uffff\3"+
			"\176\1\uffff\2\176\5\uffff\2\176\1\uffff\2\176\2\uffff\2\176\1\uffff"+
			"\5\176\1\uffff\2\176\1\uffff\4\176\2\uffff\2\176\1\167\1\176\6\uffff"+
			"\1\176\1\uffff\1\176\3\uffff\4\176\1\uffff\1\176\1\uffff\3\176\1\175"+
			"\3\176\1\uffff\4\176\1\uffff\3\176\1\uffff\1\176\1\170\2\176\1\uffff"+
			"\1\176\1\uffff\3\176\2\uffff\3\176\1\uffff\4\176\5\uffff\4\176\6\uffff"+
			"\2\176\3\uffff\1\176\1\163\3\uffff\3\176\1\uffff\1\176\2\uffff\2\176"+
			"\1\uffff\3\176\1\174\5\uffff\3\176\1\uffff\6\176\4\uffff\1\176\1\uffff"+
			"\3\176\1\uffff\1\176\1\171\3\176\1\uffff\3\176\1\uffff\4\176\1\uffff"+
			"\1\176\1\uffff\2\176\1\uffff\2\176\1\uffff\2\176\1\uffff\1\176\1\uffff"+
			"\1\176\1\uffff\1\176\2\uffff\2\176\4\uffff\2\176\1\uffff\2\176\1\uffff"+
			"\3\176\2\uffff\4\176\5\uffff\1\176\1\uffff\1\176\1\uffff\3\176\1\uffff"+
			"\1\176\2\uffff\3\176\3\uffff\14\176\1\uffff\1\176\2\uffff\2\176\4\uffff"+
			"\5\176\1\172\4\176\1\uffff\3\176\1\173\1\176\1\uffff\1\176\1\uffff\4"+
			"\176\1\uffff\7\176\1\uffff\2\176\1\uffff\1\176\1\uffff\3\176\4\uffff"+
			"\1\176\1\uffff\1\176\1\uffff\3\176\2\uffff\1\176\2\uffff\2\176\1\uffff"+
			"\1\176\1\uffff\1\176\2\uffff\5\176\1\166\3\176\2\uffff\3\176\1\uffff"+
			"\1\176\1\uffff\5\176\2\uffff\1\176\2\uffff\6\176\100\uffff\1\176\54\uffff"+
			"\1\176\70\uffff\1\176\70\uffff\1\176\3\uffff\1\176\32\uffff\1\176\7\uffff"+
			"\1\176\104\uffff\1\176",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\27\21\uffff\1\47\61\uffff\1\u0082\176\uffff\1\27\16\uffff\1\27",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\66\61\uffff\1\u0087",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\u008a\u00df\uffff\1\u008b\157\uffff\1\u008c\67\uffff\1\u0089",
			"",
			"\1\u008e\u00df\uffff\1\u008f\157\uffff\1\u0090\67\uffff\1\u008d",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\u0092\u0091\uffff\1\u0094\115\uffff\1\u0093\u00a7\uffff\1\u0091",
			"",
			"\1\u0096\u0091\uffff\1\u0098\115\uffff\1\u0097\u00a7\uffff\1\u0095",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"\1\uffff"
	};

	static final short[] DFA26_eot = DFA.unpackEncodedString(DFA26_eotS);
	static final short[] DFA26_eof = DFA.unpackEncodedString(DFA26_eofS);
	static final char[] DFA26_min = DFA.unpackEncodedStringToUnsignedChars(DFA26_minS);
	static final char[] DFA26_max = DFA.unpackEncodedStringToUnsignedChars(DFA26_maxS);
	static final short[] DFA26_accept = DFA.unpackEncodedString(DFA26_acceptS);
	static final short[] DFA26_special = DFA.unpackEncodedString(DFA26_specialS);
	static final short[][] DFA26_transition;

	static {
		int numStates = DFA26_transitionS.length;
		DFA26_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA26_transition[i] = DFA.unpackEncodedString(DFA26_transitionS[i]);
		}
	}

	protected class DFA26 extends DFA {

		public DFA26(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 26;
			this.eot = DFA26_eot;
			this.eof = DFA26_eof;
			this.min = DFA26_min;
			this.max = DFA26_max;
			this.accept = DFA26_accept;
			this.special = DFA26_special;
			this.transition = DFA26_transition;
		}
		@Override
		public String getDescription() {
			return "1058:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | createMaterializedViewStatement | createScheduledQueryStatement | alterScheduledQueryStatement | dropScheduledQueryStatement | dropViewStatement | dropMaterializedViewStatement | createFunctionStatement | createMacroStatement | dropFunctionStatement | reloadFunctionsStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | lockDatabase | unlockDatabase | createRoleStatement | dropRoleStatement | ( grantPrivileges )=> grantPrivileges | ( revokePrivileges )=> revokePrivileges | showGrants | showRoleGrants | showRolePrincipals | showRoles | grantRole | revokeRole | setRole | showCurrentRole | abortTransactionStatement | killQueryStatement | resourcePlanDdlStatements | createDataConnectorStatement | dropDataConnectorStatement );";
		}
		@Override
		public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
			TokenStream input = (TokenStream)_input;
			int _s = s;
			switch ( s ) {
					case 0 : 
						int LA26_14 = input.LA(1);
						 
						int index26_14 = input.index();
						input.rewind();
						s = -1;
						if ( (LA26_14==KW_ALL) && (synpred1_HiveParser())) {s = 102;}
						else if ( (LA26_14==KW_ALTER) && (synpred1_HiveParser())) {s = 103;}
						else if ( (LA26_14==KW_UPDATE) && (synpred1_HiveParser())) {s = 104;}
						else if ( (LA26_14==KW_CREATE) && (synpred1_HiveParser())) {s = 105;}
						else if ( (LA26_14==KW_DROP) && (synpred1_HiveParser())) {s = 106;}
						else if ( (LA26_14==KW_LOCK) ) {s = 107;}
						else if ( (LA26_14==KW_SELECT) && (synpred1_HiveParser())) {s = 108;}
						else if ( (LA26_14==KW_SHOW_DATABASE) ) {s = 109;}
						else if ( (LA26_14==KW_INSERT) && (synpred1_HiveParser())) {s = 110;}
						else if ( (LA26_14==KW_DELETE) && (synpred1_HiveParser())) {s = 111;}
						else if ( (LA26_14==Identifier||(LA26_14 >= KW_ABORT && LA26_14 <= KW_AFTER)||LA26_14==KW_ALLOC_FRACTION||LA26_14==KW_ANALYZE||LA26_14==KW_ARCHIVE||(LA26_14 >= KW_ASC && LA26_14 <= KW_AT)||(LA26_14 >= KW_AUTOCOMMIT && LA26_14 <= KW_BEFORE)||(LA26_14 >= KW_BUCKET && LA26_14 <= KW_BUCKETS)||(LA26_14 >= KW_CACHE && LA26_14 <= KW_CASCADE)||(LA26_14 >= KW_CBO && LA26_14 <= KW_CHANGE)||(LA26_14 >= KW_CHECK && LA26_14 <= KW_COLLECTION)||(LA26_14 >= KW_COLUMNS && LA26_14 <= KW_COMMENT)||(LA26_14 >= KW_COMPACT && LA26_14 <= KW_CONCATENATE)||(LA26_14 >= KW_CONTINUE && LA26_14 <= KW_COST)||LA26_14==KW_CRON||LA26_14==KW_DATA||LA26_14==KW_DATABASES||(LA26_14 >= KW_DATETIME && LA26_14 <= KW_DCPROPERTIES)||LA26_14==KW_DEBUG||(LA26_14 >= KW_DEFAULT && LA26_14 <= KW_DEFINED)||(LA26_14 >= KW_DELIMITED && LA26_14 <= KW_DESC)||(LA26_14 >= KW_DETAIL && LA26_14 <= KW_DISABLE)||(LA26_14 >= KW_DISTRIBUTE && LA26_14 <= KW_DO)||LA26_14==KW_DOW||(LA26_14 >= KW_DUMP && LA26_14 <= KW_ELEM_TYPE)||LA26_14==KW_ENABLE||(LA26_14 >= KW_ENFORCED && LA26_14 <= KW_EVERY)||(LA26_14 >= KW_EXCLUSIVE && LA26_14 <= KW_EXECUTED)||(LA26_14 >= KW_EXPIRE_SNAPSHOTS && LA26_14 <= KW_EXPRESSION)||(LA26_14 >= KW_FIELDS && LA26_14 <= KW_FIRST)||(LA26_14 >= KW_FORMAT && LA26_14 <= KW_FORMATTED)||LA26_14==KW_FUNCTIONS||(LA26_14 >= KW_HOUR && LA26_14 <= KW_IDXPROPERTIES)||LA26_14==KW_IGNORE||(LA26_14 >= KW_INDEX && LA26_14 <= KW_INDEXES)||(LA26_14 >= KW_INPATH && LA26_14 <= KW_INPUTFORMAT)||(LA26_14 >= KW_ISOLATION && LA26_14 <= KW_JAR)||(LA26_14 >= KW_JOINCOST && LA26_14 <= KW_LAST)||LA26_14==KW_LEVEL||(LA26_14 >= KW_LIMIT && LA26_14 <= KW_LOAD)||LA26_14==KW_LOCATION||(LA26_14 >= KW_LOCKS && LA26_14 <= KW_LONG)||(LA26_14 >= KW_MANAGED && LA26_14 <= KW_MANAGEMENT)||(LA26_14 >= KW_MAPJOIN && LA26_14 <= KW_MATERIALIZED)||LA26_14==KW_METADATA||(LA26_14 >= KW_MINUTE && LA26_14 <= KW_MONTH)||(LA26_14 >= KW_MOVE && LA26_14 <= KW_MSCK)||(LA26_14 >= KW_NORELY && LA26_14 <= KW_NOSCAN)||LA26_14==KW_NOVALIDATE||LA26_14==KW_NULLS||LA26_14==KW_OFFSET||(LA26_14 >= KW_OPERATOR && LA26_14 <= KW_OPTION)||(LA26_14 >= KW_OUTPUTDRIVER && LA26_14 <= KW_OUTPUTFORMAT)||(LA26_14 >= KW_OVERWRITE && LA26_14 <= KW_OWNER)||(LA26_14 >= KW_PARTITIONED && LA26_14 <= KW_PATH)||(LA26_14 >= KW_PLAN && LA26_14 <= KW_POOL)||LA26_14==KW_PRINCIPALS||LA26_14==KW_PURGE||(LA26_14 >= KW_QUARTER && LA26_14 <= KW_QUERY_PARALLELISM)||LA26_14==KW_READ||(LA26_14 >= KW_REBUILD && LA26_14 <= KW_RECORDWRITER)||(LA26_14 >= KW_RELOAD && LA26_14 <= KW_RESTRICT)||LA26_14==KW_REWRITE||(LA26_14 >= KW_ROLE && LA26_14 <= KW_ROLES)||(LA26_14 >= KW_SCHEDULED && LA26_14 <= KW_SECOND)||(LA26_14 >= KW_SEMI && LA26_14 <= KW_SERVER)||(LA26_14 >= KW_SETS && LA26_14 <= KW_SHOW)||LA26_14==KW_SKEWED||LA26_14==KW_SNAPSHOT||(LA26_14 >= KW_SORT && LA26_14 <= KW_SSL)||(LA26_14 >= KW_STATISTICS && LA26_14 <= KW_SUMMARY)||(LA26_14 >= KW_SYSTEM_TIME && LA26_14 <= KW_SYSTEM_VERSION)||LA26_14==KW_TABLES||(LA26_14 >= KW_TBLPROPERTIES && LA26_14 <= KW_TERMINATED)||LA26_14==KW_TINYINT||LA26_14==KW_TOUCH||(LA26_14 >= KW_TRANSACTION && LA26_14 <= KW_TRANSACTIONS)||LA26_14==KW_TRIM||(LA26_14 >= KW_TYPE && LA26_14 <= KW_UNARCHIVE)||LA26_14==KW_UNDO||LA26_14==KW_UNIONTYPE||(LA26_14 >= KW_UNKNOWN && LA26_14 <= KW_UNSIGNED)||(LA26_14 >= KW_URI && LA26_14 <= KW_USE)||(LA26_14 >= KW_UTC && LA26_14 <= KW_VALIDATE)||LA26_14==KW_VALUE_TYPE||(LA26_14 >= KW_VECTORIZATION && LA26_14 <= KW_WEEK)||LA26_14==KW_WHILE||(LA26_14 >= KW_WITHIN && LA26_14 <= KW_ZONE)||LA26_14==KW_BATCH||LA26_14==KW_DAYOFWEEK||LA26_14==KW_HOLD_DDLTIME||LA26_14==KW_NO_DROP||LA26_14==KW_OFFLINE||LA26_14==KW_PROTECTION||LA26_14==KW_READONLY||LA26_14==KW_TIMESTAMPTZ) ) {s = 112;}
						 
						input.seek(index26_14);
						if ( s>=0 ) return s;
						break;

					case 1 : 
						int LA26_15 = input.LA(1);
						 
						int index26_15 = input.index();
						input.rewind();
						s = -1;
						if ( (LA26_15==KW_GRANT) && (synpred2_HiveParser())) {s = 115;}
						else if ( (LA26_15==KW_ALL) && (synpred2_HiveParser())) {s = 116;}
						else if ( (LA26_15==KW_ALTER) && (synpred2_HiveParser())) {s = 117;}
						else if ( (LA26_15==KW_UPDATE) && (synpred2_HiveParser())) {s = 118;}
						else if ( (LA26_15==KW_CREATE) && (synpred2_HiveParser())) {s = 119;}
						else if ( (LA26_15==KW_DROP) && (synpred2_HiveParser())) {s = 120;}
						else if ( (LA26_15==KW_LOCK) ) {s = 121;}
						else if ( (LA26_15==KW_SELECT) && (synpred2_HiveParser())) {s = 122;}
						else if ( (LA26_15==KW_SHOW_DATABASE) ) {s = 123;}
						else if ( (LA26_15==KW_INSERT) && (synpred2_HiveParser())) {s = 124;}
						else if ( (LA26_15==KW_DELETE) && (synpred2_HiveParser())) {s = 125;}
						else if ( (LA26_15==Identifier||(LA26_15 >= KW_ABORT && LA26_15 <= KW_AFTER)||LA26_15==KW_ALLOC_FRACTION||LA26_15==KW_ANALYZE||LA26_15==KW_ARCHIVE||(LA26_15 >= KW_ASC && LA26_15 <= KW_AT)||(LA26_15 >= KW_AUTOCOMMIT && LA26_15 <= KW_BEFORE)||(LA26_15 >= KW_BUCKET && LA26_15 <= KW_BUCKETS)||(LA26_15 >= KW_CACHE && LA26_15 <= KW_CASCADE)||(LA26_15 >= KW_CBO && LA26_15 <= KW_CHANGE)||(LA26_15 >= KW_CHECK && LA26_15 <= KW_COLLECTION)||(LA26_15 >= KW_COLUMNS && LA26_15 <= KW_COMMENT)||(LA26_15 >= KW_COMPACT && LA26_15 <= KW_CONCATENATE)||(LA26_15 >= KW_CONTINUE && LA26_15 <= KW_COST)||LA26_15==KW_CRON||LA26_15==KW_DATA||LA26_15==KW_DATABASES||(LA26_15 >= KW_DATETIME && LA26_15 <= KW_DCPROPERTIES)||LA26_15==KW_DEBUG||(LA26_15 >= KW_DEFAULT && LA26_15 <= KW_DEFINED)||(LA26_15 >= KW_DELIMITED && LA26_15 <= KW_DESC)||(LA26_15 >= KW_DETAIL && LA26_15 <= KW_DISABLE)||(LA26_15 >= KW_DISTRIBUTE && LA26_15 <= KW_DO)||LA26_15==KW_DOW||(LA26_15 >= KW_DUMP && LA26_15 <= KW_ELEM_TYPE)||LA26_15==KW_ENABLE||(LA26_15 >= KW_ENFORCED && LA26_15 <= KW_EVERY)||(LA26_15 >= KW_EXCLUSIVE && LA26_15 <= KW_EXECUTED)||(LA26_15 >= KW_EXPIRE_SNAPSHOTS && LA26_15 <= KW_EXPRESSION)||(LA26_15 >= KW_FIELDS && LA26_15 <= KW_FIRST)||(LA26_15 >= KW_FORMAT && LA26_15 <= KW_FORMATTED)||LA26_15==KW_FUNCTIONS||(LA26_15 >= KW_HOUR && LA26_15 <= KW_IDXPROPERTIES)||LA26_15==KW_IGNORE||(LA26_15 >= KW_INDEX && LA26_15 <= KW_INDEXES)||(LA26_15 >= KW_INPATH && LA26_15 <= KW_INPUTFORMAT)||(LA26_15 >= KW_ISOLATION && LA26_15 <= KW_JAR)||(LA26_15 >= KW_JOINCOST && LA26_15 <= KW_LAST)||LA26_15==KW_LEVEL||(LA26_15 >= KW_LIMIT && LA26_15 <= KW_LOAD)||LA26_15==KW_LOCATION||(LA26_15 >= KW_LOCKS && LA26_15 <= KW_LONG)||(LA26_15 >= KW_MANAGED && LA26_15 <= KW_MANAGEMENT)||(LA26_15 >= KW_MAPJOIN && LA26_15 <= KW_MATERIALIZED)||LA26_15==KW_METADATA||(LA26_15 >= KW_MINUTE && LA26_15 <= KW_MONTH)||(LA26_15 >= KW_MOVE && LA26_15 <= KW_MSCK)||(LA26_15 >= KW_NORELY && LA26_15 <= KW_NOSCAN)||LA26_15==KW_NOVALIDATE||LA26_15==KW_NULLS||LA26_15==KW_OFFSET||(LA26_15 >= KW_OPERATOR && LA26_15 <= KW_OPTION)||(LA26_15 >= KW_OUTPUTDRIVER && LA26_15 <= KW_OUTPUTFORMAT)||(LA26_15 >= KW_OVERWRITE && LA26_15 <= KW_OWNER)||(LA26_15 >= KW_PARTITIONED && LA26_15 <= KW_PATH)||(LA26_15 >= KW_PLAN && LA26_15 <= KW_POOL)||LA26_15==KW_PRINCIPALS||LA26_15==KW_PURGE||(LA26_15 >= KW_QUARTER && LA26_15 <= KW_QUERY_PARALLELISM)||LA26_15==KW_READ||(LA26_15 >= KW_REBUILD && LA26_15 <= KW_RECORDWRITER)||(LA26_15 >= KW_RELOAD && LA26_15 <= KW_RESTRICT)||LA26_15==KW_REWRITE||(LA26_15 >= KW_ROLE && LA26_15 <= KW_ROLES)||(LA26_15 >= KW_SCHEDULED && LA26_15 <= KW_SECOND)||(LA26_15 >= KW_SEMI && LA26_15 <= KW_SERVER)||(LA26_15 >= KW_SETS && LA26_15 <= KW_SHOW)||LA26_15==KW_SKEWED||LA26_15==KW_SNAPSHOT||(LA26_15 >= KW_SORT && LA26_15 <= KW_SSL)||(LA26_15 >= KW_STATISTICS && LA26_15 <= KW_SUMMARY)||(LA26_15 >= KW_SYSTEM_TIME && LA26_15 <= KW_SYSTEM_VERSION)||LA26_15==KW_TABLES||(LA26_15 >= KW_TBLPROPERTIES && LA26_15 <= KW_TERMINATED)||LA26_15==KW_TINYINT||LA26_15==KW_TOUCH||(LA26_15 >= KW_TRANSACTION && LA26_15 <= KW_TRANSACTIONS)||LA26_15==KW_TRIM||(LA26_15 >= KW_TYPE && LA26_15 <= KW_UNARCHIVE)||LA26_15==KW_UNDO||LA26_15==KW_UNIONTYPE||(LA26_15 >= KW_UNKNOWN && LA26_15 <= KW_UNSIGNED)||(LA26_15 >= KW_URI && LA26_15 <= KW_USE)||(LA26_15 >= KW_UTC && LA26_15 <= KW_VALIDATE)||LA26_15==KW_VALUE_TYPE||(LA26_15 >= KW_VECTORIZATION && LA26_15 <= KW_WEEK)||LA26_15==KW_WHILE||(LA26_15 >= KW_WITHIN && LA26_15 <= KW_ZONE)||LA26_15==KW_BATCH||LA26_15==KW_DAYOFWEEK||LA26_15==KW_HOLD_DDLTIME||LA26_15==KW_NO_DROP||LA26_15==KW_OFFLINE||LA26_15==KW_PROTECTION||LA26_15==KW_READONLY||LA26_15==KW_TIMESTAMPTZ) ) {s = 126;}
						 
						input.seek(index26_15);
						if ( s>=0 ) return s;
						break;

					case 2 : 
						int LA26_107 = input.LA(1);
						 
						int index26_107 = input.index();
						input.rewind();
						s = -1;
						if ( (LA26_107==LPAREN) && (synpred1_HiveParser())) {s = 137;}
						else if ( (LA26_107==COMMA) ) {s = 138;}
						else if ( (LA26_107==KW_ON) && (synpred1_HiveParser())) {s = 139;}
						else if ( (LA26_107==KW_TO) ) {s = 140;}
						 
						input.seek(index26_107);
						if ( s>=0 ) return s;
						break;

					case 3 : 
						int LA26_109 = input.LA(1);
						 
						int index26_109 = input.index();
						input.rewind();
						s = -1;
						if ( (LA26_109==LPAREN) && (synpred1_HiveParser())) {s = 141;}
						else if ( (LA26_109==COMMA) ) {s = 142;}
						else if ( (LA26_109==KW_ON) && (synpred1_HiveParser())) {s = 143;}
						else if ( (LA26_109==KW_TO) ) {s = 144;}
						 
						input.seek(index26_109);
						if ( s>=0 ) return s;
						break;

					case 4 : 
						int LA26_121 = input.LA(1);
						 
						int index26_121 = input.index();
						input.rewind();
						s = -1;
						if ( (LA26_121==LPAREN) && (synpred2_HiveParser())) {s = 145;}
						else if ( (LA26_121==COMMA) ) {s = 146;}
						else if ( (LA26_121==KW_ON) && (synpred2_HiveParser())) {s = 147;}
						else if ( (LA26_121==KW_FROM) ) {s = 148;}
						 
						input.seek(index26_121);
						if ( s>=0 ) return s;
						break;

					case 5 : 
						int LA26_123 = input.LA(1);
						 
						int index26_123 = input.index();
						input.rewind();
						s = -1;
						if ( (LA26_123==LPAREN) && (synpred2_HiveParser())) {s = 149;}
						else if ( (LA26_123==COMMA) ) {s = 150;}
						else if ( (LA26_123==KW_ON) && (synpred2_HiveParser())) {s = 151;}
						else if ( (LA26_123==KW_FROM) ) {s = 152;}
						 
						input.seek(index26_123);
						if ( s>=0 ) return s;
						break;

					case 6 : 
						int LA26_138 = input.LA(1);
						 
						int index26_138 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 143;}
						else if ( (true) ) {s = 112;}
						 
						input.seek(index26_138);
						if ( s>=0 ) return s;
						break;

					case 7 : 
						int LA26_140 = input.LA(1);
						 
						int index26_140 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 143;}
						else if ( (true) ) {s = 112;}
						 
						input.seek(index26_140);
						if ( s>=0 ) return s;
						break;

					case 8 : 
						int LA26_142 = input.LA(1);
						 
						int index26_142 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 143;}
						else if ( (true) ) {s = 112;}
						 
						input.seek(index26_142);
						if ( s>=0 ) return s;
						break;

					case 9 : 
						int LA26_144 = input.LA(1);
						 
						int index26_144 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred1_HiveParser()) ) {s = 143;}
						else if ( (true) ) {s = 112;}
						 
						input.seek(index26_144);
						if ( s>=0 ) return s;
						break;

					case 10 : 
						int LA26_146 = input.LA(1);
						 
						int index26_146 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 151;}
						else if ( (true) ) {s = 126;}
						 
						input.seek(index26_146);
						if ( s>=0 ) return s;
						break;

					case 11 : 
						int LA26_148 = input.LA(1);
						 
						int index26_148 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 151;}
						else if ( (true) ) {s = 126;}
						 
						input.seek(index26_148);
						if ( s>=0 ) return s;
						break;

					case 12 : 
						int LA26_150 = input.LA(1);
						 
						int index26_150 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 151;}
						else if ( (true) ) {s = 126;}
						 
						input.seek(index26_150);
						if ( s>=0 ) return s;
						break;

					case 13 : 
						int LA26_152 = input.LA(1);
						 
						int index26_152 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred2_HiveParser()) ) {s = 151;}
						else if ( (true) ) {s = 126;}
						 
						input.seek(index26_152);
						if ( s>=0 ) return s;
						break;
			}
			if (state.backtracking>0) {state.failed=true; return -1;}
			NoViableAltException nvae =
				new NoViableAltException(getDescription(), 26, _s, input);
			error(nvae);
			throw nvae;
		}
	}

	static final String DFA111_eotS =
		"\125\uffff";
	static final String DFA111_eofS =
		"\2\4\1\uffff\1\4\121\uffff";
	static final String DFA111_minS =
		"\1\30\1\20\1\uffff\1\20\23\uffff\2\0\2\uffff\3\0\1\uffff\1\0\65\uffff";
	static final String DFA111_maxS =
		"\2\u02d8\1\uffff\1\u02d8\23\uffff\2\0\2\uffff\3\0\1\uffff\1\0\65\uffff";
	static final String DFA111_acceptS =
		"\2\uffff\1\2\1\uffff\1\3\7\uffff\1\1\110\uffff";
	static final String DFA111_specialS =
		"\1\0\1\1\25\uffff\1\2\1\3\2\uffff\1\4\1\5\1\6\1\uffff\1\7\65\uffff}>";
	static final String[] DFA111_transitionS = {
			"\1\4\1\uffff\6\4\1\uffff\1\4\1\uffff\1\4\3\uffff\1\4\2\uffff\3\4\1\uffff"+
			"\2\4\5\uffff\2\4\1\uffff\2\4\2\uffff\2\4\1\uffff\5\4\1\uffff\2\4\1\uffff"+
			"\4\4\2\uffff\2\4\1\uffff\1\4\6\uffff\1\4\1\2\1\4\3\uffff\4\4\1\uffff"+
			"\1\4\1\uffff\3\4\1\uffff\3\4\1\uffff\4\4\1\uffff\3\4\1\uffff\1\4\1\uffff"+
			"\2\4\1\uffff\1\4\1\uffff\3\4\2\uffff\3\4\1\uffff\4\4\5\uffff\4\4\6\uffff"+
			"\2\4\3\uffff\1\4\4\uffff\1\4\1\1\1\4\1\uffff\1\4\2\uffff\2\4\1\uffff"+
			"\3\4\6\uffff\3\4\1\uffff\6\4\4\uffff\1\4\1\uffff\3\4\1\uffff\5\4\1\uffff"+
			"\3\4\1\uffff\4\4\1\uffff\1\4\1\uffff\2\4\1\uffff\2\4\1\uffff\2\4\1\uffff"+
			"\1\4\1\uffff\1\4\1\uffff\1\4\2\uffff\2\4\1\uffff\1\4\2\uffff\2\4\1\uffff"+
			"\2\4\1\uffff\3\4\2\uffff\4\4\5\uffff\1\4\1\uffff\1\4\1\uffff\3\4\1\uffff"+
			"\1\4\2\uffff\3\4\3\uffff\14\4\1\uffff\1\4\2\uffff\2\4\4\uffff\2\4\1\3"+
			"\2\4\1\uffff\4\4\1\uffff\5\4\1\uffff\1\4\1\uffff\4\4\1\uffff\7\4\1\uffff"+
			"\2\4\1\uffff\1\4\1\uffff\3\4\4\uffff\1\4\1\uffff\1\4\1\uffff\3\4\2\uffff"+
			"\1\4\2\uffff\2\4\1\uffff\1\4\1\uffff\1\4\2\uffff\5\4\1\uffff\3\4\2\uffff"+
			"\3\4\1\uffff\1\4\1\uffff\5\4\2\uffff\1\4\2\uffff\6\4\100\uffff\1\4\54"+
			"\uffff\1\4\70\uffff\1\4\70\uffff\1\4\3\uffff\1\4\32\uffff\1\4\7\uffff"+
			"\1\4\104\uffff\1\4",
			"\1\4\1\uffff\1\14\5\uffff\1\4\1\uffff\6\4\1\uffff\1\4\1\uffff\1\4\3"+
			"\uffff\1\4\2\uffff\3\4\1\uffff\2\4\5\uffff\2\4\1\uffff\2\4\2\uffff\2"+
			"\4\1\uffff\5\4\1\uffff\2\4\1\uffff\4\4\2\uffff\2\4\1\uffff\1\4\6\uffff"+
			"\1\4\1\uffff\1\4\3\uffff\4\4\1\uffff\1\4\1\uffff\3\4\1\uffff\3\4\1\uffff"+
			"\4\4\1\uffff\3\4\1\uffff\1\4\1\uffff\2\4\1\uffff\1\4\1\uffff\3\4\2\uffff"+
			"\3\4\1\uffff\4\4\5\uffff\4\4\6\uffff\2\4\3\uffff\1\4\4\uffff\3\4\1\uffff"+
			"\1\4\2\uffff\2\4\1\uffff\3\4\6\uffff\3\4\1\uffff\6\4\4\uffff\1\4\1\uffff"+
			"\3\4\1\uffff\5\4\1\uffff\3\4\1\uffff\4\4\1\uffff\1\4\1\uffff\2\4\1\uffff"+
			"\2\4\1\uffff\2\4\1\uffff\1\4\1\uffff\1\4\1\uffff\1\4\2\uffff\2\4\1\uffff"+
			"\1\4\2\uffff\2\4\1\uffff\6\4\2\uffff\4\4\5\uffff\1\4\1\uffff\1\4\1\uffff"+
			"\3\4\1\uffff\1\4\2\uffff\3\4\3\uffff\14\4\1\uffff\1\4\2\uffff\2\4\4\uffff"+
			"\5\4\1\uffff\4\4\1\uffff\5\4\1\uffff\1\4\1\uffff\4\4\1\uffff\7\4\1\uffff"+
			"\2\4\1\uffff\1\4\1\uffff\3\4\4\uffff\1\4\1\uffff\1\4\1\uffff\3\4\2\uffff"+
			"\1\4\2\uffff\2\4\1\uffff\1\4\1\uffff\1\4\2\uffff\5\4\1\uffff\3\4\2\uffff"+
			"\3\4\1\uffff\1\4\1\uffff\5\4\2\uffff\1\4\2\uffff\6\4\100\uffff\1\4\54"+
			"\uffff\1\4\70\uffff\1\4\70\uffff\1\4\3\uffff\1\4\32\uffff\1\4\7\uffff"+
			"\1\4\104\uffff\1\4",
			"",
			"\1\4\7\uffff\1\27\1\uffff\6\37\1\uffff\1\37\1\uffff\1\37\3\uffff\1\37"+
			"\2\uffff\3\37\1\uffff\2\37\5\uffff\2\37\1\uffff\2\37\2\uffff\2\37\1\uffff"+
			"\5\37\1\uffff\2\37\1\uffff\4\37\2\uffff\2\37\1\uffff\1\37\6\uffff\1\37"+
			"\1\uffff\1\37\3\uffff\4\37\1\uffff\1\37\1\uffff\3\37\1\uffff\3\37\1\uffff"+
			"\4\37\1\uffff\3\37\1\uffff\1\37\1\uffff\2\37\1\uffff\1\37\1\uffff\3\37"+
			"\2\uffff\3\37\1\uffff\4\37\5\uffff\4\37\6\uffff\2\37\3\uffff\1\37\4\uffff"+
			"\3\37\1\uffff\1\37\2\uffff\2\37\1\uffff\3\37\6\uffff\3\37\1\uffff\6\37"+
			"\4\uffff\1\37\1\uffff\1\35\2\37\1\uffff\5\37\1\uffff\3\37\1\uffff\4\37"+
			"\1\uffff\1\37\1\uffff\2\37\1\uffff\2\37\1\uffff\2\37\1\uffff\1\37\1\uffff"+
			"\1\37\1\uffff\1\37\2\uffff\2\37\1\uffff\1\4\2\uffff\2\37\1\uffff\2\37"+
			"\1\4\3\37\2\uffff\3\37\1\30\5\uffff\1\37\1\uffff\1\37\1\uffff\3\37\1"+
			"\uffff\1\37\2\uffff\3\37\3\uffff\14\37\1\uffff\1\37\2\uffff\2\37\4\uffff"+
			"\5\37\1\uffff\4\37\1\uffff\5\37\1\uffff\1\37\1\uffff\4\37\1\uffff\1\37"+
			"\1\34\5\37\1\uffff\2\37\1\uffff\1\37\1\uffff\3\37\4\uffff\1\37\1\uffff"+
			"\1\37\1\uffff\3\37\2\uffff\1\37\2\uffff\1\33\1\37\1\uffff\1\37\1\uffff"+
			"\1\37\2\uffff\5\37\1\uffff\3\37\2\uffff\3\37\1\uffff\1\37\1\uffff\5\37"+
			"\2\uffff\1\37\2\uffff\6\37\100\uffff\1\37\54\uffff\1\37\70\uffff\1\37"+
			"\70\uffff\1\37\3\uffff\1\37\32\uffff\1\37\7\uffff\1\37\104\uffff\1\37",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\1\uffff",
			"\1\uffff",
			"",
			"",
			"\1\uffff",
			"\1\uffff",
			"\1\uffff",
			"",
			"\1\uffff",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA111_eot = DFA.unpackEncodedString(DFA111_eotS);
	static final short[] DFA111_eof = DFA.unpackEncodedString(DFA111_eofS);
	static final char[] DFA111_min = DFA.unpackEncodedStringToUnsignedChars(DFA111_minS);
	static final char[] DFA111_max = DFA.unpackEncodedStringToUnsignedChars(DFA111_maxS);
	static final short[] DFA111_accept = DFA.unpackEncodedString(DFA111_acceptS);
	static final short[] DFA111_special = DFA.unpackEncodedString(DFA111_specialS);
	static final short[][] DFA111_transition;

	static {
		int numStates = DFA111_transitionS.length;
		DFA111_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA111_transition[i] = DFA.unpackEncodedString(DFA111_transitionS[i]);
		}
	}

	protected class DFA111 extends DFA {

		public DFA111(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 111;
			this.eot = DFA111_eot;
			this.eof = DFA111_eof;
			this.min = DFA111_min;
			this.max = DFA111_max;
			this.accept = DFA111_accept;
			this.special = DFA111_special;
			this.transition = DFA111_transition;
		}
		@Override
		public String getDescription() {
			return "1348:7: ( ( KW_ID )=> compactionId -> ^( TOK_SHOW_COMPACTIONS compactionId ) | ( KW_DATABASE | KW_SCHEMA )=> ( KW_DATABASE | KW_SCHEMA ) (dbName= identifier ) ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS $dbName ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) | (parttype= partTypeExpr )? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? -> ^( TOK_SHOW_COMPACTIONS ( $parttype)? ( compactionPool )? ( compactionType )? ( compactionStatus )? ( orderByClause )? ( limitClause )? ) )";
		}
		@Override
		public int specialStateTransition(int s, IntStream _input) throws NoViableAltException {
			TokenStream input = (TokenStream)_input;
			int _s = s;
			switch ( s ) {
					case 0 : 
						int LA111_0 = input.LA(1);
						 
						int index111_0 = input.index();
						input.rewind();
						s = -1;
						if ( (LA111_0==KW_ID) ) {s = 1;}
						else if ( (LA111_0==KW_DATABASE) && (synpred15_HiveParser())) {s = 2;}
						else if ( (LA111_0==KW_SCHEMA) ) {s = 3;}
						else if ( (LA111_0==EOF||LA111_0==Identifier||(LA111_0 >= KW_ABORT && LA111_0 <= KW_AFTER)||LA111_0==KW_ALLOC_FRACTION||LA111_0==KW_ANALYZE||LA111_0==KW_ARCHIVE||(LA111_0 >= KW_ASC && LA111_0 <= KW_AT)||(LA111_0 >= KW_AUTOCOMMIT && LA111_0 <= KW_BEFORE)||(LA111_0 >= KW_BUCKET && LA111_0 <= KW_BUCKETS)||(LA111_0 >= KW_CACHE && LA111_0 <= KW_CASCADE)||(LA111_0 >= KW_CBO && LA111_0 <= KW_CHANGE)||(LA111_0 >= KW_CHECK && LA111_0 <= KW_COLLECTION)||(LA111_0 >= KW_COLUMNS && LA111_0 <= KW_COMMENT)||(LA111_0 >= KW_COMPACT && LA111_0 <= KW_CONCATENATE)||(LA111_0 >= KW_CONTINUE && LA111_0 <= KW_COST)||LA111_0==KW_CRON||LA111_0==KW_DATA||LA111_0==KW_DATABASES||(LA111_0 >= KW_DATETIME && LA111_0 <= KW_DCPROPERTIES)||LA111_0==KW_DEBUG||(LA111_0 >= KW_DEFAULT && LA111_0 <= KW_DEFINED)||(LA111_0 >= KW_DELIMITED && LA111_0 <= KW_DESC)||(LA111_0 >= KW_DETAIL && LA111_0 <= KW_DISABLE)||(LA111_0 >= KW_DISTRIBUTE && LA111_0 <= KW_DO)||LA111_0==KW_DOW||(LA111_0 >= KW_DUMP && LA111_0 <= KW_ELEM_TYPE)||LA111_0==KW_ENABLE||(LA111_0 >= KW_ENFORCED && LA111_0 <= KW_EVERY)||(LA111_0 >= KW_EXCLUSIVE && LA111_0 <= KW_EXECUTED)||(LA111_0 >= KW_EXPIRE_SNAPSHOTS && LA111_0 <= KW_EXPRESSION)||(LA111_0 >= KW_FIELDS && LA111_0 <= KW_FIRST)||(LA111_0 >= KW_FORMAT && LA111_0 <= KW_FORMATTED)||LA111_0==KW_FUNCTIONS||LA111_0==KW_HOUR||LA111_0==KW_IDXPROPERTIES||LA111_0==KW_IGNORE||(LA111_0 >= KW_INDEX && LA111_0 <= KW_INDEXES)||(LA111_0 >= KW_INPATH && LA111_0 <= KW_INPUTFORMAT)||(LA111_0 >= KW_ISOLATION && LA111_0 <= KW_JAR)||(LA111_0 >= KW_JOINCOST && LA111_0 <= KW_LAST)||LA111_0==KW_LEVEL||(LA111_0 >= KW_LIMIT && LA111_0 <= KW_LOAD)||(LA111_0 >= KW_LOCATION && LA111_0 <= KW_LONG)||(LA111_0 >= KW_MANAGED && LA111_0 <= KW_MANAGEMENT)||(LA111_0 >= KW_MAPJOIN && LA111_0 <= KW_MATERIALIZED)||LA111_0==KW_METADATA||(LA111_0 >= KW_MINUTE && LA111_0 <= KW_MONTH)||(LA111_0 >= KW_MOVE && LA111_0 <= KW_MSCK)||(LA111_0 >= KW_NORELY && LA111_0 <= KW_NOSCAN)||LA111_0==KW_NOVALIDATE||LA111_0==KW_NULLS||LA111_0==KW_OFFSET||(LA111_0 >= KW_OPERATOR && LA111_0 <= KW_OPTION)||LA111_0==KW_ORDER||(LA111_0 >= KW_OUTPUTDRIVER && LA111_0 <= KW_OUTPUTFORMAT)||(LA111_0 >= KW_OVERWRITE && LA111_0 <= KW_OWNER)||(LA111_0 >= KW_PARTITIONED && LA111_0 <= KW_PATH)||(LA111_0 >= KW_PLAN && LA111_0 <= KW_POOL)||LA111_0==KW_PRINCIPALS||LA111_0==KW_PURGE||(LA111_0 >= KW_QUARTER && LA111_0 <= KW_QUERY_PARALLELISM)||LA111_0==KW_READ||(LA111_0 >= KW_REBUILD && LA111_0 <= KW_RECORDWRITER)||(LA111_0 >= KW_RELOAD && LA111_0 <= KW_RESTRICT)||LA111_0==KW_REWRITE||(LA111_0 >= KW_ROLE && LA111_0 <= KW_ROLES)||(LA111_0 >= KW_SCHEDULED && LA111_0 <= KW_SCHEDULING_POLICY)||(LA111_0 >= KW_SCHEMAS && LA111_0 <= KW_SECOND)||(LA111_0 >= KW_SEMI && LA111_0 <= KW_SERVER)||(LA111_0 >= KW_SETS && LA111_0 <= KW_SKEWED)||LA111_0==KW_SNAPSHOT||(LA111_0 >= KW_SORT && LA111_0 <= KW_SSL)||(LA111_0 >= KW_STATISTICS && LA111_0 <= KW_SUMMARY)||(LA111_0 >= KW_SYSTEM_TIME && LA111_0 <= KW_SYSTEM_VERSION)||LA111_0==KW_TABLES||(LA111_0 >= KW_TBLPROPERTIES && LA111_0 <= KW_TERMINATED)||LA111_0==KW_TINYINT||LA111_0==KW_TOUCH||(LA111_0 >= KW_TRANSACTION && LA111_0 <= KW_TRANSACTIONS)||LA111_0==KW_TRIM||(LA111_0 >= KW_TYPE && LA111_0 <= KW_UNARCHIVE)||LA111_0==KW_UNDO||LA111_0==KW_UNIONTYPE||(LA111_0 >= KW_UNKNOWN && LA111_0 <= KW_UNSIGNED)||(LA111_0 >= KW_URI && LA111_0 <= KW_USE)||(LA111_0 >= KW_UTC && LA111_0 <= KW_VALIDATE)||LA111_0==KW_VALUE_TYPE||(LA111_0 >= KW_VECTORIZATION && LA111_0 <= KW_WEEK)||LA111_0==KW_WHILE||(LA111_0 >= KW_WITHIN && LA111_0 <= KW_ZONE)||LA111_0==KW_BATCH||LA111_0==KW_DAYOFWEEK||LA111_0==KW_HOLD_DDLTIME||LA111_0==KW_NO_DROP||LA111_0==KW_OFFLINE||LA111_0==KW_PROTECTION||LA111_0==KW_READONLY||LA111_0==KW_TIMESTAMPTZ) ) {s = 4;}
						 
						input.seek(index111_0);
						if ( s>=0 ) return s;
						break;

					case 1 : 
						int LA111_1 = input.LA(1);
						 
						int index111_1 = input.index();
						input.rewind();
						s = -1;
						if ( (LA111_1==EQUAL) && (synpred14_HiveParser())) {s = 12;}
						else if ( (LA111_1==EOF||LA111_1==DOT||LA111_1==Identifier||(LA111_1 >= KW_ABORT && LA111_1 <= KW_AFTER)||LA111_1==KW_ALLOC_FRACTION||LA111_1==KW_ANALYZE||LA111_1==KW_ARCHIVE||(LA111_1 >= KW_ASC && LA111_1 <= KW_AT)||(LA111_1 >= KW_AUTOCOMMIT && LA111_1 <= KW_BEFORE)||(LA111_1 >= KW_BUCKET && LA111_1 <= KW_BUCKETS)||(LA111_1 >= KW_CACHE && LA111_1 <= KW_CASCADE)||(LA111_1 >= KW_CBO && LA111_1 <= KW_CHANGE)||(LA111_1 >= KW_CHECK && LA111_1 <= KW_COLLECTION)||(LA111_1 >= KW_COLUMNS && LA111_1 <= KW_COMMENT)||(LA111_1 >= KW_COMPACT && LA111_1 <= KW_CONCATENATE)||(LA111_1 >= KW_CONTINUE && LA111_1 <= KW_COST)||LA111_1==KW_CRON||LA111_1==KW_DATA||LA111_1==KW_DATABASES||(LA111_1 >= KW_DATETIME && LA111_1 <= KW_DCPROPERTIES)||LA111_1==KW_DEBUG||(LA111_1 >= KW_DEFAULT && LA111_1 <= KW_DEFINED)||(LA111_1 >= KW_DELIMITED && LA111_1 <= KW_DESC)||(LA111_1 >= KW_DETAIL && LA111_1 <= KW_DISABLE)||(LA111_1 >= KW_DISTRIBUTE && LA111_1 <= KW_DO)||LA111_1==KW_DOW||(LA111_1 >= KW_DUMP && LA111_1 <= KW_ELEM_TYPE)||LA111_1==KW_ENABLE||(LA111_1 >= KW_ENFORCED && LA111_1 <= KW_EVERY)||(LA111_1 >= KW_EXCLUSIVE && LA111_1 <= KW_EXECUTED)||(LA111_1 >= KW_EXPIRE_SNAPSHOTS && LA111_1 <= KW_EXPRESSION)||(LA111_1 >= KW_FIELDS && LA111_1 <= KW_FIRST)||(LA111_1 >= KW_FORMAT && LA111_1 <= KW_FORMATTED)||LA111_1==KW_FUNCTIONS||(LA111_1 >= KW_HOUR && LA111_1 <= KW_IDXPROPERTIES)||LA111_1==KW_IGNORE||(LA111_1 >= KW_INDEX && LA111_1 <= KW_INDEXES)||(LA111_1 >= KW_INPATH && LA111_1 <= KW_INPUTFORMAT)||(LA111_1 >= KW_ISOLATION && LA111_1 <= KW_JAR)||(LA111_1 >= KW_JOINCOST && LA111_1 <= KW_LAST)||LA111_1==KW_LEVEL||(LA111_1 >= KW_LIMIT && LA111_1 <= KW_LOAD)||(LA111_1 >= KW_LOCATION && LA111_1 <= KW_LONG)||(LA111_1 >= KW_MANAGED && LA111_1 <= KW_MANAGEMENT)||(LA111_1 >= KW_MAPJOIN && LA111_1 <= KW_MATERIALIZED)||LA111_1==KW_METADATA||(LA111_1 >= KW_MINUTE && LA111_1 <= KW_MONTH)||(LA111_1 >= KW_MOVE && LA111_1 <= KW_MSCK)||(LA111_1 >= KW_NORELY && LA111_1 <= KW_NOSCAN)||LA111_1==KW_NOVALIDATE||LA111_1==KW_NULLS||LA111_1==KW_OFFSET||(LA111_1 >= KW_OPERATOR && LA111_1 <= KW_OPTION)||LA111_1==KW_ORDER||(LA111_1 >= KW_OUTPUTDRIVER && LA111_1 <= KW_OUTPUTFORMAT)||(LA111_1 >= KW_OVERWRITE && LA111_1 <= KW_PATH)||(LA111_1 >= KW_PLAN && LA111_1 <= KW_POOL)||LA111_1==KW_PRINCIPALS||LA111_1==KW_PURGE||(LA111_1 >= KW_QUARTER && LA111_1 <= KW_QUERY_PARALLELISM)||LA111_1==KW_READ||(LA111_1 >= KW_REBUILD && LA111_1 <= KW_RECORDWRITER)||(LA111_1 >= KW_RELOAD && LA111_1 <= KW_RESTRICT)||LA111_1==KW_REWRITE||(LA111_1 >= KW_ROLE && LA111_1 <= KW_ROLES)||(LA111_1 >= KW_SCHEDULED && LA111_1 <= KW_SECOND)||(LA111_1 >= KW_SEMI && LA111_1 <= KW_SERVER)||(LA111_1 >= KW_SETS && LA111_1 <= KW_SKEWED)||LA111_1==KW_SNAPSHOT||(LA111_1 >= KW_SORT && LA111_1 <= KW_SSL)||(LA111_1 >= KW_STATISTICS && LA111_1 <= KW_SUMMARY)||(LA111_1 >= KW_SYSTEM_TIME && LA111_1 <= KW_SYSTEM_VERSION)||LA111_1==KW_TABLES||(LA111_1 >= KW_TBLPROPERTIES && LA111_1 <= KW_TERMINATED)||LA111_1==KW_TINYINT||LA111_1==KW_TOUCH||(LA111_1 >= KW_TRANSACTION && LA111_1 <= KW_TRANSACTIONS)||LA111_1==KW_TRIM||(LA111_1 >= KW_TYPE && LA111_1 <= KW_UNARCHIVE)||LA111_1==KW_UNDO||LA111_1==KW_UNIONTYPE||(LA111_1 >= KW_UNKNOWN && LA111_1 <= KW_UNSIGNED)||(LA111_1 >= KW_URI && LA111_1 <= KW_USE)||(LA111_1 >= KW_UTC && LA111_1 <= KW_VALIDATE)||LA111_1==KW_VALUE_TYPE||(LA111_1 >= KW_VECTORIZATION && LA111_1 <= KW_WEEK)||LA111_1==KW_WHILE||(LA111_1 >= KW_WITHIN && LA111_1 <= KW_ZONE)||LA111_1==KW_BATCH||LA111_1==KW_DAYOFWEEK||LA111_1==KW_HOLD_DDLTIME||LA111_1==KW_NO_DROP||LA111_1==KW_OFFLINE||LA111_1==KW_PROTECTION||LA111_1==KW_READONLY||LA111_1==KW_TIMESTAMPTZ) ) {s = 4;}
						 
						input.seek(index111_1);
						if ( s>=0 ) return s;
						break;

					case 2 : 
						int LA111_23 = input.LA(1);
						 
						int index111_23 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred15_HiveParser()) ) {s = 2;}
						else if ( (true) ) {s = 4;}
						 
						input.seek(index111_23);
						if ( s>=0 ) return s;
						break;

					case 3 : 
						int LA111_24 = input.LA(1);
						 
						int index111_24 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred15_HiveParser()) ) {s = 2;}
						else if ( (true) ) {s = 4;}
						 
						input.seek(index111_24);
						if ( s>=0 ) return s;
						break;

					case 4 : 
						int LA111_27 = input.LA(1);
						 
						int index111_27 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred15_HiveParser()) ) {s = 2;}
						else if ( (true) ) {s = 4;}
						 
						input.seek(index111_27);
						if ( s>=0 ) return s;
						break;

					case 5 : 
						int LA111_28 = input.LA(1);
						 
						int index111_28 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred15_HiveParser()) ) {s = 2;}
						else if ( (true) ) {s = 4;}
						 
						input.seek(index111_28);
						if ( s>=0 ) return s;
						break;

					case 6 : 
						int LA111_29 = input.LA(1);
						 
						int index111_29 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred15_HiveParser()) ) {s = 2;}
						else if ( (true) ) {s = 4;}
						 
						input.seek(index111_29);
						if ( s>=0 ) return s;
						break;

					case 7 : 
						int LA111_31 = input.LA(1);
						 
						int index111_31 = input.index();
						input.rewind();
						s = -1;
						if ( (synpred15_HiveParser()) ) {s = 2;}
						else if ( (true) ) {s = 4;}
						 
						input.seek(index111_31);
						if ( s>=0 ) return s;
						break;
			}
			if (state.backtracking>0) {state.failed=true; return -1;}
			NoViableAltException nvae =
				new NoViableAltException(getDescription(), 111, _s, input);
			error(nvae);
			throw nvae;
		}
	}

	static final String DFA202_eotS =
		"\137\uffff";
	static final String DFA202_eofS =
		"\1\2\136\uffff";
	static final String DFA202_minS =
		"\1\11\1\14\42\uffff\1\4\72\uffff";
	static final String DFA202_maxS =
		"\1\u019e\1\u02d8\42\uffff\1\u01a2\72\uffff";
	static final String DFA202_acceptS =
		"\2\uffff\1\2\76\uffff\1\1\35\uffff";
	static final String DFA202_specialS =
		"\137\uffff}>";
	static final String[] DFA202_transitionS = {
			"\1\2\37\uffff\1\2\26\uffff\1\2\61\uffff\1\2\15\uffff\1\2\32\uffff\1\2"+
			"\4\uffff\1\2\1\uffff\1\2\3\uffff\1\2\11\uffff\1\2\1\uffff\1\2\15\uffff"+
			"\1\2\5\uffff\2\2\2\uffff\1\2\10\uffff\1\1\6\uffff\1\2\12\uffff\1\2\10"+
			"\uffff\1\2\31\uffff\1\2\10\uffff\3\2\35\uffff\1\2\15\uffff\1\2\6\uffff"+
			"\1\2\12\uffff\1\2\26\uffff\1\2\15\uffff\1\2\3\uffff\1\2\10\uffff\1\2"+
			"\1\uffff\1\2\13\uffff\1\2\14\uffff\1\2",
			"\1\2\13\uffff\10\2\1\uffff\1\2\1\uffff\1\2\3\uffff\2\2\1\uffff\3\2\1"+
			"\uffff\2\2\1\uffff\3\2\1\uffff\2\2\1\uffff\6\2\1\uffff\5\2\1\uffff\2"+
			"\2\1\uffff\4\2\2\uffff\2\2\1\uffff\1\2\3\uffff\2\2\1\uffff\1\2\1\uffff"+
			"\1\2\2\uffff\5\2\1\uffff\1\2\1\uffff\3\2\1\uffff\3\2\1\uffff\4\2\1\uffff"+
			"\5\2\1\uffff\2\2\1\uffff\1\2\1\uffff\3\2\2\uffff\10\2\2\uffff\2\2\1\uffff"+
			"\6\2\4\uffff\2\2\3\uffff\1\2\2\uffff\1\2\1\uffff\5\2\2\uffff\2\2\1\uffff"+
			"\3\2\1\uffff\1\2\1\uffff\1\2\2\uffff\3\2\1\uffff\2\2\1\44\3\2\4\uffff"+
			"\1\2\1\uffff\3\2\1\uffff\5\2\1\uffff\10\2\1\uffff\1\2\1\uffff\2\2\1\uffff"+
			"\2\2\1\uffff\6\2\1\uffff\1\2\2\uffff\2\2\4\uffff\2\2\1\uffff\2\2\1\uffff"+
			"\3\2\2\uffff\4\2\5\uffff\1\2\1\uffff\1\2\1\uffff\3\2\1\uffff\1\2\1\uffff"+
			"\4\2\3\uffff\14\2\1\uffff\1\2\2\uffff\2\2\4\uffff\5\2\1\uffff\4\2\1\uffff"+
			"\7\2\1\uffff\4\2\1\uffff\7\2\1\uffff\2\2\1\uffff\1\2\1\uffff\3\2\2\uffff"+
			"\3\2\1\uffff\1\2\1\uffff\3\2\2\uffff\2\2\1\uffff\2\2\1\uffff\1\2\1\uffff"+
			"\1\2\2\uffff\5\2\1\uffff\3\2\2\uffff\3\2\1\uffff\1\2\1\uffff\5\2\2\uffff"+
			"\1\2\2\uffff\6\2\4\uffff\1\2\2\uffff\1\2\2\uffff\3\2\1\uffff\1\2\6\uffff"+
			"\3\2\50\uffff\1\2\54\uffff\1\2\70\uffff\1\2\70\uffff\1\2\3\uffff\1\2"+
			"\32\uffff\1\2\7\uffff\1\2\104\uffff\1\2",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"\3\2\2\uffff\2\2\2\uffff\2\2\1\uffff\1\2\1\uffff\2\2\1\uffff\2\2\15"+
			"\uffff\1\2\13\uffff\1\2\170\uffff\1\2\13\uffff\1\2\17\uffff\1\2\35\uffff"+
			"\1\2\11\uffff\1\2\44\uffff\1\2\2\uffff\1\2\17\uffff\1\2\4\uffff\1\2\50"+
			"\uffff\1\101\42\uffff\1\2\27\uffff\2\2\1\uffff\2\2\1\uffff\3\2\2\uffff"+
			"\1\2\10\uffff\1\2",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			"",
			""
	};

	static final short[] DFA202_eot = DFA.unpackEncodedString(DFA202_eotS);
	static final short[] DFA202_eof = DFA.unpackEncodedString(DFA202_eofS);
	static final char[] DFA202_min = DFA.unpackEncodedStringToUnsignedChars(DFA202_minS);
	static final char[] DFA202_max = DFA.unpackEncodedStringToUnsignedChars(DFA202_maxS);
	static final short[] DFA202_accept = DFA.unpackEncodedString(DFA202_acceptS);
	static final short[] DFA202_special = DFA.unpackEncodedString(DFA202_specialS);
	static final short[][] DFA202_transition;

	static {
		int numStates = DFA202_transitionS.length;
		DFA202_transition = new short[numStates][];
		for (int i=0; i<numStates; i++) {
			DFA202_transition[i] = DFA.unpackEncodedString(DFA202_transitionS[i]);
		}
	}

	protected class DFA202 extends DFA {

		public DFA202(BaseRecognizer recognizer) {
			this.recognizer = recognizer;
			this.decisionNumber = 202;
			this.eot = DFA202_eot;
			this.eof = DFA202_eof;
			this.min = DFA202_min;
			this.max = DFA202_max;
			this.accept = DFA202_accept;
			this.special = DFA202_special;
			this.transition = DFA202_transition;
		}
		@Override
		public String getDescription() {
			return "1967:103: ( tableRowFormatMapKeysIdentifier )?";
		}
	}

    public static BitSet FOLLOW_explainStatement_in_statement1527 ;
    public static BitSet FOLLOW_EOF_in_statement1529 ;
    public static BitSet FOLLOW_execStatement_in_statement1534 ;
    public static BitSet FOLLOW_EOF_in_statement1536 ;
    public static BitSet FOLLOW_KW_EXPLAIN_in_explainStatement1557 ;
    public static BitSet FOLLOW_explainOption_in_explainStatement1566 ;
    public static BitSet FOLLOW_execStatement_in_explainStatement1569 ;
    public static BitSet FOLLOW_KW_REWRITE_in_explainStatement1600 ;
    public static BitSet FOLLOW_queryStatementExpression_in_explainStatement1602 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_explainOption1642 ;
    public static BitSet FOLLOW_KW_FORMATTED_in_explainOption1650 ;
    public static BitSet FOLLOW_KW_DEPENDENCY_in_explainOption1658 ;
    public static BitSet FOLLOW_KW_CBO_in_explainOption1666 ;
    public static BitSet FOLLOW_KW_LOGICAL_in_explainOption1683 ;
    public static BitSet FOLLOW_KW_AUTHORIZATION_in_explainOption1691 ;
    public static BitSet FOLLOW_KW_ANALYZE_in_explainOption1699 ;
    public static BitSet FOLLOW_KW_REOPTIMIZATION_in_explainOption1707 ;
    public static BitSet FOLLOW_KW_LOCKS_in_explainOption1715 ;
    public static BitSet FOLLOW_KW_AST_in_explainOption1723 ;
    public static BitSet FOLLOW_KW_VECTORIZATION_in_explainOption1732 ;
    public static BitSet FOLLOW_vectorizationOnly_in_explainOption1734 ;
    public static BitSet FOLLOW_vectorizatonDetail_in_explainOption1737 ;
    public static BitSet FOLLOW_KW_DEBUG_in_explainOption1747 ;
    public static BitSet FOLLOW_KW_DDL_in_explainOption1755 ;
    public static BitSet FOLLOW_KW_ONLY_in_vectorizationOnly1782 ;
    public static BitSet FOLLOW_KW_SUMMARY_in_vectorizatonDetail1819 ;
    public static BitSet FOLLOW_KW_OPERATOR_in_vectorizatonDetail1837 ;
    public static BitSet FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1855 ;
    public static BitSet FOLLOW_KW_DETAIL_in_vectorizatonDetail1873 ;
    public static BitSet FOLLOW_queryStatementExpression_in_execStatement1910 ;
    public static BitSet FOLLOW_loadStatement_in_execStatement1918 ;
    public static BitSet FOLLOW_exportStatement_in_execStatement1926 ;
    public static BitSet FOLLOW_importStatement_in_execStatement1934 ;
    public static BitSet FOLLOW_replDumpStatement_in_execStatement1942 ;
    public static BitSet FOLLOW_replLoadStatement_in_execStatement1950 ;
    public static BitSet FOLLOW_replStatusStatement_in_execStatement1958 ;
    public static BitSet FOLLOW_ddlStatement_in_execStatement1966 ;
    public static BitSet FOLLOW_deleteStatement_in_execStatement1974 ;
    public static BitSet FOLLOW_updateStatement_in_execStatement1982 ;
    public static BitSet FOLLOW_sqlTransactionStatement_in_execStatement1990 ;
    public static BitSet FOLLOW_mergeStatement_in_execStatement1998 ;
    public static BitSet FOLLOW_prepareStatement_in_execStatement2006 ;
    public static BitSet FOLLOW_executeStatement_in_execStatement2014 ;
    public static BitSet FOLLOW_KW_LOAD_in_loadStatement2041 ;
    public static BitSet FOLLOW_KW_DATA_in_loadStatement2043 ;
    public static BitSet FOLLOW_KW_LOCAL_in_loadStatement2048 ;
    public static BitSet FOLLOW_KW_INPATH_in_loadStatement2052 ;
    public static BitSet FOLLOW_StringLiteral_in_loadStatement2057 ;
    public static BitSet FOLLOW_KW_OVERWRITE_in_loadStatement2063 ;
    public static BitSet FOLLOW_KW_INTO_in_loadStatement2067 ;
    public static BitSet FOLLOW_KW_TABLE_in_loadStatement2069 ;
    public static BitSet FOLLOW_tableOrPartition_in_loadStatement2074 ;
    public static BitSet FOLLOW_inputFileFormat_in_loadStatement2077 ;
    public static BitSet FOLLOW_KW_FOR_in_replicationClause2132 ;
    public static BitSet FOLLOW_KW_METADATA_in_replicationClause2137 ;
    public static BitSet FOLLOW_KW_REPLICATION_in_replicationClause2141 ;
    public static BitSet FOLLOW_LPAREN_in_replicationClause2143 ;
    public static BitSet FOLLOW_StringLiteral_in_replicationClause2148 ;
    public static BitSet FOLLOW_RPAREN_in_replicationClause2151 ;
    public static BitSet FOLLOW_KW_EXPORT_in_exportStatement2195 ;
    public static BitSet FOLLOW_KW_TABLE_in_exportStatement2203 ;
    public static BitSet FOLLOW_tableOrPartition_in_exportStatement2208 ;
    public static BitSet FOLLOW_KW_TO_in_exportStatement2217 ;
    public static BitSet FOLLOW_StringLiteral_in_exportStatement2222 ;
    public static BitSet FOLLOW_replicationClause_in_exportStatement2231 ;
    public static BitSet FOLLOW_KW_IMPORT_in_importStatement2281 ;
    public static BitSet FOLLOW_KW_EXTERNAL_in_importStatement2296 ;
    public static BitSet FOLLOW_KW_TABLE_in_importStatement2300 ;
    public static BitSet FOLLOW_tableOrPartition_in_importStatement2305 ;
    public static BitSet FOLLOW_KW_FROM_in_importStatement2319 ;
    public static BitSet FOLLOW_StringLiteral_in_importStatement2324 ;
    public static BitSet FOLLOW_tableLocation_in_importStatement2336 ;
    public static BitSet FOLLOW_KW_REPL_in_replDumpStatement2390 ;
    public static BitSet FOLLOW_KW_DUMP_in_replDumpStatement2392 ;
    public static BitSet FOLLOW_replDbPolicy_in_replDumpStatement2405 ;
    public static BitSet FOLLOW_KW_REPLACE_in_replDumpStatement2417 ;
    public static BitSet FOLLOW_replDbPolicy_in_replDumpStatement2421 ;
    public static BitSet FOLLOW_KW_WITH_in_replDumpStatement2434 ;
    public static BitSet FOLLOW_replConfigs_in_replDumpStatement2438 ;
    public static BitSet FOLLOW_identifier_in_replDbPolicy2501 ;
    public static BitSet FOLLOW_DOT_in_replDbPolicy2505 ;
    public static BitSet FOLLOW_replTableLevelPolicy_in_replDbPolicy2509 ;
    public static BitSet FOLLOW_KW_REPL_in_replLoadStatement2549 ;
    public static BitSet FOLLOW_KW_LOAD_in_replLoadStatement2551 ;
    public static BitSet FOLLOW_replDbPolicy_in_replLoadStatement2562 ;
    public static BitSet FOLLOW_KW_INTO_in_replLoadStatement2572 ;
    public static BitSet FOLLOW_identifier_in_replLoadStatement2576 ;
    public static BitSet FOLLOW_KW_WITH_in_replLoadStatement2587 ;
    public static BitSet FOLLOW_replConfigs_in_replLoadStatement2591 ;
    public static BitSet FOLLOW_LPAREN_in_replConfigs2655 ;
    public static BitSet FOLLOW_replConfigsList_in_replConfigs2657 ;
    public static BitSet FOLLOW_RPAREN_in_replConfigs2659 ;
    public static BitSet FOLLOW_keyValueProperty_in_replConfigsList2700 ;
    public static BitSet FOLLOW_COMMA_in_replConfigsList2703 ;
    public static BitSet FOLLOW_keyValueProperty_in_replConfigsList2705 ;
    public static BitSet FOLLOW_StringLiteral_in_replTableLevelPolicy2753 ;
    public static BitSet FOLLOW_DOT_in_replTableLevelPolicy2757 ;
    public static BitSet FOLLOW_StringLiteral_in_replTableLevelPolicy2761 ;
    public static BitSet FOLLOW_KW_REPL_in_replStatusStatement2812 ;
    public static BitSet FOLLOW_KW_STATUS_in_replStatusStatement2814 ;
    public static BitSet FOLLOW_identifier_in_replStatusStatement2827 ;
    public static BitSet FOLLOW_KW_WITH_in_replStatusStatement2839 ;
    public static BitSet FOLLOW_replConfigs_in_replStatusStatement2843 ;
    public static BitSet FOLLOW_createDatabaseStatement_in_ddlStatement2893 ;
    public static BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement2901 ;
    public static BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement2909 ;
    public static BitSet FOLLOW_createTableStatement_in_ddlStatement2917 ;
    public static BitSet FOLLOW_dropTableStatement_in_ddlStatement2925 ;
    public static BitSet FOLLOW_truncateTableStatement_in_ddlStatement2933 ;
    public static BitSet FOLLOW_alterStatement_in_ddlStatement2941 ;
    public static BitSet FOLLOW_descStatement_in_ddlStatement2949 ;
    public static BitSet FOLLOW_showStatement_in_ddlStatement2957 ;
    public static BitSet FOLLOW_metastoreCheck_in_ddlStatement2965 ;
    public static BitSet FOLLOW_createViewStatement_in_ddlStatement2973 ;
    public static BitSet FOLLOW_createMaterializedViewStatement_in_ddlStatement2981 ;
    public static BitSet FOLLOW_createScheduledQueryStatement_in_ddlStatement2989 ;
    public static BitSet FOLLOW_alterScheduledQueryStatement_in_ddlStatement2997 ;
    public static BitSet FOLLOW_dropScheduledQueryStatement_in_ddlStatement3005 ;
    public static BitSet FOLLOW_dropViewStatement_in_ddlStatement3013 ;
    public static BitSet FOLLOW_dropMaterializedViewStatement_in_ddlStatement3021 ;
    public static BitSet FOLLOW_createFunctionStatement_in_ddlStatement3029 ;
    public static BitSet FOLLOW_createMacroStatement_in_ddlStatement3037 ;
    public static BitSet FOLLOW_dropFunctionStatement_in_ddlStatement3045 ;
    public static BitSet FOLLOW_reloadFunctionsStatement_in_ddlStatement3053 ;
    public static BitSet FOLLOW_dropMacroStatement_in_ddlStatement3061 ;
    public static BitSet FOLLOW_analyzeStatement_in_ddlStatement3069 ;
    public static BitSet FOLLOW_lockStatement_in_ddlStatement3077 ;
    public static BitSet FOLLOW_unlockStatement_in_ddlStatement3085 ;
    public static BitSet FOLLOW_lockDatabase_in_ddlStatement3093 ;
    public static BitSet FOLLOW_unlockDatabase_in_ddlStatement3101 ;
    public static BitSet FOLLOW_createRoleStatement_in_ddlStatement3109 ;
    public static BitSet FOLLOW_dropRoleStatement_in_ddlStatement3117 ;
    public static BitSet FOLLOW_grantPrivileges_in_ddlStatement3131 ;
    public static BitSet FOLLOW_revokePrivileges_in_ddlStatement3145 ;
    public static BitSet FOLLOW_showGrants_in_ddlStatement3153 ;
    public static BitSet FOLLOW_showRoleGrants_in_ddlStatement3161 ;
    public static BitSet FOLLOW_showRolePrincipals_in_ddlStatement3169 ;
    public static BitSet FOLLOW_showRoles_in_ddlStatement3177 ;
    public static BitSet FOLLOW_grantRole_in_ddlStatement3185 ;
    public static BitSet FOLLOW_revokeRole_in_ddlStatement3193 ;
    public static BitSet FOLLOW_setRole_in_ddlStatement3201 ;
    public static BitSet FOLLOW_showCurrentRole_in_ddlStatement3209 ;
    public static BitSet FOLLOW_abortTransactionStatement_in_ddlStatement3217 ;
    public static BitSet FOLLOW_killQueryStatement_in_ddlStatement3225 ;
    public static BitSet FOLLOW_resourcePlanDdlStatements_in_ddlStatement3233 ;
    public static BitSet FOLLOW_createDataConnectorStatement_in_ddlStatement3241 ;
    public static BitSet FOLLOW_dropDataConnectorStatement_in_ddlStatement3249 ;
    public static BitSet FOLLOW_KW_IF_in_ifExists3276 ;
    public static BitSet FOLLOW_KW_EXISTS_in_ifExists3278 ;
    public static BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade3315 ;
    public static BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade3333 ;
    public static BitSet FOLLOW_KW_IF_in_ifNotExists3370 ;
    public static BitSet FOLLOW_KW_NOT_in_ifNotExists3372 ;
    public static BitSet FOLLOW_KW_EXISTS_in_ifNotExists3374 ;
    public static BitSet FOLLOW_KW_FORCE_in_force3411 ;
    public static BitSet FOLLOW_KW_ENABLE_in_rewriteEnabled3448 ;
    public static BitSet FOLLOW_KW_REWRITE_in_rewriteEnabled3450 ;
    public static BitSet FOLLOW_KW_DISABLE_in_rewriteDisabled3487 ;
    public static BitSet FOLLOW_KW_REWRITE_in_rewriteDisabled3489 ;
    public static BitSet FOLLOW_KW_STORED_in_storedAsDirs3526 ;
    public static BitSet FOLLOW_KW_AS_in_storedAsDirs3528 ;
    public static BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs3530 ;
    public static BitSet FOLLOW_KW_OR_in_orReplace3567 ;
    public static BitSet FOLLOW_KW_REPLACE_in_orReplace3569 ;
    public static BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement3606 ;
    public static BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement3609 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement3611 ;
    public static BitSet FOLLOW_ifNotExists_in_createDatabaseStatement3622 ;
    public static BitSet FOLLOW_identifier_in_createDatabaseStatement3635 ;
    public static BitSet FOLLOW_databaseComment_in_createDatabaseStatement3645 ;
    public static BitSet FOLLOW_dbLocation_in_createDatabaseStatement3656 ;
    public static BitSet FOLLOW_dbManagedLocation_in_createDatabaseStatement3667 ;
    public static BitSet FOLLOW_KW_WITH_in_createDatabaseStatement3679 ;
    public static BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3681 ;
    public static BitSet FOLLOW_dbProperties_in_createDatabaseStatement3685 ;
    public static BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement3725 ;
    public static BitSet FOLLOW_KW_REMOTE_in_createDatabaseStatement3727 ;
    public static BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement3730 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement3732 ;
    public static BitSet FOLLOW_ifNotExists_in_createDatabaseStatement3743 ;
    public static BitSet FOLLOW_identifier_in_createDatabaseStatement3756 ;
    public static BitSet FOLLOW_databaseComment_in_createDatabaseStatement3766 ;
    public static BitSet FOLLOW_dbConnectorName_in_createDatabaseStatement3777 ;
    public static BitSet FOLLOW_KW_WITH_in_createDatabaseStatement3788 ;
    public static BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3790 ;
    public static BitSet FOLLOW_dbProperties_in_createDatabaseStatement3794 ;
    public static BitSet FOLLOW_KW_LOCATION_in_dbLocation3854 ;
    public static BitSet FOLLOW_StringLiteral_in_dbLocation3858 ;
    public static BitSet FOLLOW_KW_MANAGEDLOCATION_in_dbManagedLocation3900 ;
    public static BitSet FOLLOW_StringLiteral_in_dbManagedLocation3904 ;
    public static BitSet FOLLOW_LPAREN_in_dbProperties3946 ;
    public static BitSet FOLLOW_dbPropertiesList_in_dbProperties3948 ;
    public static BitSet FOLLOW_RPAREN_in_dbProperties3950 ;
    public static BitSet FOLLOW_keyValueProperty_in_dbPropertiesList3991 ;
    public static BitSet FOLLOW_COMMA_in_dbPropertiesList3994 ;
    public static BitSet FOLLOW_keyValueProperty_in_dbPropertiesList3996 ;
    public static BitSet FOLLOW_KW_USING_in_dbConnectorName4040 ;
    public static BitSet FOLLOW_identifier_in_dbConnectorName4044 ;
    public static BitSet FOLLOW_KW_USE_in_switchDatabaseStatement4080 ;
    public static BitSet FOLLOW_identifier_in_switchDatabaseStatement4082 ;
    public static BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement4121 ;
    public static BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement4124 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement4126 ;
    public static BitSet FOLLOW_ifExists_in_dropDatabaseStatement4129 ;
    public static BitSet FOLLOW_identifier_in_dropDatabaseStatement4132 ;
    public static BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement4134 ;
    public static BitSet FOLLOW_KW_COMMENT_in_databaseComment4180 ;
    public static BitSet FOLLOW_StringLiteral_in_databaseComment4184 ;
    public static BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement4224 ;
    public static BitSet FOLLOW_KW_TABLE_in_truncateTableStatement4226 ;
    public static BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement4229 ;
    public static BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement4232 ;
    public static BitSet FOLLOW_LPAREN_in_truncateTableStatement4234 ;
    public static BitSet FOLLOW_columnNameList_in_truncateTableStatement4236 ;
    public static BitSet FOLLOW_RPAREN_in_truncateTableStatement4238 ;
    public static BitSet FOLLOW_force_in_truncateTableStatement4242 ;
    public static BitSet FOLLOW_KW_DROP_in_dropTableStatement4283 ;
    public static BitSet FOLLOW_KW_TABLE_in_dropTableStatement4285 ;
    public static BitSet FOLLOW_ifExists_in_dropTableStatement4287 ;
    public static BitSet FOLLOW_tableName_in_dropTableStatement4290 ;
    public static BitSet FOLLOW_KW_PURGE_in_dropTableStatement4292 ;
    public static BitSet FOLLOW_replicationClause_in_dropTableStatement4295 ;
    public static BitSet FOLLOW_KW_INPUTFORMAT_in_inputFileFormat4344 ;
    public static BitSet FOLLOW_StringLiteral_in_inputFileFormat4348 ;
    public static BitSet FOLLOW_KW_SERDE_in_inputFileFormat4350 ;
    public static BitSet FOLLOW_StringLiteral_in_inputFileFormat4354 ;
    public static BitSet FOLLOW_identifier_in_tabTypeExpr4398 ;
    public static BitSet FOLLOW_DOT_in_tabTypeExpr4401 ;
    public static BitSet FOLLOW_identifier_in_tabTypeExpr4404 ;
    public static BitSet FOLLOW_identifier_in_tabTypeExpr4412 ;
    public static BitSet FOLLOW_DOT_in_tabTypeExpr4415 ;
    public static BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr4432 ;
    public static BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr4448 ;
    public static BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr4464 ;
    public static BitSet FOLLOW_identifier_in_tabTypeExpr4471 ;
    public static BitSet FOLLOW_tabTypeExpr_in_partTypeExpr4511 ;
    public static BitSet FOLLOW_partitionSpec_in_partTypeExpr4513 ;
    public static BitSet FOLLOW_tableName_in_tabPartColTypeExpr4553 ;
    public static BitSet FOLLOW_partitionSpec_in_tabPartColTypeExpr4555 ;
    public static BitSet FOLLOW_extColumnName_in_tabPartColTypeExpr4558 ;
    public static BitSet FOLLOW_KW_DESCRIBE_in_descStatement4605 ;
    public static BitSet FOLLOW_KW_DESC_in_descStatement4607 ;
    public static BitSet FOLLOW_KW_DATABASE_in_descStatement4629 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_descStatement4631 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_descStatement4634 ;
    public static BitSet FOLLOW_identifier_in_descStatement4640 ;
    public static BitSet FOLLOW_KW_DATACONNECTOR_in_descStatement4672 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_descStatement4675 ;
    public static BitSet FOLLOW_identifier_in_descStatement4681 ;
    public static BitSet FOLLOW_KW_FUNCTION_in_descStatement4712 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_descStatement4714 ;
    public static BitSet FOLLOW_descFuncNames_in_descStatement4720 ;
    public static BitSet FOLLOW_KW_FORMATTED_in_descStatement4757 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_descStatement4761 ;
    public static BitSet FOLLOW_tabPartColTypeExpr_in_descStatement4766 ;
    public static BitSet FOLLOW_tabPartColTypeExpr_in_descStatement4793 ;
    public static BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement4835 ;
    public static BitSet FOLLOW_KW_TABLE_in_analyzeStatement4837 ;
    public static BitSet FOLLOW_tableOrPartition_in_analyzeStatement4842 ;
    public static BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement4865 ;
    public static BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement4867 ;
    public static BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement4873 ;
    public static BitSet FOLLOW_KW_FOR_in_analyzeStatement4933 ;
    public static BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement4935 ;
    public static BitSet FOLLOW_columnNameList_in_analyzeStatement4940 ;
    public static BitSet FOLLOW_KW_CACHE_in_analyzeStatement4993 ;
    public static BitSet FOLLOW_KW_METADATA_in_analyzeStatement4995 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5039 ;
    public static BitSet FOLLOW_KW_DATABASES_in_showStatement5042 ;
    public static BitSet FOLLOW_KW_SCHEMAS_in_showStatement5044 ;
    public static BitSet FOLLOW_KW_LIKE_in_showStatement5048 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5050 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5069 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_showStatement5074 ;
    public static BitSet FOLLOW_KW_TABLES_in_showStatement5078 ;
    public static BitSet FOLLOW_KW_FROM_in_showStatement5082 ;
    public static BitSet FOLLOW_KW_IN_in_showStatement5084 ;
    public static BitSet FOLLOW_identifier_in_showStatement5089 ;
    public static BitSet FOLLOW_showTablesFilterExpr_in_showStatement5096 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5132 ;
    public static BitSet FOLLOW_KW_VIEWS_in_showStatement5134 ;
    public static BitSet FOLLOW_KW_FROM_in_showStatement5138 ;
    public static BitSet FOLLOW_KW_IN_in_showStatement5140 ;
    public static BitSet FOLLOW_identifier_in_showStatement5145 ;
    public static BitSet FOLLOW_KW_LIKE_in_showStatement5150 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5152 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5154 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5182 ;
    public static BitSet FOLLOW_KW_MATERIALIZED_in_showStatement5184 ;
    public static BitSet FOLLOW_KW_VIEWS_in_showStatement5186 ;
    public static BitSet FOLLOW_KW_FROM_in_showStatement5190 ;
    public static BitSet FOLLOW_KW_IN_in_showStatement5192 ;
    public static BitSet FOLLOW_identifier_in_showStatement5197 ;
    public static BitSet FOLLOW_KW_LIKE_in_showStatement5202 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5204 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5206 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5234 ;
    public static BitSet FOLLOW_KW_SORTED_in_showStatement5236 ;
    public static BitSet FOLLOW_KW_COLUMNS_in_showStatement5239 ;
    public static BitSet FOLLOW_KW_FROM_in_showStatement5242 ;
    public static BitSet FOLLOW_KW_IN_in_showStatement5244 ;
    public static BitSet FOLLOW_tableName_in_showStatement5247 ;
    public static BitSet FOLLOW_KW_FROM_in_showStatement5251 ;
    public static BitSet FOLLOW_KW_IN_in_showStatement5253 ;
    public static BitSet FOLLOW_identifier_in_showStatement5258 ;
    public static BitSet FOLLOW_KW_LIKE_in_showStatement5263 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5265 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5267 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5303 ;
    public static BitSet FOLLOW_KW_FUNCTIONS_in_showStatement5305 ;
    public static BitSet FOLLOW_KW_LIKE_in_showStatement5308 ;
    public static BitSet FOLLOW_showFunctionIdentifier_in_showStatement5310 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5333 ;
    public static BitSet FOLLOW_KW_PARTITIONS_in_showStatement5335 ;
    public static BitSet FOLLOW_tableName_in_showStatement5339 ;
    public static BitSet FOLLOW_partitionSpec_in_showStatement5341 ;
    public static BitSet FOLLOW_whereClause_in_showStatement5344 ;
    public static BitSet FOLLOW_orderByClause_in_showStatement5347 ;
    public static BitSet FOLLOW_limitClause_in_showStatement5350 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5380 ;
    public static BitSet FOLLOW_KW_CREATE_in_showStatement5382 ;
    public static BitSet FOLLOW_KW_DATABASE_in_showStatement5403 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_showStatement5405 ;
    public static BitSet FOLLOW_identifier_in_showStatement5410 ;
    public static BitSet FOLLOW_KW_TABLE_in_showStatement5439 ;
    public static BitSet FOLLOW_tableName_in_showStatement5443 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5468 ;
    public static BitSet FOLLOW_KW_TABLE_in_showStatement5470 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_showStatement5472 ;
    public static BitSet FOLLOW_KW_FROM_in_showStatement5476 ;
    public static BitSet FOLLOW_KW_IN_in_showStatement5478 ;
    public static BitSet FOLLOW_identifier_in_showStatement5483 ;
    public static BitSet FOLLOW_KW_LIKE_in_showStatement5487 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showStatement5489 ;
    public static BitSet FOLLOW_partitionSpec_in_showStatement5491 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5519 ;
    public static BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement5521 ;
    public static BitSet FOLLOW_tableName_in_showStatement5523 ;
    public static BitSet FOLLOW_LPAREN_in_showStatement5526 ;
    public static BitSet FOLLOW_StringLiteral_in_showStatement5530 ;
    public static BitSet FOLLOW_RPAREN_in_showStatement5532 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5554 ;
    public static BitSet FOLLOW_KW_LOCKS_in_showStatement5556 ;
    public static BitSet FOLLOW_KW_DATABASE_in_showStatement5581 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_showStatement5583 ;
    public static BitSet FOLLOW_identifier_in_showStatement5589 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_showStatement5595 ;
    public static BitSet FOLLOW_partTypeExpr_in_showStatement5629 ;
    public static BitSet FOLLOW_KW_EXTENDED_in_showStatement5636 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5668 ;
    public static BitSet FOLLOW_KW_COMPACTIONS_in_showStatement5670 ;
    public static BitSet FOLLOW_compactionId_in_showStatement5692 ;
    public static BitSet FOLLOW_KW_DATABASE_in_showStatement5725 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_showStatement5727 ;
    public static BitSet FOLLOW_identifier_in_showStatement5733 ;
    public static BitSet FOLLOW_compactionPool_in_showStatement5736 ;
    public static BitSet FOLLOW_compactionType_in_showStatement5739 ;
    public static BitSet FOLLOW_compactionStatus_in_showStatement5742 ;
    public static BitSet FOLLOW_orderByClause_in_showStatement5745 ;
    public static BitSet FOLLOW_limitClause_in_showStatement5748 ;
    public static BitSet FOLLOW_partTypeExpr_in_showStatement5792 ;
    public static BitSet FOLLOW_compactionPool_in_showStatement5796 ;
    public static BitSet FOLLOW_compactionType_in_showStatement5799 ;
    public static BitSet FOLLOW_compactionStatus_in_showStatement5802 ;
    public static BitSet FOLLOW_orderByClause_in_showStatement5805 ;
    public static BitSet FOLLOW_limitClause_in_showStatement5808 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5850 ;
    public static BitSet FOLLOW_KW_TRANSACTIONS_in_showStatement5852 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5866 ;
    public static BitSet FOLLOW_KW_CONF_in_showStatement5868 ;
    public static BitSet FOLLOW_StringLiteral_in_showStatement5870 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5886 ;
    public static BitSet FOLLOW_KW_RESOURCE_in_showStatement5888 ;
    public static BitSet FOLLOW_KW_PLAN_in_showStatement5907 ;
    public static BitSet FOLLOW_identifier_in_showStatement5911 ;
    public static BitSet FOLLOW_KW_PLANS_in_showStatement5934 ;
    public static BitSet FOLLOW_KW_SHOW_in_showStatement5957 ;
    public static BitSet FOLLOW_KW_DATACONNECTORS_in_showStatement5960 ;
    public static BitSet FOLLOW_KW_WHERE_in_showTablesFilterExpr5994 ;
    public static BitSet FOLLOW_identifier_in_showTablesFilterExpr5996 ;
    public static BitSet FOLLOW_EQUAL_in_showTablesFilterExpr5998 ;
    public static BitSet FOLLOW_StringLiteral_in_showTablesFilterExpr6000 ;
    public static BitSet FOLLOW_KW_LIKE_in_showTablesFilterExpr6022 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showTablesFilterExpr6024 ;
    public static BitSet FOLLOW_showStmtIdentifier_in_showTablesFilterExpr6026 ;
    public static BitSet FOLLOW_KW_LOCK_in_lockStatement6061 ;
    public static BitSet FOLLOW_KW_TABLE_in_lockStatement6063 ;
    public static BitSet FOLLOW_tableName_in_lockStatement6065 ;
    public static BitSet FOLLOW_partitionSpec_in_lockStatement6067 ;
    public static BitSet FOLLOW_lockMode_in_lockStatement6070 ;
    public static BitSet FOLLOW_KW_LOCK_in_lockDatabase6110 ;
    public static BitSet FOLLOW_KW_DATABASE_in_lockDatabase6113 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_lockDatabase6115 ;
    public static BitSet FOLLOW_identifier_in_lockDatabase6121 ;
    public static BitSet FOLLOW_lockMode_in_lockDatabase6124 ;
    public static BitSet FOLLOW_KW_UNLOCK_in_unlockStatement6193 ;
    public static BitSet FOLLOW_KW_TABLE_in_unlockStatement6195 ;
    public static BitSet FOLLOW_tableName_in_unlockStatement6197 ;
    public static BitSet FOLLOW_partitionSpec_in_unlockStatement6199 ;
    public static BitSet FOLLOW_KW_UNLOCK_in_unlockDatabase6239 ;
    public static BitSet FOLLOW_KW_DATABASE_in_unlockDatabase6242 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_unlockDatabase6244 ;
    public static BitSet FOLLOW_identifier_in_unlockDatabase6250 ;
    public static BitSet FOLLOW_KW_CREATE_in_createRoleStatement6287 ;
    public static BitSet FOLLOW_KW_ROLE_in_createRoleStatement6289 ;
    public static BitSet FOLLOW_identifier_in_createRoleStatement6293 ;
    public static BitSet FOLLOW_KW_DROP_in_dropRoleStatement6333 ;
    public static BitSet FOLLOW_KW_ROLE_in_dropRoleStatement6335 ;
    public static BitSet FOLLOW_identifier_in_dropRoleStatement6339 ;
    public static BitSet FOLLOW_KW_GRANT_in_grantPrivileges6379 ;
    public static BitSet FOLLOW_privilegeList_in_grantPrivileges6383 ;
    public static BitSet FOLLOW_privilegeObject_in_grantPrivileges6391 ;
    public static BitSet FOLLOW_KW_TO_in_grantPrivileges6400 ;
    public static BitSet FOLLOW_principalSpecification_in_grantPrivileges6402 ;
    public static BitSet FOLLOW_withGrantOption_in_grantPrivileges6410 ;
    public static BitSet FOLLOW_KW_REVOKE_in_revokePrivileges6459 ;
    public static BitSet FOLLOW_grantOptionFor_in_revokePrivileges6461 ;
    public static BitSet FOLLOW_privilegeList_in_revokePrivileges6464 ;
    public static BitSet FOLLOW_privilegeObject_in_revokePrivileges6466 ;
    public static BitSet FOLLOW_KW_FROM_in_revokePrivileges6469 ;
    public static BitSet FOLLOW_principalSpecification_in_revokePrivileges6471 ;
    public static BitSet FOLLOW_KW_GRANT_in_grantRole6518 ;
    public static BitSet FOLLOW_KW_ROLE_in_grantRole6520 ;
    public static BitSet FOLLOW_identifier_in_grantRole6523 ;
    public static BitSet FOLLOW_COMMA_in_grantRole6526 ;
    public static BitSet FOLLOW_identifier_in_grantRole6528 ;
    public static BitSet FOLLOW_KW_TO_in_grantRole6532 ;
    public static BitSet FOLLOW_principalSpecification_in_grantRole6534 ;
    public static BitSet FOLLOW_withAdminOption_in_grantRole6536 ;
    public static BitSet FOLLOW_KW_REVOKE_in_revokeRole6582 ;
    public static BitSet FOLLOW_adminOptionFor_in_revokeRole6584 ;
    public static BitSet FOLLOW_KW_ROLE_in_revokeRole6587 ;
    public static BitSet FOLLOW_identifier_in_revokeRole6590 ;
    public static BitSet FOLLOW_COMMA_in_revokeRole6593 ;
    public static BitSet FOLLOW_identifier_in_revokeRole6595 ;
    public static BitSet FOLLOW_KW_FROM_in_revokeRole6599 ;
    public static BitSet FOLLOW_principalSpecification_in_revokeRole6601 ;
    public static BitSet FOLLOW_KW_SHOW_in_showRoleGrants6646 ;
    public static BitSet FOLLOW_KW_ROLE_in_showRoleGrants6648 ;
    public static BitSet FOLLOW_KW_GRANT_in_showRoleGrants6650 ;
    public static BitSet FOLLOW_principalName_in_showRoleGrants6652 ;
    public static BitSet FOLLOW_KW_SHOW_in_showRoles6692 ;
    public static BitSet FOLLOW_KW_ROLES_in_showRoles6694 ;
    public static BitSet FOLLOW_KW_SHOW_in_showCurrentRole6731 ;
    public static BitSet FOLLOW_KW_CURRENT_in_showCurrentRole6733 ;
    public static BitSet FOLLOW_KW_ROLES_in_showCurrentRole6735 ;
    public static BitSet FOLLOW_KW_SET_in_setRole6772 ;
    public static BitSet FOLLOW_KW_ROLE_in_setRole6774 ;
    public static BitSet FOLLOW_KW_ALL_in_setRole6795 ;
    public static BitSet FOLLOW_KW_NONE_in_setRole6826 ;
    public static BitSet FOLLOW_identifier_in_setRole6848 ;
    public static BitSet FOLLOW_KW_SHOW_in_showGrants6889 ;
    public static BitSet FOLLOW_KW_GRANT_in_showGrants6891 ;
    public static BitSet FOLLOW_principalName_in_showGrants6893 ;
    public static BitSet FOLLOW_KW_ON_in_showGrants6897 ;
    public static BitSet FOLLOW_privilegeIncludeColObject_in_showGrants6899 ;
    public static BitSet FOLLOW_KW_SHOW_in_showRolePrincipals6944 ;
    public static BitSet FOLLOW_KW_PRINCIPALS_in_showRolePrincipals6946 ;
    public static BitSet FOLLOW_identifier_in_showRolePrincipals6950 ;
    public static BitSet FOLLOW_KW_ALL_in_privilegeIncludeColObject6997 ;
    public static BitSet FOLLOW_privObjectCols_in_privilegeIncludeColObject7011 ;
    public static BitSet FOLLOW_KW_ON_in_privilegeObject7046 ;
    public static BitSet FOLLOW_privObject_in_privilegeObject7048 ;
    public static BitSet FOLLOW_KW_DATABASE_in_privObject7075 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_privObject7077 ;
    public static BitSet FOLLOW_identifier_in_privObject7080 ;
    public static BitSet FOLLOW_KW_TABLE_in_privObject7096 ;
    public static BitSet FOLLOW_tableName_in_privObject7099 ;
    public static BitSet FOLLOW_partitionSpec_in_privObject7101 ;
    public static BitSet FOLLOW_KW_URI_in_privObject7121 ;
    public static BitSet FOLLOW_StringLiteral_in_privObject7126 ;
    public static BitSet FOLLOW_KW_SERVER_in_privObject7145 ;
    public static BitSet FOLLOW_identifier_in_privObject7147 ;
    public static BitSet FOLLOW_KW_DATABASE_in_privObjectCols7173 ;
    public static BitSet FOLLOW_KW_SCHEMA_in_privObjectCols7175 ;
    public static BitSet FOLLOW_identifier_in_privObjectCols7178 ;
    public static BitSet FOLLOW_KW_TABLE_in_privObjectCols7194 ;
    public static BitSet FOLLOW_tableName_in_privObjectCols7197 ;
    public static BitSet FOLLOW_LPAREN_in_privObjectCols7200 ;
    public static BitSet FOLLOW_columnNameList_in_privObjectCols7204 ;
    public static BitSet FOLLOW_RPAREN_in_privObjectCols7206 ;
    public static BitSet FOLLOW_partitionSpec_in_privObjectCols7210 ;
    public static BitSet FOLLOW_KW_URI_in_privObjectCols7234 ;
    public static BitSet FOLLOW_StringLiteral_in_privObjectCols7239 ;
    public static BitSet FOLLOW_KW_SERVER_in_privObjectCols7258 ;
    public static BitSet FOLLOW_identifier_in_privObjectCols7260 ;
    public static BitSet FOLLOW_privlegeDef_in_privilegeList7295 ;
    public static BitSet FOLLOW_COMMA_in_privilegeList7298 ;
    public static BitSet FOLLOW_privlegeDef_in_privilegeList7300 ;
    public static BitSet FOLLOW_privilegeType_in_privlegeDef7342 ;
    public static BitSet FOLLOW_LPAREN_in_privlegeDef7345 ;
    public static BitSet FOLLOW_columnNameList_in_privlegeDef7349 ;
    public static BitSet FOLLOW_RPAREN_in_privlegeDef7351 ;
    public static BitSet FOLLOW_KW_ALL_in_privilegeType7396 ;
    public static BitSet FOLLOW_KW_ALTER_in_privilegeType7410 ;
    public static BitSet FOLLOW_KW_UPDATE_in_privilegeType7424 ;
    public static BitSet FOLLOW_KW_CREATE_in_privilegeType7438 ;
    public static BitSet FOLLOW_KW_DROP_in_privilegeType7452 ;
    public static BitSet FOLLOW_KW_LOCK_in_privilegeType7466 ;
    public static BitSet FOLLOW_KW_SELECT_in_privilegeType7480 ;
    public static BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType7494 ;
    public static BitSet FOLLOW_KW_INSERT_in_privilegeType7508 ;
    public static BitSet FOLLOW_KW_DELETE_in_privilegeType7522 ;
    public static BitSet FOLLOW_principalName_in_principalSpecification7555 ;
    public static BitSet FOLLOW_COMMA_in_principalSpecification7558 ;
    public static BitSet FOLLOW_principalName_in_principalSpecification7560 ;
    public static BitSet FOLLOW_KW_USER_in_principalName7598 ;
    public static BitSet FOLLOW_principalIdentifier_in_principalName7600 ;
    public static BitSet FOLLOW_KW_GROUP_in_principalName7616 ;
    public static BitSet FOLLOW_principalIdentifier_in_principalName7618 ;
    public static BitSet FOLLOW_KW_ROLE_in_principalName7634 ;
    public static BitSet FOLLOW_identifier_in_principalName7636 ;
    public static BitSet FOLLOW_KW_WITH_in_withGrantOption7671 ;
    public static BitSet FOLLOW_KW_GRANT_in_withGrantOption7673 ;
    public static BitSet FOLLOW_KW_OPTION_in_withGrantOption7675 ;
    public static BitSet FOLLOW_KW_GRANT_in_grantOptionFor7712 ;
    public static BitSet FOLLOW_KW_OPTION_in_grantOptionFor7714 ;
    public static BitSet FOLLOW_KW_FOR_in_grantOptionFor7716 ;
    public static BitSet FOLLOW_KW_ADMIN_in_adminOptionFor7749 ;
    public static BitSet FOLLOW_KW_OPTION_in_adminOptionFor7751 ;
    public static BitSet FOLLOW_KW_FOR_in_adminOptionFor7753 ;
    public static BitSet FOLLOW_KW_WITH_in_withAdminOption7786 ;
    public static BitSet FOLLOW_KW_ADMIN_in_withAdminOption7788 ;
    public static BitSet FOLLOW_KW_OPTION_in_withAdminOption7790 ;
    public static BitSet FOLLOW_KW_MSCK_in_metastoreCheck7827 ;
    public static BitSet FOLLOW_KW_REPAIR_in_metastoreCheck7832 ;
    public static BitSet FOLLOW_KW_TABLE_in_metastoreCheck7843 ;
    public static BitSet FOLLOW_tableName_in_metastoreCheck7845 ;
    public static BitSet FOLLOW_KW_ADD_in_metastoreCheck7859 ;
    public static BitSet FOLLOW_KW_DROP_in_metastoreCheck7861 ;
    public static BitSet FOLLOW_KW_SYNC_in_metastoreCheck7863 ;
    public static BitSet FOLLOW_KW_PARTITIONS_in_metastoreCheck7869 ;
    public static BitSet FOLLOW_partitionSelectorSpec_in_metastoreCheck7873 ;
    public static BitSet FOLLOW_resource_in_resourceList7931 ;
    public static BitSet FOLLOW_COMMA_in_resourceList7934 ;
    public static BitSet FOLLOW_resource_in_resourceList7936 ;
    public static BitSet FOLLOW_resourceType_in_resource7974 ;
    public static BitSet FOLLOW_StringLiteral_in_resource7978 ;
    public static BitSet FOLLOW_KW_JAR_in_resourceType8015 ;
    public static BitSet FOLLOW_KW_FILE_in_resourceType8029 ;
    public static BitSet FOLLOW_KW_ARCHIVE_in_resourceType8043 ;
    public static BitSet FOLLOW_KW_CREATE_in_createFunctionStatement8074 ;
    public static BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement8079 ;
    public static BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement8083 ;
    public static BitSet FOLLOW_functionIdentifier_in_createFunctionStatement8085 ;
    public static BitSet FOLLOW_KW_AS_in_createFunctionStatement8087 ;
    public static BitSet FOLLOW_StringLiteral_in_createFunctionStatement8089 ;
    public static BitSet FOLLOW_KW_USING_in_createFunctionStatement8098 ;
    public static BitSet FOLLOW_resourceList_in_createFunctionStatement8102 ;
    public static BitSet FOLLOW_KW_DROP_in_dropFunctionStatement8188 ;
    public static BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement8193 ;
    public static BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement8197 ;
    public static BitSet FOLLOW_ifExists_in_dropFunctionStatement8199 ;
    public static BitSet FOLLOW_functionIdentifier_in_dropFunctionStatement8202 ;
    public static BitSet FOLLOW_KW_RELOAD_in_reloadFunctionsStatement8280 ;
    public static BitSet FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement8283 ;
    public static BitSet FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement8285 ;
    public static BitSet FOLLOW_KW_CREATE_in_createMacroStatement8314 ;
    public static BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement8316 ;
    public static BitSet FOLLOW_KW_MACRO_in_createMacroStatement8318 ;
    public static BitSet FOLLOW_Identifier_in_createMacroStatement8320 ;
    public static BitSet FOLLOW_LPAREN_in_createMacroStatement8328 ;
    public static BitSet FOLLOW_columnNameTypeList_in_createMacroStatement8330 ;
    public static BitSet FOLLOW_RPAREN_in_createMacroStatement8333 ;
    public static BitSet FOLLOW_expression_in_createMacroStatement8335 ;
    public static BitSet FOLLOW_KW_DROP_in_dropMacroStatement8379 ;
    public static BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement8381 ;
    public static BitSet FOLLOW_KW_MACRO_in_dropMacroStatement8383 ;
    public static BitSet FOLLOW_ifExists_in_dropMacroStatement8385 ;
    public static BitSet FOLLOW_Identifier_in_dropMacroStatement8388 ;
    public static BitSet FOLLOW_KW_CREATE_in_createViewStatement8430 ;
    public static BitSet FOLLOW_orReplace_in_createViewStatement8433 ;
    public static BitSet FOLLOW_KW_VIEW_in_createViewStatement8437 ;
    public static BitSet FOLLOW_ifNotExists_in_createViewStatement8440 ;
    public static BitSet FOLLOW_tableName_in_createViewStatement8446 ;
    public static BitSet FOLLOW_LPAREN_in_createViewStatement8457 ;
    public static BitSet FOLLOW_columnNameCommentList_in_createViewStatement8459 ;
    public static BitSet FOLLOW_RPAREN_in_createViewStatement8461 ;
    public static BitSet FOLLOW_tableComment_in_createViewStatement8465 ;
    public static BitSet FOLLOW_viewPartition_in_createViewStatement8468 ;
    public static BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement8479 ;
    public static BitSet FOLLOW_KW_AS_in_createViewStatement8490 ;
    public static BitSet FOLLOW_selectStatementWithCTE_in_createViewStatement8500 ;
    public static BitSet FOLLOW_KW_PARTITIONED_in_viewPartition8623 ;
    public static BitSet FOLLOW_KW_ON_in_viewPartition8625 ;
    public static BitSet FOLLOW_LPAREN_in_viewPartition8627 ;
    public static BitSet FOLLOW_columnNameList_in_viewPartition8629 ;
    public static BitSet FOLLOW_RPAREN_in_viewPartition8631 ;
    public static BitSet FOLLOW_viewClusterSpec_in_viewOrganization8670 ;
    public static BitSet FOLLOW_viewComplexSpec_in_viewOrganization8678 ;
    public static BitSet FOLLOW_KW_CLUSTERED_in_viewClusterSpec8705 ;
    public static BitSet FOLLOW_KW_ON_in_viewClusterSpec8707 ;
    public static BitSet FOLLOW_LPAREN_in_viewClusterSpec8709 ;
    public static BitSet FOLLOW_columnNameList_in_viewClusterSpec8711 ;
    public static BitSet FOLLOW_RPAREN_in_viewClusterSpec8713 ;
    public static BitSet FOLLOW_viewDistSpec_in_viewComplexSpec8752 ;
    public static BitSet FOLLOW_viewSortSpec_in_viewComplexSpec8754 ;
    public static BitSet FOLLOW_KW_DISTRIBUTED_in_viewDistSpec8781 ;
    public static BitSet FOLLOW_KW_ON_in_viewDistSpec8783 ;
    public static BitSet FOLLOW_LPAREN_in_viewDistSpec8785 ;
    public static BitSet FOLLOW_columnNameList_in_viewDistSpec8789 ;
    public static BitSet FOLLOW_RPAREN_in_viewDistSpec8791 ;
    public static BitSet FOLLOW_KW_SORTED_in_viewSortSpec8831 ;
    public static BitSet FOLLOW_KW_ON_in_viewSortSpec8833 ;
    public static BitSet FOLLOW_LPAREN_in_viewSortSpec8835 ;
    public static BitSet FOLLOW_columnNameList_in_viewSortSpec8839 ;
    public static BitSet FOLLOW_RPAREN_in_viewSortSpec8841 ;
    public static BitSet FOLLOW_KW_DROP_in_dropViewStatement8881 ;
    public static BitSet FOLLOW_KW_VIEW_in_dropViewStatement8883 ;
    public static BitSet FOLLOW_ifExists_in_dropViewStatement8885 ;
    public static BitSet FOLLOW_viewName_in_dropViewStatement8888 ;
    public static BitSet FOLLOW_KW_CREATE_in_createMaterializedViewStatement8926 ;
    public static BitSet FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement8928 ;
    public static BitSet FOLLOW_KW_VIEW_in_createMaterializedViewStatement8930 ;
    public static BitSet FOLLOW_ifNotExists_in_createMaterializedViewStatement8933 ;
    public static BitSet FOLLOW_tableName_in_createMaterializedViewStatement8939 ;
    public static BitSet FOLLOW_rewriteDisabled_in_createMaterializedViewStatement8949 ;
    public static BitSet FOLLOW_tableComment_in_createMaterializedViewStatement8952 ;
    public static BitSet FOLLOW_viewPartition_in_createMaterializedViewStatement8955 ;
    public static BitSet FOLLOW_viewOrganization_in_createMaterializedViewStatement8958 ;
    public static BitSet FOLLOW_tableRowFormat_in_createMaterializedViewStatement8969 ;
    public static BitSet FOLLOW_tableFileFormat_in_createMaterializedViewStatement8972 ;
    public static BitSet FOLLOW_tableLocation_in_createMaterializedViewStatement8975 ;
    public static BitSet FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement8986 ;
    public static BitSet FOLLOW_KW_AS_in_createMaterializedViewStatement8989 ;
    public static BitSet FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement8991 ;
    public static BitSet FOLLOW_KW_DROP_in_dropMaterializedViewStatement9159 ;
    public static BitSet FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement9161 ;
    public static BitSet FOLLOW_KW_VIEW_in_dropMaterializedViewStatement9163 ;
    public static BitSet FOLLOW_ifExists_in_dropMaterializedViewStatement9165 ;
    public static BitSet FOLLOW_viewName_in_dropMaterializedViewStatement9168 ;
    public static BitSet FOLLOW_KW_CREATE_in_createScheduledQueryStatement9206 ;
    public static BitSet FOLLOW_KW_SCHEDULED_in_createScheduledQueryStatement9208 ;
    public static BitSet FOLLOW_KW_QUERY_in_createScheduledQueryStatement9210 ;
    public static BitSet FOLLOW_identifier_in_createScheduledQueryStatement9214 ;
    public static BitSet FOLLOW_scheduleSpec_in_createScheduledQueryStatement9224 ;
    public static BitSet FOLLOW_executedAsSpec_in_createScheduledQueryStatement9234 ;
    public static BitSet FOLLOW_enableSpecification_in_createScheduledQueryStatement9245 ;
    public static BitSet FOLLOW_definedAsSpec_in_createScheduledQueryStatement9256 ;
    public static BitSet FOLLOW_KW_DROP_in_dropScheduledQueryStatement9375 ;
    public static BitSet FOLLOW_KW_SCHEDULED_in_dropScheduledQueryStatement9377 ;
    public static BitSet FOLLOW_KW_QUERY_in_dropScheduledQueryStatement9379 ;
    public static BitSet FOLLOW_identifier_in_dropScheduledQueryStatement9383 ;
    public static BitSet FOLLOW_KW_ALTER_in_alterScheduledQueryStatement9445 ;
    public static BitSet FOLLOW_KW_SCHEDULED_in_alterScheduledQueryStatement9447 ;
    public static BitSet FOLLOW_KW_QUERY_in_alterScheduledQueryStatement9449 ;
    public static BitSet FOLLOW_identifier_in_alterScheduledQueryStatement9453 ;
    public static BitSet FOLLOW_alterScheduledQueryChange_in_alterScheduledQueryStatement9469 ;
    public static BitSet FOLLOW_scheduleSpec_in_alterScheduledQueryChange9545 ;
    public static BitSet FOLLOW_executedAsSpec_in_alterScheduledQueryChange9553 ;
    public static BitSet FOLLOW_enableSpecification_in_alterScheduledQueryChange9561 ;
    public static BitSet FOLLOW_definedAsSpec_in_alterScheduledQueryChange9569 ;
    public static BitSet FOLLOW_KW_EXECUTE_in_alterScheduledQueryChange9577 ;
    public static BitSet FOLLOW_KW_CRON_in_scheduleSpec9614 ;
    public static BitSet FOLLOW_StringLiteral_in_scheduleSpec9618 ;
    public static BitSet FOLLOW_KW_EVERY_in_scheduleSpec9639 ;
    public static BitSet FOLLOW_Number_in_scheduleSpec9643 ;
    public static BitSet FOLLOW_intervalQualifiers_in_scheduleSpec9648 ;
    public static BitSet FOLLOW_KW_AT_in_scheduleSpec9660 ;
    public static BitSet FOLLOW_KW_OFFSET_in_scheduleSpec9662 ;
    public static BitSet FOLLOW_KW_BY_in_scheduleSpec9664 ;
    public static BitSet FOLLOW_StringLiteral_in_scheduleSpec9669 ;
    public static BitSet FOLLOW_KW_EXECUTED_in_executedAsSpec9727 ;
    public static BitSet FOLLOW_KW_AS_in_executedAsSpec9729 ;
    public static BitSet FOLLOW_StringLiteral_in_executedAsSpec9733 ;
    public static BitSet FOLLOW_KW_DEFINED_in_definedAsSpec9777 ;
    public static BitSet FOLLOW_KW_AS_in_definedAsSpec9780 ;
    public static BitSet FOLLOW_statement_in_definedAsSpec9782 ;
    public static BitSet FOLLOW_functionIdentifier_in_showFunctionIdentifier9821 ;
    public static BitSet FOLLOW_StringLiteral_in_showFunctionIdentifier9829 ;
    public static BitSet FOLLOW_identifier_in_showStmtIdentifier9856 ;
    public static BitSet FOLLOW_StringLiteral_in_showStmtIdentifier9864 ;
    public static BitSet FOLLOW_KW_COMMENT_in_tableComment9897 ;
    public static BitSet FOLLOW_StringLiteral_in_tableComment9901 ;
    public static BitSet FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec9938 ;
    public static BitSet FOLLOW_KW_BY_in_createTablePartitionSpec9940 ;
    public static BitSet FOLLOW_LPAREN_in_createTablePartitionSpec9942 ;
    public static BitSet FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec9949 ;
    public static BitSet FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec9957 ;
    public static BitSet FOLLOW_RPAREN_in_createTablePartitionSpec9960 ;
    public static BitSet FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec9988 ;
    public static BitSet FOLLOW_KW_BY_in_createTablePartitionSpec9990 ;
    public static BitSet FOLLOW_KW_SPEC_in_createTablePartitionSpec9992 ;
    public static BitSet FOLLOW_LPAREN_in_createTablePartitionSpec9994 ;
    public static BitSet FOLLOW_partitionTransformSpec_in_createTablePartitionSpec10001 ;
    public static BitSet FOLLOW_RPAREN_in_createTablePartitionSpec10004 ;
    public static BitSet FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec10044 ;
    public static BitSet FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec10047 ;
    public static BitSet FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec10049 ;
    public static BitSet FOLLOW_columnName_in_createTablePartitionColumnSpec10091 ;
    public static BitSet FOLLOW_COMMA_in_createTablePartitionColumnSpec10094 ;
    public static BitSet FOLLOW_columnName_in_createTablePartitionColumnSpec10096 ;
    public static BitSet FOLLOW_columnNameTransformConstraint_in_partitionTransformSpec10138 ;
    public static BitSet FOLLOW_COMMA_in_partitionTransformSpec10141 ;
    public static BitSet FOLLOW_columnNameTransformConstraint_in_partitionTransformSpec10143 ;
    public static BitSet FOLLOW_partitionTransformType_in_columnNameTransformConstraint10181 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10220 ;
    public static BitSet FOLLOW_KW_YEAR_in_partitionTransformType10251 ;
    public static BitSet FOLLOW_LPAREN_in_partitionTransformType10253 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10255 ;
    public static BitSet FOLLOW_RPAREN_in_partitionTransformType10257 ;
    public static BitSet FOLLOW_KW_MONTH_in_partitionTransformType10288 ;
    public static BitSet FOLLOW_LPAREN_in_partitionTransformType10290 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10292 ;
    public static BitSet FOLLOW_RPAREN_in_partitionTransformType10294 ;
    public static BitSet FOLLOW_KW_DAY_in_partitionTransformType10325 ;
    public static BitSet FOLLOW_LPAREN_in_partitionTransformType10327 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10329 ;
    public static BitSet FOLLOW_RPAREN_in_partitionTransformType10331 ;
    public static BitSet FOLLOW_KW_HOUR_in_partitionTransformType10362 ;
    public static BitSet FOLLOW_LPAREN_in_partitionTransformType10364 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10366 ;
    public static BitSet FOLLOW_RPAREN_in_partitionTransformType10368 ;
    public static BitSet FOLLOW_KW_TRUNCATE_in_partitionTransformType10399 ;
    public static BitSet FOLLOW_LPAREN_in_partitionTransformType10401 ;
    public static BitSet FOLLOW_Number_in_partitionTransformType10407 ;
    public static BitSet FOLLOW_COMMA_in_partitionTransformType10409 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10411 ;
    public static BitSet FOLLOW_RPAREN_in_partitionTransformType10413 ;
    public static BitSet FOLLOW_KW_BUCKET_in_partitionTransformType10447 ;
    public static BitSet FOLLOW_LPAREN_in_partitionTransformType10449 ;
    public static BitSet FOLLOW_Number_in_partitionTransformType10455 ;
    public static BitSet FOLLOW_COMMA_in_partitionTransformType10457 ;
    public static BitSet FOLLOW_columnName_in_partitionTransformType10459 ;
    public static BitSet FOLLOW_RPAREN_in_partitionTransformType10461 ;
    public static BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets10520 ;
    public static BitSet FOLLOW_KW_BY_in_tableBuckets10522 ;
    public static BitSet FOLLOW_LPAREN_in_tableBuckets10524 ;
    public static BitSet FOLLOW_columnNameList_in_tableBuckets10528 ;
    public static BitSet FOLLOW_RPAREN_in_tableBuckets10530 ;
    public static BitSet FOLLOW_KW_SORTED_in_tableBuckets10533 ;
    public static BitSet FOLLOW_KW_BY_in_tableBuckets10535 ;
    public static BitSet FOLLOW_LPAREN_in_tableBuckets10537 ;
    public static BitSet FOLLOW_columnNameOrderList_in_tableBuckets10541 ;
    public static BitSet FOLLOW_RPAREN_in_tableBuckets10543 ;
    public static BitSet FOLLOW_KW_INTO_in_tableBuckets10547 ;
    public static BitSet FOLLOW_Number_in_tableBuckets10551 ;
    public static BitSet FOLLOW_KW_BUCKETS_in_tableBuckets10553 ;
    public static BitSet FOLLOW_KW_SKEWED_in_tableSkewed10605 ;
    public static BitSet FOLLOW_KW_BY_in_tableSkewed10607 ;
    public static BitSet FOLLOW_LPAREN_in_tableSkewed10609 ;
    public static BitSet FOLLOW_columnNameList_in_tableSkewed10613 ;
    public static BitSet FOLLOW_RPAREN_in_tableSkewed10615 ;
    public static BitSet FOLLOW_KW_ON_in_tableSkewed10617 ;
    public static BitSet FOLLOW_LPAREN_in_tableSkewed10619 ;
    public static BitSet FOLLOW_skewedValueElement_in_tableSkewed10624 ;
    public static BitSet FOLLOW_RPAREN_in_tableSkewed10627 ;
    public static BitSet FOLLOW_storedAsDirs_in_tableSkewed10636 ;
    public static BitSet FOLLOW_rowFormatSerde_in_rowFormat10684 ;
    public static BitSet FOLLOW_rowFormatDelimited_in_rowFormat10700 ;
    public static BitSet FOLLOW_KW_RECORDREADER_in_recordReader10749 ;
    public static BitSet FOLLOW_StringLiteral_in_recordReader10751 ;
    public static BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter10800 ;
    public static BitSet FOLLOW_StringLiteral_in_recordWriter10802 ;
    public static BitSet FOLLOW_KW_ROW_in_rowFormatSerde10851 ;
    public static BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde10853 ;
    public static BitSet FOLLOW_KW_SERDE_in_rowFormatSerde10855 ;
    public static BitSet FOLLOW_StringLiteral_in_rowFormatSerde10859 ;
    public static BitSet FOLLOW_KW_WITH_in_rowFormatSerde10862 ;
    public static BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10864 ;
    public static BitSet FOLLOW_tableProperties_in_rowFormatSerde10868 ;
    public static BitSet FOLLOW_KW_ROW_in_rowFormatDelimited10920 ;
    public static BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited10922 ;
    public static BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited10924 ;
    public static BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10926 ;
    public static BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10929 ;
    public static BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10932 ;
    public static BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10935 ;
    public static BitSet FOLLOW_tableRowNullFormat_in_rowFormatDelimited10938 ;
    public static BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat10997 ;
    public static BitSet FOLLOW_rowFormatSerde_in_tableRowFormat11017 ;
    public static BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed11064 ;
    public static BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed11067 ;
    public static BitSet FOLLOW_LPAREN_in_tableProperties11100 ;
    public static BitSet FOLLOW_tablePropertiesList_in_tableProperties11102 ;
    public static BitSet FOLLOW_RPAREN_in_tableProperties11104 ;
    public static BitSet FOLLOW_keyValueProperty_in_tablePropertiesList11145 ;
    public static BitSet FOLLOW_COMMA_in_tablePropertiesList11148 ;
    public static BitSet FOLLOW_keyValueProperty_in_tablePropertiesList11150 ;
    public static BitSet FOLLOW_keyProperty_in_tablePropertiesList11175 ;
    public static BitSet FOLLOW_COMMA_in_tablePropertiesList11178 ;
    public static BitSet FOLLOW_keyProperty_in_tablePropertiesList11180 ;
    public static BitSet FOLLOW_StringLiteral_in_keyValueProperty11226 ;
    public static BitSet FOLLOW_EQUAL_in_keyValueProperty11228 ;
    public static BitSet FOLLOW_StringLiteral_in_keyValueProperty11232 ;
    public static BitSet FOLLOW_StringLiteral_in_keyProperty11279 ;
    public static BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier11323 ;
    public static BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier11325 ;
    public static BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11327 ;
    public static BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11331 ;
    public static BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier11334 ;
    public static BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11336 ;
    public static BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11340 ;
    public static BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier11392 ;
    public static BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier11394 ;
    public static BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier11396 ;
    public static BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier11398 ;
    public static BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier11402 ;
    public static BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11448 ;
    public static BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11450 ;
    public static BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11452 ;
    public static BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11454 ;
    public static BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11458 ;
    public static BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11504 ;
    public static BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11506 ;
    public static BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11508 ;
    public static BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11512 ;
    public static BitSet FOLLOW_KW_NULL_in_tableRowNullFormat11558 ;
    public static BitSet FOLLOW_KW_DEFINED_in_tableRowNullFormat11560 ;
    public static BitSet FOLLOW_KW_AS_in_tableRowNullFormat11562 ;
    public static BitSet FOLLOW_StringLiteral_in_tableRowNullFormat11566 ;
    public static BitSet FOLLOW_KW_STORED_in_tableFileFormat11621 ;
    public static BitSet FOLLOW_KW_AS_in_tableFileFormat11623 ;
    public static BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11625 ;
    public static BitSet FOLLOW_StringLiteral_in_tableFileFormat11629 ;
    public static BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11631 ;
    public static BitSet FOLLOW_StringLiteral_in_tableFileFormat11635 ;
    public static BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11638 ;
    public static BitSet FOLLOW_StringLiteral_in_tableFileFormat11642 ;
    public static BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11644 ;
    public static BitSet FOLLOW_StringLiteral_in_tableFileFormat11648 ;
    public static BitSet FOLLOW_KW_STORED_in_tableFileFormat11686 ;
    public static BitSet FOLLOW_KW_BY_in_tableFileFormat11688 ;
    public static BitSet FOLLOW_StringLiteral_in_tableFileFormat11692 ;
    public static BitSet FOLLOW_KW_WITH_in_tableFileFormat11704 ;
    public static BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11706 ;
    public static BitSet FOLLOW_tableProperties_in_tableFileFormat11710 ;
    public static BitSet FOLLOW_KW_STORED_in_tableFileFormat11724 ;
    public static BitSet FOLLOW_KW_AS_in_tableFileFormat11726 ;
    public static BitSet FOLLOW_identifier_in_tableFileFormat11730 ;
    public static BitSet FOLLOW_KW_STORED_in_tableFileFormat11769 ;
    public static BitSet FOLLOW_KW_BY_in_tableFileFormat11771 ;
    public static BitSet FOLLOW_identifier_in_tableFileFormat11775 ;
    public static BitSet FOLLOW_KW_WITH_in_tableFileFormat11787 ;
    public static BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11789 ;
    public static BitSet FOLLOW_tableProperties_in_tableFileFormat11793 ;
    public static BitSet FOLLOW_KW_STORED_in_tableFileFormat11807 ;
    public static BitSet FOLLOW_KW_AS_in_tableFileFormat11809 ;
    public static BitSet FOLLOW_identifier_in_tableFileFormat11813 ;
    public static BitSet FOLLOW_KW_STORED_in_tableFileFormat11852 ;
    public static BitSet FOLLOW_KW_AS_in_tableFileFormat11854 ;
    public static BitSet FOLLOW_identifier_in_tableFileFormat11858 ;
    public static BitSet FOLLOW_KW_LOCATION_in_tableLocation11906 ;
    public static BitSet FOLLOW_StringLiteral_in_tableLocation11910 ;
    public static BitSet FOLLOW_columnNameType_in_columnNameTypeList11946 ;
    public static BitSet FOLLOW_COMMA_in_columnNameTypeList11949 ;
    public static BitSet FOLLOW_columnNameType_in_columnNameTypeList11951 ;
    public static BitSet FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList11989 ;
    public static BitSet FOLLOW_COMMA_in_columnNameTypeOrConstraintList11992 ;
    public static BitSet FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList11994 ;
    public static BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList12032 ;
    public static BitSet FOLLOW_COMMA_in_columnNameColonTypeList12035 ;
    public static BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList12037 ;
    public static BitSet FOLLOW_columnName_in_columnNameList12075 ;
    public static BitSet FOLLOW_COMMA_in_columnNameList12078 ;
    public static BitSet FOLLOW_columnName_in_columnNameList12080 ;
    public static BitSet FOLLOW_identifier_in_columnName12124 ;
    public static BitSet FOLLOW_identifier_in_extColumnName12157 ;
    public static BitSet FOLLOW_DOT_in_extColumnName12160 ;
    public static BitSet FOLLOW_KW_ELEM_TYPE_in_extColumnName12170 ;
    public static BitSet FOLLOW_KW_KEY_TYPE_in_extColumnName12180 ;
    public static BitSet FOLLOW_KW_VALUE_TYPE_in_extColumnName12190 ;
    public static BitSet FOLLOW_identifier_in_extColumnName12194 ;
    public static BitSet FOLLOW_columnNameOrder_in_columnNameOrderList12224 ;
    public static BitSet FOLLOW_COMMA_in_columnNameOrderList12227 ;
    public static BitSet FOLLOW_columnNameOrder_in_columnNameOrderList12229 ;
    public static BitSet FOLLOW_LPAREN_in_columnParenthesesList12267 ;
    public static BitSet FOLLOW_columnNameList_in_columnParenthesesList12270 ;
    public static BitSet FOLLOW_RPAREN_in_columnParenthesesList12272 ;
    public static BitSet FOLLOW_enableSpecification_in_enableValidateSpecification12300 ;
    public static BitSet FOLLOW_validateSpecification_in_enableValidateSpecification12302 ;
    public static BitSet FOLLOW_enforcedSpecification_in_enableValidateSpecification12311 ;
    public static BitSet FOLLOW_KW_ENABLE_in_enableSpecification12338 ;
    public static BitSet FOLLOW_KW_DISABLE_in_enableSpecification12352 ;
    public static BitSet FOLLOW_KW_VALIDATE_in_validateSpecification12385 ;
    public static BitSet FOLLOW_KW_NOVALIDATE_in_validateSpecification12399 ;
    public static BitSet FOLLOW_KW_ENFORCED_in_enforcedSpecification12432 ;
    public static BitSet FOLLOW_KW_NOT_in_enforcedSpecification12446 ;
    public static BitSet FOLLOW_KW_ENFORCED_in_enforcedSpecification12448 ;
    public static BitSet FOLLOW_KW_RELY_in_relySpecification12482 ;
    public static BitSet FOLLOW_KW_NORELY_in_relySpecification12497 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_createConstraint12531 ;
    public static BitSet FOLLOW_identifier_in_createConstraint12535 ;
    public static BitSet FOLLOW_tableLevelConstraint_in_createConstraint12539 ;
    public static BitSet FOLLOW_constraintOptsCreate_in_createConstraint12541 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName12616 ;
    public static BitSet FOLLOW_identifier_in_alterConstraintWithName12620 ;
    public static BitSet FOLLOW_tableLevelConstraint_in_alterConstraintWithName12622 ;
    public static BitSet FOLLOW_constraintOptsAlter_in_alterConstraintWithName12624 ;
    public static BitSet FOLLOW_pkUkConstraint_in_tableLevelConstraint12661 ;
    public static BitSet FOLLOW_checkConstraint_in_tableLevelConstraint12669 ;
    public static BitSet FOLLOW_tableConstraintType_in_pkUkConstraint12696 ;
    public static BitSet FOLLOW_columnParenthesesList_in_pkUkConstraint12700 ;
    public static BitSet FOLLOW_KW_CHECK_in_checkConstraint12740 ;
    public static BitSet FOLLOW_LPAREN_in_checkConstraint12742 ;
    public static BitSet FOLLOW_expression_in_checkConstraint12744 ;
    public static BitSet FOLLOW_RPAREN_in_checkConstraint12746 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_createForeignKey12786 ;
    public static BitSet FOLLOW_identifier_in_createForeignKey12790 ;
    public static BitSet FOLLOW_KW_FOREIGN_in_createForeignKey12794 ;
    public static BitSet FOLLOW_KW_KEY_in_createForeignKey12796 ;
    public static BitSet FOLLOW_columnParenthesesList_in_createForeignKey12800 ;
    public static BitSet FOLLOW_KW_REFERENCES_in_createForeignKey12803 ;
    public static BitSet FOLLOW_tableName_in_createForeignKey12807 ;
    public static BitSet FOLLOW_columnParenthesesList_in_createForeignKey12811 ;
    public static BitSet FOLLOW_constraintOptsCreate_in_createForeignKey12813 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName12906 ;
    public static BitSet FOLLOW_identifier_in_alterForeignKeyWithName12910 ;
    public static BitSet FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName12912 ;
    public static BitSet FOLLOW_KW_KEY_in_alterForeignKeyWithName12914 ;
    public static BitSet FOLLOW_columnParenthesesList_in_alterForeignKeyWithName12918 ;
    public static BitSet FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName12921 ;
    public static BitSet FOLLOW_tableName_in_alterForeignKeyWithName12925 ;
    public static BitSet FOLLOW_columnParenthesesList_in_alterForeignKeyWithName12929 ;
    public static BitSet FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName12931 ;
    public static BitSet FOLLOW_skewedColumnValues_in_skewedValueElement12994 ;
    public static BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement13003 ;
    public static BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13030 ;
    public static BitSet FOLLOW_COMMA_in_skewedColumnValuePairList13033 ;
    public static BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13035 ;
    public static BitSet FOLLOW_LPAREN_in_skewedColumnValuePair13079 ;
    public static BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair13083 ;
    public static BitSet FOLLOW_RPAREN_in_skewedColumnValuePair13085 ;
    public static BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues13127 ;
    public static BitSet FOLLOW_COMMA_in_skewedColumnValues13130 ;
    public static BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues13132 ;
    public static BitSet FOLLOW_constant_in_skewedColumnValue13176 ;
    public static BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement13209 ;
    public static BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement13218 ;
    public static BitSet FOLLOW_KW_NULLS_in_nullOrdering13272 ;
    public static BitSet FOLLOW_KW_FIRST_in_nullOrdering13274 ;
    public static BitSet FOLLOW_KW_NULLS_in_nullOrdering13288 ;
    public static BitSet FOLLOW_KW_LAST_in_nullOrdering13290 ;
    public static BitSet FOLLOW_identifier_in_columnNameOrder13323 ;
    public static BitSet FOLLOW_orderSpecification_in_columnNameOrder13327 ;
    public static BitSet FOLLOW_nullOrdering_in_columnNameOrder13332 ;
    public static BitSet FOLLOW_columnNameComment_in_columnNameCommentList13529 ;
    public static BitSet FOLLOW_COMMA_in_columnNameCommentList13532 ;
    public static BitSet FOLLOW_columnNameComment_in_columnNameCommentList13534 ;
    public static BitSet FOLLOW_identifier_in_columnNameComment13574 ;
    public static BitSet FOLLOW_KW_COMMENT_in_columnNameComment13577 ;
    public static BitSet FOLLOW_StringLiteral_in_columnNameComment13581 ;
    public static BitSet FOLLOW_KW_ASC_in_orderSpecificationRewrite13629 ;
    public static BitSet FOLLOW_KW_DESC_in_orderSpecificationRewrite13643 ;
    public static BitSet FOLLOW_expression_in_columnRefOrder13676 ;
    public static BitSet FOLLOW_orderSpecificationRewrite_in_columnRefOrder13680 ;
    public static BitSet FOLLOW_nullOrdering_in_columnRefOrder13685 ;
    public static BitSet FOLLOW_identifier_in_columnNameType13988 ;
    public static BitSet FOLLOW_colType_in_columnNameType13990 ;
    public static BitSet FOLLOW_KW_COMMENT_in_columnNameType13993 ;
    public static BitSet FOLLOW_StringLiteral_in_columnNameType13997 ;
    public static BitSet FOLLOW_tableConstraint_in_columnNameTypeOrConstraint14093 ;
    public static BitSet FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint14105 ;
    public static BitSet FOLLOW_createForeignKey_in_tableConstraint14136 ;
    public static BitSet FOLLOW_createConstraint_in_tableConstraint14148 ;
    public static BitSet FOLLOW_identifier_in_columnNameTypeConstraint14179 ;
    public static BitSet FOLLOW_colType_in_columnNameTypeConstraint14181 ;
    public static BitSet FOLLOW_columnConstraint_in_columnNameTypeConstraint14183 ;
    public static BitSet FOLLOW_KW_COMMENT_in_columnNameTypeConstraint14188 ;
    public static BitSet FOLLOW_StringLiteral_in_columnNameTypeConstraint14192 ;
    public static BitSet FOLLOW_foreignKeyConstraint_in_columnConstraint14256 ;
    public static BitSet FOLLOW_colConstraint_in_columnConstraint14269 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint14300 ;
    public static BitSet FOLLOW_identifier_in_foreignKeyConstraint14304 ;
    public static BitSet FOLLOW_KW_REFERENCES_in_foreignKeyConstraint14308 ;
    public static BitSet FOLLOW_tableName_in_foreignKeyConstraint14312 ;
    public static BitSet FOLLOW_LPAREN_in_foreignKeyConstraint14314 ;
    public static BitSet FOLLOW_columnName_in_foreignKeyConstraint14318 ;
    public static BitSet FOLLOW_RPAREN_in_foreignKeyConstraint14320 ;
    public static BitSet FOLLOW_constraintOptsCreate_in_foreignKeyConstraint14322 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_colConstraint14430 ;
    public static BitSet FOLLOW_identifier_in_colConstraint14434 ;
    public static BitSet FOLLOW_columnConstraintType_in_colConstraint14438 ;
    public static BitSet FOLLOW_constraintOptsCreate_in_colConstraint14440 ;
    public static BitSet FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint14518 ;
    public static BitSet FOLLOW_alterColConstraint_in_alterColumnConstraint14531 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint14562 ;
    public static BitSet FOLLOW_identifier_in_alterForeignKeyConstraint14566 ;
    public static BitSet FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint14570 ;
    public static BitSet FOLLOW_tableName_in_alterForeignKeyConstraint14574 ;
    public static BitSet FOLLOW_LPAREN_in_alterForeignKeyConstraint14576 ;
    public static BitSet FOLLOW_columnName_in_alterForeignKeyConstraint14580 ;
    public static BitSet FOLLOW_RPAREN_in_alterForeignKeyConstraint14582 ;
    public static BitSet FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint14584 ;
    public static BitSet FOLLOW_KW_CONSTRAINT_in_alterColConstraint14692 ;
    public static BitSet FOLLOW_identifier_in_alterColConstraint14696 ;
    public static BitSet FOLLOW_columnConstraintType_in_alterColConstraint14700 ;
    public static BitSet FOLLOW_constraintOptsAlter_in_alterColConstraint14702 ;
    public static BitSet FOLLOW_KW_NOT_in_columnConstraintType14767 ;
    public static BitSet FOLLOW_KW_NULL_in_columnConstraintType14769 ;
    public static BitSet FOLLOW_KW_DEFAULT_in_columnConstraintType14790 ;
    public static BitSet FOLLOW_defaultVal_in_columnConstraintType14792 ;
    public static BitSet FOLLOW_checkConstraint_in_columnConstraintType14810 ;
    public static BitSet FOLLOW_tableConstraintType_in_columnConstraintType14818 ;
    public static BitSet FOLLOW_constant_in_defaultVal14835 ;
    public static BitSet FOLLOW_function_in_defaultVal14843 ;
    public static BitSet FOLLOW_castExpression_in_defaultVal14851 ;
    public static BitSet FOLLOW_KW_PRIMARY_in_tableConstraintType14868 ;
    public static BitSet FOLLOW_KW_KEY_in_tableConstraintType14870 ;
    public static BitSet FOLLOW_KW_UNIQUE_in_tableConstraintType14888 ;
    public static BitSet FOLLOW_enableValidateSpecification_in_constraintOptsCreate14923 ;
    public static BitSet FOLLOW_relySpecification_in_constraintOptsCreate14925 ;
    public static BitSet FOLLOW_enableValidateSpecification_in_constraintOptsAlter14943 ;
    public static BitSet FOLLOW_relySpecification_in_constraintOptsAlter14945 ;
    public static BitSet FOLLOW_identifier_in_columnNameColonType14975 ;
    public static BitSet FOLLOW_COLON_in_columnNameColonType14977 ;
    public static BitSet FOLLOW_colType_in_columnNameColonType14979 ;
    public static BitSet FOLLOW_KW_COMMENT_in_columnNameColonType14982 ;
    public static BitSet FOLLOW_StringLiteral_in_columnNameColonType14986 ;
    public static BitSet FOLLOW_type_in_colType15070 ;
    public static BitSet FOLLOW_colType_in_colTypeList15097 ;
    public static BitSet FOLLOW_COMMA_in_colTypeList15100 ;
    public static BitSet FOLLOW_colType_in_colTypeList15102 ;
    public static BitSet FOLLOW_primitiveType_in_type15130 ;
    public static BitSet FOLLOW_listType_in_type15138 ;
    public static BitSet FOLLOW_structType_in_type15146 ;
    public static BitSet FOLLOW_mapType_in_type15154 ;
    public static BitSet FOLLOW_unionType_in_type15162 ;
    public static BitSet FOLLOW_KW_TINYINT_in_primitiveType15184 ;
    public static BitSet FOLLOW_KW_SMALLINT_in_primitiveType15205 ;
    public static BitSet FOLLOW_KW_INT_in_primitiveType15225 ;
    public static BitSet FOLLOW_KW_BIGINT_in_primitiveType15250 ;
    public static BitSet FOLLOW_KW_BOOLEAN_in_primitiveType15272 ;
    public static BitSet FOLLOW_KW_FLOAT_in_primitiveType15293 ;
    public static BitSet FOLLOW_KW_REAL_in_primitiveType15316 ;
    public static BitSet FOLLOW_KW_DOUBLE_in_primitiveType15340 ;
    public static BitSet FOLLOW_KW_PRECISION_in_primitiveType15342 ;
    public static BitSet FOLLOW_KW_DATE_in_primitiveType15364 ;
    public static BitSet FOLLOW_KW_DATETIME_in_primitiveType15388 ;
    public static BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType15408 ;
    public static BitSet FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType15427 ;
    public static BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType15449 ;
    public static BitSet FOLLOW_KW_WITH_in_primitiveType15451 ;
    public static BitSet FOLLOW_KW_LOCAL_in_primitiveType15453 ;
    public static BitSet FOLLOW_KW_TIME_in_primitiveType15455 ;
    public static BitSet FOLLOW_KW_ZONE_in_primitiveType15457 ;
    public static BitSet FOLLOW_KW_STRING_in_primitiveType15489 ;
    public static BitSet FOLLOW_KW_BINARY_in_primitiveType15511 ;
    public static BitSet FOLLOW_KW_DECIMAL_in_primitiveType15533 ;
    public static BitSet FOLLOW_LPAREN_in_primitiveType15536 ;
    public static BitSet FOLLOW_Number_in_primitiveType15540 ;
    public static BitSet FOLLOW_COMMA_in_primitiveType15543 ;
    public static BitSet FOLLOW_Number_in_primitiveType15547 ;
    public static BitSet FOLLOW_RPAREN_in_primitiveType15551 ;
    public static BitSet FOLLOW_KW_VARCHAR_in_primitiveType15575 ;
    public static BitSet FOLLOW_LPAREN_in_primitiveType15577 ;
    public static BitSet FOLLOW_Number_in_primitiveType15581 ;
    public static BitSet FOLLOW_RPAREN_in_primitiveType15583 ;
    public static BitSet FOLLOW_KW_CHAR_in_primitiveType15608 ;
    public static BitSet FOLLOW_LPAREN_in_primitiveType15610 ;
    public static BitSet FOLLOW_Number_in_primitiveType15614 ;
    public static BitSet FOLLOW_RPAREN_in_primitiveType15616 ;
    public static BitSet FOLLOW_KW_ARRAY_in_listType15660 ;
    public static BitSet FOLLOW_LESSTHAN_in_listType15662 ;
    public static BitSet FOLLOW_type_in_listType15664 ;
    public static BitSet FOLLOW_GREATERTHAN_in_listType15666 ;
    public static BitSet FOLLOW_KW_STRUCT_in_structType15703 ;
    public static BitSet FOLLOW_LESSTHAN_in_structType15705 ;
    public static BitSet FOLLOW_columnNameColonTypeList_in_structType15707 ;
    public static BitSet FOLLOW_GREATERTHAN_in_structType15709 ;
    public static BitSet FOLLOW_KW_MAP_in_mapType15744 ;
    public static BitSet FOLLOW_LESSTHAN_in_mapType15746 ;
    public static BitSet FOLLOW_primitiveType_in_mapType15750 ;
    public static BitSet FOLLOW_COMMA_in_mapType15752 ;
    public static BitSet FOLLOW_type_in_mapType15756 ;
    public static BitSet FOLLOW_GREATERTHAN_in_mapType15758 ;
    public static BitSet FOLLOW_KW_UNIONTYPE_in_unionType15801 ;
    public static BitSet FOLLOW_LESSTHAN_in_unionType15803 ;
    public static BitSet FOLLOW_colTypeList_in_unionType15805 ;
    public static BitSet FOLLOW_GREATERTHAN_in_unionType15807 ;
    public static BitSet FOLLOW_KW_UNION_in_setOperator15842 ;
    public static BitSet FOLLOW_KW_ALL_in_setOperator15844 ;
    public static BitSet FOLLOW_KW_UNION_in_setOperator15858 ;
    public static BitSet FOLLOW_KW_DISTINCT_in_setOperator15860 ;
    public static BitSet FOLLOW_KW_INTERSECT_in_setOperator15875 ;
    public static BitSet FOLLOW_KW_ALL_in_setOperator15877 ;
    public static BitSet FOLLOW_KW_INTERSECT_in_setOperator15891 ;
    public static BitSet FOLLOW_KW_DISTINCT_in_setOperator15893 ;
    public static BitSet FOLLOW_KW_EXCEPT_in_setOperator15908 ;
    public static BitSet FOLLOW_KW_ALL_in_setOperator15910 ;
    public static BitSet FOLLOW_KW_EXCEPT_in_setOperator15924 ;
    public static BitSet FOLLOW_KW_DISTINCT_in_setOperator15926 ;
    public static BitSet FOLLOW_KW_MINUS_in_setOperator15941 ;
    public static BitSet FOLLOW_KW_ALL_in_setOperator15943 ;
    public static BitSet FOLLOW_KW_MINUS_in_setOperator15957 ;
    public static BitSet FOLLOW_KW_DISTINCT_in_setOperator15959 ;
    public static BitSet FOLLOW_withClause_in_queryStatementExpression15996 ;
    public static BitSet FOLLOW_queryStatementExpressionBody_in_queryStatementExpression16004 ;
    public static BitSet FOLLOW_fromStatement_in_queryStatementExpressionBody16036 ;
    public static BitSet FOLLOW_regularBody_in_queryStatementExpressionBody16044 ;
    public static BitSet FOLLOW_KW_WITH_in_withClause16061 ;
    public static BitSet FOLLOW_cteStatement_in_withClause16063 ;
    public static BitSet FOLLOW_COMMA_in_withClause16066 ;
    public static BitSet FOLLOW_cteStatement_in_withClause16068 ;
    public static BitSet FOLLOW_identifier_in_cteStatement16094 ;
    public static BitSet FOLLOW_LPAREN_in_cteStatement16097 ;
    public static BitSet FOLLOW_columnNameList_in_cteStatement16101 ;
    public static BitSet FOLLOW_RPAREN_in_cteStatement16103 ;
    public static BitSet FOLLOW_KW_AS_in_cteStatement16107 ;
    public static BitSet FOLLOW_LPAREN_in_cteStatement16109 ;
    public static BitSet FOLLOW_queryStatementExpression_in_cteStatement16111 ;
    public static BitSet FOLLOW_RPAREN_in_cteStatement16113 ;
    public static BitSet FOLLOW_singleFromStatement_in_fromStatement16140 ;
    public static BitSet FOLLOW_setOperator_in_fromStatement16152 ;
    public static BitSet FOLLOW_singleFromStatement_in_fromStatement16156 ;
    public static BitSet FOLLOW_fromClause_in_singleFromStatement16366 ;
    public static BitSet FOLLOW_body_in_singleFromStatement16376 ;
    public static BitSet FOLLOW_insertClause_in_regularBody16413 ;
    public static BitSet FOLLOW_selectStatement_in_regularBody16425 ;
    public static BitSet FOLLOW_selectStatement_in_regularBody16449 ;
    public static BitSet FOLLOW_selectClause_in_atomSelectStatement16469 ;
    public static BitSet FOLLOW_fromClause_in_atomSelectStatement16476 ;
    public static BitSet FOLLOW_whereClause_in_atomSelectStatement16484 ;
    public static BitSet FOLLOW_groupByClause_in_atomSelectStatement16492 ;
    public static BitSet FOLLOW_havingClause_in_atomSelectStatement16500 ;
    public static BitSet FOLLOW_window_clause_in_atomSelectStatement16508 ;
    public static BitSet FOLLOW_qualifyClause_in_atomSelectStatement16516 ;
    public static BitSet FOLLOW_LPAREN_in_atomSelectStatement16598 ;
    public static BitSet FOLLOW_selectStatement_in_atomSelectStatement16601 ;
    public static BitSet FOLLOW_RPAREN_in_atomSelectStatement16603 ;
    public static BitSet FOLLOW_valuesSource_in_atomSelectStatement16614 ;
    public static BitSet FOLLOW_atomSelectStatement_in_selectStatement16634 ;
    public static BitSet FOLLOW_setOpSelectStatement_in_selectStatement16641 ;
    public static BitSet FOLLOW_orderByClause_in_selectStatement16650 ;
    public static BitSet FOLLOW_clusterByClause_in_selectStatement16658 ;
    public static BitSet FOLLOW_distributeByClause_in_selectStatement16666 ;
    public static BitSet FOLLOW_sortByClause_in_selectStatement16674 ;
    public static BitSet FOLLOW_limitClause_in_selectStatement16682 ;
    public static BitSet FOLLOW_setOperator_in_setOpSelectStatement16947 ;
    public static BitSet FOLLOW_atomSelectStatement_in_setOpSelectStatement16951 ;
    public static BitSet FOLLOW_withClause_in_selectStatementWithCTE17586 ;
    public static BitSet FOLLOW_selectStatement_in_selectStatementWithCTE17594 ;
    public static BitSet FOLLOW_insertClause_in_body17624 ;
    public static BitSet FOLLOW_selectClause_in_body17629 ;
    public static BitSet FOLLOW_lateralView_in_body17634 ;
    public static BitSet FOLLOW_whereClause_in_body17640 ;
    public static BitSet FOLLOW_groupByClause_in_body17646 ;
    public static BitSet FOLLOW_havingClause_in_body17652 ;
    public static BitSet FOLLOW_window_clause_in_body17658 ;
    public static BitSet FOLLOW_qualifyClause_in_body17664 ;
    public static BitSet FOLLOW_orderByClause_in_body17670 ;
    public static BitSet FOLLOW_clusterByClause_in_body17676 ;
    public static BitSet FOLLOW_distributeByClause_in_body17682 ;
    public static BitSet FOLLOW_sortByClause_in_body17688 ;
    public static BitSet FOLLOW_limitClause_in_body17694 ;
    public static BitSet FOLLOW_selectClause_in_body17790 ;
    public static BitSet FOLLOW_lateralView_in_body17795 ;
    public static BitSet FOLLOW_whereClause_in_body17801 ;
    public static BitSet FOLLOW_groupByClause_in_body17807 ;
    public static BitSet FOLLOW_havingClause_in_body17813 ;
    public static BitSet FOLLOW_window_clause_in_body17819 ;
    public static BitSet FOLLOW_qualifyClause_in_body17825 ;
    public static BitSet FOLLOW_orderByClause_in_body17831 ;
    public static BitSet FOLLOW_clusterByClause_in_body17837 ;
    public static BitSet FOLLOW_distributeByClause_in_body17843 ;
    public static BitSet FOLLOW_sortByClause_in_body17849 ;
    public static BitSet FOLLOW_limitClause_in_body17855 ;
    public static BitSet FOLLOW_KW_INSERT_in_insertClause17979 ;
    public static BitSet FOLLOW_KW_OVERWRITE_in_insertClause17981 ;
    public static BitSet FOLLOW_destination_in_insertClause17983 ;
    public static BitSet FOLLOW_ifNotExists_in_insertClause17985 ;
    public static BitSet FOLLOW_KW_INSERT_in_insertClause18004 ;
    public static BitSet FOLLOW_KW_INTO_in_insertClause18006 ;
    public static BitSet FOLLOW_KW_TABLE_in_insertClause18008 ;
    public static BitSet FOLLOW_tableOrPartition_in_insertClause18011 ;
    public static BitSet FOLLOW_LPAREN_in_insertClause18014 ;
    public static BitSet FOLLOW_columnNameList_in_insertClause18018 ;
    public static BitSet FOLLOW_RPAREN_in_insertClause18020 ;
    public static BitSet FOLLOW_KW_LOCAL_in_destination18076 ;
    public static BitSet FOLLOW_KW_DIRECTORY_in_destination18080 ;
    public static BitSet FOLLOW_StringLiteral_in_destination18082 ;
    public static BitSet FOLLOW_tableRowFormat_in_destination18084 ;
    public static BitSet FOLLOW_tableFileFormat_in_destination18087 ;
    public static BitSet FOLLOW_KW_TABLE_in_destination18120 ;
    public static BitSet FOLLOW_tableOrPartition_in_destination18122 ;
    public static BitSet FOLLOW_KW_LIMIT_in_limitClause18154 ;
    public static BitSet FOLLOW_Number_in_limitClause18160 ;
    public static BitSet FOLLOW_COMMA_in_limitClause18162 ;
    public static BitSet FOLLOW_Number_in_limitClause18168 ;
    public static BitSet FOLLOW_KW_LIMIT_in_limitClause18191 ;
    public static BitSet FOLLOW_Number_in_limitClause18195 ;
    public static BitSet FOLLOW_KW_OFFSET_in_limitClause18197 ;
    public static BitSet FOLLOW_Number_in_limitClause18201 ;
    public static BitSet FOLLOW_KW_DELETE_in_deleteStatement18245 ;
    public static BitSet FOLLOW_KW_FROM_in_deleteStatement18247 ;
    public static BitSet FOLLOW_tableName_in_deleteStatement18249 ;
    public static BitSet FOLLOW_whereClause_in_deleteStatement18252 ;
    public static BitSet FOLLOW_tableOrColumn_in_columnAssignmentClause18287 ;
    public static BitSet FOLLOW_EQUAL_in_columnAssignmentClause18289 ;
    public static BitSet FOLLOW_precedencePlusExpressionOrDefault_in_columnAssignmentClause18292 ;
    public static BitSet FOLLOW_defaultValue_in_precedencePlusExpressionOrDefault18325 ;
    public static BitSet FOLLOW_precedencePlusExpression_in_precedencePlusExpressionOrDefault18333 ;
    public static BitSet FOLLOW_KW_SET_in_setColumnsClause18355 ;
    public static BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause18357 ;
    public static BitSet FOLLOW_COMMA_in_setColumnsClause18360 ;
    public static BitSet FOLLOW_columnAssignmentClause_in_setColumnsClause18362 ;
    public static BitSet FOLLOW_KW_UPDATE_in_updateStatement18404 ;
    public static BitSet FOLLOW_tableName_in_updateStatement18406 ;
    public static BitSet FOLLOW_setColumnsClause_in_updateStatement18408 ;
    public static BitSet FOLLOW_whereClause_in_updateStatement18410 ;
    public static BitSet FOLLOW_startTransactionStatement_in_sqlTransactionStatement18452 ;
    public static BitSet FOLLOW_commitStatement_in_sqlTransactionStatement18457 ;
    public static BitSet FOLLOW_rollbackStatement_in_sqlTransactionStatement18462 ;
    public static BitSet FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement18467 ;
    public static BitSet FOLLOW_KW_START_in_startTransactionStatement18481 ;
    public static BitSet FOLLOW_KW_TRANSACTION_in_startTransactionStatement18483 ;
    public static BitSet FOLLOW_transactionMode_in_startTransactionStatement18487 ;
    public static BitSet FOLLOW_COMMA_in_startTransactionStatement18492 ;
    public static BitSet FOLLOW_transactionMode_in_startTransactionStatement18494 ;
    public static BitSet FOLLOW_isolationLevel_in_transactionMode18525 ;
    public static BitSet FOLLOW_transactionAccessMode_in_transactionMode18531 ;
    public static BitSet FOLLOW_KW_READ_in_transactionAccessMode18554 ;
    public static BitSet FOLLOW_KW_ONLY_in_transactionAccessMode18556 ;
    public static BitSet FOLLOW_KW_READ_in_transactionAccessMode18566 ;
    public static BitSet FOLLOW_KW_WRITE_in_transactionAccessMode18568 ;
    public static BitSet FOLLOW_KW_ISOLATION_in_isolationLevel18587 ;
    public static BitSet FOLLOW_KW_LEVEL_in_isolationLevel18589 ;
    public static BitSet FOLLOW_levelOfIsolation_in_isolationLevel18591 ;
    public static BitSet FOLLOW_KW_SNAPSHOT_in_levelOfIsolation18616 ;
    public static BitSet FOLLOW_KW_COMMIT_in_commitStatement18635 ;
    public static BitSet FOLLOW_KW_WORK_in_commitStatement18639 ;
    public static BitSet FOLLOW_KW_ROLLBACK_in_rollbackStatement18661 ;
    public static BitSet FOLLOW_KW_WORK_in_rollbackStatement18665 ;
    public static BitSet FOLLOW_KW_SET_in_setAutoCommitStatement18686 ;
    public static BitSet FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement18688 ;
    public static BitSet FOLLOW_booleanValueTok_in_setAutoCommitStatement18690 ;
    public static BitSet FOLLOW_KW_ABORT_in_abortTransactionStatement18725 ;
    public static BitSet FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement18727 ;
    public static BitSet FOLLOW_Number_in_abortTransactionStatement18731 ;
    public static BitSet FOLLOW_KW_MERGE_in_mergeStatement18777 ;
    public static BitSet FOLLOW_QUERY_HINT_in_mergeStatement18779 ;
    public static BitSet FOLLOW_KW_INTO_in_mergeStatement18782 ;
    public static BitSet FOLLOW_tableName_in_mergeStatement18784 ;
    public static BitSet FOLLOW_KW_AS_in_mergeStatement18787 ;
    public static BitSet FOLLOW_identifier_in_mergeStatement18790 ;
    public static BitSet FOLLOW_KW_USING_in_mergeStatement18794 ;
    public static BitSet FOLLOW_joinSourcePart_in_mergeStatement18796 ;
    public static BitSet FOLLOW_KW_ON_in_mergeStatement18798 ;
    public static BitSet FOLLOW_expression_in_mergeStatement18800 ;
    public static BitSet FOLLOW_whenClauses_in_mergeStatement18802 ;
    public static BitSet FOLLOW_whenMatchedAndClause_in_whenClauses18851 ;
    public static BitSet FOLLOW_whenMatchedThenClause_in_whenClauses18853 ;
    public static BitSet FOLLOW_whenNotMatchedClause_in_whenClauses18857 ;
    public static BitSet FOLLOW_KW_WHEN_in_whenNotMatchedClause18884 ;
    public static BitSet FOLLOW_KW_NOT_in_whenNotMatchedClause18886 ;
    public static BitSet FOLLOW_KW_MATCHED_in_whenNotMatchedClause18888 ;
    public static BitSet FOLLOW_KW_AND_in_whenNotMatchedClause18891 ;
    public static BitSet FOLLOW_expression_in_whenNotMatchedClause18893 ;
    public static BitSet FOLLOW_KW_THEN_in_whenNotMatchedClause18897 ;
    public static BitSet FOLLOW_KW_INSERT_in_whenNotMatchedClause18899 ;
    public static BitSet FOLLOW_columnParenthesesList_in_whenNotMatchedClause18904 ;
    public static BitSet FOLLOW_KW_VALUES_in_whenNotMatchedClause18908 ;
    public static BitSet FOLLOW_valueRowConstructor_in_whenNotMatchedClause18910 ;
    public static BitSet FOLLOW_KW_WHEN_in_whenMatchedAndClause18957 ;
    public static BitSet FOLLOW_KW_MATCHED_in_whenMatchedAndClause18959 ;
    public static BitSet FOLLOW_KW_AND_in_whenMatchedAndClause18961 ;
    public static BitSet FOLLOW_expression_in_whenMatchedAndClause18963 ;
    public static BitSet FOLLOW_KW_THEN_in_whenMatchedAndClause18965 ;
    public static BitSet FOLLOW_updateOrDelete_in_whenMatchedAndClause18967 ;
    public static BitSet FOLLOW_KW_WHEN_in_whenMatchedThenClause19005 ;
    public static BitSet FOLLOW_KW_MATCHED_in_whenMatchedThenClause19007 ;
    public static BitSet FOLLOW_KW_THEN_in_whenMatchedThenClause19009 ;
    public static BitSet FOLLOW_updateOrDelete_in_whenMatchedThenClause19011 ;
    public static BitSet FOLLOW_KW_UPDATE_in_updateOrDelete19040 ;
    public static BitSet FOLLOW_setColumnsClause_in_updateOrDelete19042 ;
    public static BitSet FOLLOW_KW_DELETE_in_updateOrDelete19060 ;
    public static BitSet FOLLOW_KW_KILL_in_killQueryStatement19092 ;
    public static BitSet FOLLOW_KW_QUERY_in_killQueryStatement19094 ;
    public static BitSet FOLLOW_StringLiteral_in_killQueryStatement19098 ;
    public static BitSet FOLLOW_KW_ID_in_compactionId19129 ;
    public static BitSet FOLLOW_EQUAL_in_compactionId19131 ;
    public static BitSet FOLLOW_Number_in_compactionId19135 ;
    public static BitSet FOLLOW_KW_POOL_in_compactionPool19156 ;
    public static BitSet FOLLOW_StringLiteral_in_compactionPool19160 ;
    public static BitSet FOLLOW_KW_TYPE_in_compactionType19181 ;
    public static BitSet FOLLOW_StringLiteral_in_compactionType19185 ;
    public static BitSet FOLLOW_KW_STATUS_in_compactionStatus19206 ;
    public static BitSet FOLLOW_StringLiteral_in_compactionStatus19210 ;
    public static BitSet FOLLOW_grantPrivileges_in_synpred1_HiveParser3126 ;
    public static BitSet FOLLOW_revokePrivileges_in_synpred2_HiveParser3140 ;
    public static BitSet FOLLOW_KW_ELEM_TYPE_in_synpred3_HiveParser4427 ;
    public static BitSet FOLLOW_KW_KEY_TYPE_in_synpred4_HiveParser4443 ;
    public static BitSet FOLLOW_KW_VALUE_TYPE_in_synpred5_HiveParser4459 ;
    public static BitSet FOLLOW_KW_DATACONNECTOR_in_synpred7_HiveParser4666 ;
    public static BitSet FOLLOW_KW_FUNCTION_in_synpred8_HiveParser4707 ;
    public static BitSet FOLLOW_KW_COMPUTE_in_synpred10_HiveParser4860 ;
    public static BitSet FOLLOW_KW_CACHE_in_synpred11_HiveParser4988 ;
    public static BitSet FOLLOW_KW_ID_in_synpred14_HiveParser5687 ;
    public static BitSet FOLLOW_KW_ALL_in_synpred16_HiveParser6787 ;
    public static BitSet FOLLOW_KW_NONE_in_synpred17_HiveParser6818 ;
    public static BitSet FOLLOW_KW_ALL_in_synpred18_HiveParser6992 ;
    public static BitSet FOLLOW_storedAsDirs_in_synpred19_HiveParser10631 ;
    public static BitSet FOLLOW_KW_STORED_in_synpred20_HiveParser11612 ;
    public static BitSet FOLLOW_KW_AS_in_synpred20_HiveParser11614 ;
    public static BitSet FOLLOW_KW_INPUTFORMAT_in_synpred20_HiveParser11616 ;
    public static BitSet FOLLOW_KW_ELEM_TYPE_in_synpred21_HiveParser12165 ;
    public static BitSet FOLLOW_KW_KEY_TYPE_in_synpred22_HiveParser12175 ;
    public static BitSet FOLLOW_KW_VALUE_TYPE_in_synpred23_HiveParser12185 ;
    public static BitSet FOLLOW_KW_DEFAULT_in_synpred24_HiveParser18313 ;
    public static BitSet FOLLOW_set_in_synpred24_HiveParser18315 ;

    public static void initBitSet0() {
        FOLLOW_explainStatement_in_statement1527 =  new BitSet(new long[]{0x0000000000000000L});
        FOLLOW_EOF_in_statement1529 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_execStatement_in_statement1534 =  new BitSet(new long[]{0x0000000000000000L});
        FOLLOW_EOF_in_statement1536 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXPLAIN_in_explainStatement1557 =  new BitSet(new long[]{0x1000280C04000000L,0x08811D0C00010080L,0x400101008C000508L,0x0000000081083900L,0x0242010C34480004L,0x2412200800000008L,0x0000000000020040L});
        FOLLOW_explainOption_in_explainStatement1566 =  new BitSet(new long[]{0x1000280C04000000L,0x08811D0C00010080L,0x400101008C000508L,0x0000000081083900L,0x0242010434480004L,0x2412200800000008L,0x0000000000020040L});
        FOLLOW_execStatement_in_explainStatement1569 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REWRITE_in_explainStatement1600 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0001000008000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020040L});
        FOLLOW_queryStatementExpression_in_explainStatement1602 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXTENDED_in_explainOption1642 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FORMATTED_in_explainOption1650 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DEPENDENCY_in_explainOption1658 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CBO_in_explainOption1666 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000008000L,0x0400000000000000L});
        FOLLOW_KW_LOGICAL_in_explainOption1683 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_AUTHORIZATION_in_explainOption1691 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ANALYZE_in_explainOption1699 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REOPTIMIZATION_in_explainOption1707 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCKS_in_explainOption1715 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_AST_in_explainOption1723 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_VECTORIZATION_in_explainOption1732 =  new BitSet(new long[]{0x0000000000000002L,0x0000200000000000L,0x0000000000000200L,0x00000C0000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_vectorizationOnly_in_explainOption1734 =  new BitSet(new long[]{0x0000000000000002L,0x0000200000000000L,0x0000000000000200L,0x0000080000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_vectorizatonDetail_in_explainOption1737 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DEBUG_in_explainOption1747 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DDL_in_explainOption1755 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ONLY_in_vectorizationOnly1782 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SUMMARY_in_vectorizatonDetail1819 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_OPERATOR_in_vectorizatonDetail1837 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXPRESSION_in_vectorizatonDetail1855 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DETAIL_in_vectorizatonDetail1873 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_queryStatementExpression_in_execStatement1910 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_loadStatement_in_execStatement1918 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_exportStatement_in_execStatement1926 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_importStatement_in_execStatement1934 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_replDumpStatement_in_execStatement1942 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_replLoadStatement_in_execStatement1950 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_replStatusStatement_in_execStatement1958 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_ddlStatement_in_execStatement1966 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_deleteStatement_in_execStatement1974 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_updateStatement_in_execStatement1982 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_sqlTransactionStatement_in_execStatement1990 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_mergeStatement_in_execStatement1998 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_prepareStatement_in_execStatement2006 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_executeStatement_in_execStatement2014 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOAD_in_loadStatement2041 =  new BitSet(new long[]{0x0000000000000000L,0x0000000001000000L});
        FOLLOW_KW_DATA_in_loadStatement2043 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000200000000000L,0x0000000000000200L});
        FOLLOW_KW_LOCAL_in_loadStatement2048 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000200000000000L});
        FOLLOW_KW_INPATH_in_loadStatement2052 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_loadStatement2057 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L,0x0010000000000000L});
        FOLLOW_KW_OVERWRITE_in_loadStatement2063 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_INTO_in_loadStatement2067 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_loadStatement2069 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableOrPartition_in_loadStatement2074 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000800000000000L});
        FOLLOW_inputFileFormat_in_loadStatement2077 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FOR_in_replicationClause2132 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L,0x0000000040000000L});
        FOLLOW_KW_METADATA_in_replicationClause2137 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_KW_REPLICATION_in_replicationClause2141 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_replicationClause2143 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_replicationClause2148 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_replicationClause2151 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXPORT_in_exportStatement2195 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_exportStatement2203 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableOrPartition_in_exportStatement2208 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_KW_TO_in_exportStatement2217 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_exportStatement2222 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_replicationClause_in_exportStatement2231 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_IMPORT_in_importStatement2281 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000800L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_EXTERNAL_in_importStatement2296 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_importStatement2300 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableOrPartition_in_importStatement2305 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
        FOLLOW_KW_FROM_in_importStatement2319 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_importStatement2324 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_tableLocation_in_importStatement2336 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REPL_in_replDumpStatement2390 =  new BitSet(new long[]{0x0000000000000000L,0x0100000000000000L});
        FOLLOW_KW_DUMP_in_replDumpStatement2392 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_replDbPolicy_in_replDumpStatement2405 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_REPLACE_in_replDumpStatement2417 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_replDbPolicy_in_replDumpStatement2421 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_replDumpStatement2434 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_replConfigs_in_replDumpStatement2438 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_replDbPolicy2501 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_DOT_in_replDbPolicy2505 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_replTableLevelPolicy_in_replDbPolicy2509 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REPL_in_replLoadStatement2549 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
        FOLLOW_KW_LOAD_in_replLoadStatement2551 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_replDbPolicy_in_replLoadStatement2562 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0010000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_INTO_in_replLoadStatement2572 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_replLoadStatement2576 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_replLoadStatement2587 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_replConfigs_in_replLoadStatement2591 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_LPAREN_in_replConfigs2655 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_replConfigsList_in_replConfigs2657 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_replConfigs2659 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_keyValueProperty_in_replConfigsList2700 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_replConfigsList2703 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_keyValueProperty_in_replConfigsList2705 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_StringLiteral_in_replTableLevelPolicy2753 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_DOT_in_replTableLevelPolicy2757 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_replTableLevelPolicy2761 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REPL_in_replStatusStatement2812 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_STATUS_in_replStatusStatement2814 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_replStatusStatement2827 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    }
    public static void initBitSet1() {
        FOLLOW_KW_WITH_in_replStatusStatement2839 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_replConfigs_in_replStatusStatement2843 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createDatabaseStatement_in_ddlStatement2893 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_switchDatabaseStatement_in_ddlStatement2901 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropDatabaseStatement_in_ddlStatement2909 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createTableStatement_in_ddlStatement2917 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropTableStatement_in_ddlStatement2925 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_truncateTableStatement_in_ddlStatement2933 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_alterStatement_in_ddlStatement2941 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_descStatement_in_ddlStatement2949 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showStatement_in_ddlStatement2957 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_metastoreCheck_in_ddlStatement2965 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createViewStatement_in_ddlStatement2973 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createMaterializedViewStatement_in_ddlStatement2981 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createScheduledQueryStatement_in_ddlStatement2989 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_alterScheduledQueryStatement_in_ddlStatement2997 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropScheduledQueryStatement_in_ddlStatement3005 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropViewStatement_in_ddlStatement3013 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropMaterializedViewStatement_in_ddlStatement3021 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createFunctionStatement_in_ddlStatement3029 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createMacroStatement_in_ddlStatement3037 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropFunctionStatement_in_ddlStatement3045 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_reloadFunctionsStatement_in_ddlStatement3053 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropMacroStatement_in_ddlStatement3061 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_analyzeStatement_in_ddlStatement3069 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_lockStatement_in_ddlStatement3077 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_unlockStatement_in_ddlStatement3085 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_lockDatabase_in_ddlStatement3093 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_unlockDatabase_in_ddlStatement3101 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createRoleStatement_in_ddlStatement3109 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropRoleStatement_in_ddlStatement3117 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_grantPrivileges_in_ddlStatement3131 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_revokePrivileges_in_ddlStatement3145 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showGrants_in_ddlStatement3153 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showRoleGrants_in_ddlStatement3161 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showRolePrincipals_in_ddlStatement3169 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showRoles_in_ddlStatement3177 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_grantRole_in_ddlStatement3185 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_revokeRole_in_ddlStatement3193 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_setRole_in_ddlStatement3201 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showCurrentRole_in_ddlStatement3209 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_abortTransactionStatement_in_ddlStatement3217 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_killQueryStatement_in_ddlStatement3225 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_resourcePlanDdlStatements_in_ddlStatement3233 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createDataConnectorStatement_in_ddlStatement3241 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_dropDataConnectorStatement_in_ddlStatement3249 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_IF_in_ifExists3276 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_EXISTS_in_ifExists3278 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_RESTRICT_in_restrictOrCascade3315 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CASCADE_in_restrictOrCascade3333 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_IF_in_ifNotExists3370 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_KW_NOT_in_ifNotExists3372 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_EXISTS_in_ifNotExists3374 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FORCE_in_force3411 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ENABLE_in_rewriteEnabled3448 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_KW_REWRITE_in_rewriteEnabled3450 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DISABLE_in_rewriteDisabled3487 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_KW_REWRITE_in_rewriteDisabled3489 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STORED_in_storedAsDirs3526 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_storedAsDirs3528 =  new BitSet(new long[]{0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_DIRECTORIES_in_storedAsDirs3530 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_OR_in_orReplace3567 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
        FOLLOW_KW_REPLACE_in_orReplace3569 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createDatabaseStatement3606 =  new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_DATABASE_in_createDatabaseStatement3609 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_createDatabaseStatement3611 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifNotExists_in_createDatabaseStatement3622 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_createDatabaseStatement3635 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000040L,0x0000000000000000L,0x0000000000020400L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_databaseComment_in_createDatabaseStatement3645 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000020400L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_dbLocation_in_createDatabaseStatement3656 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_dbManagedLocation_in_createDatabaseStatement3667 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_createDatabaseStatement3679 =  new BitSet(new long[]{0x0000000000000000L,0x0000000100000000L});
        FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3681 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_dbProperties_in_createDatabaseStatement3685 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createDatabaseStatement3725 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
        FOLLOW_KW_REMOTE_in_createDatabaseStatement3727 =  new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_DATABASE_in_createDatabaseStatement3730 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_createDatabaseStatement3732 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifNotExists_in_createDatabaseStatement3743 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_createDatabaseStatement3756 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_databaseComment_in_createDatabaseStatement3766 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_dbConnectorName_in_createDatabaseStatement3777 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_createDatabaseStatement3788 =  new BitSet(new long[]{0x0000000000000000L,0x0000000100000000L});
        FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement3790 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_dbProperties_in_createDatabaseStatement3794 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCATION_in_dbLocation3854 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_dbLocation3858 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MANAGEDLOCATION_in_dbManagedLocation3900 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_dbManagedLocation3904 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_LPAREN_in_dbProperties3946 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_dbPropertiesList_in_dbProperties3948 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_dbProperties3950 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_keyValueProperty_in_dbPropertiesList3991 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_dbPropertiesList3994 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_keyValueProperty_in_dbPropertiesList3996 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_KW_USING_in_dbConnectorName4040 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_dbConnectorName4044 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_USE_in_switchDatabaseStatement4080 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_switchDatabaseStatement4082 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropDatabaseStatement4121 =  new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_DATABASE_in_dropDatabaseStatement4124 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
    }
    public static void initBitSet2() {
        FOLLOW_KW_SCHEMA_in_dropDatabaseStatement4126 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifExists_in_dropDatabaseStatement4129 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_dropDatabaseStatement4132 =  new BitSet(new long[]{0x0200000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L});
        FOLLOW_restrictOrCascade_in_dropDatabaseStatement4134 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_COMMENT_in_databaseComment4180 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_databaseComment4184 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TRUNCATE_in_truncateTableStatement4224 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EF7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_TABLE_in_truncateTableStatement4226 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tablePartitionPrefix_in_truncateTableStatement4229 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000020L,0x0000000000800000L});
        FOLLOW_KW_COLUMNS_in_truncateTableStatement4232 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_truncateTableStatement4234 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_truncateTableStatement4236 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_truncateTableStatement4238 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_force_in_truncateTableStatement4242 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropTableStatement4283 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_dropTableStatement4285 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifExists_in_dropTableStatement4287 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_dropTableStatement4290 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000400000L,0x0000000000000000L,0x0000000000000080L});
        FOLLOW_KW_PURGE_in_dropTableStatement4292 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_replicationClause_in_dropTableStatement4295 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INPUTFORMAT_in_inputFileFormat4344 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_inputFileFormat4348 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
        FOLLOW_KW_SERDE_in_inputFileFormat4350 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_inputFileFormat4354 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_tabTypeExpr4398 =  new BitSet(new long[]{0xB360DC8AFD010002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_DOT_in_tabTypeExpr4401 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_tabTypeExpr4404 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_tabTypeExpr4412 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_DOT_in_tabTypeExpr4415 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr4432 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_KW_KEY_TYPE_in_tabTypeExpr4448 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr4464 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_identifier_in_tabTypeExpr4471 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_tabTypeExpr_in_partTypeExpr4511 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_partitionSpec_in_partTypeExpr4513 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_tableName_in_tabPartColTypeExpr4553 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3F61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_partitionSpec_in_tabPartColTypeExpr4555 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_extColumnName_in_tabPartColTypeExpr4558 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DESCRIBE_in_descStatement4605 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBCF02CF6FL,0xFDC0ECB8660787DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_DESC_in_descStatement4607 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBCF02CF6FL,0xFDC0ECB8660787DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_DATABASE_in_descStatement4629 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460787DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_descStatement4631 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460787DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_EXTENDED_in_descStatement4634 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_descStatement4640 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATACONNECTOR_in_descStatement4672 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460787DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_EXTENDED_in_descStatement4675 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_descStatement4681 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FUNCTION_in_descStatement4712 =  new BitSet(new long[]{0xB76FDD9AFD6C6070L,0xEB7DEEEBC502CF6FL,0xFDC2EEF8461F87DCL,0xF3B6395EDAFF7DF0L,0xBFBDF0EBFFE7AEA0L,0xEB9DF2B2750EB7F7L,0x0000001C0270DF97L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_EXTENDED_in_descStatement4714 =  new BitSet(new long[]{0xB76FDD9AFD6C6070L,0xEB7DEEEBC502CF6FL,0xFDC2EEF8461F83DCL,0xF3B6395EDAFF7DF0L,0xBFBDF0EBFFE7AEA0L,0xEB9DF2B2750EB7F7L,0x0000001C0270DF97L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_descFuncNames_in_descStatement4720 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FORMATTED_in_descStatement4757 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_EXTENDED_in_descStatement4761 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tabPartColTypeExpr_in_descStatement4766 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_tabPartColTypeExpr_in_descStatement4793 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ANALYZE_in_analyzeStatement4835 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_analyzeStatement4837 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableOrPartition_in_analyzeStatement4842 =  new BitSet(new long[]{0x0100000000000000L,0x0000000000000400L});
        FOLLOW_KW_COMPUTE_in_analyzeStatement4865 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
        FOLLOW_KW_STATISTICS_in_analyzeStatement4867 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000400000L,0x0000000400000000L});
        FOLLOW_KW_NOSCAN_in_analyzeStatement4873 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FOR_in_analyzeStatement4933 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_COLUMNS_in_analyzeStatement4935 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_analyzeStatement4940 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CACHE_in_analyzeStatement4993 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_KW_METADATA_in_analyzeStatement4995 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5039 =  new BitSet(new long[]{0x0000000000000000L,0x0000000004000000L,0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
        FOLLOW_KW_DATABASES_in_showStatement5042 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_SCHEMAS_in_showStatement5044 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_LIKE_in_showStatement5048 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showStmtIdentifier_in_showStatement5050 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5069 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000400L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
        FOLLOW_KW_EXTENDED_in_showStatement5074 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
        FOLLOW_KW_TABLES_in_showStatement5078 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0EEB84E0783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F9BL,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_FROM_in_showStatement5082 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_IN_in_showStatement5084 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5089 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F9BL,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showTablesFilterExpr_in_showStatement5096 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5132 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
        FOLLOW_KW_VIEWS_in_showStatement5134 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0EEB84E0783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_FROM_in_showStatement5138 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_IN_in_showStatement5140 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5145 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_LIKE_in_showStatement5150 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showStmtIdentifier_in_showStatement5152 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showStmtIdentifier_in_showStatement5154 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5182 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_KW_MATERIALIZED_in_showStatement5184 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
        FOLLOW_KW_VIEWS_in_showStatement5186 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0EEB84E0783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_FROM_in_showStatement5190 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_IN_in_showStatement5192 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5197 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_LIKE_in_showStatement5202 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showStmtIdentifier_in_showStatement5204 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showStmtIdentifier_in_showStatement5206 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5234 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000020L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
        FOLLOW_KW_SORTED_in_showStatement5236 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_COLUMNS_in_showStatement5239 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000020008000000L});
        FOLLOW_KW_FROM_in_showStatement5242 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_IN_in_showStatement5244 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_showStatement5247 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0EEB84E0783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_FROM_in_showStatement5251 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
    }
    public static void initBitSet3() {
        FOLLOW_KW_IN_in_showStatement5253 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5258 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DF0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_LIKE_in_showStatement5263 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showStmtIdentifier_in_showStatement5265 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showStmtIdentifier_in_showStatement5267 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5303 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_KW_FUNCTIONS_in_showStatement5305 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_LIKE_in_showStatement5308 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showFunctionIdentifier_in_showStatement5310 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5333 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
        FOLLOW_KW_PARTITIONS_in_showStatement5335 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_showStatement5339 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040400000000040L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
        FOLLOW_partitionSpec_in_showStatement5341 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
        FOLLOW_whereClause_in_showStatement5344 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L});
        FOLLOW_orderByClause_in_showStatement5347 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_limitClause_in_showStatement5350 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5380 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000010000L});
        FOLLOW_KW_CREATE_in_showStatement5382 =  new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L,0x0000000000004000L});
        FOLLOW_KW_DATABASE_in_showStatement5403 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_showStatement5405 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5410 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TABLE_in_showStatement5439 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_showStatement5443 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5468 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_showStatement5470 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_EXTENDED_in_showStatement5472 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000020008000000L,0x0000000000000020L});
        FOLLOW_KW_FROM_in_showStatement5476 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_IN_in_showStatement5478 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5483 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_LIKE_in_showStatement5487 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showStmtIdentifier_in_showStatement5489 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_partitionSpec_in_showStatement5491 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5519 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_KW_TBLPROPERTIES_in_showStatement5521 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_showStatement5523 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_showStatement5526 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_showStatement5530 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_showStatement5532 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5554 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
        FOLLOW_KW_LOCKS_in_showStatement5556 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC702CF6FL,0xFDC0ECB8460787DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_DATABASE_in_showStatement5581 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_showStatement5583 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5589 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_EXTENDED_in_showStatement5595 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_partTypeExpr_in_showStatement5629 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_EXTENDED_in_showStatement5636 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5668 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000200L});
        FOLLOW_KW_COMPACTIONS_in_showStatement5670 =  new BitSet(new long[]{0xB360DC8AFD000002L,0xEB5DEEEBC702CF6FL,0xFDC0ECB8460783DCL,0xF3B65956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_compactionId_in_showStatement5692 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATABASE_in_showStatement5725 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_showStatement5727 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5733 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x8000400000000040L,0x0000000000000000L,0x0000001000000020L});
        FOLLOW_compactionPool_in_showStatement5736 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L,0x0000000000000000L,0x0000001000000020L});
        FOLLOW_compactionType_in_showStatement5739 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_compactionStatus_in_showStatement5742 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L});
        FOLLOW_orderByClause_in_showStatement5745 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_limitClause_in_showStatement5748 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_partTypeExpr_in_showStatement5792 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x8000400000000040L,0x0000000000000000L,0x0000001000000020L});
        FOLLOW_compactionPool_in_showStatement5796 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L,0x0000000000000000L,0x0000001000000020L});
        FOLLOW_compactionType_in_showStatement5799 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_compactionStatus_in_showStatement5802 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000400000000040L});
        FOLLOW_orderByClause_in_showStatement5805 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_limitClause_in_showStatement5808 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5850 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_KW_TRANSACTIONS_in_showStatement5852 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5866 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000001000L});
        FOLLOW_KW_CONF_in_showStatement5868 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_showStatement5870 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5886 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
        FOLLOW_KW_RESOURCE_in_showStatement5888 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x3000000000000000L});
        FOLLOW_KW_PLAN_in_showStatement5907 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showStatement5911 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_PLANS_in_showStatement5934 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showStatement5957 =  new BitSet(new long[]{0x0000000000000000L,0x0000000010000000L});
        FOLLOW_KW_DATACONNECTORS_in_showStatement5960 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WHERE_in_showTablesFilterExpr5994 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showTablesFilterExpr5996 =  new BitSet(new long[]{0x0000000000040000L});
        FOLLOW_EQUAL_in_showTablesFilterExpr5998 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_showTablesFilterExpr6000 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LIKE_in_showTablesFilterExpr6022 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000800001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_showStmtIdentifier_in_showTablesFilterExpr6024 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_showStmtIdentifier_in_showTablesFilterExpr6026 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCK_in_lockStatement6061 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_lockStatement6063 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_lockStatement6065 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L,0x0040000000000000L,0x0100000000000000L});
        FOLLOW_partitionSpec_in_lockStatement6067 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0100000000000000L});
        FOLLOW_lockMode_in_lockStatement6070 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCK_in_lockDatabase6110 =  new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_DATABASE_in_lockDatabase6113 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_lockDatabase6115 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_lockDatabase6121 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0100000000000000L});
        FOLLOW_lockMode_in_lockDatabase6124 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UNLOCK_in_unlockStatement6193 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_unlockStatement6195 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_unlockStatement6197 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_partitionSpec_in_unlockStatement6199 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UNLOCK_in_unlockDatabase6239 =  new BitSet(new long[]{0x0000000000000000L,0x0000000002000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_DATABASE_in_unlockDatabase6242 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_unlockDatabase6244 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_unlockDatabase6250 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createRoleStatement6287 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
    }
    public static void initBitSet4() {
        FOLLOW_KW_ROLE_in_createRoleStatement6289 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_createRoleStatement6293 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropRoleStatement6333 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_KW_ROLE_in_dropRoleStatement6335 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_dropRoleStatement6339 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_GRANT_in_grantPrivileges6379 =  new BitSet(new long[]{0x0000000500000000L,0x0080010000010000L,0x0001000000000000L,0x0000000000000800L,0x0402000000000000L,0x0002000000000000L});
        FOLLOW_privilegeList_in_grantPrivileges6383 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_privilegeObject_in_grantPrivileges6391 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_KW_TO_in_grantPrivileges6400 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000004000000000L,0x0020000000000000L});
        FOLLOW_principalSpecification_in_grantPrivileges6402 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_withGrantOption_in_grantPrivileges6410 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REVOKE_in_revokePrivileges6459 =  new BitSet(new long[]{0x0000000500000000L,0x0080010000010000L,0x0001000080000000L,0x0000000000000800L,0x0402000000000000L,0x0002000000000000L});
        FOLLOW_grantOptionFor_in_revokePrivileges6461 =  new BitSet(new long[]{0x0000000500000000L,0x0080010000010000L,0x0001000000000000L,0x0000000000000800L,0x0402000000000000L,0x0002000000000000L});
        FOLLOW_privilegeList_in_revokePrivileges6464 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000000L,0x0000020000000000L});
        FOLLOW_privilegeObject_in_revokePrivileges6466 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
        FOLLOW_KW_FROM_in_revokePrivileges6469 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000004000000000L,0x0020000000000000L});
        FOLLOW_principalSpecification_in_revokePrivileges6471 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_GRANT_in_grantRole6518 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_ROLE_in_grantRole6520 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_grantRole6523 =  new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_COMMA_in_grantRole6526 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_grantRole6528 =  new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_KW_TO_in_grantRole6532 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000004000000000L,0x0020000000000000L});
        FOLLOW_principalSpecification_in_grantRole6534 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_withAdminOption_in_grantRole6536 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REVOKE_in_revokeRole6582 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_adminOptionFor_in_revokeRole6584 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_ROLE_in_revokeRole6587 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_revokeRole6590 =  new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000008000000L});
        FOLLOW_COMMA_in_revokeRole6593 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_revokeRole6595 =  new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000008000000L});
        FOLLOW_KW_FROM_in_revokeRole6599 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000004000000000L,0x0020000000000000L});
        FOLLOW_principalSpecification_in_revokeRole6601 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showRoleGrants6646 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_KW_ROLE_in_showRoleGrants6648 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
        FOLLOW_KW_GRANT_in_showRoleGrants6650 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000004000000000L,0x0020000000000000L});
        FOLLOW_principalName_in_showRoleGrants6652 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showRoles6692 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
        FOLLOW_KW_ROLES_in_showRoles6694 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showCurrentRole6731 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_CURRENT_in_showCurrentRole6733 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
        FOLLOW_KW_ROLES_in_showCurrentRole6735 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SET_in_setRole6772 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_KW_ROLE_in_setRole6774 =  new BitSet(new long[]{0xB360DC8BFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61957DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_ALL_in_setRole6795 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NONE_in_setRole6826 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_setRole6848 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showGrants6889 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
        FOLLOW_KW_GRANT_in_showGrants6891 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000100000000L,0x0000020000000000L,0x0000004000000000L,0x0020000000000000L});
        FOLLOW_principalName_in_showGrants6893 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_showGrants6897 =  new BitSet(new long[]{0xB360DC8BFD000000L,0xEB5DEEEBC702CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EF7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_privilegeIncludeColObject_in_showGrants6899 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_in_showRolePrincipals6944 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_KW_PRINCIPALS_in_showRolePrincipals6946 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_showRolePrincipals6950 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ALL_in_privilegeIncludeColObject6997 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_privObjectCols_in_privilegeIncludeColObject7011 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ON_in_privilegeObject7046 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC702CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EF7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_privObject_in_privilegeObject7048 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATABASE_in_privObject7075 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_privObject7077 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_privObject7080 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TABLE_in_privObject7096 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_privObject7099 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_partitionSpec_in_privObject7101 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_URI_in_privObject7121 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_privObject7126 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SERVER_in_privObject7145 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_privObject7147 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATABASE_in_privObjectCols7173 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_SCHEMA_in_privObjectCols7175 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_privObjectCols7178 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TABLE_in_privObjectCols7194 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_privObjectCols7197 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_privObjectCols7200 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_privObjectCols7204 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_privObjectCols7206 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_partitionSpec_in_privObjectCols7210 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_URI_in_privObjectCols7234 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_privObjectCols7239 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SERVER_in_privObjectCols7258 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_privObjectCols7260 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_privlegeDef_in_privilegeList7295 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_privilegeList7298 =  new BitSet(new long[]{0x0000000500000000L,0x0080010000010000L,0x0001000000000000L,0x0000000000000800L,0x0402000000000000L,0x0002000000000000L});
        FOLLOW_privlegeDef_in_privilegeList7300 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_privilegeType_in_privlegeDef7342 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_privlegeDef7345 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_privlegeDef7349 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_privlegeDef7351 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ALL_in_privilegeType7396 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ALTER_in_privilegeType7410 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UPDATE_in_privilegeType7424 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_privilegeType7438 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_privilegeType7452 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCK_in_privilegeType7466 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SELECT_in_privilegeType7480 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SHOW_DATABASE_in_privilegeType7494 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INSERT_in_privilegeType7508 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DELETE_in_privilegeType7522 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_principalName_in_principalSpecification7555 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_principalSpecification7558 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000004000000000L,0x0020000000000000L});
    }
    public static void initBitSet5() {
        FOLLOW_principalName_in_principalSpecification7560 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_KW_USER_in_principalName7598 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000010001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_principalIdentifier_in_principalName7600 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_GROUP_in_principalName7616 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000010001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_principalIdentifier_in_principalName7618 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ROLE_in_principalName7634 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_principalName7636 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WITH_in_withGrantOption7671 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
        FOLLOW_KW_GRANT_in_withGrantOption7673 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_OPTION_in_withGrantOption7675 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_GRANT_in_grantOptionFor7712 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_OPTION_in_grantOptionFor7714 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_KW_FOR_in_grantOptionFor7716 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ADMIN_in_adminOptionFor7749 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_OPTION_in_adminOptionFor7751 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_KW_FOR_in_adminOptionFor7753 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WITH_in_withAdminOption7786 =  new BitSet(new long[]{0x0000000040000000L});
        FOLLOW_KW_ADMIN_in_withAdminOption7788 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_OPTION_in_withAdminOption7790 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MSCK_in_metastoreCheck7827 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000008000000L,0x0000000000004000L});
        FOLLOW_KW_REPAIR_in_metastoreCheck7832 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_KW_TABLE_in_metastoreCheck7843 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_metastoreCheck7845 =  new BitSet(new long[]{0x0000000020000002L,0x0080000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
        FOLLOW_KW_ADD_in_metastoreCheck7859 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
        FOLLOW_KW_DROP_in_metastoreCheck7861 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
        FOLLOW_KW_SYNC_in_metastoreCheck7863 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0100000000000000L});
        FOLLOW_KW_PARTITIONS_in_metastoreCheck7869 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_partitionSelectorSpec_in_metastoreCheck7873 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_resource_in_resourceList7931 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_resourceList7934 =  new BitSet(new long[]{0x0000008000000000L,0x0000000000000000L,0x0100000000010000L});
        FOLLOW_resource_in_resourceList7936 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_resourceType_in_resource7974 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_resource7978 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_JAR_in_resourceType8015 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FILE_in_resourceType8029 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ARCHIVE_in_resourceType8043 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createFunctionStatement8074 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
        FOLLOW_KW_TEMPORARY_in_createFunctionStatement8079 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
        FOLLOW_KW_FUNCTION_in_createFunctionStatement8083 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_functionIdentifier_in_createFunctionStatement8085 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_createFunctionStatement8087 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_createFunctionStatement8089 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_KW_USING_in_createFunctionStatement8098 =  new BitSet(new long[]{0x0000008000000000L,0x0000000000000000L,0x0100000000010000L});
        FOLLOW_resourceList_in_createFunctionStatement8102 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropFunctionStatement8188 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
        FOLLOW_KW_TEMPORARY_in_dropFunctionStatement8193 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
        FOLLOW_KW_FUNCTION_in_dropFunctionStatement8197 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifExists_in_dropFunctionStatement8199 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_functionIdentifier_in_dropFunctionStatement8202 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_RELOAD_in_reloadFunctionsStatement8280 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000060000000L});
        FOLLOW_KW_FUNCTIONS_in_reloadFunctionsStatement8283 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FUNCTION_in_reloadFunctionsStatement8285 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createMacroStatement8314 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
        FOLLOW_KW_TEMPORARY_in_createMacroStatement8316 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
        FOLLOW_KW_MACRO_in_createMacroStatement8318 =  new BitSet(new long[]{0x0000000001000000L});
        FOLLOW_Identifier_in_createMacroStatement8320 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_createMacroStatement8328 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000040001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameTypeList_in_createMacroStatement8330 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_createMacroStatement8333 =  new BitSet(new long[]{0xBF6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDCAECFA461FB3FCL,0xF3B6197EDAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x000000180B921F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_expression_in_createMacroStatement8335 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropMacroStatement8379 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
        FOLLOW_KW_TEMPORARY_in_dropMacroStatement8381 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000008000L});
        FOLLOW_KW_MACRO_in_dropMacroStatement8383 =  new BitSet(new long[]{0x0000000001000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_ifExists_in_dropMacroStatement8385 =  new BitSet(new long[]{0x0000000001000000L});
        FOLLOW_Identifier_in_dropMacroStatement8388 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createViewStatement8430 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000200000000000L,0x0000000000000000L,0x4000000000000000L});
        FOLLOW_orReplace_in_createViewStatement8433 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
        FOLLOW_KW_VIEW_in_createViewStatement8437 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifNotExists_in_createViewStatement8440 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_createViewStatement8446 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000040L,0x0000000000000000L,0x0080000000000000L,0x0000000000000000L,0x0000000000020000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_createViewStatement8457 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameCommentList_in_createViewStatement8459 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_createViewStatement8461 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000040L,0x0000000000000000L,0x0080000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tableComment_in_createViewStatement8465 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_viewPartition_in_createViewStatement8468 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tablePropertiesPrefixed_in_createViewStatement8479 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_createViewStatement8490 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020040L});
        FOLLOW_selectStatementWithCTE_in_createViewStatement8500 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_PARTITIONED_in_viewPartition8623 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_viewPartition8625 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_viewPartition8627 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_viewPartition8629 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_viewPartition8631 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_viewClusterSpec_in_viewOrganization8670 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_viewComplexSpec_in_viewOrganization8678 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CLUSTERED_in_viewClusterSpec8705 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_viewClusterSpec8707 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_viewClusterSpec8709 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_viewClusterSpec8711 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_viewClusterSpec8713 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_viewDistSpec_in_viewComplexSpec8752 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
        FOLLOW_viewSortSpec_in_viewComplexSpec8754 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DISTRIBUTED_in_viewDistSpec8781 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_viewDistSpec8783 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_viewDistSpec8785 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_viewDistSpec8789 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_viewDistSpec8791 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SORTED_in_viewSortSpec8831 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_viewSortSpec8833 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_viewSortSpec8835 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_viewSortSpec8839 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    }
    public static void initBitSet6() {
        FOLLOW_RPAREN_in_viewSortSpec8841 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropViewStatement8881 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
        FOLLOW_KW_VIEW_in_dropViewStatement8883 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifExists_in_dropViewStatement8885 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_viewName_in_dropViewStatement8888 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createMaterializedViewStatement8926 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_KW_MATERIALIZED_in_createMaterializedViewStatement8928 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
        FOLLOW_KW_VIEW_in_createMaterializedViewStatement8930 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifNotExists_in_createMaterializedViewStatement8933 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_createMaterializedViewStatement8939 =  new BitSet(new long[]{0x0000020000000000L,0x0009000000000042L,0x0000000000000000L,0x0080000000000400L,0x0000040000000000L,0x0000000000020040L});
        FOLLOW_rewriteDisabled_in_createMaterializedViewStatement8949 =  new BitSet(new long[]{0x0000020000000000L,0x0008000000000042L,0x0000000000000000L,0x0080000000000400L,0x0000040000000000L,0x0000000000020040L});
        FOLLOW_tableComment_in_createMaterializedViewStatement8952 =  new BitSet(new long[]{0x0000020000000000L,0x0008000000000002L,0x0000000000000000L,0x0080000000000400L,0x0000040000000000L,0x0000000000020040L});
        FOLLOW_viewPartition_in_createMaterializedViewStatement8955 =  new BitSet(new long[]{0x0000020000000000L,0x0008000000000002L,0x0000000000000000L,0x0000000000000400L,0x0000040000000000L,0x0000000000020040L});
        FOLLOW_viewOrganization_in_createMaterializedViewStatement8958 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L,0x0000040000000000L,0x0000000000020040L});
        FOLLOW_tableRowFormat_in_createMaterializedViewStatement8969 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L,0x0000000000000000L,0x0000000000020040L});
        FOLLOW_tableFileFormat_in_createMaterializedViewStatement8972 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tableLocation_in_createMaterializedViewStatement8975 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tablePropertiesPrefixed_in_createMaterializedViewStatement8986 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_createMaterializedViewStatement8989 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020040L});
        FOLLOW_selectStatementWithCTE_in_createMaterializedViewStatement8991 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropMaterializedViewStatement9159 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_KW_MATERIALIZED_in_dropMaterializedViewStatement9161 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
        FOLLOW_KW_VIEW_in_dropMaterializedViewStatement9163 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECF8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_ifExists_in_dropMaterializedViewStatement9165 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_viewName_in_dropMaterializedViewStatement9168 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CREATE_in_createScheduledQueryStatement9206 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_SCHEDULED_in_createScheduledQueryStatement9208 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_QUERY_in_createScheduledQueryStatement9210 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_createScheduledQueryStatement9214 =  new BitSet(new long[]{0x0000000000000000L,0x8000000000020000L});
        FOLLOW_scheduleSpec_in_createScheduledQueryStatement9224 =  new BitSet(new long[]{0x0000020000000000L,0x0801008000000000L,0x0000000000000010L});
        FOLLOW_executedAsSpec_in_createScheduledQueryStatement9234 =  new BitSet(new long[]{0x0000020000000000L,0x0801008000000000L});
        FOLLOW_enableSpecification_in_createScheduledQueryStatement9245 =  new BitSet(new long[]{0x0000020000000000L,0x0000008000000000L});
        FOLLOW_definedAsSpec_in_createScheduledQueryStatement9256 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DROP_in_dropScheduledQueryStatement9375 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_SCHEDULED_in_dropScheduledQueryStatement9377 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_QUERY_in_dropScheduledQueryStatement9379 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_dropScheduledQueryStatement9383 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ALTER_in_alterScheduledQueryStatement9445 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
        FOLLOW_KW_SCHEDULED_in_alterScheduledQueryStatement9447 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_QUERY_in_alterScheduledQueryStatement9449 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_alterScheduledQueryStatement9453 =  new BitSet(new long[]{0x0000020000000000L,0x8801008000020000L,0x0000000000000018L});
        FOLLOW_alterScheduledQueryChange_in_alterScheduledQueryStatement9469 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_scheduleSpec_in_alterScheduledQueryChange9545 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_executedAsSpec_in_alterScheduledQueryChange9553 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_enableSpecification_in_alterScheduledQueryChange9561 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_definedAsSpec_in_alterScheduledQueryChange9569 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXECUTE_in_alterScheduledQueryChange9577 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CRON_in_scheduleSpec9614 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_scheduleSpec9618 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EVERY_in_scheduleSpec9639 =  new BitSet(new long[]{0x0000000000000000L,0x0000000080000000L,0x0000000800000000L,0x0000000018000000L,0x0001000000000000L,0x0000000000000000L,0x0000000000800800L});
        FOLLOW_Number_in_scheduleSpec9643 =  new BitSet(new long[]{0x0000000000000000L,0x0000000080000000L,0x0000000800000000L,0x0000000018000000L,0x0001000000000000L,0x0000000000000000L,0x0000000000000800L});
        FOLLOW_intervalQualifiers_in_scheduleSpec9648 =  new BitSet(new long[]{0x0000100000000002L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
        FOLLOW_KW_AT_in_scheduleSpec9660 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_KW_OFFSET_in_scheduleSpec9662 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_scheduleSpec9664 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_scheduleSpec9669 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXECUTED_in_executedAsSpec9727 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_executedAsSpec9729 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_executedAsSpec9733 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DEFINED_in_definedAsSpec9777 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_definedAsSpec9780 =  new BitSet(new long[]{0x0000000C04000000L,0x0881190000010080L,0x4001010088000188L,0x0000000081080900L,0x0242010430480004L,0x0412200800000008L,0x0000000000020040L});
        FOLLOW_statement_in_definedAsSpec9782 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_functionIdentifier_in_showFunctionIdentifier9821 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_StringLiteral_in_showFunctionIdentifier9829 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_showStmtIdentifier9856 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_StringLiteral_in_showStmtIdentifier9864 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_COMMENT_in_tableComment9897 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableComment9901 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec9938 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_createTablePartitionSpec9940 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_createTablePartitionSpec9942 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_createTablePartitionColumnTypeSpec_in_createTablePartitionSpec9949 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_createTablePartitionColumnSpec_in_createTablePartitionSpec9957 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_createTablePartitionSpec9960 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_PARTITIONED_in_createTablePartitionSpec9988 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_createTablePartitionSpec9990 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
        FOLLOW_KW_SPEC_in_createTablePartitionSpec9992 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_createTablePartitionSpec9994 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2BA750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_partitionTransformSpec_in_createTablePartitionSpec10001 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_createTablePartitionSpec10004 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec10044 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_createTablePartitionColumnTypeSpec10047 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameTypeConstraint_in_createTablePartitionColumnTypeSpec10049 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_columnName_in_createTablePartitionColumnSpec10091 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_createTablePartitionColumnSpec10094 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_createTablePartitionColumnSpec10096 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_columnNameTransformConstraint_in_partitionTransformSpec10138 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_partitionTransformSpec10141 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2BA750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameTransformConstraint_in_partitionTransformSpec10143 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_partitionTransformType_in_columnNameTransformConstraint10181 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_columnName_in_partitionTransformType10220 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_YEAR_in_partitionTransformType10251 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_partitionTransformType10253 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_partitionTransformType10255 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_partitionTransformType10257 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MONTH_in_partitionTransformType10288 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_partitionTransformType10290 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_partitionTransformType10292 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_partitionTransformType10294 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DAY_in_partitionTransformType10325 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_partitionTransformType10327 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
    }
    public static void initBitSet7() {
        FOLLOW_columnName_in_partitionTransformType10329 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_partitionTransformType10331 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_HOUR_in_partitionTransformType10362 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_partitionTransformType10364 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_partitionTransformType10366 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_partitionTransformType10368 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TRUNCATE_in_partitionTransformType10399 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_partitionTransformType10401 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_partitionTransformType10407 =  new BitSet(new long[]{0x0000000000000200L});
        FOLLOW_COMMA_in_partitionTransformType10409 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_partitionTransformType10411 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_partitionTransformType10413 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_BUCKET_in_partitionTransformType10447 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_partitionTransformType10449 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_partitionTransformType10455 =  new BitSet(new long[]{0x0000000000000200L});
        FOLLOW_COMMA_in_partitionTransformType10457 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_partitionTransformType10459 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_partitionTransformType10461 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CLUSTERED_in_tableBuckets10520 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableBuckets10522 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_tableBuckets10524 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_tableBuckets10528 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_tableBuckets10530 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000001L});
        FOLLOW_KW_SORTED_in_tableBuckets10533 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableBuckets10535 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_tableBuckets10537 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameOrderList_in_tableBuckets10541 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_tableBuckets10543 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_INTO_in_tableBuckets10547 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_tableBuckets10551 =  new BitSet(new long[]{0x0040000000000000L});
        FOLLOW_KW_BUCKETS_in_tableBuckets10553 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SKEWED_in_tableSkewed10605 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableSkewed10607 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_tableSkewed10609 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_tableSkewed10613 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_tableSkewed10615 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_tableSkewed10617 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_tableSkewed10619 =  new BitSet(new long[]{0x0000000002001000L,0x0000000020600000L,0x0000000000002000L,0x0000002000000000L,0x0000000000000000L,0x0000000400C00000L,0x0000000809820000L});
        FOLLOW_skewedValueElement_in_tableSkewed10624 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_tableSkewed10627 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_storedAsDirs_in_tableSkewed10636 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_rowFormatSerde_in_rowFormat10684 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_rowFormatDelimited_in_rowFormat10700 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_RECORDREADER_in_recordReader10749 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_recordReader10751 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_RECORDWRITER_in_recordWriter10800 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_recordWriter10802 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ROW_in_rowFormatSerde10851 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_KW_FORMAT_in_rowFormatSerde10853 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0008000000000000L});
        FOLLOW_KW_SERDE_in_rowFormatSerde10855 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_rowFormatSerde10859 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_rowFormatSerde10862 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde10864 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tableProperties_in_rowFormatSerde10868 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ROW_in_rowFormatDelimited10920 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000002000000L});
        FOLLOW_KW_FORMAT_in_rowFormatDelimited10922 =  new BitSet(new long[]{0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_DELIMITED_in_rowFormatDelimited10924 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000008L,0x0000000000008000L,0x0000002000080080L});
        FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited10926 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000008L,0x0000000000000000L,0x0000002000080080L});
        FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited10929 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000002000080080L});
        FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited10932 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000002000000080L});
        FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited10935 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
        FOLLOW_tableRowNullFormat_in_rowFormatDelimited10938 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_rowFormatDelimited_in_tableRowFormat10997 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_rowFormatSerde_in_tableRowFormat11017 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed11064 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tableProperties_in_tablePropertiesPrefixed11067 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_LPAREN_in_tableProperties11100 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_tablePropertiesList_in_tableProperties11102 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_tableProperties11104 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_keyValueProperty_in_tablePropertiesList11145 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_tablePropertiesList11148 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_keyValueProperty_in_tablePropertiesList11150 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_keyProperty_in_tablePropertiesList11175 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_tablePropertiesList11178 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_keyProperty_in_tablePropertiesList11180 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_StringLiteral_in_keyValueProperty11226 =  new BitSet(new long[]{0x0000000000040000L});
        FOLLOW_EQUAL_in_keyValueProperty11228 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_keyValueProperty11232 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_StringLiteral_in_keyProperty11279 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier11323 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
        FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier11325 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11327 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11331 =  new BitSet(new long[]{0x0000000000000002L,0x4000000000000000L});
        FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier11334 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier11336 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier11340 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier11392 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
        FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier11394 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
        FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier11396 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier11398 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier11402 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier11448 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000000000000L});
        FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier11450 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
        FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier11452 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier11454 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier11458 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier11504 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
        FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier11506 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier11508 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier11512 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NULL_in_tableRowNullFormat11558 =  new BitSet(new long[]{0x0000000000000000L,0x0000008000000000L});
    }
    public static void initBitSet8() {
        FOLLOW_KW_DEFINED_in_tableRowNullFormat11560 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_tableRowNullFormat11562 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableRowNullFormat11566 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STORED_in_tableFileFormat11621 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_tableFileFormat11623 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
        FOLLOW_KW_INPUTFORMAT_in_tableFileFormat11625 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableFileFormat11629 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0004000000000000L});
        FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat11631 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableFileFormat11635 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
        FOLLOW_KW_INPUTDRIVER_in_tableFileFormat11638 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableFileFormat11642 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
        FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat11644 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableFileFormat11648 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STORED_in_tableFileFormat11686 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableFileFormat11688 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableFileFormat11692 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_tableFileFormat11704 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11706 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tableProperties_in_tableFileFormat11710 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_STORED_in_tableFileFormat11724 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_tableFileFormat11726 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_tableFileFormat11730 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STORED_in_tableFileFormat11769 =  new BitSet(new long[]{0x0080000000000000L});
        FOLLOW_KW_BY_in_tableFileFormat11771 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_tableFileFormat11775 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_tableFileFormat11787 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat11789 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_tableProperties_in_tableFileFormat11793 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_STORED_in_tableFileFormat11807 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_tableFileFormat11809 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_tableFileFormat11813 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STORED_in_tableFileFormat11852 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_tableFileFormat11854 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_tableFileFormat11858 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCATION_in_tableLocation11906 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_tableLocation11910 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_columnNameType_in_columnNameTypeList11946 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_columnNameTypeList11949 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameType_in_columnNameTypeList11951 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList11989 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_columnNameTypeOrConstraintList11992 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502EF6FL,0xFDC0ECB8470783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EB0L,0xEB9DF6B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameTypeOrConstraint_in_columnNameTypeOrConstraintList11994 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_columnNameColonType_in_columnNameColonTypeList12032 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_columnNameColonTypeList12035 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameColonType_in_columnNameColonTypeList12037 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_columnName_in_columnNameList12075 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_columnNameList12078 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_columnNameList12080 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_identifier_in_columnName12124 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_extColumnName12157 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_DOT_in_extColumnName12160 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_ELEM_TYPE_in_extColumnName12170 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_KW_KEY_TYPE_in_extColumnName12180 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_KW_VALUE_TYPE_in_extColumnName12190 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_identifier_in_extColumnName12194 =  new BitSet(new long[]{0x0000000000010002L});
        FOLLOW_columnNameOrder_in_columnNameOrderList12224 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_columnNameOrderList12227 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameOrder_in_columnNameOrderList12229 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_LPAREN_in_columnParenthesesList12267 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_columnParenthesesList12270 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_columnParenthesesList12272 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_enableSpecification_in_enableValidateSpecification12300 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L,0x0000000000000000L,0x0200000000000000L});
        FOLLOW_validateSpecification_in_enableValidateSpecification12302 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_enforcedSpecification_in_enableValidateSpecification12311 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ENABLE_in_enableSpecification12338 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DISABLE_in_enableSpecification12352 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_VALIDATE_in_validateSpecification12385 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NOVALIDATE_in_validateSpecification12399 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ENFORCED_in_enforcedSpecification12432 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NOT_in_enforcedSpecification12446 =  new BitSet(new long[]{0x0000000000000000L,0x2000000000000000L});
        FOLLOW_KW_ENFORCED_in_enforcedSpecification12448 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_RELY_in_relySpecification12482 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NORELY_in_relySpecification12497 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_createConstraint12531 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_createConstraint12535 =  new BitSet(new long[]{0x8000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L,0x0000040000000000L});
        FOLLOW_tableLevelConstraint_in_createConstraint12539 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsCreate_in_createConstraint12541 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_alterConstraintWithName12616 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_alterConstraintWithName12620 =  new BitSet(new long[]{0x8000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L,0x0000040000000000L});
        FOLLOW_tableLevelConstraint_in_alterConstraintWithName12622 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsAlter_in_alterConstraintWithName12624 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_pkUkConstraint_in_tableLevelConstraint12661 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_checkConstraint_in_tableLevelConstraint12669 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_tableConstraintType_in_pkUkConstraint12696 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_columnParenthesesList_in_pkUkConstraint12700 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CHECK_in_checkConstraint12740 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_checkConstraint12742 =  new BitSet(new long[]{0xBF6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDCAECFA461FB3FCL,0xF3B6197EDAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x000000180B921F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_expression_in_checkConstraint12744 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_checkConstraint12746 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_createForeignKey12786 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_createForeignKey12790 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
        FOLLOW_KW_FOREIGN_in_createForeignKey12794 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
        FOLLOW_KW_KEY_in_createForeignKey12796 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_columnParenthesesList_in_createForeignKey12800 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_REFERENCES_in_createForeignKey12803 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_createForeignKey12807 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_columnParenthesesList_in_createForeignKey12811 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsCreate_in_createForeignKey12813 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_alterForeignKeyWithName12906 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_alterForeignKeyWithName12910 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
        FOLLOW_KW_FOREIGN_in_alterForeignKeyWithName12912 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
    }
    public static void initBitSet9() {
        FOLLOW_KW_KEY_in_alterForeignKeyWithName12914 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_columnParenthesesList_in_alterForeignKeyWithName12918 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_REFERENCES_in_alterForeignKeyWithName12921 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_alterForeignKeyWithName12925 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_columnParenthesesList_in_alterForeignKeyWithName12929 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsAlter_in_alterForeignKeyWithName12931 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_skewedColumnValues_in_skewedValueElement12994 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_skewedColumnValuePairList_in_skewedValueElement13003 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13030 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_skewedColumnValuePairList13033 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList13035 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_LPAREN_in_skewedColumnValuePair13079 =  new BitSet(new long[]{0x0000000002001000L,0x0000000020600000L,0x0000000000002000L,0x0000002000000000L,0x0000000000000000L,0x0000000400C00000L,0x0000000809800000L});
        FOLLOW_skewedColumnValues_in_skewedColumnValuePair13083 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_skewedColumnValuePair13085 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_skewedColumnValue_in_skewedColumnValues13127 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_skewedColumnValues13130 =  new BitSet(new long[]{0x0000000002001000L,0x0000000020600000L,0x0000000000002000L,0x0000002000000000L,0x0000000000000000L,0x0000000400C00000L,0x0000000809800000L});
        FOLLOW_skewedColumnValue_in_skewedColumnValues13132 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_constant_in_skewedColumnValue13176 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_skewedColumnValue_in_skewedValueLocationElement13209 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement13218 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NULLS_in_nullOrdering13272 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
        FOLLOW_KW_FIRST_in_nullOrdering13274 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NULLS_in_nullOrdering13288 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x8000000000000000L});
        FOLLOW_KW_LAST_in_nullOrdering13290 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_columnNameOrder13323 =  new BitSet(new long[]{0x0000040000000002L,0x0000080000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_orderSpecification_in_columnNameOrder13327 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_nullOrdering_in_columnNameOrder13332 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_columnNameComment_in_columnNameCommentList13529 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_columnNameCommentList13532 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameComment_in_columnNameCommentList13534 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_identifier_in_columnNameComment13574 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000040L});
        FOLLOW_KW_COMMENT_in_columnNameComment13577 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_columnNameComment13581 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ASC_in_orderSpecificationRewrite13629 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DESC_in_orderSpecificationRewrite13643 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_expression_in_columnRefOrder13676 =  new BitSet(new long[]{0x0000040000000002L,0x0000080000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_orderSpecificationRewrite_in_columnRefOrder13680 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_nullOrdering_in_columnRefOrder13685 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_columnNameType13988 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_colType_in_columnNameType13990 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000040L});
        FOLLOW_KW_COMMENT_in_columnNameType13993 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_columnNameType13997 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_tableConstraint_in_columnNameTypeOrConstraint14093 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_columnNameTypeConstraint_in_columnNameTypeOrConstraint14105 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createForeignKey_in_tableConstraint14136 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_createConstraint_in_tableConstraint14148 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_columnNameTypeConstraint14179 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_colType_in_columnNameTypeConstraint14181 =  new BitSet(new long[]{0x8000000000000002L,0x0000002000002040L,0x0000000000000000L,0x0000000800000000L,0x0000000000100010L,0x0000040000000000L});
        FOLLOW_columnConstraint_in_columnNameTypeConstraint14183 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000040L});
        FOLLOW_KW_COMMENT_in_columnNameTypeConstraint14188 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_columnNameTypeConstraint14192 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_foreignKeyConstraint_in_columnConstraint14256 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_colConstraint_in_columnConstraint14269 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_foreignKeyConstraint14300 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_foreignKeyConstraint14304 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_REFERENCES_in_foreignKeyConstraint14308 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_foreignKeyConstraint14312 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_foreignKeyConstraint14314 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_foreignKeyConstraint14318 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_foreignKeyConstraint14320 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsCreate_in_foreignKeyConstraint14322 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_colConstraint14430 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_colConstraint14434 =  new BitSet(new long[]{0x8000000000000000L,0x0000002000000000L,0x0000000000000000L,0x0000000800000000L,0x0000000000000010L,0x0000040000000000L});
        FOLLOW_columnConstraintType_in_colConstraint14438 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsCreate_in_colConstraint14440 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_alterForeignKeyConstraint_in_alterColumnConstraint14518 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_alterColConstraint_in_alterColumnConstraint14531 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_alterForeignKeyConstraint14562 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_alterForeignKeyConstraint14566 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_REFERENCES_in_alterForeignKeyConstraint14570 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_alterForeignKeyConstraint14574 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_alterForeignKeyConstraint14576 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnName_in_alterForeignKeyConstraint14580 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_alterForeignKeyConstraint14582 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsAlter_in_alterForeignKeyConstraint14584 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CONSTRAINT_in_alterColConstraint14692 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_alterColConstraint14696 =  new BitSet(new long[]{0x8000000000000000L,0x0000002000000000L,0x0000000000000000L,0x0000000800000000L,0x0000000000000010L,0x0000040000000000L});
        FOLLOW_columnConstraintType_in_alterColConstraint14700 =  new BitSet(new long[]{0x0000000000000002L,0x2801000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_constraintOptsAlter_in_alterColConstraint14702 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NOT_in_columnConstraintType14767 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
        FOLLOW_KW_NULL_in_columnConstraintType14769 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DEFAULT_in_columnConstraintType14790 =  new BitSet(new long[]{0xBB6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDC2ECFA460FA3DCL,0xF3B61976DAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x0000000809801F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_defaultVal_in_columnConstraintType14792 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_checkConstraint_in_columnConstraintType14810 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_tableConstraintType_in_columnConstraintType14818 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_constant_in_defaultVal14835 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_function_in_defaultVal14843 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_castExpression_in_defaultVal14851 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_PRIMARY_in_tableConstraintType14868 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
        FOLLOW_KW_KEY_in_tableConstraintType14870 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UNIQUE_in_tableConstraintType14888 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_enableValidateSpecification_in_constraintOptsCreate14923 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L,0x0000000000800000L});
        FOLLOW_relySpecification_in_constraintOptsCreate14925 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_enableValidateSpecification_in_constraintOptsAlter14943 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000200000000L,0x0000000000800000L});
        FOLLOW_relySpecification_in_constraintOptsAlter14945 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_identifier_in_columnNameColonType14975 =  new BitSet(new long[]{0x0000000000000100L});
        FOLLOW_COLON_in_columnNameColonType14977 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_colType_in_columnNameColonType14979 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000040L});
        FOLLOW_KW_COMMENT_in_columnNameColonType14982 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_columnNameColonType14986 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_type_in_colType15070 =  new BitSet(new long[]{0x0000000000000002L});
    }
    public static void initBitSet10() {
        FOLLOW_colType_in_colTypeList15097 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_colTypeList15100 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_colType_in_colTypeList15102 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_primitiveType_in_type15130 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_listType_in_type15138 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_structType_in_type15146 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_mapType_in_type15154 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_unionType_in_type15162 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TINYINT_in_primitiveType15184 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SMALLINT_in_primitiveType15205 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INT_in_primitiveType15225 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_BIGINT_in_primitiveType15250 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_BOOLEAN_in_primitiveType15272 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FLOAT_in_primitiveType15293 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_REAL_in_primitiveType15316 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DOUBLE_in_primitiveType15340 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000002L});
        FOLLOW_KW_PRECISION_in_primitiveType15342 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATE_in_primitiveType15364 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATETIME_in_primitiveType15388 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TIMESTAMP_in_primitiveType15408 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TIMESTAMPLOCALTZ_in_primitiveType15427 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TIMESTAMP_in_primitiveType15449 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_KW_WITH_in_primitiveType15451 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000200L});
        FOLLOW_KW_LOCAL_in_primitiveType15453 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
        FOLLOW_KW_TIME_in_primitiveType15455 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
        FOLLOW_KW_ZONE_in_primitiveType15457 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STRING_in_primitiveType15489 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_BINARY_in_primitiveType15511 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DECIMAL_in_primitiveType15533 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_primitiveType15536 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_primitiveType15540 =  new BitSet(new long[]{0x0000000000000200L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_COMMA_in_primitiveType15543 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_primitiveType15547 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_primitiveType15551 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_VARCHAR_in_primitiveType15575 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_primitiveType15577 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_primitiveType15581 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_primitiveType15583 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CHAR_in_primitiveType15608 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_primitiveType15610 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_primitiveType15614 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_primitiveType15616 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ARRAY_in_listType15660 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_LESSTHAN_in_listType15662 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_type_in_listType15664 =  new BitSet(new long[]{0x0000000000200000L});
        FOLLOW_GREATERTHAN_in_listType15666 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STRUCT_in_structType15703 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_LESSTHAN_in_structType15705 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameColonTypeList_in_structType15707 =  new BitSet(new long[]{0x0000000000200000L});
        FOLLOW_GREATERTHAN_in_structType15709 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MAP_in_mapType15744 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_LESSTHAN_in_mapType15746 =  new BitSet(new long[]{0x400E000000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000000000L,0x1000000000008000L,0x1000000001C00100L});
        FOLLOW_primitiveType_in_mapType15750 =  new BitSet(new long[]{0x0000000000000200L});
        FOLLOW_COMMA_in_mapType15752 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_type_in_mapType15756 =  new BitSet(new long[]{0x0000000000200000L});
        FOLLOW_GREATERTHAN_in_mapType15758 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UNIONTYPE_in_unionType15801 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_LESSTHAN_in_unionType15803 =  new BitSet(new long[]{0x400E010000000000L,0x0020001060000000L,0x0002000000080000L,0x0000000000080000L,0x1000000000008000L,0x1000020001C00300L});
        FOLLOW_colTypeList_in_unionType15805 =  new BitSet(new long[]{0x0000000000200000L});
        FOLLOW_GREATERTHAN_in_unionType15807 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UNION_in_setOperator15842 =  new BitSet(new long[]{0x0000000100000000L});
        FOLLOW_KW_ALL_in_setOperator15844 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UNION_in_setOperator15858 =  new BitSet(new long[]{0x0000000000000002L,0x0002000000000000L});
        FOLLOW_KW_DISTINCT_in_setOperator15860 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INTERSECT_in_setOperator15875 =  new BitSet(new long[]{0x0000000100000000L});
        FOLLOW_KW_ALL_in_setOperator15877 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INTERSECT_in_setOperator15891 =  new BitSet(new long[]{0x0000000000000002L,0x0002000000000000L});
        FOLLOW_KW_DISTINCT_in_setOperator15893 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXCEPT_in_setOperator15908 =  new BitSet(new long[]{0x0000000100000000L});
        FOLLOW_KW_ALL_in_setOperator15910 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_EXCEPT_in_setOperator15924 =  new BitSet(new long[]{0x0000000000000002L,0x0002000000000000L});
        FOLLOW_KW_DISTINCT_in_setOperator15926 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MINUS_in_setOperator15941 =  new BitSet(new long[]{0x0000000100000000L});
        FOLLOW_KW_ALL_in_setOperator15943 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_MINUS_in_setOperator15957 =  new BitSet(new long[]{0x0000000000000002L,0x0002000000000000L});
        FOLLOW_KW_DISTINCT_in_setOperator15959 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_withClause_in_queryStatementExpression15996 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0001000008000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020000L});
        FOLLOW_queryStatementExpressionBody_in_queryStatementExpression16004 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_fromStatement_in_queryStatementExpressionBody16036 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_regularBody_in_queryStatementExpressionBody16044 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WITH_in_withClause16061 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_cteStatement_in_withClause16063 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_withClause16066 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_cteStatement_in_withClause16068 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_identifier_in_cteStatement16094 =  new BitSet(new long[]{0x0000020000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_cteStatement16097 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_cteStatement16101 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_cteStatement16103 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_cteStatement16107 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_cteStatement16109 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0001000008000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020040L});
        FOLLOW_queryStatementExpression_in_cteStatement16111 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_cteStatement16113 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_singleFromStatement_in_fromStatement16140 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0004000000000001L,0x0000000004000000L,0x0000000000000000L,0x0000010000000000L});
        FOLLOW_setOperator_in_fromStatement16152 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
        FOLLOW_singleFromStatement_in_fromStatement16156 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0004000000000001L,0x0000000004000000L,0x0000000000000000L,0x0000010000000000L});
        FOLLOW_fromClause_in_singleFromStatement16366 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0001000000000000L,0x0000000000080000L,0x0002000000080000L});
        FOLLOW_body_in_singleFromStatement16376 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0001000000000000L,0x0000000000080000L,0x0002000000080000L});
        FOLLOW_insertClause_in_regularBody16413 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020000L});
        FOLLOW_selectStatement_in_regularBody16425 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_selectStatement_in_regularBody16449 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_selectClause_in_atomSelectStatement16469 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000508000000L,0x0000000000000000L,0x0000000000000100L,0x0000000000000000L,0x0000000000000028L});
    }
    public static void initBitSet11() {
        FOLLOW_fromClause_in_atomSelectStatement16476 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000500000000L,0x0000000000000000L,0x0000000000000100L,0x0000000000000000L,0x0000000000000028L});
        FOLLOW_whereClause_in_atomSelectStatement16484 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000500000000L,0x0000000000000000L,0x0000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_groupByClause_in_atomSelectStatement16492 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000400000000L,0x0000000000000000L,0x0000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_havingClause_in_atomSelectStatement16500 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_window_clause_in_atomSelectStatement16508 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
        FOLLOW_qualifyClause_in_atomSelectStatement16516 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_LPAREN_in_atomSelectStatement16598 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020000L});
        FOLLOW_selectStatement_in_atomSelectStatement16601 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_atomSelectStatement16603 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_valuesSource_in_atomSelectStatement16614 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_atomSelectStatement_in_selectStatement16634 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0004000000000001L,0x0000400004000040L,0x8000000000000000L,0x0000010000000000L});
        FOLLOW_setOpSelectStatement_in_selectStatement16641 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000000L});
        FOLLOW_orderByClause_in_selectStatement16650 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_clusterByClause_in_selectStatement16658 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000000L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_distributeByClause_in_selectStatement16666 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_sortByClause_in_selectStatement16674 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_limitClause_in_selectStatement16682 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_setOperator_in_setOpSelectStatement16947 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020000L});
        FOLLOW_atomSelectStatement_in_setOpSelectStatement16951 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0004000000000001L,0x0000000004000000L,0x0000000000000000L,0x0000010000000000L});
        FOLLOW_withClause_in_selectStatementWithCTE17586 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L,0x0400000000000000L,0x0000000000020000L});
        FOLLOW_selectStatement_in_selectStatementWithCTE17594 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_insertClause_in_body17624 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L,0x0002000000080000L});
        FOLLOW_selectClause_in_body17629 =  new BitSet(new long[]{0x0000000000000202L,0x0004000000000001L,0x0000000500000000L,0x0000400000000041L,0x8000000000000100L,0x0000000000000000L,0x0000000000000028L});
        FOLLOW_lateralView_in_body17634 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000500000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000028L});
        FOLLOW_whereClause_in_body17640 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000500000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_groupByClause_in_body17646 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000400000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_havingClause_in_body17652 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_window_clause_in_body17658 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000100L});
        FOLLOW_qualifyClause_in_body17664 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000000L});
        FOLLOW_orderByClause_in_body17670 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_clusterByClause_in_body17676 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000000L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_distributeByClause_in_body17682 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_sortByClause_in_body17688 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_limitClause_in_body17694 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_selectClause_in_body17790 =  new BitSet(new long[]{0x0000000000000202L,0x0004000000000001L,0x0000000500000000L,0x0000400000000041L,0x8000000000000100L,0x0000000000000000L,0x0000000000000028L});
        FOLLOW_lateralView_in_body17795 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000500000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000028L});
        FOLLOW_whereClause_in_body17801 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000500000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_groupByClause_in_body17807 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000400000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_havingClause_in_body17813 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000100L,0x0000000000000000L,0x0000000000000020L});
        FOLLOW_window_clause_in_body17819 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000100L});
        FOLLOW_qualifyClause_in_body17825 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000400000000040L,0x8000000000000000L});
        FOLLOW_orderByClause_in_body17831 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000001L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_clusterByClause_in_body17837 =  new BitSet(new long[]{0x0000000000000002L,0x0004000000000000L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_distributeByClause_in_body17843 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L,0x8000000000000000L});
        FOLLOW_sortByClause_in_body17849 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_limitClause_in_body17855 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INSERT_in_insertClause17979 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_OVERWRITE_in_insertClause17981 =  new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L,0x0000000000000000L,0x0000000000000200L,0x0000000000000000L,0x0000000000004000L});
        FOLLOW_destination_in_insertClause17983 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000004000000000L});
        FOLLOW_ifNotExists_in_insertClause17985 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_INSERT_in_insertClause18004 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_INTO_in_insertClause18006 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EF7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_TABLE_in_insertClause18008 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableOrPartition_in_insertClause18011 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_LPAREN_in_insertClause18014 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnNameList_in_insertClause18018 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_RPAREN_in_insertClause18020 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LOCAL_in_destination18076 =  new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L});
        FOLLOW_KW_DIRECTORY_in_destination18080 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_destination18082 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L,0x0000000000000040L});
        FOLLOW_tableRowFormat_in_destination18084 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
        FOLLOW_tableFileFormat_in_destination18087 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TABLE_in_destination18120 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableOrPartition_in_destination18122 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LIMIT_in_limitClause18154 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_limitClause18160 =  new BitSet(new long[]{0x0000000000000200L});
        FOLLOW_COMMA_in_limitClause18162 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_limitClause18168 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_LIMIT_in_limitClause18191 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_limitClause18195 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
        FOLLOW_KW_OFFSET_in_limitClause18197 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_limitClause18201 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DELETE_in_deleteStatement18245 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000008000000L});
        FOLLOW_KW_FROM_in_deleteStatement18247 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_deleteStatement18249 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
        FOLLOW_whereClause_in_deleteStatement18252 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_tableOrColumn_in_columnAssignmentClause18287 =  new BitSet(new long[]{0x0000000000040000L});
        FOLLOW_EQUAL_in_columnAssignmentClause18289 =  new BitSet(new long[]{0xBF6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDCAECFA461FB3DCL,0xF3B61976DAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x000000180B921F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_precedencePlusExpressionOrDefault_in_columnAssignmentClause18292 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_defaultValue_in_precedencePlusExpressionOrDefault18325 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_precedencePlusExpression_in_precedencePlusExpressionOrDefault18333 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SET_in_setColumnsClause18355 =  new BitSet(new long[]{0xB360DC8AFD000200L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnAssignmentClause_in_setColumnsClause18357 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_setColumnsClause18360 =  new BitSet(new long[]{0xB360DC8AFD000200L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_columnAssignmentClause_in_setColumnsClause18362 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_KW_UPDATE_in_updateStatement18404 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_updateStatement18406 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_setColumnsClause_in_updateStatement18408 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
        FOLLOW_whereClause_in_updateStatement18410 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_startTransactionStatement_in_sqlTransactionStatement18452 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_commitStatement_in_sqlTransactionStatement18457 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_rollbackStatement_in_sqlTransactionStatement18462 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_setAutoCommitStatement_in_sqlTransactionStatement18467 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_START_in_startTransactionStatement18481 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000010000000L});
        FOLLOW_KW_TRANSACTION_in_startTransactionStatement18483 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0040000000000000L,0x0000000000000000L,0x0000000000002000L});
        FOLLOW_transactionMode_in_startTransactionStatement18487 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_COMMA_in_startTransactionStatement18492 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0040000000000000L,0x0000000000000000L,0x0000000000002000L});
        FOLLOW_transactionMode_in_startTransactionStatement18494 =  new BitSet(new long[]{0x0000000000000202L});
        FOLLOW_isolationLevel_in_transactionMode18525 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_transactionAccessMode_in_transactionMode18531 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_READ_in_transactionAccessMode18554 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
    }
    public static void initBitSet12() {
        FOLLOW_KW_ONLY_in_transactionAccessMode18556 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_READ_in_transactionAccessMode18566 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_WRITE_in_transactionAccessMode18568 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ISOLATION_in_isolationLevel18587 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
        FOLLOW_KW_LEVEL_in_isolationLevel18589 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x2000000000000000L});
        FOLLOW_levelOfIsolation_in_isolationLevel18591 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SNAPSHOT_in_levelOfIsolation18616 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_COMMIT_in_commitStatement18635 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
        FOLLOW_KW_WORK_in_commitStatement18639 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ROLLBACK_in_rollbackStatement18661 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000100L});
        FOLLOW_KW_WORK_in_rollbackStatement18665 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_SET_in_setAutoCommitStatement18686 =  new BitSet(new long[]{0x0000400000000000L});
        FOLLOW_KW_AUTOCOMMIT_in_setAutoCommitStatement18688 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000002000L,0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
        FOLLOW_booleanValueTok_in_setAutoCommitStatement18690 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ABORT_in_abortTransactionStatement18725 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
        FOLLOW_KW_TRANSACTIONS_in_abortTransactionStatement18727 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_abortTransactionStatement18731 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_KW_MERGE_in_mergeStatement18777 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
        FOLLOW_QUERY_HINT_in_mergeStatement18779 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
        FOLLOW_KW_INTO_in_mergeStatement18782 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_tableName_in_mergeStatement18784 =  new BitSet(new long[]{0xB360DE8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEBDDF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_KW_AS_in_mergeStatement18787 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EB7F7L,0x0000000000001F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_identifier_in_mergeStatement18790 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_KW_USING_in_mergeStatement18794 =  new BitSet(new long[]{0xB360DC8AFD000000L,0xEB5DEEEBC502CF6FL,0xFDC0ECB8460783DCL,0xF3B61956DAF77DD0L,0xAFBDF0CBFFC72EA0L,0xEB9DF2B2750EF7F7L,0x0000000000021F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_joinSourcePart_in_mergeStatement18796 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
        FOLLOW_KW_ON_in_mergeStatement18798 =  new BitSet(new long[]{0xBF6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDCAECFA461FB3FCL,0xF3B6197EDAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x000000180B921F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_expression_in_mergeStatement18800 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
        FOLLOW_whenClauses_in_mergeStatement18802 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_whenMatchedAndClause_in_whenClauses18851 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
        FOLLOW_whenMatchedThenClause_in_whenClauses18853 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
        FOLLOW_whenNotMatchedClause_in_whenClauses18857 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WHEN_in_whenNotMatchedClause18884 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_KW_NOT_in_whenNotMatchedClause18886 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_KW_MATCHED_in_whenNotMatchedClause18888 =  new BitSet(new long[]{0x0000001000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_AND_in_whenNotMatchedClause18891 =  new BitSet(new long[]{0xBF6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDCAECFA461FB3FCL,0xF3B6197EDAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x000000180B921F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_expression_in_whenNotMatchedClause18893 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_THEN_in_whenNotMatchedClause18897 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
        FOLLOW_KW_INSERT_in_whenNotMatchedClause18899 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L,0x0000000000020000L});
        FOLLOW_columnParenthesesList_in_whenNotMatchedClause18904 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
        FOLLOW_KW_VALUES_in_whenNotMatchedClause18908 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000020000L});
        FOLLOW_valueRowConstructor_in_whenNotMatchedClause18910 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WHEN_in_whenMatchedAndClause18957 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_KW_MATCHED_in_whenMatchedAndClause18959 =  new BitSet(new long[]{0x0000001000000000L});
        FOLLOW_KW_AND_in_whenMatchedAndClause18961 =  new BitSet(new long[]{0xBF6EDD8AFF001000L,0xEB7DEEEBE562CF6FL,0xFDCAECFA461FB3FCL,0xF3B6197EDAFF7DD0L,0xBFBDF0CBFFC7AEA0L,0xEB9DF2B675CEB7F7L,0x000000180B921F93L,0x0400000000002000L,0x0008000000000000L,0x0001100000000000L,0x0000000000080800L,0x0000000001000000L});
        FOLLOW_expression_in_whenMatchedAndClause18963 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_THEN_in_whenMatchedAndClause18965 =  new BitSet(new long[]{0x0000000000000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
        FOLLOW_updateOrDelete_in_whenMatchedAndClause18967 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_WHEN_in_whenMatchedThenClause19005 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000400000L});
        FOLLOW_KW_MATCHED_in_whenMatchedThenClause19007 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
        FOLLOW_KW_THEN_in_whenMatchedThenClause19009 =  new BitSet(new long[]{0x0000000000000000L,0x0000010000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0002000000000000L});
        FOLLOW_updateOrDelete_in_whenMatchedThenClause19011 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_UPDATE_in_updateOrDelete19040 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0040000000000000L});
        FOLLOW_setColumnsClause_in_updateOrDelete19042 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DELETE_in_updateOrDelete19060 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_KILL_in_killQueryStatement19092 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
        FOLLOW_KW_QUERY_in_killQueryStatement19094 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_killQueryStatement19098 =  new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_KW_ID_in_compactionId19129 =  new BitSet(new long[]{0x0000000000040000L});
        FOLLOW_EQUAL_in_compactionId19131 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000800000L});
        FOLLOW_Number_in_compactionId19135 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_POOL_in_compactionPool19156 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_compactionPool19160 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_TYPE_in_compactionType19181 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_compactionType19185 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STATUS_in_compactionStatus19206 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
        FOLLOW_StringLiteral_in_compactionStatus19210 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_grantPrivileges_in_synpred1_HiveParser3126 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_revokePrivileges_in_synpred2_HiveParser3140 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ELEM_TYPE_in_synpred3_HiveParser4427 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_KEY_TYPE_in_synpred4_HiveParser4443 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_VALUE_TYPE_in_synpred5_HiveParser4459 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DATACONNECTOR_in_synpred7_HiveParser4666 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_FUNCTION_in_synpred8_HiveParser4707 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_COMPUTE_in_synpred10_HiveParser4860 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_CACHE_in_synpred11_HiveParser4988 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ID_in_synpred14_HiveParser5687 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ALL_in_synpred16_HiveParser6787 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_NONE_in_synpred17_HiveParser6818 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ALL_in_synpred18_HiveParser6992 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_storedAsDirs_in_synpred19_HiveParser10631 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_STORED_in_synpred20_HiveParser11612 =  new BitSet(new long[]{0x0000020000000000L});
        FOLLOW_KW_AS_in_synpred20_HiveParser11614 =  new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
        FOLLOW_KW_INPUTFORMAT_in_synpred20_HiveParser11616 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_ELEM_TYPE_in_synpred21_HiveParser12165 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_KEY_TYPE_in_synpred22_HiveParser12175 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_VALUE_TYPE_in_synpred23_HiveParser12185 =  new BitSet(new long[]{0x0000000000000002L});
        FOLLOW_KW_DEFAULT_in_synpred24_HiveParser18313 =  new BitSet(new long[]{0xFFFFFFFFFFFEFFF0L,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0xFFFFFFFFFFFFFFFFL,0x01FFFFFFFFFFFFFFL});
        FOLLOW_set_in_synpred24_HiveParser18315 =  new BitSet(new long[]{0x0000000000000002L});
    }

    static {
        initBitSet0();
        initBitSet1();
        initBitSet2();
        initBitSet3();
        initBitSet4();
        initBitSet5();
        initBitSet6();
        initBitSet7();
        initBitSet8();
        initBitSet9();
        initBitSet10();
        initBitSet11();
        initBitSet12();
    }

}
